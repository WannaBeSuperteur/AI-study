
## 목차

* [1. Thinkless 개요 및 등장 배경](#1-thinkless-개요-및-등장-배경)
* [2. Thinkless의 핵심 아이디어](#2-thinkless의-핵심-아이디어)
  * [2-1. Distillation for Warm-up](#2-1-distillation-for-warm-up)
  * [2-2. Reinforcement Learning with DeGRPO](#2-2-reinforcement-learning-with-degrpo)
* [3. 실험 및 그 결과](#3-실험-및-그-결과)
  * [3-1. 실험 설정](#3-1-실험-설정)
  * [3-2. Hybrid Reasoning 결과](#3-2-hybrid-reasoning-결과)
  * [3-3. Reinforcement Learning 결과](#3-3-reinforcement-learning-결과)
  * [3-4. Warm-up Distillation 상세](#3-4-warm-up-distillation-상세)
* [4. 논의 사항](#4-논의-사항)

## 논문 소개

* Gongfan Fang and Xinyin Ma et al., "Thinkless: LLM Learns When to Think", 2025
* [arXiv Link](https://arxiv.org/pdf/2505.13379)

## 1. Thinkless 개요 및 등장 배경

**Thinkless** 는 **[추론 기능을 포함한](../../AI%20Basics/LLM%20Basics/LLM_기초_추론형_모델.md) LLM이 주어진 프롬프트에 대해 '추론'을 해야 할지 말아야 할지 결정하는 '판단력'을 부여하는 컨셉** 의 방법론이다.

* Thinkless 의 등장 배경
  * 최근 등장하고 있는 추론형 모델의 성공 요인은 [Chain of Thought (COT)](../../AI%20Basics/LLM%20Basics/LLM_기초_Chain_of_Thought.md) 방법론임
  * 그러나, **CoT 방법을 모든 사용자 프롬프트에 똑같이 적용하면 자원 낭비가 발생** 할 수 있음
  * 이를 위해 다음과 같은 방법들이 등장했으나, **모델이 추론을 실시할지 말지를 결정하는 부분** 은 여전히 해결되지 않은 과제임
    * 추론형 모델의 inference 효율성 향상
    * **hybrid reasoning** 등 방법 존재

## 2. Thinkless의 핵심 아이디어

### 2-1. Distillation for Warm-up

### 2-2. Reinforcement Learning with DeGRPO

## 3. 실험 및 그 결과

### 3-1. 실험 설정

### 3-2. Hybrid Reasoning 결과

### 3-3. Reinforcement Learning 결과

### 3-4. Warm-up Distillation 상세

## 4. 논의 사항
