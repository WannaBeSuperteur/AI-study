## 목차

* [1. LLM 의 Hallucination (환각 현상) 요약](#1-llm-의-hallucination-환각-현상-요약)
  * [1-1. Hallucination 의 분류](#1-1-hallucination-의-분류)
  * [1-2. Hallucination 의 탐지](#1-2-hallucination-의-탐지)
  * [1-3. Hallucination 의 제거](#1-3-hallucination-의-제거)
* [2. Hallucination 이 LLM 의 창의성을 나타내는 이유](#2-hallucination-이-llm-의-창의성을-나타내는-이유)
  * [2-1. LLM 의 창의성의 정의](#2-1-llm-의-창의성의-정의)
  * [2-2. LLM 의 창의성의 평가 방법](#2-2-llm-의-창의성의-평가-방법)
  * [2-3. LLM 의 창의성 평가 관련 최근 연구](#2-3-llm-의-창의성-평가-관련-최근-연구)
* [3. LLM 의 Hallucination 을 창의적 도구로 이용하는 방법](#3-llm-의-hallucination-을-창의적-도구로-이용하는-방법)
  * [3-1. Divergent Phase](#3-1-divergent-phase)
  * [3-2. Convergent Phase](#3-2-convergent-phase)

## 논문 소개

* Jun Zhang, Jue Wang et al., "A Survey on Large Language Model Hallucination via a Creativity Perspective", 2024
* [arXiv Link](https://arxiv.org/pdf/2402.06647)

## 1. LLM 의 Hallucination (환각 현상) 요약

이 논문에서는 환각 현상을 **LLM 이 잘못되거나 관련 없는 정보를 생성하는 현상** 으로 정의한다.

* 환각 현상의 원인
  * 잘못된 정보
  * Alignment process ([Fine Tuning](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning.md) 등) 의 오류
* 환각 현상의 심각성
  * LLM 이 대중화됨에 따라 환각 현상은 **반드시 해결해야 하는 문제 중 하나** 로 떠오르고 있다. 

| 구분        | 설명                                                                                                                                                                                                                                                                                                         |
|-----------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 환각 현상의 분류 | - **factuality** hallucination 과 **faithfulness** hallucination 으로 구분<br>- **factuality** hallucination 은 factual **inconsistency** 와 factual **fabrication** 의 형태로 구분<br>- **faithfulness** hallucination 은 LLM 이 **사용자의 지시 또는 문맥에 맞지 않는** 내용을 생성하는 것                                                     |
| 환각 현상의 탐지 | - **factuality** hallucination 은 **외부 정보/지식** 을 활용하는 전략 사용<br>- **faithfulness** hallucination 은 **Classifier-based, QA-based, prompting-based metric** 을 이용하여 탐지                                                                                                                                          |
| 환각 현상의 제거 | - [RLHF (Reinforcement Learning from Human Feedback)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_DPO_ORPO.md#1-1-rlhf-reinforcement-learning-from-human-feedback) 의 학습 단계에서는, Hallucination 제거를 위한 reward score 를 사용<br>- inference 단계에서는, **외부 정보/지식을 추출하여 decoding (문장 생성) 에 적용** 하는 방법이 사용될 수 있음 |

### 1-1. Hallucination 의 분류

환각 현상은 다음과 같이 분류할 수 있다.

* 기본적인 분류

| 분류                             | 설명                                    |
|--------------------------------|---------------------------------------|
| **factuality** hallucination   | LLM 이 생성한 내용이 **실제 현실의 사실과 다름**       |
| **faithfulness** hallucination | LLM 이 **사용자의 지시 또는 문맥에 맞지 않는** 내용을 생성 |

* Factuality Hallucination 의 형태 분류

| Factuality Hallucination 의 형태 | 설명                                                                           |
|-------------------------------|------------------------------------------------------------------------------|
| factual **inconsistency**     | LLM 이 생성한 내용이 **실제 현실의 사실과 직접적으로 모순** 됨                                      |
| factual **fabrication**       | LLM 이 해당 내용에 대한 지식을 갖고 있지 않아서, 현실의 지식을 기반으로 생성할 수 없기에 **아무렇게나 정보를 생성** 하는 현상 |

* Faithfulness Hallucination 의 형태 분류

| Faithfulness Hallucination 의 형태 | 설명                                                                                   |
|---------------------------------|--------------------------------------------------------------------------------------|
| **instruction** inconsistency   | LLM 이 생성한 내용이 사용자의 특정한 지시와 맞지 않음                                                     |
| **context** inconsistency       | LLM 이 생성한 내용이 **주어진 상황** 을 고려할 때 **무관하거나 부적절** 함                                     |
| **logical** inconsistency       | LLM 이 추론 과정에 대한 내용을 생성할 때, 그 **추론 과정에 오류** 가 있거나, 또는 **추론 과정과 최종 출력에 mismatch 가 있음** |

### 1-2. Hallucination 의 탐지

### 1-3. Hallucination 의 제거

## 2. Hallucination 이 LLM 의 창의성을 나타내는 이유

### 2-1. LLM 의 창의성의 정의

### 2-2. LLM 의 창의성의 평가 방법

### 2-3. LLM 의 창의성 평가 관련 최근 연구

## 3. LLM 의 Hallucination 을 창의적 도구로 이용하는 방법

### 3-1. Divergent Phase

### 3-2. Convergent Phase