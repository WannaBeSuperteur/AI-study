## 목차

* [1. 기존 Autoregressive LLM 의 도전 과제](#1-기존-autoregressive-llm-의-도전-과제)
  * [1-1. Next token prediction 에 의한 LLM 지능의 upper bound](#1-1-next-token-prediction-에-의한-llm-지능의-upper-bound) 
  * [1-2. LLM 의 O(n^2) 의 너무 큰 시간 복잡도](#1-2-llm-의-on2-의-너무-큰-시간-복잡도)
* [2. Markov Model 을 이용한 LLM 추론](#2-markov-model-을-이용한-llm-추론)
  * [2-1. LLM 추론 과정 상세](#2-1-llm-추론-과정-상세)
  * [2-2. Text Generation 과 추론의 관계](#2-2-text-generation-과-추론의-관계)
* [3. 실제 구현 방식](#3-실제-구현-방식)
  * [3-1. Reasoning step 의 자동 생성](#3-1-reasoning-step-의-자동-생성)
  * [3-2. Self-reinforced Training](#3-2-self-reinforced-training)
  * [3-3. Inference 시점에서의 연산](#3-3-inference-시점에서의-연산)
* [4. 실제 연구 사례](#4-실제-연구-사례)

## 논문 소개

* Jun Wang, "A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1", 2025
* [arXiv Link](https://arxiv.org/pdf/2502.10867)

## 1. 기존 Autoregressive LLM 의 도전 과제

### 1-1. Next token prediction 에 의한 LLM 지능의 upper bound

### 1-2. LLM 의 O(n^2) 의 너무 큰 시간 복잡도

## 2. Markov Model 을 이용한 LLM 추론

### 2-1. LLM 추론 과정 상세

### 2-2. Text Generation 과 추론의 관계

## 3. 실제 구현 방식

### 3-1. Reasoning step 의 자동 생성

### 3-2. Self-reinforced Training

### 3-3. Inference 시점에서의 연산

## 4. 실제 연구 사례