## 목차

* [1. (Part IV) LLM 은 어떻게 쓰이고 Augment 되는가?](#1-part-iv-llm-은-어떻게-쓰이고-augment-되는가)
  * [1-1. LLM 의 한계](#1-1-llm-의-한계)
  * [1-2. LLM 의 프롬프트 설계 및 엔지니어링](#1-2-llm-의-프롬프트-설계-및-엔지니어링)
  * [1-3. LLM 의 Augmentation : RAG](#1-3-llm-의-augmentation--rag)
  * [1-4. 추가적인 도구 사용](#1-4-추가적인-도구-사용)
  * [1-5. LLM 에이전트](#1-5-llm-에이전트)
* [2. (Part VII) LLM 의 도전 과제 및 미래](#2-part-vii-llm-의-도전-과제-및-미래)
  * [2-1. 더 작고 효율적인 LLM](#2-1-더-작고-효율적인-llm)
  * [2-2. Attention 이후의, LLM의 새로운 구조](#2-2-attention-이후의-llm의-새로운-구조)
  * [2-3. 멀티모달 모델](#2-3-멀티모달-모델)
  * [2-4. LLM 의 사용 및 Augementation 기술의 발전](#2-4-llm-의-사용-및-augementation-기술의-발전)
  * [2-5. LLM 의 보안 및 윤리](#2-5-llm-의-보안-및-윤리)

## 논문 소개

* Shervin Minaee, Tomas Mikolov et al., "Large Language Models: A Survey", 2024
* [arXiv Link](https://arxiv.org/pdf/2402.06196)
* 이 문서에서 다룰 파트
  * Part IV. LLM 은 어떻게 쓰이고 Augment 되는가?
  * Part VII. LLM 의 도전 과제 및 미래

## 1. (Part IV) LLM 은 어떻게 쓰이고 Augment 되는가?

이 부분은 다음과 같은 내용으로 구성된다.

* LLM 의 한계
* LLM 의 [프롬프트 설계 및 엔지니어링](../../AI%20Basics/LLM%20Basics/LLM_기초_Prompt_Engineering.md)
* LLM 의 Augmentation : [RAG (Retrieval-Augmented Generation, 검색 증강 생성)](../../AI%20Basics/LLM%20Basics/LLM_기초_RAG.md)
* 추가적인 도구 사용
* LLM 에이전트

### 1-1. LLM 의 한계

LLM 은 근본적으로 **다음에 나타날 token을 예측하도록 설계** 되었기 때문에, [Fine-tuning](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning.md) 과 같은 기술의 발달에도 불구하고 다음과 같은 한계점이 존재한다.

* 이전 프롬프트의 내용을 기억하지 못한다.
* 확률적으로 next token 을 생성한다는 점이 문제가 될 수 있다.
* 외부 데이터 접근 불가
* 매우 큰 크기로 인해 많은 GPU 자원 필요
* 환각 현상

**1. [환각 현상](../../AI%20Basics/LLM%20Basics/LLM_기초_환각_현상.md) (Hallucination)**

* 위 문서에서도 설명되어 있지만, 환각 현상은 **내재적 환각** 과 **외재적 환각** 으로 구분된다.
* 아래 표에서 **원본 데이터** 는 GPT-4 등 일반적으로 널리 알려진 LLM에서는 **LLM이 학습한 세계에 대한 다양한 지식** 을 의미한다.

| 구분                                   | 설명                                              |
|--------------------------------------|-------------------------------------------------|
| 내재적 환각<br>(Intrinsic Hallucinations) | 원본 데이터와의 논리적 모순 또는 부정확한 정보 생성                   |
| 외재적 환각<br>(Extrinsic Hallucinations) | 원본 데이터에 없는 내용을 질문할 때, 그 데이터를 통해 검증할 수 없는 정보를 생성 |

* 환각 현상의 극복을 위한 시도
  * [RLHF (Reinforcement Learning from Human Feedback, 인간 피드백을 통한 강화학습)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_DPO_ORPO.md#1-1-rlhf-reinforcement-learning-from-human-feedback) 와 같은 방법이 시도되었다.
  * 그러나, **확률적으로 next token 을 생성한다는 본질적인 특징에 의한 한계점** 은 여전히 존재한다.
  * 환각 현상 극복은 프롬프트 엔지니어링, 모델 선택 등 **여러 분야에 걸쳐 있는** 문제이다.

**2. 환각 현상을 측정할 수 있는 [LLM 평가 Metric](../../AI%20Basics/LLM%20Basics/LLM_기초_LLM의_성능_평가.md)**

* 환각 현상 측정에 사용되는 Metric 은 다음과 같다.

| 구분          | 설명                                                                                                       |
|-------------|----------------------------------------------------------------------------------------------------------|
| 통계적 방법      | ROUGE, BLEU 등<br>- 내재적 환각 현상 측정 가능<br>PARENT, PARENT-T, Knowledge-F1 등<br>- 구조적인 지식 데이터가 있을 때 사용 가능      |
| 언어 모델 기반 방법 | - IE-Based Metrics<br>- QA-Based Metrics<br>- NLI-Based Metrics<br>- Faithfulness Classification Metrics |
| 기타          | - 사람이 직접 평가                                                                                              |

이 중에서 **언어 모델 기반 방법** 에 대한 상세 설명은 다음과 같다.

| 구분                                  | 설명                                                                                 |
|-------------------------------------|------------------------------------------------------------------------------------|
| IE-Based Metrics                    | - Information Extraction Model (정보 추출 모델) 을 이용하여 **지식을 간소화**<br>- 이 지식을 원본 데이터와 비교 |
| QA-Based Metrics                    | - 생성된 콘텐츠와, **질문-답변 프레임워크를 통해 추출** 한 원본 데이터를 비교                                    |
| NLI-Based Metrics                   | - **자연 언어 추론 데이터셋** 을 이용한 평가                                                       |
| Faithfulness Classification Metrics | - **task에 특화된 데이터셋** 을 이용한 평가                                                      |

### 1-2. LLM 의 프롬프트 설계 및 엔지니어링

LLM 이 원하는 답변을 생성하게 하기 위해서는 프롬프트에 질문이나 지시 등이 필요한데, 그 질문이나 지시를 작성하는 전략을 [프롬프트 엔지니어링 (Prompt Engineering)](../../AI%20Basics/LLM%20Basics/LLM_기초_Prompt_Engineering.md) 이라고 한다.

* Prompt Engineering 은 **LLM을 목적에 맞게 정교하게 사용** 하기 위한 기술인 셈이다.

프롬프트 엔지니어링의 전략은 다음과 같다.

| 구분                                                                                  | 설명                                                                                                                                                                                                                                                         |
|-------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Chain-of-Thought (CoT)](../../AI%20Basics/LLM%20Basics/LLM_기초_Chain_of_Thought.md) | - 일반적인 LLM이 추론에 특화되어 있지 않다는 문제점을 해결<br>- **추론 절차를 LLM에게 제공** 하여 이 문제를 해결<br>- **Zero-shot CoT** : LLM에게 단순히 단계적으로 생각하라고 함<br> - **Manual CoT** : 단계적 사고의 예시를 제공, Zero-shot 보다 효과적임                                                                         |
| Tree-of-Thought (ToT)                                                               | - 각 가지가 서로 다른 사고 과정을 나타내는 **'생각의 나무'** 아이디어<br>- 복잡한 사고를 요하는 경우에 적합                                                                                                                                                                                        |
| Self-Consistency                                                                    | - 동일한 프롬프트에 대해 LLM이 여러 개의 응답을 생성하면, 그 응답 각각에 대해 **일관성을 분석**<br>- Ensemble 기반 아이디어, "여러 개의 응답을 생성하면 그것들 중 정확한 것이 있을 것이다"<br>- 답변의 진실성이 중요한 경우에 적합                                                                                                           |
| Reflection                                                                          | - 추론에 기반하여, **LLM이 자신이 생성한 답변을 평가** 하도록 함<br>- 이것은 LLM의 'self-editing' 능력에 기반함                                                                                                                                                                             |
| Expert Prompting                                                                    | - LLM에게 **전문가로서의 역할을 지정** 한 후, 고품질의 답변을 하도록 함                                                                                                                                                                                                              |
| Chains                                                                              | - LLM 이 생성한 답변 내에서 **여러 개의 component 를 연결** 하는 아이디어<br>- 최종 답변에 기여하는 **서로 연결된 여러 step을 생성** 하는 방법                                                                                                                                                          |
| Rails                                                                               | - LLM 이 **사용자가 지정한 템플릿** 에 따라 응답을 생성하게 하는 기술<br>- LLM 응답의 정확도 및 보안성 향상 가능<br> - **Topical Rails** : LLM이 특정 domain 에 대한 응답을 하게 함<br>- **Fact-checking Rails** : 잘못된 응답 생성 최소화 (환각 현상 방지)<br>**- Jailbreaking Rails** : LLM이 자체적 제한 사항을 위반하는 응답을 생성하는 것을 방지 |
| Automatic Prompt Engineering (APE)                                                  | 프롬프트 생성 자동화. 그 과정은 다음과 같다.<br>- **Prompt Generation** : LLM이 주어진 task에 대한 가능한 prompt 를 생성<br>**Prompt Scoring** : 각 prompt 를 그 효율성 등에 따라 점수화<br>**Refinement and Iteration** : 이 점수 평가를 통해 prompt를 다듬음                                                     |

### 1-3. LLM 의 Augmentation : RAG

* LLM 은 **자체적으로 최신 정보에 대한 지식을 가지고 있지 않다** 는 한계점이 있는데, 이를 극복하기 위해서 LLM 을 Augmentation 하는 방법이 사용된다.
* 그 대표적인 방법으로 [RAG (Retrieval-Augmented Generation, 검색 증강 생성)](../../AI%20Basics/LLM%20Basics/LLM_기초_RAG.md) 이 있다.

![image](../images/LLM_Survey_250322_1.PNG)

[(출처)](https://arxiv.org/pdf/2402.06196) : Shervin Minaee, Tomas Mikolov et al., "Large Language Models: A Survey", 2024

**FLARE (Forward-looking Active Retrieval Augmented Generation)**

* 목표
  * RAG 와 결합하여 사용되는 LLM 의 능력을 향상시킨다.
* 핵심 아이디어
  * LLM 의 **다음 내용에 대한 예측 (Prediction) + 정보 검색 (Information Retrieval)** 의 결합
* 상세
  * LLM 은 다음에 올 내용을 예측한다.
  * 이 예측을 RAG 에 입력되는 query 로 하여, 정보 검색 (Information Retrieval) 을 실시한다.
  * 정보 검색을 일회성으로 실시하는 전통적인 RAG 과는 다른 방법론이다.
* 특징
  * LLM 에 의해 생성된 각 segment 들에 대해 **confidence 평가** 가 이루어진다. 
  * 이 confidence 평가 점수가 정해진 기준보다 낮으면 **해당 내용을 쿼리로 하여 RAG 을 통해 정보를 검색** 한다.
  * RAG 을 통해 추출된 정보는 **LLM 이 문장을 다시 생성하거나 다듬는 데** 사용된다.

![image](../images/LLM_Survey_250322_2.PNG)

### 1-4. 추가적인 도구 사용

* LLM 은 RAG 이외에도 여러 가지 추가적인 도구 (API call 등) 와 결합할 수 있다.
* 이 도구들을 통해 LLM 의 능력 범위를 확장시킬 수 있다.

**관련 논문**

| 논문                                                                                                                       | 설명                                                                                          |
|--------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|
| [Toolformer: Language Models Can Teach Themselves to Use Tools (2023.02)](https://arxiv.org/pdf/2302.04761)              | - LLM에게 **어떤 도구 (검색 엔진, 계산기, API 파라미터 등) 를 이용해야 할지** 를 학습시킴                                 |
| [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/pdf/2305.15334)                            | - **API 활용** 능력이 GPT-4보다 우수                                                                 |
| [ART: Automatic multi-step reasoning and tool-use for large language models (2023.03)](https://arxiv.org/pdf/2303.09014) | - 외부 도구를 이용한 **자동화된 CoT 프롬프트 엔지니어링**<br>- 여러 가지 프롬프트 엔지니어링 전략으로 LLM의 복잡한 과제 (추론 등) 해결 능력 향상 |

### 1-5. LLM 에이전트

**LLM 에이전트 (LLM Agents)** 는 **LLM과 다른 도구들의 결합을 통해 특정 분야의 작업을 자동으로 수행할 수 있는 시스템** 을 말한다.

* 사용자 및 환경과 상호작용하며, 어떤 도구를 사용할지 등 결정을 내릴 수 있다.
* LLM 에이전트의 핵심 기능은 다음과 같다.

| 구분    | 설명                               |
|-------|----------------------------------|
| 도구 사용 | 외부 도구 (API 등) 및 서비스에 대한 접근 및 사용  |
| 의사 결정 | 입력, 맥락, 사용 가능한 도구 등 정보에 의한 의사 결정 |

![image](../images/LLM_Survey_250322_3.PNG)

[(출처)](https://arxiv.org/pdf/2402.06196) : Shervin Minaee, Tomas Mikolov et al., "Large Language Models: A Survey", 2024

**LLM 에이전트를 위한 Prompt Engineering 기술**

| 기술 (논문)                                                                                                                             | 설명                                                                                                                                                                                                                                                                                                                                                                                                                  |
|-------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models (2023.05)](https://arxiv.org/pdf/2305.18323) | 외부 정보 및 도구에 의존하지 않고도 **추론 계획을 LLM 스스로 수립** 할 수 있도록 함 (논문에서는 이를 직접 관찰하는 것과 추론하는 것을 서로 분리, 즉 reasoning 을 direct observation 으로부터 decoupling 했다고 표현)<br>- 필요한 정보가 주어질 때마다, 추론을 위한 구조화된 framework 을 자체 생성<br>- 토큰 효율성 및 도구 사용 실패 (tool failure) 에 대한 robustness 측면에서 우수<br><br>세부 동작 방식<br>- **Meta-planning** : 처음에는 주어진 문제를 해결하기 위한 Outline 계획 수립<br>- **Execution** : Meta-planning 에서 수립한 계획을 주어진 정보를 이용 (결합) 하여 실행 |
| [ReAct: Synergzing Reasoning and Acting in Language Models (2022.10)](https://arxiv.org/pdf/2210.03629)                             | LLM 이 말로서 생성되는 추론뿐만 아니라 **실제 실행 가능한 step을 생성** 하게 한다.<br>- 이를 통해 모델의 문제 해결 능력 향상<br>- 추론 과정 생성과 행동 사이를 모델이 오갈 수 있음                                                                                                                                                                                                                                                                                                  |
| [DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents (2023.03)](https://arxiv.org/pdf/2303.17071) | **특정 맥락에서 여러 Agent를 사용** 할 수 있게 한다.<br>- Researcher : 정보를 가져오고 분석하는 Agent<br>- Decider : 제공된 정보를 이용하여 최종 결정을 내리는 Agent<br><br>이러한 **역할 분담** 을 통해 **문제 해결 및 의사 결정 능력을 향상** 시킨다.<br>- 따라서 **복잡한 문제 해결/의사 결정 과제** 에서 좋은 성능을 발휘할 수 있다.                                                                                                                                                                                  |

## 2. (Part VII) LLM 의 도전 과제 및 미래

이 부분은 다음과 같은 내용으로 구성된다.

* 더 작고 효율적인 LLM
* [Attention](../../Natural%20Language%20Processing/Basics_어텐션%20(Attention).md) 메커니즘 이후의, LLM 의 새로운 구조
* 멀티모달 모델
* LLM 의 사용 및 Augementation 기술의 발전
* LLM 의 보안 및 윤리 ([환각 현상](../../AI%20Basics/LLM%20Basics/LLM_기초_환각_현상.md) 등)

### 2-1. 더 작고 효율적인 LLM

### 2-2. Attention 이후의, LLM의 새로운 구조

### 2-3. 멀티모달 모델

### 2-4. LLM 의 사용 및 Augementation 기술의 발전

### 2-5. LLM 의 보안 및 윤리