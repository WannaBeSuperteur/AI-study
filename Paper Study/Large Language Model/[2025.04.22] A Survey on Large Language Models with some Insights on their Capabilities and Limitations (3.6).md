## 목차

* [1. Parameter-efficient Model Adaption](#1-parameter-efficient-model-adaption)
  * [1-1. Adapter Tuning](#1-1-adapter-tuning)
  * [1-2. Prefix Tuning](#1-2-prefix-tuning)
  * [1-3. Prompt Tuning](#1-3-prompt-tuning)
  * [1-4. LoRA (Low-Rank Adaption)](#1-4-lora-low-rank-adaption)
* [2. Memory-efficient Model Adaption](#2-memory-efficient-model-adaption)
  * [2-1. Quantization](#2-1-quantization)

## 논문 소개

* Andrea Matarazzo and Riccardo Torlone, "A Survey on Large Language Models with some Insights on their Capabilities and Limitations", 2025
* [arXiv Link](https://arxiv.org/pdf/2501.04040)
* 이 문서에서 다룰 파트
  * "3. Foundations of Large Language Models" 중 **3-6. Tuning and Optimization**
* 참고하면 좋은 문서
  * [LLM Fine-Tuning 방법 설명](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning.md)
  * [LLM Quantization 방법 설명](../../AI%20Basics/LLM%20Basics/LLM_기초_Quantization.md)

## 1. Parameter-efficient Model Adaption

Parameter-efficient Model Adaption 은 **LLM 을 Fine-Tuning 할 때, 그 성능 향상도는 최대한 유지하면서 학습하는 파라미터의 개수를 줄이는** 것이다.

* 이러한 Fine-Tuning 을 [PEFT (Parameter-Efficient Fine-Tuning)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_PEFT.md) 라고 한다.

그 방법으로는 대표적으로 **Adapter Tuning, Prefix Tuning, Prompt Tuning, LoRA (Low-Rank Adaption)** 의 4가지가 있다.

| 방법                       | 설명                                                                                                                              |
|--------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| Adapter Tuning           | 'Adapter'라고 하는, 학습 가능한 작은 모듈을 layer 사이에 추가<br>- Fine-Tuning 대상인 새로운 task 가 **전체 모델을 재 학습 시켜야 하는 수준** 일 때의 Fine-Tuning 의 비효율성 해결 |
| Prefix Tuning            | 'prefix'라고 하는, task-specific vector 를 LLM 입력에 추가                                                                                |
| Prompt Tuning            | 'prompt token'이라는, 학습 가능한 vector 를 LLM 에 포함                                                                                     |
| LoRA (Low-Rank Adaption) | 원래 가중치 행렬 $W$ 를 **2개의 작은 행렬 $A$, $B$ 로 분해** 하여, **메모리 사용량 및 연산량을 드라마틱하게 감소**                                                    |

![image](../images/LLM_Survey_250422_1.PNG)

[(출처)](https://arxiv.org/pdf/2501.04040) : Andrea Matarazzo and Riccardo Torlone, "A Survey on Large Language Models with some Insights on their Capabilities and Limitations"

### 1-1. Adapter Tuning

**Adapter Tuning** 은 'Adapter'라고 하는, 학습 가능한 작은 모듈을 layer 사이에 추가하여 **해당 모듈을 추가 학습** 시키는 것이다.

* 기본 학습 방법
  * 학습 가능한 Adapter Layer 를 기존 Feed-Forward Layer 와 [Layer Normalization](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Regularization.md#4-2-layer-normalization) 사이에 추가한다.
  * 원래 모델에 있던 나머지 파라미터들은 모두 **Frozen 상태로 둔다.**
* 특히 유용한 경우
  * Fine-Tuning 대상인 새로운 task 를 학습하려면 **전체 모델을 재 학습 시켜야 하는 수준** 일 때, 이러한 비효율성을 해결하기 위한 것이다.
  * 즉, **기존 Pre-train 된 task와 다른 새로운 task 를 여러 개 학습** 할 때 유용한 방법이라고 할 수 있다.
* [참고 문서 (Adapter Layer 추가)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_PEFT.md#2-5-adapter-layer-추가)

**1. Adapter Tuning 의 레이어 구조**

![image](../images/LLM_Survey_250422_2.PNG)

[(출처)](https://arxiv.org/pdf/2501.04040) : Andrea Matarazzo and Riccardo Torlone, "A Survey on Large Language Models with some Insights on their Capabilities and Limitations"

**2. Feed-forward Down-project & Feed-forward Up-project 레이어**

Adapter Layer 는 다음과 같이 **Feed-forward Down-project** 와 **Feed-forward Up-project** 레이어로 구성된다.

| 레이어                       | 설명                                                                             | 수식                         |
|---------------------------|--------------------------------------------------------------------------------|----------------------------|
| Feed-forward Down-project | 입력 차원 $d$ 을 더 작은 중간 차원 $m$ 으로 mapping<br>- ($x (dim: d)$ → $y (dim: m)$ )      | $y = \sigma (W_d x + b_d)$ |
| Feed-forward Up-project   | 중간 차원 $m$ 을 입력 차원과 동일한 출력 차원 $d$ 로 mapping<br>- ($y (dim: m)$ → $z (dim: d)$ ) | $z = \sigma (W_u y + b_u)$ |

* 이때 출력 벡터 $z$ 는 **입력 벡터 $x$ 에 대한 reconstruction** 에 해당한다.

**3. Parallel Adapter**

Transformer 에서는 **Parallel Adapter** 라는 기법을 사용하는데, 그 컨셉은 다음과 같다.

* Adapter 가 Attention Layer 와 Feed-Forward Layer 각각에 대해 **병렬적으로 추가됨**
* LLM Fine-Tuning 에서의 학습 가능한 파라미터 개수를 효과적으로 줄일 수 있음

### 1-2. Prefix Tuning

Prefix Tuning은 다음과 같이 **'prefix'라고 하는, task-specific vector 를 LLM 입력에 추가** 하는 방법을 말한다.

* 전통적인 Fine-Tuning 은 각 task에 대해 **개별적으로 모델을 저장** 해야 하는 문제점이 있다.
* Prefix Tuning은 'prefix'라고 하는 일종의 파라미터 집합을 이용하여 이를 해결한다.
  * 이를 통해 **저장 공간 및 연산량을 크게 감소시킬** 수 있다. 

![image](../images/LLM_Survey_250422_3.PNG)

[(출처)](https://arxiv.org/pdf/2501.04040) : Andrea Matarazzo and Riccardo Torlone, "A Survey on Large Language Models with some Insights on their Capabilities and Limitations"

**Prefix vector 최적화 방법**

Prefix vector 를 이용하여 LLM을 Fine-Tuning 시키는 방법으로는 **Re-parameterization** 을 이용하는 것이 있다.

* Multi-Layer Perceptron (MLP) 을 이용하여, **Prefix 를 직접 최적화하는 대신 작은 크기의 행렬을 Prefix 의 Parameter 행렬로 mapping** 시키는 방법이다.
  * 이 방법은 학습을 안정화시키는 것으로 증명된 바 있다. 
* 이 방법은 [이 논문](https://arxiv.org/pdf/2101.00190) 에서 제안되었다.

### 1-3. Prompt Tuning

Prompt Tuning은 **'prompt token'이라는, 학습 가능한 vector 를 LLM 에 포함하여 Fine-Tuning** 하는 방법이다.

* Prompt Token 은 **task-specific embedding** 으로, LLM 의 입력 레이어에 포함된다.
* 입력 레이어에서는 **이 Prompt Token 이 원래 텍스트의 임베딩과 concatenate 되는 형태** 로 입력이 주어지고, LLM 이 그 입력을 처리한다.
* P-tuning 이라는 방법이 있는데, 이 방법은 **context, prompt, target 을 나타내는 token** 이 각각 있고, 이를 유연하게 합치는 형태의 방법론이다.

![image](../images/LLM_Survey_250422_4.PNG)

[(출처)](https://arxiv.org/pdf/2501.04040) : Andrea Matarazzo and Riccardo Torlone, "A Survey on Large Language Models with some Insights on their Capabilities and Limitations"

**P-tuning v2**

P-tuning v2 는 [해당 논문](https://arxiv.org/pdf/2110.07602) 에서 제안된 방법으로, **모든 레이어에 continuous prompt 를 적용** 하는 방식으로 Prompt Tuning 을 확장한다.

* 이는 input layer 에만 Prompt 가 추가되는 방법에서 발전시켜서, 기존 Prompt Tuning 의 단점을 해결한 것이다.
* P-Tuning v2 의 핵심 아이디어는 다음과 같다.
  * 모든 레이어에 'continuous prompt'를 적용하여 **전체 파라미터 개수를 크게 늘리지 않고도 학습 가능한 파라미터 개수 향상** 
  * **Prompt Token (vector) 와 LLM 간의 상호작용 메커니즘을 변경** 하여, 간단하고 복잡한 여러 가지 task 들에 대한 적용 가능성을 높임

### 1-4. LoRA (Low-Rank Adaption)



## 2. Memory-efficient Model Adaption

### 2-1. Quantization