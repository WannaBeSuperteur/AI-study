
## 목차

* [1. 환각 현상에 대한 몇 가지 사항](#1-환각-현상에-대한-몇-가지-사항)
  * [1-1. Pre-training 에 의한 오류](#1-1-pre-training-에-의한-오류)
  * [1-2. 환각 현상은 왜 Post-training 이후에도 있는가?](#1-2-환각-현상은-왜-post-training-이후에도-있는가)
* [2. Pre-training Error](#2-pre-training-error)
  * [2-1. Prompt 없는 Reduction](#2-1-prompt-없는-reduction)
  * [2-2. Prompt 있는 Reduction](#2-2-prompt-있는-reduction)
  * [2-3. base model 의 Error Factor](#2-3-base-model-의-error-factor)
  * [2-4. 추가적인 Factor](#2-4-추가적인-factor)
* [3. Post-training 에서의 환각 현상](#3-post-training-에서의-환각-현상)
  * [3-1. 모델 평가가 환각 현상을 강화시킴](#3-1-모델-평가가-환각-현상을-강화시킴)
  * [3-2. 명백한 Confidence Target](#3-2-명백한-confidence-target)
* [4. 논의 사항](#4-논의-사항)
* [5. 본 연구의 한계점](#5-본-연구의-한계점)

## 논문 소개

* Adam Tauman Kalai and Ofir Nachum et al., "Why Language Models Hallucinate", 2025
* [OpenAI Paper Link](https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf)

## 1. 환각 현상에 대한 몇 가지 사항

* LLM의 환각 현상에 대해 다음과 같이 알아 두어야 할 사항들이 몇 가지 있다.

| 알아 두어야 할 사항                       | 설명                                                                                                                                                                                                                             |
|-----------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Pre-training 에 의한 오류              | 오류가 없는 데이터셋으로 학습하더라도, **Pre-training 을 통해 [Objective function](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Loss_function.md#1-1-loss-function-과-cost-function-objective-function) 이 최소화** 되면서 **오류를 생성하는 LLM** 이 될 수 있다. |
| Post-training 이후에도 환각 현상이 존재하는 이유 | - 많은 언어 모델은 **시험 형태의 벤치마크 데이터셋에 최적화** 되어 있다.<br>- 따라서, **```I don't know``` 와 같은 응답은 0점** 이기 때문에 **어떻게든 답을 생성하려고** 하기 때문이다.                                                                                                    |

### 1-1. Pre-training 에 의한 오류

**1. 핵심 요약**

> - 오류가 없는 데이터셋으로 Pre-training 하더라도, Pre-training 과정에서 **Objective Function 의 값이 최소화** 된다.
> - 이 과정에서 **오류를 생성하는 LLM** 으로 학습될 수 있다.
> - 그 원인은 **binary classification** 의 관점에서 생각해 볼 수 있다.

**2. IIV (Is-It-Valid) Binary Classification**

* 이 문제를 다음과 같은 **IIV (Is-It-Valid) Binary Classification** 컨셉에서 생각하면 다음과 같다.
  * 많은 양의 response 가 있는 학습 데이터셋에서, 각 데이터의 label은 **valid (+)** 또는 **invalid (-)** 이다. 
  * 이 경우, **어떤 언어 모델** 이든 이 문제를 해결하는 **IIV Classifier** 가 될 수 있다.
  * 이를 통해 **환각 현상과 IIV misclassification의 관계** 를 설명할 수 있다.

![image](../images/LLM_Hallucination_OpenAI_1.PNG)

[(출처)](https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf) : Adam Tauman Kalai and Ofir Nachum et al., "Why Language Models Hallucinate"

* 이때, 환각 현상 비율 (generative errors) 과 IIV 오분류 비율에는 다음과 같은 관계가 있다.
  * **(generative error rate) ≥ 2 · (IIV mis-classification rate)**
* 참고로, **LLM의 모든 오류가 환각 현상인 것은 아니다.**

### 1-2. 환각 현상은 왜 Post-training 이후에도 있는가?

**1. 핵심 요약**

> - 많은 언어 모델은 그 평가지표인 **시험 형태의 벤치마크 데이터셋에 최적화** 되어 있다. (무응답은 0점으로 처리되는)
> - 따라서, **```I don't know``` 와 같은 응답은 0점** 이기 때문에, 많은 LLM은 **어떻게든 답을 생성하려고** 하는 방향으로 학습되기 때문이다.

**2. 상세 설명**

* 학생이 객관식 시험에서 답을 모를 때 '찍는' 것처럼, LLM 역시 **guessing (추측)** 을 한다.
  * 그 결과, 그 추측이 잘못되었을 때 발생하는 것이 바로 **LLM의 환각 현상** 이다.
  * 이때 **해당 추측에 대한 confidence는 전반적으로 낮다.**
* LLM에서는 이 원리가 다음과 같이 작동한다.
  * 위와 같은 형태의 시험에서, LLM 역시 **아무 답변도 하지 않는 것보다 추측이라도 해서 답하는 것이 더 높은 'reward'를 받는다.**
  * 따라서, LLM 역시 **더 높은 reward** 를 받기 위해 '추측'을 하고, 이것이 **환각 현상** 으로 이어진다.

## 2. Pre-training Error

### 2-1. Prompt 없는 Reduction

### 2-2. Prompt 있는 Reduction

### 2-3. base model 의 Error Factor

### 2-4. 추가적인 Factor

## 3. Post-training 에서의 환각 현상

### 3-1. 모델 평가가 환각 현상을 강화시킴

### 3-2. 명백한 Confidence Target

## 4. 논의 사항

## 5. 본 연구의 한계점

