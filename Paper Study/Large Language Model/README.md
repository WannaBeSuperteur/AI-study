## Large Language Model

* **Total 17 Papers | 19 Documents** (2025.07.11)
  * Including 17 Generative AI Papers
  * üíª (Single LLM Product / Model), ü§ñ (LLM Agent), üß™ (LLM Methodology), ‚öñ (LLM Ethics), üß† [(LLM Reasoning)](../../AI%20Basics/LLM%20Basics/LLM_Í∏∞Ï¥à_Ï∂îÎ°†Ìòï_Î™®Îç∏.md), üí¨ (others)

| Study Date<br>(Study Doc. Link)                                                                                                                                                      | Paper                                                                                                                                             | Published | ÎπÑÍ≥†                                                                                                                                      |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------|
| 2025.03.12 - 03.13 [(Study Doc)](%5B2025.03.12%5D%20LLaMA%20-%20Open%20and%20Efficient%20Foundation%20Language%20Models.md)                                                          | üíª [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)                                                       | 2023.02   | [DeepSeek ÌôúÏö© ÌîÑÎ°úÏ†ùÌä∏ (2025.03.12 - 03.27)](https://github.com/WannaBeSuperteur/AI_Projects/tree/main/2025_03_12_DeepSeek_LLM) Í¥ÄÎ†® ÎÖºÎ¨∏Ïùò Ï∞∏Í≥† ÎÖºÎ¨∏ |
| 2025.03.13 [(Study Doc)](%5B2025.03.13%5D%20DeepSeek%20LLM%20Scaling%20Open-Source%20Language%20Models%20with%20Longtermism.md)                                                      | üíª [DeepSeek LLM Scaling Open-Source Language Models with Longtermism](https://arxiv.org/pdf/2401.02954)                                          | 2024.01   | DeepSeek ÌôúÏö© ÌîÑÎ°úÏ†ùÌä∏ (2025.03.12 - 03.27) Í¥ÄÎ†®                                                                                                |
| 2025.03.13 [(Study Doc)](%5B2025.03.13%5D%20DeepSeek-R1%20-%20Incentivizing%20Reasoning%20Capability%20in%20LLM%20via%20Reinforcement%20Learning.md)                                 | üíª [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)                         | 2025.01   | DeepSeek ÌôúÏö© ÌîÑÎ°úÏ†ùÌä∏ (2025.03.12 - 03.27) Í¥ÄÎ†®                                                                                                |
| 2025.03.22 + 2025.03.27 [(Study Doc)](%5B2025.03.22%5D%20Large%20Language%20Models%20A%20Survey%20(IV,%20VII).md)                                                                    | üí¨ [Large Language Models: A Survey](https://arxiv.org/pdf/2402.06196) - Part III (G,H,I), IV, VII                                                | 2024.02   |                                                                                                                                         |
| 2025.04.04 [(Study Doc)](%5B2025.04.04%5D%20A%20Survey%20on%20Large%20Language%20Models%20with%20some%20Insights%20on%20their%20Capabilities%20and%20Limitations%20(3.1,%203.3).md)  | üí¨ [A Survey on Large Language Models with some Insights on their Capabilities and Limitations](https://arxiv.org/pdf/2501.04040) - Part 3.1, 3.3 | 2025.01   |                                                                                                                                         |
| 2025.04.09 [(Study Doc)](%5B2025.04.09%5D%20KTO%20-%20Model%20Alignment%20as%20Prospect%20Theoretic%20Optimization.md)                                                               | üß™ [KTO: Model Alignment as Prospect Theoretic Optimization](https://arxiv.org/pdf/2402.01306)                                                    | 2024.02   | [Í∞ÄÏÉÅ Ïù∏Í∞Ñ ÏÉùÏÑ± ÌîÑÎ°úÏ†ùÌä∏ (Oh-LoRA v1) (2025.04.08 - 04.25)](https://github.com/WannaBeSuperteur/AI_Projects/tree/main/2025_04_08_OhLoRA) Í¥ÄÎ†® ÎÖºÎ¨∏    |
| 2025.04.16 - 04.19 [(Study Doc)](%5B2025.04.16%5D%20A%20Survey%20on%20Large%20Language%20Models%20with%20some%20Insights%20on%20their%20Capabilities%20and%20Limitations%20(3.5).md) | üí¨ [A Survey on Large Language Models with some Insights on their Capabilities and Limitations](https://arxiv.org/pdf/2501.04040) - Part 3.5      | 2025.01   |                                                                                                                                         |
| 2025.04.22 - 04.26 [(Study Doc)](%5B2025.04.22%5D%20A%20Survey%20on%20Large%20Language%20Models%20with%20some%20Insights%20on%20their%20Capabilities%20and%20Limitations%20(3.6).md) | üí¨ [A Survey on Large Language Models with some Insights on their Capabilities and Limitations](https://arxiv.org/pdf/2501.04040) - Part 3.6      | 2025.01   |                                                                                                                                         |
| 2025.04.27 + 2025.05.02 [(Study Doc)](%5B2025.04.27%5D%20Train%20Small,%20Infer%20Large%20-%20Memory-Efficient%20LoRA%20Training%20for%20Large%20Language%20Models.md)               | üß™ [Train Small, Infer Large - Memory-Efficient LoRA Training for Large Language Models](https://arxiv.org/pdf/2502.13533)                        | 2025.02   |                                                                                                                                         |
| 2025.05.05 - 05.08 [(Study Doc)](%5B2025.05.05%5D%20A%20Survey%20on%20Large%20Language%20Model%20Hallucination%20via%20a%20Creativity%20Perspective.md)                              | üí¨ [A Survey on Large Language Model Hallucination via a Creativity Perspective](https://arxiv.org/pdf/2402.06647)                                | 2024.02   |                                                                                                                                         |
| 2025.05.14 - 05.16 [(Study Doc)](%5B2025.05.14%5D%20A%20Tutorial%20on%20LLM%20Reasoning%20-%20Relevant%20Methods%20behind%20ChatGPT%20o1.md)                                         | üß† [A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1](https://arxiv.org/pdf/2502.10867)                                            | 2025.02   |                                                                                                                                         |
| 2025.05.18 - 05.22 [(Study Doc)](%5B2025.05.18%5D%20Can%201B%20LLM%20Surpass%20405B%20LLM%20-%20Rethinking%20Compute-Optimal%20Test-Time%20Scaling.md)                               | üß† [Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling](https://arxiv.org/pdf/2502.06703)                                  | 2025.02   |                                                                                                                                         |
| 2025.05.26 + 05.29 [(Study Doc)](%5B2025.05.26%5D%20CodeCoR%20-%20An%20LLM-Based%20Self-Reflective%20Multi-Agent%20Framework%20for%20Code%20Generation.md)                           | ü§ñ [CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation](https://arxiv.org/pdf/2501.07811)                            | 2025.01   |                                                                                                                                         |
| 2025.06.07 [(Study Doc)](%5B2025.06.07%5D%20Can%20LLM%20feedback%20enhance%20review%20quality%20-%20A%20randomized%20study%20of%2020K%20reviews%20at%20ICLR%202025.md)               | ü§ñ [Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025](https://arxiv.org/pdf/2504.09737)                    | 2025.04   |                                                                                                                                         |
| 2025.06.09 - 06.10 [(Study Doc)](%5B2025.06.09%5D%20LLM%20Agents%20for%20Education%20-%20Advances%20and%20Applications.md)                                                           | ü§ñ [LLM Agents for Education: Advances and Applications](https://arxiv.org/pdf/2503.11733)                                                        | 2025.03   |                                                                                                                                         |
| 2025.06.19 - 06.20 [(Study Doc)](%5B2025.06.19%5D%20A%20Survey%20on%20Trustworthy%20LLM%20Agents%20-%20Threats%20and%20Countermeasures.md)                                           | ‚öñ [A Survey on Trustworthy LLM Agents: Threats and Countermeasures](https://arxiv.org/pdf/2503.09648)                                             | 2025.03   | [Oh-LoRA v4 (2025.06.24 - 06.30)](https://github.com/WannaBeSuperteur/AI_Projects/tree/main/2025_06_24_OhLoRA_v4) Í∞úÎ∞ú Ïãú Ï∞∏Í≥† ÎÖºÎ¨∏            |
| 2025.06.23 [(Study Doc)](%5B2025.06.23%5D%20LLM%20Agents%20Making%20Agent%20Tools.md)                                                                                                | ü§ñ [LLM Agents Making Agent Tools](https://arxiv.org/pdf/2502.11705?)                                                                             | 2025.02   |                                                                                                                                         |
| 2025.07.01 - 07.02 [(Study Doc)](%5B2025.07.01%5D%20Large%20Language%20Diffusion%20Models.md)                                                                                        | üß™ [Large Language Diffusion Models](https://arxiv.org/pdf/2502.09992)                                                                            | 2025.02   |                                                                                                                                         |
| 2025.07.11 [(Study Doc)](%5B2025.07.11%5D%20LLM-Based%20Multi-Agent%20Systems%20for%20Software%20Engineering%20-%20Literature%20Review,%20Vision%20and%20the%20Road%20Ahead.md)      | ü§ñ [LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead](https://arxiv.org/pdf/2404.04834)       | 2024.04   |                                                                                                                                         |

