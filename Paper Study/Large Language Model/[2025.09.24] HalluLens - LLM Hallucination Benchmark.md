
## 목차

* [1. LLM 환각 현상 개요](#1-llm-환각-현상-개요)
  * [1-1. LLM 환각 현상과 Factuality (사실) 의 구분](#1-1-llm-환각-현상과-factuality-사실-의-구분) 
  * [1-2. 환각 현상의 종류](#1-2-환각-현상의-종류)
  * [1-3. 환각 현상의 가능한 원인](#1-3-환각-현상의-가능한-원인)
* [2. 환각 현상 평가 Benchmark 의 선택 기준](#2-환각-현상-평가-benchmark-의-선택-기준)
* [3. HalluLens 개요](#3-hallulens-개요)
* [4. HalluLens 를 이용한 Extrinsic Hallucination 평가](#4-hallulens-를-이용한-extrinsic-hallucination-평가)
  * [4-1. PreciseWikiQA](#4-1-precisewikiqa)
  * [4-2. LongWiki](#4-2-longwiki)
  * [4-3. NonExistentRefusal](#4-3-nonexistentrefusal)
* [5. HalluLens 를 이용한 Intrinsic Hallucination 평가](#5-hallulens-를-이용한-intrinsic-hallucination-평가)
  * [5-1. HHEM leaderboard](#5-1-hhem-leaderboard)
  * [5-2. ANAH 2.0 (with reference)](#5-2-anah-20-with-reference)
  * [5-3. FaithEval](#5-3-faitheval)
* [6. 기존 평가 벤치마크와의 비교](#6-기존-평가-벤치마크와의-비교)

## 논문 소개

* Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark", 2025
* [arXiv Link](https://arxiv.org/pdf/2504.17550)

## 참고

* [LLM의 환각 현상 (Hallucination)](../../AI%20Basics/LLM%20Basics/LLM_기초_환각_현상.md)
* [OpenAI가 말하는 환각 현상의 원인 (2025.09. 논문)](%5B2025.09.09%5D%20Why%20Language%20Models%20Hallucinate.md)

## 1. LLM 환각 현상 개요

LLM의 **환각 현상 (Hallucination)** 은 LLM이 다음에 해당하는 답변을 생성하는 것을 의미한다.

* 사용자 입력 또는 LLM의 이전 답변과 논리적 모순 발생
* 현실의 실제 지식과 불일치

환각 현상은 다음과 같은 문제점의 원인이다.

* LLM의 성능 및 신뢰성 감소
* 경우에 따라 **LLM을 윤리적으로 신뢰하기 어렵게 할 수 있음**

### 1-1. LLM 환각 현상과 Factuality (사실) 의 구분

![image](../images/HalluLens_2.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

LLM이 생성하는 **사실적 정보 (Factuality)** 와 **환각 현상** 은 생성된 콘텐츠의 신뢰성과 관련된 내용이지만, 다음과 같은 점에서 구분된다.

| 항목               | 사실적 정보 (Factuality)              | 환각 현상 (Hallucination)                                      |
|------------------|----------------------------------|------------------------------------------------------------|
| 기본 관점            | LLM이 생성한 내용의 **절대적인 정확도**        | 모델이 생성한 내용의 **일관성 (consistency)**                          |
| reference source | 이미 구축된 검증용 출처                    | 모델이 접근 가능한 지식                                              |
| 기본 설명            | 이미 존재하는, 기존 세계에 대한 지식에 기반한 내용 생성 | **사용자 입력 및 학습 데이터** 를 기준으로 한 **일관성 (consistency)** 이 부족한 것 |

### 1-2. 환각 현상의 종류

![image](../images/HalluLens_1.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

LLM 환각 현상의 종류는 다음과 같다.

|           | Extrinsic Hallucination<br>(외재적 환각)                                                   | Intrinsic Hallucination<br>(내재적 환각)            |
|-----------|---------------------------------------------------------------------------------------|------------------------------------------------|
| 정의        | LLM이 생성한 결과물이 **학습 데이터** 와의 일관성이 떨어지는 경우                                              | LLM이 생성한 결과물이 **사용자 입력 내용** 과 일관성이 떨어지는 경우     |
| 일관성 부족 대상 | 학습 데이터                                                                                | 사용자 입력 내용                                      |
| 모델의 한계    | 학습 데이터로부터 **지식을 습득하는 능력**                                                             | **inference-time 에서의 일관성 유지** 능력               |
| 추가 설명     | 모델이 **새로운 콘텐츠 (지시에 의한 free-form text 등)** 를 생성하거나, **knowledge gap 을 채우려고** 할 때 발생 가능 | 입력 내용과 모순되거나, 원래 입력 내용으로부터 **추론할 수 없는** 내용을 생성 |

### 1-3. 환각 현상의 가능한 원인

LLM 환각 현상의 가능한 발생 원인은 다음과 같다.

| 원인 분류         | 원인                            | 설명                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 발생 가능한 환각 현상               |
|---------------|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------|
| Data-Related  | 없거나 제한된 지식                    | 학습 데이터에서 **사용자 쿼리와 관련된 지식이 부족한** 경우<br>- 이때 모델은 **어떻게든 답변을 생성** 하려고 함<br>- 이것은 잠재적인 환각 현상의 원인이 됨                                                                                                                                                                                                                                                                                                                                                                                                              | Extrinsic                  |
| Data-Related  | 서로 모순되거나 noisy 한 학습 데이터/입력 쿼리 | 학습 데이터 또는 사용자 쿼리가 **서로 모순되거나 noisy 하여 모델에게 혼란을 주거나 mislead** 하는 경우<br>- semantic understanding 등은 도전적인 과제임                                                                                                                                                                                                                                                                                                                                                                                                    | both Extrinsic & Intrinsic |
| Model-Related |                               | 다음과 같이 다양한 원인이 있을 수 있음<br>- [트랜스포머 구조](../../Natural%20Language%20Processing/Basics_트랜스포머%20모델.md) 기반 [Attention 메커니즘](../../Natural%20Language%20Processing/Basics_트랜스포머%20모델.md#3-트랜스포머에서의-어텐션-메커니즘) 의 한계<br>- [RLHF (Reinforcement Learning from Human Feedback)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_DPO_ORPO.md#1-1-rlhf-reinforcement-learning-from-human-feedback) 의 학습 전략의 문제<br>- LLM의 Pre-training & [Fine-Tuning](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning.md) 학습 프로세스의 문제점 | both Extrinsic & Intrinsic |

## 2. 환각 현상 평가 Benchmark 의 선택 기준

환각 현상을 측정하고 평가하기 위한 Benchmark 의 선택 기준은 다음과 같다.

| Benchmark 선택 기준             | 설명                                                                                                                |
|-----------------------------|-------------------------------------------------------------------------------------------------------------------|
| 의도하지 않은 데이터 유출 (leakage) 방지 | LLM의 학습 데이터는 인터넷상의 데이터를 포함하며, **이를 포함한 데이터는 오염 (contamination) 되어 있을 수 있다.**                                      |
| 실제 현실 적용 가능성                | LLM의 학습 데이터는 **현실 세계의 use case와 비슷해야** 한다.<br>- 여러 가지 주제, 프롬프트 스타일 등을 포함하여 **최대한 현실에 맞는 종합적인 평가** 가 되어야 한다.       |
| 높은 안정성 & 민감성                | - 같은 모델에 대해 여러 번 평가를 반복할 때도 **안정적인 결과를 출력** 해야 한다.<br>- 즉, **높은 민감성을 유지** 하면서도 **intra-model variance 가 낮아야** 한다. |
| 오픈소스 여부 (= Reproducibility) | **LLM 개발의 투명성** 보장을 위해, LLM 벤치마크는 **재생산 가능한 (reproducible) 오픈소스 데이터** 여야 한다.                                      |

## 3. HalluLens 개요

![image](../images/HalluLens_3.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

**HalluLens** 는 위에서 말한 **Extrinsic Hallucination** 과 **Intrinsic Hallucination** task 를 포함한 **LLM 환각 현상 평가 벤치마크** 이다.

* Extrinsic Hallucination 을 평가하기 위한 테스트 데이터셋은 **동적으로 생성된다.**

## 4. HalluLens 를 이용한 Extrinsic Hallucination 평가

**HalluLens 의 Part (a)** 는 LLM의 환각 현상, 특히 **학습 데이터와의 일관성 부족에 해당하는 Extrinsic Hallucination** 을 평가하기 위한 벤치마크이다.

* HalluLens 의 task 는 다음과 같다.

| 분류                        | task               | task 설명                                     |
|---------------------------|--------------------|---------------------------------------------|
| Modeling Error 관련         | PreciseWikiQA      | **간결한 답변** 에 대한 평가                          |
| Modeling Error 관련         | LongWiki           | **세부적인** long-form content 에 대한 **일관성** 평가  |
| Unseen Data 에 의한 환각 현상 관련 | NonExistentRefusal | 학습 데이터에 정보가 없는, **답변 불가능한** 질문에 대한 대응 능력 평가 |

![image](../images/HalluLens_4.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

### 4-1. PreciseWikiQA

### 4-2. LongWiki

### 4-3. NonExistentRefusal

## 5. HalluLens 를 이용한 Intrinsic Hallucination 평가

### 5-1. HHEM leaderboard

### 5-2. ANAH 2.0 (with reference)

### 5-3. FaithEval

## 6. 기존 평가 벤치마크와의 비교
