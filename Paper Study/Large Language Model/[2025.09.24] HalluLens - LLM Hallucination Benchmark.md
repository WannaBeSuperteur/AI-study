
## 목차

* [1. LLM 환각 현상 개요](#1-llm-환각-현상-개요)
  * [1-1. LLM 환각 현상과 Factuality (사실) 의 구분](#1-1-llm-환각-현상과-factuality-사실-의-구분) 
  * [1-2. 환각 현상의 종류](#1-2-환각-현상의-종류)
  * [1-3. 환각 현상의 가능한 원인](#1-3-환각-현상의-가능한-원인)
* [2. 환각 현상 평가 Benchmark 의 선택 기준](#2-환각-현상-평가-benchmark-의-선택-기준)
* [3. HalluLens 개요](#3-hallulens-개요)
* [4. HalluLens 를 이용한 Extrinsic Hallucination 평가](#4-hallulens-를-이용한-extrinsic-hallucination-평가)
  * [4-1. PreciseWikiQA](#4-1-precisewikiqa)
  * [4-2. LongWiki](#4-2-longwiki)
  * [4-3. NonExistentRefusal](#4-3-nonexistentrefusal)
* [5. HalluLens 를 이용한 Intrinsic Hallucination 평가](#5-hallulens-를-이용한-intrinsic-hallucination-평가)
  * [5-1. HHEM leaderboard](#5-1-hhem-leaderboard)
  * [5-2. ANAH 2.0 (with reference)](#5-2-anah-20-with-reference)
  * [5-3. FaithEval](#5-3-faitheval)
* [6. 기존 평가 벤치마크와의 비교](#6-기존-평가-벤치마크와의-비교)

## 논문 소개

* Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark", 2025
* [arXiv Link](https://arxiv.org/pdf/2504.17550)

## 참고

* [LLM의 환각 현상 (Hallucination)](../../AI%20Basics/LLM%20Basics/LLM_기초_환각_현상.md)
* [OpenAI가 말하는 환각 현상의 원인 (2025.09. 논문)](%5B2025.09.09%5D%20Why%20Language%20Models%20Hallucinate.md)

## 1. LLM 환각 현상 개요

LLM의 **환각 현상 (Hallucination)** 은 LLM이 다음에 해당하는 답변을 생성하는 것을 의미한다.

* 사용자 입력 또는 LLM의 이전 답변과 논리적 모순 발생
* 현실의 실제 지식과 불일치

환각 현상은 다음과 같은 문제점의 원인이다.

* LLM의 성능 및 신뢰성 감소
* 경우에 따라 **LLM을 윤리적으로 신뢰하기 어렵게 할 수 있음**

### 1-1. LLM 환각 현상과 Factuality (사실) 의 구분

![image](../images/HalluLens_2.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

LLM이 생성하는 **사실적 정보 (Factuality)** 와 **환각 현상** 은 생성된 콘텐츠의 신뢰성과 관련된 내용이지만, 다음과 같은 점에서 구분된다.

| 항목               | 사실적 정보 (Factuality)              | 환각 현상 (Hallucination)                                      |
|------------------|----------------------------------|------------------------------------------------------------|
| 기본 관점            | LLM이 생성한 내용의 **절대적인 정확도**        | 모델이 생성한 내용의 **일관성 (consistency)**                          |
| reference source | 이미 구축된 검증용 출처                    | 모델이 접근 가능한 지식                                              |
| 기본 설명            | 이미 존재하는, 기존 세계에 대한 지식에 기반한 내용 생성 | **사용자 입력 및 학습 데이터** 를 기준으로 한 **일관성 (consistency)** 이 부족한 것 |

### 1-2. 환각 현상의 종류

![image](../images/HalluLens_1.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

LLM 환각 현상의 종류는 다음과 같다.

|           | Extrinsic Hallucination<br>(외재적 환각)                                                   | Intrinsic Hallucination<br>(내재적 환각)            |
|-----------|---------------------------------------------------------------------------------------|------------------------------------------------|
| 정의        | LLM이 생성한 결과물이 **학습 데이터** 와의 일관성이 떨어지는 경우                                              | LLM이 생성한 결과물이 **사용자 입력 내용** 과 일관성이 떨어지는 경우     |
| 일관성 부족 대상 | 학습 데이터                                                                                | 사용자 입력 내용                                      |
| 모델의 한계    | 학습 데이터로부터 **지식을 습득하는 능력**                                                             | **inference-time 에서의 일관성 유지** 능력               |
| 추가 설명     | 모델이 **새로운 콘텐츠 (지시에 의한 free-form text 등)** 를 생성하거나, **knowledge gap 을 채우려고** 할 때 발생 가능 | 입력 내용과 모순되거나, 원래 입력 내용으로부터 **추론할 수 없는** 내용을 생성 |

### 1-3. 환각 현상의 가능한 원인

LLM 환각 현상의 가능한 발생 원인은 다음과 같다.

| 원인 분류         | 원인                            | 설명                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 발생 가능한 환각 현상               |
|---------------|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------|
| Data-Related  | 없거나 제한된 지식                    | 학습 데이터에서 **사용자 쿼리와 관련된 지식이 부족한** 경우<br>- 이때 모델은 **어떻게든 답변을 생성** 하려고 함<br>- 이것은 잠재적인 환각 현상의 원인이 됨                                                                                                                                                                                                                                                                                                                                                                                                              | Extrinsic                  |
| Data-Related  | 서로 모순되거나 noisy 한 학습 데이터/입력 쿼리 | 학습 데이터 또는 사용자 쿼리가 **서로 모순되거나 noisy 하여 모델에게 혼란을 주거나 mislead** 하는 경우<br>- semantic understanding 등은 도전적인 과제임                                                                                                                                                                                                                                                                                                                                                                                                    | both Extrinsic & Intrinsic |
| Model-Related |                               | 다음과 같이 다양한 원인이 있을 수 있음<br>- [트랜스포머 구조](../../Natural%20Language%20Processing/Basics_트랜스포머%20모델.md) 기반 [Attention 메커니즘](../../Natural%20Language%20Processing/Basics_트랜스포머%20모델.md#3-트랜스포머에서의-어텐션-메커니즘) 의 한계<br>- [RLHF (Reinforcement Learning from Human Feedback)](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning_DPO_ORPO.md#1-1-rlhf-reinforcement-learning-from-human-feedback) 의 학습 전략의 문제<br>- LLM의 Pre-training & [Fine-Tuning](../../AI%20Basics/LLM%20Basics/LLM_기초_Fine_Tuning.md) 학습 프로세스의 문제점 | both Extrinsic & Intrinsic |

## 2. 환각 현상 평가 Benchmark 의 선택 기준

환각 현상을 측정하고 평가하기 위한 Benchmark 의 선택 기준은 다음과 같다.

| Benchmark 선택 기준             | 설명                                                                                                                |
|-----------------------------|-------------------------------------------------------------------------------------------------------------------|
| 의도하지 않은 데이터 유출 (leakage) 방지 | LLM의 학습 데이터는 인터넷상의 데이터를 포함하며, **이를 포함한 데이터는 오염 (contamination) 되어 있을 수 있다.**                                      |
| 실제 현실 적용 가능성                | LLM의 학습 데이터는 **현실 세계의 use case와 비슷해야** 한다.<br>- 여러 가지 주제, 프롬프트 스타일 등을 포함하여 **최대한 현실에 맞는 종합적인 평가** 가 되어야 한다.       |
| 높은 안정성 & 민감성                | - 같은 모델에 대해 여러 번 평가를 반복할 때도 **안정적인 결과를 출력** 해야 한다.<br>- 즉, **높은 민감성을 유지** 하면서도 **intra-model variance 가 낮아야** 한다. |
| 오픈소스 여부 (= Reproducibility) | **LLM 개발의 투명성** 보장을 위해, LLM 벤치마크는 **재생산 가능한 (reproducible) 오픈소스 데이터** 여야 한다.                                      |

## 3. HalluLens 개요

![image](../images/HalluLens_3.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

**HalluLens** 는 위에서 말한 **Extrinsic Hallucination** 과 **Intrinsic Hallucination** task 를 포함한 **LLM 환각 현상 평가 벤치마크** 이다.

* Extrinsic Hallucination 을 평가하기 위한 테스트 데이터셋은 **동적으로 생성된다.**

## 4. HalluLens 를 이용한 Extrinsic Hallucination 평가

**HalluLens 의 Part (a)** 는 LLM의 환각 현상 중 **학습 데이터와의 일관성 부족에 해당하는 Extrinsic Hallucination** 을 평가하기 위한 벤치마크이다.

* HalluLens 의 **Part (a)** 의 task 는 다음과 같다.

| 분류                        | task               | task 설명                                     |
|---------------------------|--------------------|---------------------------------------------|
| Modeling Error 관련         | PreciseWikiQA      | **간결한 답변** 에 대한 평가                          |
| Modeling Error 관련         | LongWiki           | **세부적인** long-form content 에 대한 **일관성** 평가  |
| Unseen Data 에 의한 환각 현상 관련 | NonExistentRefusal | 학습 데이터에 정보가 없는, **답변 불가능한** 질문에 대한 대응 능력 평가 |

![image](../images/HalluLens_4.PNG)

[(출처)](https://arxiv.org/pdf/2504.17550) : Yejin Bang and Ziwei Ji et al., "HalluLens: LLM Hallucination Benchmark"

### 4-1. PreciseWikiQA

**PreciseWikiQA** 는 **학습 데이터에 있는 지식을 기반으로 한 간결한 쿼리에 대한 환각 현상 발생률** 을 측정하기 위한 벤치마크이다.

* Metric

| Metric                           | 설명                                                                          |
|----------------------------------|-----------------------------------------------------------------------------|
| False Refusal Rate               | 모델이 답변을 시도하지 않고, 그 대신 ```죄송합니다. 관련 정보가 부족하여 답변이 어렵습니다.``` 와 같은 메시지를 출력하는 비율 |
| Hallucination Rate (not refused) | 모델이 답변을 거부하지 않았을 때, **잘못된 답변을 생성하여 환각 현상을 일으키는** 비율                         |
| Correct Answer Rate              | 전체 샘플 중 모델이 **답변 거부 없이 알맞은 답변을 생성하는 비율**                                    |

* Pipeline

| Pipeline 구성 요소                 | 설명                                                                                                                                     |
|--------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|
| Question Source Selection      | - GoodWiki 데이터셋 (위키피디아의 ```good quality``` 로 표시된 44,754 개 문서)<br>- 안정성 유지를 위해 **각 page의 난이도를 측정하여 난이도 조절**                             |
| Question and Answer Generation | 다음과 같은 step 으로 구성<br>- 모델이 질문을 생성하도록 프롬프팅하여 **질문 생성**<br>- reference 를 이용하여 **답변 생성**                                                  |
| Inference                      | 생성된 질문을 이용하여 inference 실시                                                                                                              |
| Evaluation                     | 다음을 판단<br>- 모델의 답변 거부 (refusal)<br>- 생성된 답변의 정확도<br>이때, LLM이 생성한 답변에 대해 ```correct``` ```incorrect``` ```unverifiable``` 중 하나로 분류하도록 함 |

### 4-2. LongWiki

**LongWiki** 는 **학습 데이터를 기반으로 Long-form Content 를 생성하여, 그 일관성을 측정** 하기 위한 벤치마크이다.

* Metric

| Metric             | 설명                                                                          |
|--------------------|-----------------------------------------------------------------------------|
| False Refusal Rate | 모델이 답변을 시도하지 않고, 그 대신 ```죄송합니다. 관련 정보가 부족하여 답변이 어렵습니다.``` 와 같은 메시지를 출력하는 비율 |
| Precision          | Prompt 에 대한 **위키피디아 문서 근거 자료** 의 평균 개수                                      |
| Recall@K           | Prompt 에 대해 **생성된 답변이 너무 짧거나 불완전하지 않은 것을 보장** 하기 위한 근거 자료의 평균 개수            |
| F1@K               | Precision 과 Recall@K 의 조화 평균                                                |

* Pipeline

| Pipeline 구성 요소 | 설명                                                                                                                                                                                                                                                                    |
|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 테스트 프롬프트 생성    | 데이터셋<br>- GoodWiki 데이터셋 사용 (PreciseWikiQA 와 유사)<br><br>데이터 생성 과정<br>- 위키피디아 문서의 section이 주어졌을 때, **prompt generator LLM** 을 이용하여 paragraph-level answer 가 필요한 프롬프트 생성<br>- 해당 프롬프트의 **answerability (답변 가능성)** 평가<br>- 답변 가능하다고 평가 시, **LLM은 reference 에 근거하여 답변 생성** |
| Inference      | 최대 1,024 개의 토큰으로 생성                                                                                                                                                                                                                                                   |
| Evaluation     | **Refusal** Evaluation & **Claim** Evaluation & **Reference** Evidence Evaluation                                                                                                                                                                                     |

* Refusal & Claim & Reference Evidence Evaluation

| 구분                            | 설명                                                 |
|-------------------------------|----------------------------------------------------|
| Refusal Evaluation            | 답변을 제공하는 대신 **답변을 제공할 수 없다는 메시지를 출력** 할 줄 아는 능력 평가 |
| Claim Evaluation              | LLM이 생성한 문장을 **더 작은, 검증 가능한 단위 (claim)** 로 나눔      |
| Reference Evidence Evaluation | **각 claim 에 대한 검증** 을 위해, 관련 페이지에 대한 범위를 좁힘        |

### 4-3. NonExistentRefusal

**NonExistentRefusal** 은 LLM이 **자신이 학습한 지식의 범위 내에서 답변을 제공할 수 없을** 때 **그럴듯한 답변을 생성하는 환각 현상의 비율** 을 측정하기 위한 벤치마크이다.

* Subtask

| Subtask           | 설명                                            |
|-------------------|-----------------------------------------------|
| MixedEntities     | 동물, 식물, 의료 등 4가지 도메인에서 **존재하지 않는 이름** 생성      |
| GeneratedEntities | 위와 같이 존재하지 않는 이름들을 **LLM에게 요청하여 다양한 분야에서** 생성 |

* Metric

| Metric                | 설명                                                                                      |
|-----------------------|-----------------------------------------------------------------------------------------|
| False Acceptance Rate | 모델이 **존재하지 않는 객체에 대해 답변이 불가능하다는 메시지 대신 '그럴듯한 답변'을 생성** 하는 비율<br>- 즉, **환각 현상 발생률** 을 의미 |

* Pipeline

| Pipeline 구성 요소      | 설명                                                                                                                                                                |
|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Prompt Construction | 존재하지 않는 객체에 대한 이름 생성<br>- MixedEntities, GeneratedEntities                                                                                                        |
| Inference           | 다음 예시와 같이 **총 10가지의 서로 다른 prompt 유형** 을 이용<br>- ```Can you describe the {type} {nonexistent_name}?```<br>- ```I'm curious about the {type} {nonexistent_name}.``` |
| Evaluation          | LLM이 생성한 답변을 이용하여 **False Acceptance Rate** 측정                                                                                                                    |

## 5. HalluLens 를 이용한 Intrinsic Hallucination 평가

**HalluLens 의 Part (b)** 는 LLM의 환각 현상 중 **입력되는 문맥과의 일관성이 부족한 경우의 환각 현상** 을 평가하기 위한 벤치마크이다.

* Intrinsic Hallucination 은 다음과 같은 이유로 Extrinsic Hallucination 에 비해 **상대적으로 연구가 잘 되어 있다.**
  * LLM 이전부터, 언어를 생성하는 모델은 **Source Input 을 필요로 했음**
  * 검증을 위해 필요한 데이터가 **깔끔하고 잘 정의되어** 있음
* HalluLens 의 **Part (b)** 의 벤치마크는 다음과 같다.

| 벤치마크                      | 설명                                                      | 테스트 데이터셋                                      | 평가 Metric                              |
|---------------------------|---------------------------------------------------------|-----------------------------------------------|----------------------------------------|
| HHEM leaderboard          | **텍스트 요약** 분야에서 내재적 환각 현상 평가                            | CNN/Daily Mail Corpus                         | Factual Inconsistency                  |
| ANAH 2.0 (with reference) | LLM에 의해 생성된 답변과 **사실적으로 정확한 입력 내용** 과의 일관성 측정           | 위키피디아, Baidu Baike 등 **공개된 다양한 Corpus**       | ANAH-v2 데이터셋으로 학습된 annotator 를 이용하여 평가 |
| FaithEval                 | 입력 데이터가 **noisy 하거나 실제 사실과 다른 (모순되는)** 경우의 내재적 환각 현상 평가 | **잘 알려진 학술적 QA 데이터셋** 에서 유래한 약 4,900 개의 문제 포함 | Accuracy (ACC)                         |

### 5-1. HHEM leaderboard

* 실험 결과 요약

| LLM                           | Hallucination Rate |
|-------------------------------|--------------------|
| GPT-4o                        | 1.5 %              |
| Llama-3.1-405B-Instruct       | 3.9 %              |
| Llama-3.3-70B-Instruct        | 4.0 %              |
| Llama-3.1-8B-Instruct         | 5.4 %              |
| (Anthropic) Claude-3.5-Sonnet | 4.6 %              |
| Gemma-1.1-2B-it               | **27.8 %**         |
| Qwen2.5-0.5B-Instruct         | **25.2 %**         |

### 5-2. ANAH 2.0 (with reference)

* 실험 결과 요약

| LLM         | Hallucination Rate |
|-------------|--------------------|
| Qwen1.5-14B | 5.33 %             |
| LLaMa-7B    | **58.16 %**        |

### 5-3. FaithEval

* 실험 결과 모델

| LLM          | Hallucination Rate  |
|--------------|---------------------|
| 다양한 Chat LLM | 13.6 % - **68.4 %** |

## 6. 기존 평가 벤치마크와의 비교
