
## 목차

* [1. 핵심 내용 요약](#1-핵심-내용-요약)
* [2. MLLMs (Multi-modal Large Language Models)](#2-mllms-multi-modal-large-language-models)
* [3. 실험 결과](#3-실험-결과)
  * [3-1. VQDv1 데이터셋에 대한 Visual Query Detection](#3-1-vqdv1-데이터셋에-대한-visual-query-detection)
  * [3-2. TDIUC 데이터셋에 대한 Fine-Grained VQA 평가](#3-2-tdiuc-데이터셋에-대한-fine-grained-vqa-평가)
  * [3-3. TallyQA 데이터셋에 대한 Counting (개수 세기) 평가](#3-3-tallyqa-데이터셋에-대한-counting-개수-세기-평가)
  * [3-4. DVQA 데이터셋에 대한 차트 해석 능력 평가](#3-4-dvqa-데이터셋에-대한-차트-해석-능력-평가)
* [4. 현대 MLLM의 강점 및 약점 분석](#4-현대-mllm의-강점-및-약점-분석)
  * [4-1. 강점: 물체 해석 (인식) & 장면 이해](#4-1-강점-물체-해석-인식--장면-이해)
  * [4-2. 약점: 복잡한 추론, 정밀한 Counting (개수 세기)](#4-2-약점-복잡한-추론-정밀한-counting-개수-세기)
* [5. Open-Source vs. Closed-Source 모델 성능 비교](#5-open-source-vs-closed-source-모델-성능-비교)
* [6. 모델 크기 및 이미지 해상도에 따른 성능 추이](#6-모델-크기-및-이미지-해상도에-따른-성능-추이)

## 논문 소개

* Jian Lu and Shikhar Srivastava et al., "Revisiting Multi-Modal LLM Evaluation", 2025
* [Open Access Link](https://openaccess.thecvf.com/content/CVPR2025W/BEAM/papers/Lu_Revisiting_Multi-Modal_LLM_Evaluation_CVPRW_2025_paper.pdf)

## 1. 핵심 내용 요약

* 이 논문에서 다루는 핵심 내용은 다음과 같다.

| 핵심 내용                                             | 설명                                                                  |
|---------------------------------------------------|---------------------------------------------------------------------|
| MLLMs (Multi-modal Large Language Models) 에 대한 평가 | 평가 대상 데이터셋 : **TallyQA, TDIUC, DVQA**<br>- 이전에 드러나지 않았던 MLLM의 약점 탐구 |
| MLLM의 **시각 정보 해석** 능력 평가                          | 평가 대상 데이터셋 : **VQDv1**<br>- 여러 개의 물체가 있는 이미지에 대한 복잡한 추론 능력 평가       |
| 현재의 MLLM의 **강점 및 약점 분석** 및 특징화                    | 향후 MLLM의 발전 방향 제시                                                   |

* 이 논문에서 사용하는 데이터셋은 다음과 같다.

| 데이터셋    | 설명                                                              |
|---------|-----------------------------------------------------------------|
| VQDv1   | 모델이 1개의 물체를 localize 하는 대신 **여러 개의 bounding box 를 생성** 하는 능력 평가 |
| TallyQA | counting (개수 세기) 등 **복잡한 시각 정보 해석 능력** 평가                       |
| TDIUC   | 모델의 **다양한 측면에서의 역량 (versatility)** 평가                           |
| DVQA    | **차트 형식으로 된 시각 자료** 를 해석 및 분석하는 능력 평가                           |

## 2. MLLMs (Multi-modal Large Language Models)

**MLLM** 은 **Multi-modal Large Language Model** 을 가리킨다.

* MLLM 의 일반적인 구성

| 구성 요소                      | 설명                                          |
|----------------------------|---------------------------------------------|
| Pre-trained LLM            |                                             |
| Pre-trained Vision Encoder |                                             |
| **Learned Adapter**        | 시각 표현 (visual) 과 언어 표현 (linguistic) 을 align |

* 널리 알려진 MLLM

![image](../images/LLM_MultiModal_Eval_1.PNG)

| MLLM            | 설명 및 기술적 요소                                                                                                                                                | 파라미터 개수                | 이미지 해상도                                                                    |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|----------------------------------------------------------------------------|
| BLIP2           | **lightweight Querying Transformer (Q-Former)**<br>- image & text 해석을 연결하기 위해, **image & text transformer** 를 submodule 로 가짐                               | **188M** (transformer) |                                                                            |
| iBLIP           | **instruction-aware Query Transformer**<br>- 모델이 prompt 의 지시에 기반하여 visual feature 를 추출할 수 있도록 함                                                            |                        |                                                                            |
| LLaVA           | LLaVA 1.5 에서는 visual encoder 를 개선하여 **더 높은 해상도의 이미지** 처리                                                                                                   |                        | **336 x 336** (LLaVA 1.5)                                                  |
| CogVLM          | 사전 학습된 고정된 (frozen) 언어 모델과 image encoder 간의 gap 을 줄이기 위한 **새로운 방법론** 도입<br>- 학습 가능한 **visual expert 모듈** 도입                                                |                        |                                                                            |
| QwenVL          | **3단계 학습 파이프라인**<br>- **bounding box 입출력** 을 처리하는 새로운 입출력 메커니즘 사용                                                                                          |                        | **448 x 448**                                                              |
| LLaVA-NeXT      | LLaVA 1.5 를 다음 부분에 집중하여 업데이트<br>- 시각적 추론 능력<br> - OCR (optical character recognition)<br>- 멀티모달 기반 문서 이해                                                   | 본 논문에서는 **7B** 버전 사용   | 최대 **1344 x 336**                                                          |
| Mini-Gemini     | **Dual-encoder Architecture** 도입<br>- 저차원 및 고차원 시각 임베딩을 **분리하여 처리**<br>- 고차원 영역과 저차원 visual query 를 patch level 에서 연결하는 **patch information mining** 기술 사용 | 본 논문에서는 **7B** 버전 사용   | **672 x 672** (Mini-Gemini-HD, MGM-HD)<br>**336 x 336** (Mini-Gemini, MGM) |
| LLaVA-OneVision | 1개의 모델을 학습하여 **다양한 modality 를 처리** 가능한 **거대한 멀티모달 모델의 집합**<br>- 단일 이미지, 여러 장의 이미지, 비디오 등                                                                   | 본 논문에서는 **7B** 버전 사용   |                                                                            |
| GPT-4o, GPT-4V  | - OpenAI 개발<br>- GPT-4 정도 규모의 LLM이 **시각 정보 입력을 처리** 할 수 있도록 함                                                                                              |                        |                                                                            |

## 3. 실험 결과

### 3-1. VQDv1 데이터셋에 대한 Visual Query Detection

### 3-2. TDIUC 데이터셋에 대한 Fine-Grained VQA 평가

### 3-3. TallyQA 데이터셋에 대한 Counting (개수 세기) 평가

### 3-4. DVQA 데이터셋에 대한 차트 해석 능력 평가

## 4. 현대 MLLM의 강점 및 약점 분석

### 4-1. 강점: 물체 해석 (인식) & 장면 이해

### 4-2. 약점: 복잡한 추론, 정밀한 Counting (개수 세기)

## 5. Open-Source vs. Closed-Source 모델 성능 비교

## 6. 모델 크기 및 이미지 해상도에 따른 성능 추이
