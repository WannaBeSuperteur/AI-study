
## 목차

* [1. Stable-Hair 개요 및 핵심 아이디어](#1-stable-hair-개요-및-핵심-아이디어)
* [2. Stable-Hair 의 방법](#2-stable-hair-의-방법)
  * [2-1. Stage 1. Bald State 로 정규화](#2-1-stage-1-bald-state-로-정규화---bald-converter)
  * [2-2. Stage 1. Bald State 로 정규화 - 학습 데이터 수집](#2-2-stage-1-bald-state-로-정규화---학습-데이터-수집)
  * [2-3. Stage 2. Hair Transfer & Integration](#2-3-stage-2-hair-transfer--integration) 
* [3. 모델 학습 & Loss Function](#3-모델-학습--loss-function)
* [4. 실험 및 그 결과](#4-실험-및-그-결과)
  * [4-1. 실험 구현 상세](#4-1-실험-구현-상세)
  * [4-2. 평가 Metric](#4-2-평가-metric)
  * [4-3. 실험 결과](#4-3-실험-결과)

## 논문 소개

* Yuxuan Zhang and Qing Zhang et al., "Stable-Hair: Real-World Hair Transfer via Diffusion Model"
* [AAAI Download Link](https://ojs.aaai.org/index.php/AAAI/article/view/33123/35278)

## 1. Stable-Hair 개요 및 핵심 아이디어

**Stable-Hair** 는 [Diffusion Model](../../Generative%20AI/Basics_Diffusion%20Model.md) 을 기반으로 한 **최초의 헤어스타일 수정 프레임워크** 이다.

* 핵심 아이디어

| 핵심 아이디어                  | 설명                                                                                                                   |
|--------------------------|----------------------------------------------------------------------------------------------------------------------|
| Hair Extractor           | reference image 를 인코딩하고, 또 **상세한 hair feature 를 주입** 한다.                                                             |
| 새로운 Latent ControlNet 구조 | - Bald Converter (기존 헤어스타일 이미지를 Bald 이미지로 변환)<br>- pixel space 에서의 헤어스타일 변환 프로세스를 **latent space 에서의 프로세스로 mapping** |

## 2. Stable-Hair 의 방법

* Stable-Hair 방법의 전체 구조

![image](../images/StableHair_1.PNG)

[(출처)](https://ojs.aaai.org/index.php/AAAI/article/view/33123/35278) : Yuxuan Zhang and Qing Zhang et al., "Stable-Hair: Real-World Hair Transfer via Diffusion Model"

* Stable-Hair 방법의 단계
  * 아래와 같은 two-stage 방법을 통해 **헤어스타일 변환을 안정적으로 진행** 할 수 있으며, **원본 이미지의 내용을 유지** 할 수 있다.

| 단계                                        | 설명                                                                                  |
|-------------------------------------------|-------------------------------------------------------------------------------------|
| Stage 1 **(Bald State 로 정규화)**            | 입력된 원본 이미지를 **bald 헤어스타일의 proxy image** 로 변환<br>- 이때 **Bald Converter** 를 이용        |
| Stage 2 **(Hair Transfer & Integration)** | reference hair 이미지를, **bald 헤어스타일의 proxy image** 를 baseline 으로 해서 **그 특징을 합성하여** 변환 |

### 2-1. Stage 1. Bald State 로 정규화 - Bald Converter

**Bald Converter** 는 다음과 같은 역할을 한다.

* 입력된 원본 이미지를 **Bald 헤어스타일의 proxy image 로 변환**
  * 기본적인 형태의 Diffusion 모델과 **본 연구에서 설계한 Latent ControlNet을 결합** 시킨 형태
  * 학습된 Bald Converter 는 **추가적인 image alignment 등 작업 없이도 원본 이미지에서 hair 영역을 제거** 할 수 있음 
* 원본 이미지를 **Bald image 로 정규화** 하는 것이 중요한 이유는 다음과 같다.
  * 헤어스타일 변환에서 모델 성능 향상
  * 성능 향상의 이유는 **hair 영역을 제거** 함으로써 **모델이 hair 영역 대신 얼굴 영역의 feature 등에 집중** 할 수 있기 때문

### 2-2. Stage 1. Bald State 로 정규화 - 학습 데이터 수집

**Bald Converter 의 학습이 완료** 되면, 이를 이용하여 **헤어스타일 변환에 필요한 학습 데이터셋을 생성** 할 수 있다.

* 학습 데이터 구성

| 학습 데이터          | 설명                               | 생성에 사용된 모델<br>(또는 생성 방법)                                                                                                                           |
|-----------------|----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|
| bald 헤어스타일 이미지  | 학습에 필요한 bald head 이미지            | **Bald Converter**                                                                                                                                 |
| Original image  | 입력된 원본 이미지                       |                                                                                                                                                    |
| Reference image | Original image 와는 **다른 포즈의** 이미지 | - **ChatGPT** 를 이용하여 **Original image** 에서 **non-hairstyle 에 해당하는 부분의 caption** 을 생성<br>- 이 caption을 hair mask 와 함께 **inpainting model** 에 입력하여 생성 |

![image](../images/StableHair_2.PNG)

[(출처)](https://ojs.aaai.org/index.php/AAAI/article/view/33123/35278) : Yuxuan Zhang and Qing Zhang et al., "Stable-Hair: Real-World Hair Transfer via Diffusion Model"

**상세 과정 설명**

| 순서 | Step   | 과정 설명                                                                                     |
|----|--------|-------------------------------------------------------------------------------------------|
| 1  | Step 1 | Bald Converter 를 이용하여 **Bald Proxy Image** 생성                                             |
| 2  | Step 2 | Original image 의 **hair mask 를 생성**<br>scale & paste → Segmentation 추정                    |
| 3  | Step 2 | ChatGPT를 이용하여 Original image 의 **hair 를 제외한 영역에 대한 caption** 생성                           |
| 4  | Step 2 | **hair mask + caption + original image** 를 Inpainting Model 에 입력하여 **Reference Image** 생성 |

### 2-3. Stage 2. Hair Transfer & Integration

## 3. 모델 학습 & Loss Function

## 4. 실험 및 그 결과

### 4-1. 실험 구현 상세

### 4-2. 평가 Metric

### 4-3. 실험 결과