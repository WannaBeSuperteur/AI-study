## 목차

* [1. GigaGAN 핵심 아이디어](#1-gigagan-핵심-아이디어)
* [2. GigaGAN 의 전체 구조](#2-gigagan-의-전체-구조)
* [3. Generator](#3-generator)
  * [3-1. Text and latent-code conditioning](#3-1-text-and-latent-code-conditioning)
  * [3-2. Synthesis Network (with adaptive kernel selection)](#3-2-synthesis-network-with-adaptive-kernel-selection)
* [4. Discriminator](#4-discriminator)
  * [4-1. Text conditioning & Multi-scale image processing](#4-1-text-conditioning--multi-scale-image-processing)
  * [4-2. Loss Term 1 (Multi-scale input, multi-scale output adversarial)](#4-2-loss-term-1-multi-scale-input-multi-scale-output-adversarial)
  * [4-3. Loss Term 2 (Matching-aware Loss)](#4-3-loss-term-2-matching-aware-loss)
  * [4-4. Loss Term 3 (CLIP contrastive Loss)](#4-4-loss-term-3-clip-contrastive-loss)
* [5. GAN-based Upsampler](#5-gan-based-upsampler)
* [6. 실험 결과](#6-실험-결과)

## 논문 소개

* Minguk Kang and Jun-Yan Zhu et al., "Scaling up GANs for Text-to-Image Synthesis", 2023
* [arXiv Link](https://arxiv.org/pdf/2303.05511)
* 개인적으로는 Figure 1 최상단의 ```a human growing colorful flowers from her hair``` 의 컨셉을 Oh-LoRA 향후 버전에 유사하게 적용해 보고 싶음

## 1. GigaGAN 핵심 아이디어

## 2. GigaGAN 의 전체 구조

## 3. Generator

### 3-1. Text and latent-code conditioning

### 3-2. Synthesis Network (with adaptive kernel selection)

## 4. Discriminator

### 4-1. Text conditioning & Multi-scale image processing

### 4-2. Loss Term 1 (Multi-scale input, multi-scale output adversarial)

### 4-3. Loss Term 2 (Matching-aware Loss)

### 4-4. Loss Term 3 (CLIP contrastive Loss)

## 5. GAN-based Upsampler

## 6. 실험 결과