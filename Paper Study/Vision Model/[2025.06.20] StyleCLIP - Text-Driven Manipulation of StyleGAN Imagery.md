## ëª©ì°¨

* [1. StyleCLIP ì˜ í•µì‹¬ ì•„ì´ë””ì–´ ë° êµ¬ì„± ìš”ì†Œ](#1-styleclip-ì˜-í•µì‹¬-ì•„ì´ë””ì–´-ë°-êµ¬ì„±-ìš”ì†Œ)
* [2. Latent Optimization](#2-latent-optimization)
* [3. Latent Mapper](#3-latent-mapper)
* [4. Global Directions](#4-global-directions)
* [5. ì‹¤í—˜ ê²°ê³¼](#5-ì‹¤í—˜-ê²°ê³¼)

## ë…¼ë¬¸ ì†Œê°œ

* Or Patashnik and Zongze Wu et al., "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery", 2021
* [arXiv Link](https://arxiv.org/pdf/2103.17249)

## 1. StyleCLIP ì˜ í•µì‹¬ ì•„ì´ë””ì–´ ë° êµ¬ì„± ìš”ì†Œ

StyleCLIP ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

* Source Image â†’ **mapping** (latent code $w$) â†’ input ($w$ + **generated residuals**) to StyleGAN

| í•µì‹¬ ì•„ì´ë””ì–´ (ëª¨ë¸)                                                                                         | ì„¤ëª…                                                                                                                     |
|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|
| **í…ìŠ¤íŠ¸ ê¸°ë°˜** latent optimization **(optimizer)**                                                       | CLIP ëª¨ë¸ì€ **loss network** ìœ¼ë¡œ ì‚¬ìš©ë¨                                                                                       |
| latent residual mapper **(mapper)**                                                                  | - íŠ¹ì • text prompt ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµë¨<br>- ì£¼ì–´ì§„ latent space ì— ëŒ€í•´ **'local step' (íŠ¹ì • íŠ¹ì§•ë§Œ ë°”ë€ ì´ë¯¸ì§€)** ì„ ìƒì„±                           |
| **text prompt** ë¥¼ StyleGAN ì˜ style space ì— ëŒ€í•œ **global direction** ìœ¼ë¡œ mapping **(global direction)** | 'disentanglement' ([StyleGAN ë…¼ë¬¸](https://arxiv.org/pdf/1812.04948) ê°œë…) ë¿ë§Œ ì•„ë‹ˆë¼, **ì´ë¯¸ì§€ ì¡°ì‘ (manipulation) ì˜ ê°•ë„** ê¹Œì§€ ì¡°ì ˆ ê°€ëŠ¥ |

* ê° í•µì‹¬ ì•„ì´ë””ì–´ component ë³„ **pre-process & í•™ìŠµ & ì¶”ë¡  ì‹œê°„** ë° **latent space** ë“± ì •ë³´

![image](../images/StyleCLIP_1.PNG)

[(ì¶œì²˜)](https://arxiv.org/pdf/2103.17249) : Or Patashnik and Zongze Wu et al., "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery"

## 2. Latent Optimization

**Latent Optimization** ì—ì„œ CLIP ëª¨ë¸ì€ **[Loss Function](../../AI%20Basics/Deep%20Learning%20Basics/ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Loss_function.md) ê³„ì‚°ì„ ìœ„í•œ ì‹ ê²½ë§** ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.

* í•µì‹¬ ì•„ì´ë””ì–´
  * source latent code $w_s \in W+$ ì— ëŒ€í•´, **$D_{CLIP}$ Loss + [L2 Loss](../../AI%20Basics/Deep%20Learning%20Basics/ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Regularization.md#2-l1-l2-regularization) + (ìƒì„± ì´ë¯¸ì§€ì˜ ArcFace ê²°ê³¼ ê°„) Cosine Similarity Loss ì˜ í•©** ì´ ìµœì†Œê°€ ë˜ëŠ” $w \in W+$ ë¥¼ ì°¾ëŠ”ë‹¤. 

| Loss                                 | Loss ì„¤ëª…                                                                                                                                                      | ê³„ì‚° ëŒ€ìƒ                                    |
|--------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------|
| $D_{CLIP}$ Loss                      | ê³„ì‚° ëŒ€ìƒ (2ê°œ) ì˜ **CLIP embedding** ê°„ì˜ Cosine Distance                                                                                                           | generated image $G(w)$ ë° text prompt $t$ |
| L2 Loss                              |                                                                                                                                                              | latent code $w$, $w_s$                   |
| Cosine Similarity Loss<br>($L_{ID}$) | - latent code (2ê°œ) ë¥¼ StyleGAN Generator ì— ê°ê° ì…ë ¥ì‹œì¼œ ì´ë¯¸ì§€ 2ì¥ ìƒì„±<br>- í•´ë‹¹ 2ì¥ì˜ ì´ë¯¸ì§€ë¥¼ **ArcFace Network ì— í†µê³¼ì‹œí‚¨ ê²°ê³¼** ì— ëŒ€í•œ Cosine Similarity Loss **(= identity loss)** | $w$, $w_s$                               |

![image](../images/StyleCLIP_2.PNG)

* Total Loss ìˆ˜ì‹
  * $D_{CLIP} (G(w), t) + \lambda_{L2} ||w - w_s||2 + \lambda_{ID} L_{ID}(w)$ 
  * $L_{ID}(w) = 1 - <R(G(w_s)), R(G(w))>$

* notations

| notation                       | ì„¤ëª…                                          |
|--------------------------------|---------------------------------------------|
| $w$, $w_s$ ($\in W+$)          | intermediate StyleGAN latent code from $W+$ |
| $t$                            | text prompt                                 |
| $G(Â·)$                         | StyleGAN Generator                          |
| $\lambda_{L2}$, $\lambda_{ID}$ | ê° Loss term ì— ëŒ€í•œ ê°€ì¤‘ì¹˜                        |
| $R(Â·)$                         | pre-trained ArcFace Network                 |

## 3. Latent Mapper

* í•µì‹¬ ì•„ì´ë””ì–´
  * ìœ„ì™€ ê°™ì€ [Latent Optimization](#2-latent-optimization) ì€ **ì´ë¯¸ì§€ê°€ ë³€í•˜ê¸° ì‰½ê³  (versatile), íŠ¹ì • ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•˜ê¸° ìœ„í•œ ìµœì í™”ì— ê¸´ ì‹œê°„ì´ ì†Œìš”** ëœë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.
  * ë”°ë¼ì„œ, **í•™ìŠµëœ mapping network** ë¥¼ ì´ìš©í•˜ì—¬ **text prompt $t$ ì— ëŒ€í•´ $W+$ ì— ëŒ€í•œ manipulation step $M_t(w)$ ì„ ì¶”ë¡ ** í•˜ëŠ” ëª¨ë¸ì„ ê³ ì•ˆí•œë‹¤.
  * ì´ë•Œ, manipulation step ì€ **$W+$ space** ì— ëŒ€í•´ ìƒì„±ëœë‹¤.

**1. Latent Mapper ì˜ êµ¬ì¡°**

![image](../images/StyleCLIP_3.PNG)

[(ì¶œì²˜)](https://arxiv.org/pdf/2103.17249) : Or Patashnik and Zongze Wu et al., "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery"

* latent mapper ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.
  * $M_t(w) = (M_t^c(w_c), M_t^m(w_m), M_t^f(w_f))$
  * with input image $w = (w_c, w_m, w_f)$
* êµ¬ì„± ìš”ì†Œ ë° notations

| êµ¬ì„± ìš”ì†Œ (notation)                     | ì„¤ëª…                                                                                       |
|--------------------------------------|------------------------------------------------------------------------------------------|
| $M_t(w)$                             | latent code $w$ ì— ëŒ€í•´, latent mapper $M_t$ ë¥¼ ì´ìš©í•˜ì—¬ ë„ì¶œëœ **manipulation step (= residuals)** |
| $M^c, M^m, M^f$                      | $w$ â†’ $M_t(w)$ ë¡œì˜ ë³€í™˜ì„ ìœ„í•œ mapper<br>- 3ê°œì˜ mapper ì¤‘ **ì¼ë¶€ë¶„ë§Œ í•™ìŠµë„ ê°€ëŠ¥**                        |
| $w_c, w_m, w_f$                      | $w$ ë¥¼ ê° mapper ë¥¼ ì´ìš©í•˜ì—¬ mapping ì‹œí‚¤ê¸° ìœ„í•´ ë‚˜ëˆˆ 3ê°œì˜ subset                                       |
| $M_t^c(w_c), M_t^m(w_m), M_t^f(w_f)$ | manipulation step $M_t(w)$ ì˜ êµ¬ì„± ìš”ì†Œ **($w$ ì˜ ê° subset ì— ëŒ€í•œ)**                             |

**2. Loss Function**

Latent Mapper ì˜ Loss Function ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

* í•µì‹¬ ì•„ì´ë””ì–´
  * **ìµœì¢… ìƒì„± ì´ë¯¸ì§€** ì™€ **text prompt $t$** ì‚¬ì´ì˜ **CLIP loss (= cosine distance) ë¥¼ ìµœì†Œí™”**
  * L2 Loss ëŠ” [Latent Optimization](#2-latent-optimization) ì—ì„œì™€ ë‹¬ë¦¬, **$M_t(w)$ ìì²´ì— ëŒ€í•œ** L2 Loss ë¡œ ìˆ˜ì •
  * ArcFace Network Loss ($L_{ID}$) ëŠ” [Latent Optimization](#2-latent-optimization) ê³¼ ë™ì¼

* ìˆ˜ì‹
  * $L(w) = L_{CLIP}(w) + \lambda_{L2} ||M_t(w)||2 + \lambda_{ID} L_{ID} (w)$

| êµ¬ì„± ìš”ì†Œ                                         | í•µì‹¬ ì„¤ëª…                                                                                                                                         | ìƒì„¸ ì„¤ëª…                                                                                                                                                                          |
|-----------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| $L_{CLIP}(w)$                                 | ìµœì¢… ìƒì„± ì´ë¯¸ì§€ - text prompt ê°„ CLIP loss (= cosine distance)                                                                                       | - $L_{CLIP}(w) = D_{CLIP}(G(w + M_t(w)), t)$<br>- $D_{CLIP}$ Loss ëŠ” [Latent Optimization](#2-latent-optimization) ê³¼ ë™ì¼<br>- $G(w + M_t(w))$ : ìµœì¢… ìƒì„± ì´ë¯¸ì§€<br>- $t$ : text prompt |
| $\lambda_{L2} \vert\vert M_t(w) \vert\vert_2$ | $M_t(w)$ ì— ëŒ€í•œ [L2 Loss](../../AI%20Basics/Deep%20Learning%20Basics/ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Regularization.md#2-l1-l2-regularization) **(ê°€ì¤‘ì¹˜: $\lambda_{L2}$)** |                                                                                                                                                                                |
| $\lambda_{ID} L_{ID} (w)$                     | ArcFace Network Loss **(ê°€ì¤‘ì¹˜: $\lambda_{ID}$)**                                                                                                | - Cosine Distance (Identity Loss)<br>- [Latent Optimization](#2-latent-optimization) ê³¼ ë™ì¼                                                                                      |

![image](../images/StyleCLIP_4.PNG)

**3. ì‹¤í—˜ ê²°ê³¼**

* ê° ì†ì„±ì— ëŒ€í•œ manipulation direction ê°„ì˜ ìƒê´€ê³„ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
* [Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) v3 ('25.05.26 - 06.05) ì˜ **StyleGAN-VectorFind-v8**](https://github.com/WannaBeSuperteur/AI_Projects/blob/main/2025_05_26_OhLoRA_v3/stylegan/stylegan_vectorfind_v8/image_generation_report.md) ë° [Oh-LoRA v3.1 ('25.06.07 - 06.13) ì˜ **StyleGAN-VectorFind-v9**](https://github.com/WannaBeSuperteur/AI_Projects/blob/main/2025_06_07_OhLoRA_v3_1/stylegan/stylegan_vectorfind_v9/image_generation_report.md) ë³´ë‹¤ëŠ” **ë‹¤ì†Œ ë‚®ì€ í¸** ì´ë‹¤.

![image](../images/StyleCLIP_5.PNG)

[(ì¶œì²˜)](https://arxiv.org/pdf/2103.17249) : Or Patashnik and Zongze Wu et al., "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery"

## 4. Global Directions

## 5. ì‹¤í—˜ ê²°ê³¼