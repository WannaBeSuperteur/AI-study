## 목차

* [1. StyleCLIP 의 핵심 아이디어](#1-styleclip-의-핵심-아이디어)
* [2. StyleCLIP 의 구성 요소](#2-styleclip-의-구성-요소)
* [3. Latent Optimization](#3-latent-optimization)
* [4. Latent Mapper](#4-latent-mapper)
* [5. Global Directions](#5-global-directions)
* [6. 실험 결과](#6-실험-결과)

## 논문 소개

* Or Patashnik and Zongze Wu et al., "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery", 2021
* [arXiv Link](https://arxiv.org/pdf/2103.17249)

## 1. StyleCLIP 의 핵심 아이디어

StyleCLIP 의 핵심 아이디어는 다음과 같다.

* Source Image → **mapping** (latent code $w$) → input ($w$ + **generated residuals**) to StyleGAN

| 핵심 아이디어                                                                       | 설명                                                                                                                     |
|-------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|
| **텍스트 기반** latent optimization                                                | CLIP 모델은 **loss network** 으로 사용됨                                                                                       |
| latent residual mapper                                                        | - 특정 text prompt 를 이용하여 학습됨<br>- 주어진 latent space 에 대해 'local step'을 생성                                                |
| **text prompt** 를 StyleGAN 의 style space 에 대한 **global direction** 으로 mapping | 'disentanglement' ([StyleGAN 논문](https://arxiv.org/pdf/1812.04948) 개념) 뿐만 아니라, **이미지 조작 (manipulation) 의 강도** 까지 조절 가능 |

## 2. StyleCLIP 의 구성 요소

## 3. Latent Optimization

## 4. Latent Mapper

## 5. Global Directions

## 6. 실험 결과