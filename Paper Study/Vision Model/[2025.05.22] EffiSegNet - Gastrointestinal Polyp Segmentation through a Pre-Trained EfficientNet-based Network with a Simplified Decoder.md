## 목차

* [1. EffiSegNet 의 구조](#1-effisegnet-의-구조)
  * [1-1. typical U-Net 구조의 문제점](#1-1-typical-u-net-구조의-문제점) 
  * [1-2. EffiSegNet 에서의 문제 해결 방법](#1-2-effisegnet-에서의-문제-해결-방법)
  * [1-3. Loss Function](#1-3-loss-function)
* [2. 실험 설정 및 결과](#2-실험-설정-및-결과)
  * [2-1. 실험 설정](#2-1-실험-설정)
  * [2-2. 실험 결과](#2-2-실험-결과)

## 논문 소개

* Ioannis A. Vezakis and Konstantinos Georgas et al., "EffiSegNet: Gastrointestinal Polyp Segmentation through a Pre-Trained EfficientNet-based Network with a Simplified Decoder", 2024
* [arXiv Link](https://arxiv.org/pdf/2407.16298v1)

## 1. EffiSegNet 의 구조

**1. 핵심 아이디어**

* EfficientNet image classifier 를 backbone (encoder) 으로 사용
* [U-Net](../../Image%20Processing/Model_U-Net.md) 에서 아이디어를 얻음
* **pre-trained parameter 의 비중이 최대한 높아지도록** 모델 구조 설계 → **computational overhead 감소**

**2. 모델 구조**

![image](../images/EffiSegNet_1.PNG)

[(출처)](https://arxiv.org/pdf/2407.16298v1) : Ioannis A. Vezakis and Konstantinos Georgas et al., "EffiSegNet: Gastrointestinal Polyp Segmentation through a Pre-Trained EfficientNet-based Network with a Simplified Decoder"

| 구성 요소                        | 상태          | 설명                                                                                                                                                                                     |
|------------------------------|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| EfficientNet Modules         | Pre-trained | - backbone network<br>- end 로 갈수록 resolution 이 작아지고 channel 이 많아짐<br>- 각 모듈에서 출력된 정보를 **element-wise 하게 add 하여 Ghost Module 로 전달**                                                     |
| Ghost Module                 |             | - **feature fusion** 용으로 사용<br>- **제한된 숫자의** 파라미터 및 연산을 통해 **많은 feature map 을 효과적으로 생성** → **non-pretrained params 를 줄이는** 데 기여                                                        |
| 3x3 2D Conv (to 32 channels) |             | - [U-Net 의 메모리 및 계산량 감소 목적](#1-2-effisegnet-에서의-문제-해결-방법)                                                                                                                              |
| 1x1 2D Conv (to H x W x 1)   |             | - 최종 레이어에 해당<br>- 직후의 [활성화 함수](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_활성화_함수.md) 는 [Sigmoid](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_활성화_함수.md#2-1-sigmoid-함수) 함수 |

**3. EffiSegNet 모델 별 파라미터 개수**

* B0 에서 B7 로 갈수록 전체 파라미터 수가 늘어난다.
* 이때 **Pre-trained params 가 더 빠른 속도로** 늘어나므로, **Random init params 의 비율은 감소 추세** 가 된다.

![image](../images/EffiSegNet_2.PNG)

[(출처)](https://arxiv.org/pdf/2407.16298v1) : Ioannis A. Vezakis and Konstantinos Georgas et al., "EffiSegNet: Gastrointestinal Polyp Segmentation through a Pre-Trained EfficientNet-based Network with a Simplified Decoder"

### 1-1. typical U-Net 구조의 문제점

**1. [U-Net](../../Image%20Processing/Model_U-Net.md) 의 프로세스**

* U-Net 프로세스
  * 먼저 **feature map 이 channel dimension 에 맞게 upsample → concatenate** 되고,
  * 이렇게 합쳐진 feature map 들은 **이어지는 Conv. Layer 에서 refine** 된다.
* 수식
  * $\overline{x}(s) = F_s(concat(x_s, up(x_{s+1})))$
* 수식 설명

| notation       | 설명                                                                                       |
|----------------|------------------------------------------------------------------------------------------|
| $s$ (stage)    | feature map 의 신경망에서의 위치를 나타내는 'level'<br>- EffiSegNet 구조 그림에서 각 EfficientNet Module 에 해당 |
| $x_s$          | stage $s$ 의 output feature map                                                           |
| $x_{s+1}$      | 다음 stage 의 output feature map                                                            |
| $F_s(·)$       | **여러 개의 Convolutional Layer 의 stack 을 하나의 module 로 나타낸 것**                               |
| $up(·)$        | upsampling (dimension 을 2배로 증가)                                                          |
| $concat(·, ·)$ | concatenation (2개의 feature map 에 대한)                                                     |

**2. U-Net 프로세스의 문제점**

* 위 수식과 같은 feature fusion 은 **메모리 및 계산량이 많다.**

### 1-2. EffiSegNet 에서의 문제 해결 방법

**1. U-Net 문제점 해결 방법 요약**

* 여러 개의 Conv. Layer 대신 **1개의 Simple Conv. Layer** → [Batch Normalization](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Regularization.md#4-1-batch-normalization) → Nearest Neighbor (NN) interpolation 을 통한 upsampling
* 최적의 channel 개수는 32
* EffiSegNet 구조 그림의 **3x3 2D Conv. to 32 channels** 에 해당

**2. 수식 및 그 설명**

* 수식
  * $\displaystyle \overline{x}(s) = \Sigma_{s=1}^n up(F_s(x_s)) + F_0(x_0)$ 
* 수식 설명

| notation | 설명                                                             |
|----------|----------------------------------------------------------------|
| $n$      | network depth ($n = 5$ for EfficientNet)                       |
| $F_s(·)$ | **3x3 2D Convolution layer, to 32 channels (1개의 Conv. Layer)** |
| $up(·)$  | upsampling (dimension 을 2배로 증가)                                |

### 1-3. Loss Function

* [Dice Loss](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Loss_function.md#2-7-dice-loss) 와 [Cross-Entropy Loss](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Loss_function.md#2-5-categorical-cross-entropy-loss) 의 평균값을 이용
  * 즉 **이 2가지의 Loss 를 모두 고려한 종합적인 Loss Function** 을 사용
* 각 Loss Term 의 용도

| Loss Term          | 용도                                                                                           |
|--------------------|----------------------------------------------------------------------------------------------|
| Dice Loss          | - binary value 로 주어지는 Segmentation 영역의 정답 레이블에 대한 정확도 향상<br>- 즉, **Segmentation 영역의 정확한 도출** |
| Cross-Entropy Loss | - Multi-Class Segmentation 에서, **주어진 픽셀을 알맞은 Class 로 분류** 하는 정확도 향상                          |

## 2. 실험 설정 및 결과

### 2-1. 실험 설정

### 2-2. 실험 결과