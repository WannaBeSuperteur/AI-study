
## 목차

* [1. Traditional vs. LVLM-driven OCR](#1-traditional-vs-lvlm-driven-ocr)
  * [1-1. 전통적인 OCR 방법](#1-1-전통적인-ocr-방법)
  * [1-2. LVLM-driven OCR 방법](#1-2-lvlm-driven-ocr-방법)
* [2. General OCR Theory 프레임워크의 핵심 아이디어](#2-general-ocr-theory-프레임워크의-핵심-아이디어)
  * [2-1. 상세 학습 과정](#2-1-상세-학습-과정) 
* [3. General OCR Theory 상세 - Vision Encoder 사전학습](#3-general-ocr-theory-상세---vision-encoder-사전학습)
* [4. General OCR Theory 상세 - Multi-task Joint Training을 통한 OCR-2.0의 지식 스케일업](#4-general-ocr-theory-상세---multi-task-joint-training을-통한-ocr-20의-지식-스케일업)
  * [4-1. Joint-training을 위한 데이터 수집](#4-1-joint-training을-위한-데이터-수집)
  * [4-2. Decoder Post-training을 통한 OCR feature 커스터마이징](#4-2-decoder-post-training을-통한-ocr-feature-커스터마이징)
* [5. 실험 결과](#5-실험-결과)
  * [5-1. 실험 설정 상세](#5-1-실험-설정-상세)
  * [5-2. Plain/Formatted Document 에서의 OCR 성능](#5-2-plainformatted-document-에서의-ocr-성능)
  * [5-3. Scene Text 에서의 OCR 성능](#5-3-scene-text-에서의-ocr-성능)
  * [5-4. Fine-grained OCR 성능](#5-4-fine-grained-ocr-성능)
  * [5-5. 보다 다양한 OCR 성능](#5-5-보다-다양한-ocr-성능)

## 논문 소개

* Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model", 2024
* [arXiv Link](https://arxiv.org/pdf/2409.01704)

## 1. Traditional vs. LVLM-driven OCR

기존의 전통적인 OCR 방법과 LVLM (Large Vision-Language Model) 에 의한 OCR 방법의 핵심 차이점은 다음과 같다.

|       | 기존 OCR 방법                                                                     | LVLM 기반 OCR 방법                                                                                            |
|-------|-------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| 이름    | OCR-1.0                                                                       | OCR-2.0                                                                                                   |
| 핵심 모듈 | 여러 개의 전문가 모듈                                                                  | frozen CLIP Encoder                                                                                       |
| 문제점   | - 여러 개의 전문가 모듈로 인한 시스템 오류, 높은 유지 비용 등<br>- **특정 sub-task 에 최적화** 되어 일반화 성능 부족 | - vanilla CLIP 모델이 **out-of-domain OCR task** 에서의 OCR 성능 bottleneck 으로 작용<br>- frozen LLM 사용 시, 문자 압축률 낮음 |
| 해결 방법 |                                                                               | - (문자 압축률 문제 해결 방법) **sliding window** 방법으로 입력 이미지를 작은 patch 로 분해                                         |

### 1-1. 전통적인 OCR 방법

기존의 전통적인 OCR 방법은 **OCR-1.0** 이라고 하며, 다음과 같은 특징이 있다.

* 여러 개의 **expert module (전문가 모듈)** 로 구성
  * 전문가 모듈에는 layout analysis, text detection, region extraction 등을 독립적으로 수행하는 각각의 모듈 존재
  * 이와 같이 여러 개의 모듈을 사용하는 이유는 **텍스트 인식 모듈 단독으로는 인식에 실패하는 경우가 많기** 때문
  * 한편, 이와 같이 여러 개의 모듈로 구성된 복잡한 프로세스는 **시스템 오류가 있고, 유지 비용이 높을 수 있음**
* **특정한 sub-task에 최적화** 된 구성
  * 즉, **일반화 성능 (general ability)** 이 부족함 

### 1-2. LVLM-driven OCR 방법

**LVLM (Large Vision-Language Model)** 기반의 OCR 방법은 **OCR-2.0** 이라고 하며, 다음과 같은 특징이 있다.

* 인식 및 추론 관련 **종합적 역량** 을 보유하고 있음
* 대부분의 LVLM 은 **frozen CLIP Encoder 모델** 이 OCR 성능의 핵심 요인
  * 이러한 모델에서 **out-of-domain task** 에 대한 OCR 성능의 bottleneck 은 보통 **vanilla CLIP 모델** 임
  * 일부 LVLM 에서는 **encoder 를 학습 가능하게 하고 LLM 을 freeze 시키는** 형태로 구성
    * 이를 통해 CLIP encoder 의 성능을 향상시킴
* frozen LLM 사용 시, 문제점 및 해결 방법

| 구분    | 설명                                                                                                                        |
|-------|---------------------------------------------------------------------------------------------------------------------------|
| 문제점   | 문자 압축률이 낮음 (low optical character compression rate)<br>- 이는 frozen LLM 이 **image token 으로부터 많은 양의 텍스트를 decode 하기 어렵기** 때문 |
| 해결 방법 | **sliding window** 를 이용하여 입력 이미지를 **작은 patch 로 분해**                                                                       |

## 2. General OCR Theory 프레임워크의 핵심 아이디어

**General OCR Theory (GOT)** 프레임워크는 다음과 같이 **image encoder, linear layer, output decoder 의 3가지 모듈** 로 구성되어 있다.

| 모듈                                  | 설명                                                                        |
|-------------------------------------|---------------------------------------------------------------------------|
| image encoder (= Vision Encoder)    | 본 논문에서는 **VitDet** 을 사용                                                   |
| linear layer                        | **Vision Encoder** 와 **Language Decoder** 사이의 channel dimension 을 mapping |
| output decoder (= Language Decoder) | 언어 모델                                                                     |

![image](../images/GeneralOCRTheory_1.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

### 2-1. 상세 학습 과정

**General OCR Theory (GOT)** 프레임워크의 상세 학습 과정은 다음과 같다.

| 단계                             | 설명                                                                                                                                                                                                               |
|--------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Pre-training Vision Encoder    | **순수한 텍스트 인식 task** 에 대해 Vision Encoder 를 Pre-training<br>- 이때, **효율적인 학습** 을 위해 encoder 로 gradient 를 전달하기 위한 **아주 작은 decoder** 를 사용<br>- 이때, Vision Encoder 가 문자 인코딩을 하는 능력을 얻게 하기 위해 **텍스트와 문자를 포함한 이미지** 로 학습 |
| Joint-training Encoder-Decoder | 학습된 Vision Encoder 와 새로 만들어진 큰 Decoder 를 연결하여 **GOT 구조 완성**<br>- 이때 **더 다양한 종류의** OCR 학습 데이터를 사용                                                                                                                 |
| Post-training Language Decoder | GOT 모델의 **일반화 성능 향상**<br>- Fine-grained & Multi-crop/page synthetic data 등을 학습 데이터로 추가<br>- region prompt OCR 등 다양한 케이스 대응                                                                                       |

## 3. General OCR Theory 상세 - Vision Encoder 사전학습

여기서는 **OCR 전용 Vision Encoder를 사전학습** 하는 것에 대해 다룬다.

* **General OCR Theory** 에서는 Vision Encoder 구조로 **VitDet 의 80M param version** 을 사용한다.
  * 그 이유는 **local attention 을 통해 고해상도 이미지에 대한 계산량을 줄일** 수 있기 때문이다.
  * Encoder의 마지막 2개 레이어에 대해서는 다음과 같은 **Vary-tiny Setting** 구조를 적용한다.

![image](../images/GeneralOCRTheory_2.PNG)

* 학습 데이터 구성

![image](../images/GeneralOCRTheory_3.PNG)

## 4. General OCR Theory 상세 - Multi-task Joint Training을 통한 OCR-2.0의 지식 스케일업

* 내용 요약

| OCR 학습                | 사용 데이터                                                                                |
|-----------------------|---------------------------------------------------------------------------------------|
| Joint Training        | - **Plain OCR data (80%)**<br>- Mathpix-markdown formatted data<br>- General OCR data |
| Decoder Post-training | - Fine-grained data<br>- Multi-crop data<br>- Multi-page data                         |

### 4-1. Joint-training을 위한 데이터 수집

데이터를 수집하기 위한 **데이터 엔진** 을 사용하여 Joint-training 을 실시하는 이유는 다음과 같다.

* OCR-2.0 모델의 지식을 **General OCR Theory 프레임워크에 충분히 주입** 해야 하는데, 이때 **Plain OCR data 만으로는 부족** 하다.
* 따라서 이를 위해 **적절한 데이터 엔진 및 synthesis method** 가 필요하다.

![image](../images/GeneralOCRTheory_4.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

**데이터 분포**

| 데이터 유형                          | 데이터                       | 설명                                                                                                           |
|---------------------------------|---------------------------|--------------------------------------------------------------------------------------------------------------|
| Plain OCR data                  | Plain OCR data            | **전체의 80%** 비율                                                                                               |
| Mathpix-markdown formatted data | 수학 수식                     | **100만 개** 의 LaTeX 수학 수식 fragment 를 추출 → HTML 변환 → SVG 변환 → PNG로 저장                                          |
| Mathpix-markdown formatted data | 화학식                       | ```ChEMBL_25``` 파일에서 **200만 개** 의 데이터 확보                                                                     |
| Mathpix-markdown formatted data | 테이블 형태의 데이터               | 크롤링한 ```.tex``` 파일에서 **30만 개** 의 테이블 데이터를 확보하여 이미지로 변환                                                       |
| Mathpix-markdown formatted data | Full-page 데이터             | - **Nougat Method** 를 이용하여 **50만 개** 의 **영어** 마크다운 PDF 텍스트 데이터 확보<br>- 그 외에도 **50만 개** 의 **중국어** 마크다운 데이터 확보 |
| General OCR data                | Sheet Music (악보)          | ```GrandStaff``` 데이터셋에서 **50만 개** 데이터 확보                                                                     |
| General OCR data                | Geometric shape (기하학적 도형) | - **약 100만 개** 데이터 확보<br>- 기하학은 **LVLM이 AGI로 진행하기 위한 필수 요소**                                                 |
| General OCR data                | Chart (막대, 원그래프 등)        | - **약 200만 개** 데이터 확보<br>- 차트는 데이터 시각화 및 분석을 통한 연구에서 중요 요소                                                   |

### 4-2. Decoder Post-training을 통한 OCR feature 커스터마이징

* Decoder Post-Training 을 위해서 다음과 같은 종류의 데이터를 사용한다.

| 데이터 엔진                   | 사용 목적<br>(향상시키려는 OCR 기능) | 설명                                                                                           |
|--------------------------|--------------------------|----------------------------------------------------------------------------------------------|
| Fine-grained Data Engine | Interactive OCR          | 사용자 프롬프트가 **박스 좌표 / 색깔** 등을 포함하는 경우, **해당 region 에 대해 OCR을 실시** 해야 함                         |
| Multi-crop Data Engine   | Ultra-large-image OCR    | 2페이지의 horizontal PDF와 같이 **아주 큰 이미지** 에 대한 OCR 처리                                            |
| Multi-page Data Engine   | Batched PDF-file OCR     | - 여러 페이지의 데이터를 처리하기 위한 **일종의 "for loop"** 를 OCR task 에 적용<br>- 이를 위해 **페이지 나누기 판단** 을 잘 해야 함 |

## 5. 실험 결과

* 실험 결과 요약
  * **Plain Text, Scene Text** 에서, 대부분의 경우에 대해 General OCR Theory (GOT) 성능이 **다른 모든 Method 보다 좋다.**
  * **Fine-grained OCR** 등 보다 다양한 OCR task 에서도 GOT Method 의 성능이 가장 좋다.
  * **Formatted Document** 의 경우, **"Markdown All Text & General (Sheet music & Geometry)" > "Formula & Table"** 순으로 성능이 좋다.

### 5-1. 실험 설정 상세

* 본 실험에서의 실험 설정은 다음과 같다.

| 실험 설정                                                                                                   | 설정값                                                                                                                                           |
|---------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| GPU                                                                                                     | **8 x 8 L40s** GPU                                                                                                                            |
| global batch size                                                                                       | **128**                                                                                                                                       |
| train epochs                                                                                            | **3** epochs                                                                                                                                  |
| [Optimizer](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Optimizer.md)                             | [**AdamW** Optimizer](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Optimizer.md#2-3-adamw)                                               |
| [Learning Rate](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Learning_Rate.md)                     | **0.0001** (= 1e-4)<br>(**beginning** learning rate at **Post-Training** stage : **0.00002** (= 2e-5))                                        | 
| [Learning Rate Scheduler](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Learning_Rate_Scheduler.md) | [**Cosine Annealing** Scheduler](../../AI%20Basics/Deep%20Learning%20Basics/딥러닝_기초_Learning_Rate_Scheduler.md#2-6-cosine-annealing-scheduler) |
| max token length                                                                                        | - Joint Training : **6,000** (= 6K)<br>- Post-Training : **8,192** (= 8K) (for multi-patch/page OCR)                                          |

* 각 train-data process 에서, **새로운 feature 추가 시에도 모델의 기본 성능이 저하되지 않게** 하기 위해 **80%의 데이터는 다음 stage 에서 사용** 된다.

### 5-2. Plain/Formatted Document 에서의 OCR 성능

* **Plain** Document 에서의 OCR 성능
  * 대부분의 경우에서, General OCR Theory 성능이 **다른 모든 Method 보다 좋다.**

![image](../images/GeneralOCRTheory_5.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

* **Formatted** Document 에서의 OCR 성능
  * **"Markdown All Text & General (Sheet music & Geometry)" > "Formula & Table"** 순으로 성능이 좋다.

![image](../images/GeneralOCRTheory_6.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

### 5-3. Scene Text 에서의 OCR 성능

* **Scene Text** 에서의 OCR 성능
  * **Plain Text** 에서와 마찬가지로, 대부분의 경우에서 General OCR Theory 성능이 **다른 모든 Method 보다 좋다.**

![image](../images/GeneralOCRTheory_5.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

### 5-4. Fine-grained OCR 성능

* **Fine-grained OCR** 에서의 OCR 성능
  * 모든 Metric 에 대해서 General OCR Theory 성능이 **다른 모든 Method 보다 좋다.**

![image](../images/GeneralOCRTheory_8.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"

### 5-5. 보다 다양한 OCR 성능

* 모든 벤치마크 데이터셋 & Metric 에 대해서 General OCR Theory 성능이 **다른 모든 Method 보다 좋다.**

![image](../images/GeneralOCRTheory_9.PNG)

[(출처)](https://arxiv.org/pdf/2409.01704) : Haoran Wei and Chenglong Liu et al., "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model"
