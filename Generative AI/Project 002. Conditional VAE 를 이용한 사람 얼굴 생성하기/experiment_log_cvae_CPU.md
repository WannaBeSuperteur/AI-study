## 실험 개요
* 실험 조건
  * 기본 설정 
    * **first 2,976 images / 16 epochs**
    * **CPU에서 작동**
  * learning rate 설정
    * 초기값 **0.0002**
    * epoch 4 이후 매 epoch 마다 **0.99 배**
    * 최종적으로 learning rate가 **0.0001 미만** 이 되면 learning rate 감소 멈춤
* 용어 설명
  * HIDDEN_DIMS : latent vector 차원 개수
  * MSE loss weight : KL loss의 weight에 대한 reconstruction loss의 weight의 비중
  * info : Conditional VAE의 condition에 해당하는 값으로, **성별 정보, hair color, mouth (입을 벌린 정도), eyes (눈을 뜬 정도)** 로 구성

## MODEL 15 (2024.04.10 18시)
* 직전 모델과의 차이점 : **MSE Loss weight 을 1.0 으로 적용**
* HIDDEN_DIMS : **48**
* MSE loss weight : **1.0**
* 최종 loss : **0.0725**

```
2024-04-10 18:25:15.917736: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 208s 70ms/sample - loss: 2.0965 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.3255 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.2384 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1909 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1609 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.1394 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1240 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.1119 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 0.1028 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.0958 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.0897 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.0851 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.0811 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 0.0779 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.0752 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 233s 78ms/sample - loss: 0.0725 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/eb9b7336-9f0d-4511-9526-39dd2c1f78c0)

## MODEL 14 (2024.04.10 16시)
* 직전 모델과의 차이점 : **HIDDEN_DIM 을 48 로 적용**
* HIDDEN_DIMS : **48**
* MSE loss weight : **2.0**
* 최종 loss : **0.1167**

```
2024-04-10 16:39:58.092962: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 213s 72ms/sample - loss: 1.3411 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 229s 77ms/sample - loss: 0.3855 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.2890 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 229s 77ms/sample - loss: 0.2346 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 0.2010 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 0.1783 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1627 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 0.1518 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.1434 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.1371 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 0.1322 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1279 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 0.1247 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 0.1217 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 0.1189 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 219s 73ms/sample - loss: 0.1167 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/262df59d-fed9-4749-929a-695223c41040)

## MODEL 13 (2024.04.10 13시)
* 직전 모델과의 차이점 : **MSE Loss weight 을 2.0 으로 적용**
* HIDDEN_DIMS : **30**
* MSE loss weight : **2.0**
* 최종 loss : **0.1241**

```
2024-04-10 13:43:01.725611: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 210s 71ms/sample - loss: 3.1100 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 0.3759 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.2980 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 247s 83ms/sample - loss: 0.2516 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 0.2205 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 228s 77ms/sample - loss: 0.1984 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 225s 75ms/sample - loss: 0.1815 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 225s 76ms/sample - loss: 0.1687 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 0.1586 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.1507 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 0.1440 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 222s 74ms/sample - loss: 0.1386 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 0.1341 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1303 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.1270 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.1241 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/17bb15db-4136-4b96-8934-bc49b7932aeb)

## MODEL 12 (2024.04.10 12시)
* 직전 모델과의 차이점 : **HIDDEN_DIM 을 30 으로 적용**
* HIDDEN_DIMS : **30**
* MSE loss weight : **5**
* 최종 loss : **0.2514**

```
2024-04-10 12:06:07.334532: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 213s 72ms/sample - loss: 1.5586 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 227s 76ms/sample - loss: 0.5541 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.4663 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 0.4052 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.3628 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 225s 75ms/sample - loss: 0.3327 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 0.3112 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 0.2954 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.2845 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.2752 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.2693 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.2643 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 222s 74ms/sample - loss: 0.2598 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 0.2567 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 233s 78ms/sample - loss: 0.2539 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.2514 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/d65a91f3-4acb-4103-b2d6-64f4d93a984d)

## MODEL 11 (2024.04.10 10시)
* 직전 모델과의 차이점 : **MSE Loss weight 을 5로 적용**
* HIDDEN_DIMS : **40**
* MSE loss weight : **5**
* 최종 loss : **0.2574**

```
2024-04-10 10:49:02.870705: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 212s 71ms/sample - loss: 2.0138 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 0.5672 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 0.4755 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 230s 77ms/sample - loss: 0.4144 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 229s 77ms/sample - loss: 0.3721 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 230s 77ms/sample - loss: 0.3425 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 225s 76ms/sample - loss: 0.3205 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 232s 78ms/sample - loss: 0.3053 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 249s 84ms/sample - loss: 0.2939 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 228s 77ms/sample - loss: 0.2841 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 245s 82ms/sample - loss: 0.2774 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 227s 76ms/sample - loss: 0.2717 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 227s 76ms/sample - loss: 0.2668 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 227s 76ms/sample - loss: 0.2630 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 0.2599 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 228s 77ms/sample - loss: 0.2574 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/8f659d7c-04eb-4812-bf74-165383d38238)

## MODEL 10 (2024.04.10 9시)
* 직전 모델과의 차이점 : **HIDDEN_DIM 을 80 으로 적용**
* HIDDEN_DIMS : **80**
* MSE loss weight : **100**
* 최종 loss : **4.7952**

```
2024-04-10 09:40:14.184747: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 12.5805 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 240s 81ms/sample - loss: 5.8773 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 236s 79ms/sample - loss: 5.5089 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 238s 80ms/sample - loss: 5.3291 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 238s 80ms/sample - loss: 5.1813 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 244s 82ms/sample - loss: 5.1705 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 241s 81ms/sample - loss: 5.0934 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 238s 80ms/sample - loss: 5.0061 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 238s 80ms/sample - loss: 4.9759 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 236s 79ms/sample - loss: 4.9186 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 237s 80ms/sample - loss: 4.9246 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 237s 80ms/sample - loss: 4.8627 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 237s 80ms/sample - loss: 4.8363 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 237s 80ms/sample - loss: 4.8238 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 248s 83ms/sample - loss: 4.8166 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 242s 81ms/sample - loss: 4.7952 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/1364618a-2761-4b32-8079-29be454c97f9)

## MODEL 9 (2024.04.10 1시)
* 직전 모델과의 차이점 : **latent vector를 "각각 info와 함께" decoder의 모든 레이어로 전달**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.6327**

```
2024-04-10 01:31:27.072230: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 209s 70ms/sample - loss: 11.5517 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.5926 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 5.2818 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 5.1826 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 5.0530 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 5.0179 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 219s 74ms/sample - loss: 4.9562 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 4.9254 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 4.8664 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.8055 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.7541 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.7736 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.7324 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.6769 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.6939 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 4.6327 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/21ef14b0-2787-42ed-a7c3-0cbf90c6a59f)

## MODEL 8 (2024.04.10 0시)
* 직전 모델과의 차이점 : **latent vector를 decoder의 모든 레이어로 전달**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.8037**

```
2024-04-10 00:19:57.012911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 13.5682 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 6.0757 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 226s 76ms/sample - loss: 5.6681 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.4658 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.3384 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.2723 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 224s 75ms/sample - loss: 5.1622 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.1231 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 5.0514 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 5.0000 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 231s 78ms/sample - loss: 4.9971 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 225s 76ms/sample - loss: 4.9581 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 4.9198 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 222s 75ms/sample - loss: 4.8544 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 221s 74ms/sample - loss: 4.8287 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 4.8037 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/c0cff02b-7bcd-4444-9233-f40404b76d9f)

## MODEL 7 (2024.04.07 22시)
* 직전 모델과의 차이점 : **encoder의, latent vector로 연결되는 마지막 dense layer에 activation 추가**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.8944**

```
2024-04-07 22:36:40.373063: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 205s 69ms/sample - loss: 13.6085 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 6.3185 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 229s 77ms/sample - loss: 5.9087 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 228s 77ms/sample - loss: 5.6666 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 239s 80ms/sample - loss: 5.4786 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 241s 81ms/sample - loss: 5.3713 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 206s 69ms/sample - loss: 5.2733 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 195s 66ms/sample - loss: 5.2235 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 192s 64ms/sample - loss: 5.1661 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 193s 65ms/sample - loss: 5.1076 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 195s 65ms/sample - loss: 5.0501 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 192s 64ms/sample - loss: 4.9975 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 191s 64ms/sample - loss: 4.9523 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 190s 64ms/sample - loss: 4.9602 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 191s 64ms/sample - loss: 4.9162 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 192s 65ms/sample - loss: 4.8944 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/7bfd2916-f9cb-4afb-ab79-b5520adfdc2b)

## MODEL 6 (2024.04.07 21시)
* 직전 모델과의 차이점 : **info를 encoder의 모든 레이어 및 encoder의 최종 concatenate layer로 전달**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.9354**

```
2024-04-07 21:29:01.195765: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 277s 93ms/sample - loss: 14.7479 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 253s 85ms/sample - loss: 6.3923 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 242s 81ms/sample - loss: 5.9616 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 235s 79ms/sample - loss: 5.6729 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 217s 73ms/sample - loss: 5.4910 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 211s 71ms/sample - loss: 5.4110 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 205s 69ms/sample - loss: 5.3089 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 215s 72ms/sample - loss: 5.2543 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 231s 78ms/sample - loss: 5.2357 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 220s 74ms/sample - loss: 5.1590 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 214s 72ms/sample - loss: 5.1166 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 234s 79ms/sample - loss: 5.0633 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 223s 75ms/sample - loss: 5.0241 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 217s 73ms/sample - loss: 4.9840 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 216s 73ms/sample - loss: 4.9520 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 230s 77ms/sample - loss: 4.9354 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/fd659d13-2cd3-4f64-b160-f4eba585119c)

## MODEL 5 (2024.04.07 20시)
* 직전 모델과의 차이점 : **info를 encoder의 모든 레이어로 전달**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.9236**

```
2024-04-07 20:03:09.950116: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 174s 58ms/sample - loss: 14.4955 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 196s 66ms/sample - loss: 6.3566 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 192s 65ms/sample - loss: 5.9037 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 197s 66ms/sample - loss: 5.6259 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 192s 64ms/sample - loss: 5.4734 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 192s 64ms/sample - loss: 5.4035 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 192s 65ms/sample - loss: 5.3094 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 194s 65ms/sample - loss: 5.2284 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 192s 65ms/sample - loss: 5.1586 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 194s 65ms/sample - loss: 5.1321 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 204s 69ms/sample - loss: 5.0941 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 210s 71ms/sample - loss: 5.0535 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 196s 66ms/sample - loss: 5.0025 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 214s 72ms/sample - loss: 4.9507 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 207s 69ms/sample - loss: 4.9401 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 208s 70ms/sample - loss: 4.9236 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/071ad1b5-f0ae-448d-ad2a-b1b8af2c5824)

## MODEL 4 (2024.04.07 12시)
* 직전 모델과의 차이점 : **Conv, Deconv 의 Kernel size 를 3x3 -> 4x4 로 증가**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.9574**

```
INCREMENT PARAMS + Conv, Deconv 3x3 -> 4x4
2024-04-07 12:06:52.092280: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 169s 57ms/sample - loss: 14.7040 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 184s 62ms/sample - loss: 6.3789 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 186s 63ms/sample - loss: 5.9288 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 188s 63ms/sample - loss: 5.6765 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 184s 62ms/sample - loss: 5.4955 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.4036 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.3260 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.2598 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.2130 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.1476 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 186s 62ms/sample - loss: 5.1172 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 184s 62ms/sample - loss: 5.0636 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 5.0302 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 184s 62ms/sample - loss: 4.9812 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 185s 62ms/sample - loss: 4.9642 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 186s 63ms/sample - loss: 4.9574 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/19945d6c-5b5b-4643-8999-ff97fb6ddad0)

## MODEL 3 (2024.04.07 11시)
* 직전 모델과의 차이점 : **모델의 각 layer의 파라미터 개수 증가**
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.9837**

```
2024-04-07 11:20:09.724261: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 135s 45ms/sample - loss: 16.8612 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 6.6041 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 6.0549 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 158s 53ms/sample - loss: 5.7869 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 158s 53ms/sample - loss: 5.6039 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 149s 50ms/sample - loss: 5.5000 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 5.4133 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 5.3421 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 150s 51ms/sample - loss: 5.2628 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 149s 50ms/sample - loss: 5.2348 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 150s 51ms/sample - loss: 5.1706 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 5.1286 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 155s 52ms/sample - loss: 5.1074 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 152s 51ms/sample - loss: 5.0642 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 151s 51ms/sample - loss: 5.0210 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 152s 51ms/sample - loss: 4.9837 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/e741b1d2-8dc6-489d-8247-95c7d90cd55b)

## MODEL 2 (2024.04.07 10시)
* 직전 모델과의 차이점 : **HIDDEN_DIMS 를 40 -> 256 으로 증가**
* HIDDEN_DIMS : **256**
* MSE loss weight : **100**
* 최종 loss : **5.0959**

```
2024-04-07 10:41:01.282913: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 114s 38ms/sample - loss: 17.9720 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 6.6432 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 127s 43ms/sample - loss: 6.1130 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 126s 42ms/sample - loss: 5.8594 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 124s 42ms/sample - loss: 5.7000 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.5899 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.4985 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.4041 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.3510 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 130s 44ms/sample - loss: 5.3141 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 127s 43ms/sample - loss: 5.2152 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.1896 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.1808 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 135s 45ms/sample - loss: 5.1261 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 5.1267 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 127s 43ms/sample - loss: 5.0959 - lr: 1.7728e-04
```

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/37660902-a1f4-4968-b823-48f1b4e97838)

## 기본 모델 (2024.04.07 01시)
* HIDDEN_DIMS : **40**
* MSE loss weight : **100**
* 최종 loss : **4.9777**

```
2024-04-07 00:34:40.907343: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/16
2976/2976 [==============================] - 111s 37ms/sample - loss: 16.6413 - lr: 2.0000e-04
Epoch 2/16
2976/2976 [==============================] - 125s 42ms/sample - loss: 6.4488 - lr: 2.0000e-04
Epoch 3/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.9380 - lr: 2.0000e-04
Epoch 4/16
2976/2976 [==============================] - 126s 42ms/sample - loss: 5.6942 - lr: 2.0000e-04
Epoch 5/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.5447 - lr: 1.9800e-04
Epoch 6/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.4459 - lr: 1.9602e-04
Epoch 7/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.3587 - lr: 1.9406e-04
Epoch 8/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.2837 - lr: 1.9212e-04
Epoch 9/16
2976/2976 [==============================] - 123s 41ms/sample - loss: 5.2024 - lr: 1.9020e-04
Epoch 10/16
2976/2976 [==============================] - 150s 51ms/sample - loss: 5.1951 - lr: 1.8830e-04
Epoch 11/16
2976/2976 [==============================] - 150s 50ms/sample - loss: 5.1479 - lr: 1.8641e-04
Epoch 12/16
2976/2976 [==============================] - 148s 50ms/sample - loss: 5.0783 - lr: 1.8455e-04
Epoch 13/16
2976/2976 [==============================] - 137s 46ms/sample - loss: 5.0514 - lr: 1.8270e-04
Epoch 14/16
2976/2976 [==============================] - 124s 42ms/sample - loss: 5.0056 - lr: 1.8088e-04
Epoch 15/16
2976/2976 [==============================] - 122s 41ms/sample - loss: 5.0103 - lr: 1.7907e-04
Epoch 16/16
2976/2976 [==============================] - 124s 42ms/sample - loss: 4.9777 - lr: 1.7728e-04
```

![test_image_mock_test](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/9bfc3f99-63b5-490e-b9b0-49158db31448)

## 실험 결론
* Model 7과 Model 8의 차이를 볼 때, 다음과 같은 **skip-connection과 유사한 구성** 이 C-VAE의 성능 향상에 도움이 된다.
  * Encoder의 모든 level의 layer 의 출력을 latent vector 직전의 concatenation 부분과 연결한다.
  * Decoder도 마찬가지로 latent vector를 모든 level의 layer로 전달한다.
* MSE Loss weight이 작아질수록 **이미지의 다양성이 떨어진다.**
  * 참고 : **$\beta$-VAE** (논문 : https://openreview.net/forum?id=Sy2fzU9gl)
  * 이미지의 다양성이 높을수록 C-VAE가 생성하는 이미지의 품질도 좋아질 것으로 추정된다.
