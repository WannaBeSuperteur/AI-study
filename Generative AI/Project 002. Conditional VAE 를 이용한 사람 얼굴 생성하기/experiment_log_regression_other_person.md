## 모델
```regression_other_person```

## 모델의 목적
이미지에 있는 인물 사진에 중심 인물 외의 다른 인물이 보이는지 판단한다.
* 0부터 1까지의 값
* ```1.0``` : 다른 인물의 얼굴이 보임, ```0.5``` : 다른 인물이 조금이라도 보임 (얼굴은 보이지 않음), ```0.0``` : 다른 인물이 보이지 않고 중심 인물만 보임

## 모델 학습 로그 (평균으로 수렴)
* 학습 설정
  * max epochs : **40 epochs**
  * 학습 데이터 개수 : 남성 1,000 장, 여성 1,000 장의 **총 2,000 장 이미지**
* 학습 결과 : 각 성별 평균값으로 예측했을 때에 비해 MSE 기준으로 오차가 **1.23배** 큼 **(평균으로 수렴)**
  * validation loss (MSE) : **0.0417**
  * 각 성별에 대해 평균값 (male: 0.0385, female: 0.0495) 으로 예측했을 때의 MSE (male: 0.0313, female: 0.0368) 의 평균값 : **0.0340** 

```
train input (gender prob)        : (2000, 2)
[[9.9998210e-01 1.7932965e-05]
 [9.1045230e-01 8.9547730e-02]
 [9.9990190e-01 9.8053760e-05]
 ...
 [1.3854587e-04 9.9986150e-01]
 [3.9756913e-09 1.0000000e+00]
 [4.5712350e-05 9.9995434e-01]]

train output                     : (2000, 1)
[[0.]
 [0.]
 [0.]
 ...
 [0.]
 [0.]
 [0.]]

Epoch 1/40
57/57 [==============================] - 16s 246ms/step - loss: 0.8278 - val_loss: 0.4294 - lr: 4.8000e-04
Epoch 2/40
57/57 [==============================] - 16s 273ms/step - loss: 0.2990 - val_loss: 0.2162 - lr: 4.8000e-04
Epoch 3/40
57/57 [==============================] - 17s 291ms/step - loss: 0.1628 - val_loss: 0.1321 - lr: 4.8000e-04
Epoch 4/40
57/57 [==============================] - 17s 299ms/step - loss: 0.1048 - val_loss: 0.1115 - lr: 4.8000e-04
Epoch 5/40
57/57 [==============================] - 18s 323ms/step - loss: 0.0781 - val_loss: 0.0721 - lr: 4.8000e-04
Epoch 6/40
57/57 [==============================] - 21s 360ms/step - loss: 0.0623 - val_loss: 0.0606 - lr: 4.8000e-04
Epoch 7/40
57/57 [==============================] - 20s 347ms/step - loss: 0.0539 - val_loss: 0.0559 - lr: 4.8000e-04
Epoch 8/40
57/57 [==============================] - 19s 338ms/step - loss: 0.0483 - val_loss: 0.0511 - lr: 4.8000e-04
Epoch 9/40
57/57 [==============================] - 20s 356ms/step - loss: 0.0445 - val_loss: 0.0542 - lr: 4.8000e-04
Epoch 10/40
57/57 [==============================] - 21s 363ms/step - loss: 0.0422 - val_loss: 0.0477 - lr: 4.8000e-04
Epoch 11/40
57/57 [==============================] - 20s 351ms/step - loss: 0.0410 - val_loss: 0.0465 - lr: 4.8000e-04
Epoch 12/40
57/57 [==============================] - 21s 360ms/step - loss: 0.0399 - val_loss: 0.0426 - lr: 4.8000e-04
Epoch 13/40
57/57 [==============================] - 21s 364ms/step - loss: 0.0389 - val_loss: 0.0420 - lr: 4.8000e-04
Epoch 14/40
57/57 [==============================] - 20s 356ms/step - loss: 0.0381 - val_loss: 0.0412 - lr: 4.8000e-04
Epoch 15/40
57/57 [==============================] - 21s 364ms/step - loss: 0.0378 - val_loss: 0.0411 - lr: 4.8000e-04
Epoch 16/40
57/57 [==============================] - 21s 372ms/step - loss: 0.0386 - val_loss: 0.0430 - lr: 4.8000e-04
Epoch 17/40
57/57 [==============================] - 20s 353ms/step - loss: 0.0372 - val_loss: 0.0430 - lr: 4.8000e-04
Epoch 18/40
57/57 [==============================] - 21s 360ms/step - loss: 0.0371 - val_loss: 0.0412 - lr: 1.2000e-04
Epoch 19/40
57/57 [==============================] - 20s 352ms/step - loss: 0.0369 - val_loss: 0.0406 - lr: 1.2000e-04
Epoch 20/40
57/57 [==============================] - 20s 355ms/step - loss: 0.0371 - val_loss: 0.0407 - lr: 1.2000e-04
Epoch 21/40
57/57 [==============================] - 20s 353ms/step - loss: 0.0361 - val_loss: 0.0442 - lr: 1.2000e-04
Epoch 22/40
57/57 [==============================] - 20s 351ms/step - loss: 0.0363 - val_loss: 0.0412 - lr: 3.0000e-05
Epoch 23/40
57/57 [==============================] - 20s 350ms/step - loss: 0.0364 - val_loss: 0.0419 - lr: 3.0000e-05
Epoch 24/40
57/57 [==============================] - 20s 354ms/step - loss: 0.0365 - val_loss: 0.0417 - lr: 7.5000e-06
Epoch 25/40
57/57 [==============================] - 20s 359ms/step - loss: 0.0363 - val_loss: 0.0417 - lr: 7.5000e-06
Epoch 26/40
57/57 [==============================] - 20s 354ms/step - loss: 0.0366 - val_loss: 0.0417 - lr: 1.8750e-06
Epoch 27/40
57/57 [==============================] - 21s 361ms/step - loss: 0.0365 - val_loss: 0.0417 - lr: 1.8750e-06
Epoch 28/40
57/57 [==============================] - 21s 364ms/step - loss: 0.0360 - val_loss: 0.0417 - lr: 4.6875e-07
Epoch 29/40
57/57 [==============================] - 21s 366ms/step - loss: 0.0363 - val_loss: 0.0417 - lr: 4.6875e-07
Model: "regression__other__person__model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 flatten (Flatten)           multiple                  0

 max_pooling (MaxPooling2D)  multiple                  0

 dropout (Dropout)           multiple                  0

 conv0L (Conv2D)             multiple                  896

 conv1L (Conv2D)             multiple                  9248

 conv2L (Conv2D)             multiple                  18496

 conv3L (Conv2D)             multiple                  73856

 conv0R (Conv2D)             multiple                  896

 conv1R (Conv2D)             multiple                  9248

 conv2R (Conv2D)             multiple                  18496

 conv3R (Conv2D)             multiple                  73856

 dense_0 (Dense)             multiple                  3408384

 dense_1 (Dense)             multiple                  32960

 dense_final (Dense)         multiple                  67

=================================================================
Total params: 3,646,403
Trainable params: 3,646,403
Non-trainable params: 0
_________________________________________________________________
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.
shape of train input (images - left side)  : (2000, 120, 20, 3)
shape of train input (images - right side) : (2000, 120, 20, 3)
shape of train input (gender prob)         : (2000, 2)
shape of train output                      : (2000, 1)
tf.Tensor(
[[0.0725787 ]
 [0.07772368]
 [0.08368353]
 [0.12341718]
 [0.11261249]
 [0.07859596]
 [0.07743949]
 [0.06956036]
 [0.11126577]
 [0.08256613]
 [0.08552401]
 [0.0867945 ]
 [0.08645363]
 [0.1149277 ]
 [0.06447506]
 [0.102539  ]
 [0.09789647]
 [0.08344387]
 [0.07387964]
 [0.10111997]
 [0.09831441]
 [0.07274536]
 [0.0952794 ]
 [0.09666979]
 [0.06781802]
 [0.09971881]
 [0.101798  ]
 [0.0991417 ]
 [0.09932333]
 [0.09974965]
 [0.08843687]
 [0.06485683]
 [0.10194091]
 [0.07558181]
 [0.07232898]
 [0.08281155]
 [0.10420721]
 [0.07412495]
 [0.09620806]
 [0.10252038]
 [0.07679196]
 [0.10721275]
 [0.07639091]
 [0.08382391]
 [0.10806636]], shape=(45, 1), dtype=float32)
```

맨 아래쪽의 ```tf.Tensor``` 부분의 **15개의 값 (모델 출력값) 이 서로 비슷하면, 모델 출력이 평균 등 특정 값으로 수렴** 했다는 의미이므로 **학습이 제대로 되지 않은 것** 이다.