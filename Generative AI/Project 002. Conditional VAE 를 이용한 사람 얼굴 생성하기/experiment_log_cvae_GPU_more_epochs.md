각 모델에 대한 자세한 정보는 ```experiment_log_cvae_GPU.md``` 파일 참고.

## MODEL 28, 29, 30 차이점

||MODEL 28|MODEL 29|MODEL 30|
|---|---|---|---|
|HIDDEN_DIMS|231|231|149|
|decoder 60 x 60, 120 x 120 feature direct connection|O|X|O|

## MODEL 30
**학습 로그**
```
Epoch 1/60
2024-04-21 14:54:49.338377: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8907
2024-04-21 14:54:50.293885: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
16864/16864 [==============================] - 130s 8ms/sample - loss: 4755.0363 - lr: 4.0000e-04
Epoch 2/60
16864/16864 [==============================] - 129s 8ms/sample - loss: 3360.1639 - lr: 4.0000e-04
Epoch 3/60
16864/16864 [==============================] - 130s 8ms/sample - loss: 3120.6261 - lr: 4.0000e-04
Epoch 4/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 2970.7720 - lr: 4.0000e-04
Epoch 5/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 2874.3569 - lr: 3.9000e-04
Epoch 6/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2788.2695 - lr: 3.8025e-04
Epoch 7/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2718.0864 - lr: 3.7074e-04
Epoch 8/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2663.5662 - lr: 3.6148e-04
Epoch 9/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2602.2131 - lr: 3.5244e-04
Epoch 10/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2558.6862 - lr: 3.4363e-04
Epoch 11/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2502.8397 - lr: 3.3504e-04
Epoch 12/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2456.4720 - lr: 3.2666e-04
Epoch 13/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2409.2965 - lr: 3.1849e-04
Epoch 14/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2367.0115 - lr: 3.1053e-04
Epoch 15/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2325.4493 - lr: 3.0277e-04
Epoch 16/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2286.2942 - lr: 2.9520e-04
Epoch 17/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2240.0588 - lr: 2.8782e-04
Epoch 18/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2200.0304 - lr: 2.8062e-04
Epoch 19/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2162.3508 - lr: 2.7361e-04
Epoch 20/60
16864/16864 [==============================] - 133s 8ms/sample - loss: 2122.2130 - lr: 2.6677e-04
Epoch 21/60
16864/16864 [==============================] - 133s 8ms/sample - loss: 2087.2146 - lr: 2.6010e-04
Epoch 22/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2049.2267 - lr: 2.5360e-04
Epoch 23/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 2011.4648 - lr: 2.4726e-04
Epoch 24/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1980.7810 - lr: 2.4108e-04
Epoch 25/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1944.9631 - lr: 2.3505e-04
Epoch 26/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1910.4221 - lr: 2.2917e-04
Epoch 27/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1875.5178 - lr: 2.2344e-04
Epoch 28/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1849.1796 - lr: 2.1786e-04
Epoch 29/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1822.5898 - lr: 2.1241e-04
Epoch 30/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1794.1397 - lr: 2.0710e-04
Epoch 31/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1768.3969 - lr: 2.0192e-04
Epoch 32/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1745.7649 - lr: 1.9687e-04
Epoch 33/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1717.9128 - lr: 1.9195e-04
Epoch 34/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1698.0928 - lr: 1.8715e-04
Epoch 35/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1676.6619 - lr: 1.8247e-04
Epoch 36/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1654.5372 - lr: 1.7791e-04
Epoch 37/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1635.0138 - lr: 1.7347e-04
Epoch 38/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1610.0323 - lr: 1.6913e-04
Epoch 39/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1594.5154 - lr: 1.6490e-04
Epoch 40/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1572.3686 - lr: 1.6078e-04
Epoch 41/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1555.6286 - lr: 1.5676e-04
Epoch 42/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1541.9175 - lr: 1.5284e-04
Epoch 43/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1523.9654 - lr: 1.4902e-04
Epoch 44/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1509.3555 - lr: 1.4529e-04
Epoch 45/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1493.9440 - lr: 1.4166e-04
Epoch 46/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1477.4304 - lr: 1.3812e-04
Epoch 47/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1465.1736 - lr: 1.3467e-04
Epoch 48/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1450.7437 - lr: 1.3130e-04
Epoch 49/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1441.3151 - lr: 1.2802e-04
Epoch 50/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1428.4416 - lr: 1.2482e-04
Epoch 51/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1418.2368 - lr: 1.2170e-04
Epoch 52/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1406.1589 - lr: 1.1865e-04
Epoch 53/60
16864/16864 [==============================] - 131s 8ms/sample - loss: 1396.6022 - lr: 1.1569e-04
Epoch 54/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1385.0001 - lr: 1.1280e-04
Epoch 55/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1375.3753 - lr: 1.0998e-04
Epoch 56/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1365.0408 - lr: 1.0723e-04
Epoch 57/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1356.3636 - lr: 1.0455e-04
Epoch 58/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1346.6184 - lr: 1.0193e-04
Epoch 59/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1339.0214 - lr: 9.9383e-05
Epoch 60/60
16864/16864 [==============================] - 132s 8ms/sample - loss: 1330.5528 - lr: 9.9383e-05
```

**Loss 그래프**

![cvae_train_result](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/cffb258f-ffeb-4dbd-8b5f-13d0917a42b1)

**60 epochs 생성 이미지**
* Final Loss : **1330.5528**

![생성이미지](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/45252dff-6c7d-4506-92d8-cd233606e32b)

**24 epochs 생성 이미지**
* Final Loss : **2007.7193**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/46a39880-724f-4f1b-8c71-5500affa3b2a)

## MODEL 29
### 학습 로그
**150 epochs 학습 로그**

```
Epoch 1/150
2024-04-21 18:34:05.871516: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8907
2024-04-21 18:34:06.809338: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
16864/16864 [==============================] - 98s 6ms/sample - loss: 4568.2323 - lr: 6.0000e-04
Epoch 2/150
16864/16864 [==============================] - 95s 6ms/sample - loss: 2959.6126 - lr: 6.0000e-04
Epoch 3/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 2727.5061 - lr: 6.0000e-04
Epoch 4/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 2610.1215 - lr: 6.0000e-04
Epoch 5/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2511.2128 - lr: 5.8050e-04
Epoch 6/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2442.6838 - lr: 5.6163e-04
Epoch 7/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2373.2536 - lr: 5.4338e-04
Epoch 8/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2321.5928 - lr: 5.2572e-04
Epoch 9/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2267.2470 - lr: 5.0863e-04
Epoch 10/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2211.1085 - lr: 4.9210e-04
Epoch 11/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2163.1721 - lr: 4.7611e-04
Epoch 12/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2112.9902 - lr: 4.6064e-04
Epoch 13/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2057.5322 - lr: 4.4567e-04
Epoch 14/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 2013.3071 - lr: 4.3118e-04
Epoch 15/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1968.0952 - lr: 4.1717e-04
Epoch 16/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1926.5999 - lr: 4.0361e-04
Epoch 17/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1882.8316 - lr: 3.9049e-04
Epoch 18/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1844.2137 - lr: 3.7780e-04
Epoch 19/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1802.4636 - lr: 3.6552e-04
Epoch 20/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1764.7975 - lr: 3.5364e-04
Epoch 21/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1729.5384 - lr: 3.4215e-04
Epoch 22/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1698.4840 - lr: 3.3103e-04
Epoch 23/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1668.1463 - lr: 3.2027e-04
Epoch 24/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1642.2701 - lr: 3.0986e-04
Epoch 25/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1613.7034 - lr: 2.9979e-04
Epoch 26/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1592.9619 - lr: 2.9605e-04
Epoch 27/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1572.2682 - lr: 2.9235e-04
Epoch 28/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1551.3216 - lr: 2.8869e-04
Epoch 29/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1537.2153 - lr: 2.8508e-04
Epoch 30/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1518.6548 - lr: 2.8152e-04
Epoch 31/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1500.8801 - lr: 2.7800e-04
Epoch 32/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1484.4955 - lr: 2.7452e-04
Epoch 33/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1472.3584 - lr: 2.7109e-04
Epoch 34/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1455.5277 - lr: 2.6770e-04
Epoch 35/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1442.4153 - lr: 2.6436e-04
Epoch 36/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1430.9583 - lr: 2.6105e-04
Epoch 37/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1419.8082 - lr: 2.5779e-04
Epoch 38/150
16864/16864 [==============================] - 96s 6ms/sample - loss: 1406.0128 - lr: 2.5457e-04
Epoch 39/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1394.2532 - lr: 2.5139e-04
Epoch 40/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1383.3148 - lr: 2.4824e-04
Epoch 41/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1372.1218 - lr: 2.4514e-04
Epoch 42/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1363.2609 - lr: 2.4208e-04
Epoch 43/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1351.9303 - lr: 2.3905e-04
Epoch 44/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1345.6589 - lr: 2.3606e-04
Epoch 45/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1335.6643 - lr: 2.3311e-04
Epoch 46/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1326.9456 - lr: 2.3020e-04
Epoch 47/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1317.7758 - lr: 2.2732e-04
Epoch 48/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1308.1048 - lr: 2.2448e-04
Epoch 49/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1301.2583 - lr: 2.2167e-04
Epoch 50/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1291.5315 - lr: 2.1890e-04
Epoch 51/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1285.6793 - lr: 2.1617e-04
Epoch 52/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1281.7713 - lr: 2.1346e-04
Epoch 53/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1273.0246 - lr: 2.1080e-04
Epoch 54/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1264.1846 - lr: 2.0816e-04
Epoch 55/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1256.9304 - lr: 2.0556e-04
Epoch 56/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1251.6267 - lr: 2.0299e-04
Epoch 57/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1245.1696 - lr: 2.0045e-04
Epoch 58/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1240.7262 - lr: 1.9795e-04
Epoch 59/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1234.5420 - lr: 1.9547e-04
Epoch 60/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1228.8393 - lr: 1.9303e-04
Epoch 61/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1223.1824 - lr: 1.9062e-04
Epoch 62/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1215.8008 - lr: 1.8823e-04
Epoch 63/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1209.7906 - lr: 1.8588e-04
Epoch 64/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1205.9459 - lr: 1.8356e-04
Epoch 65/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1201.1867 - lr: 1.8126e-04
Epoch 66/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1196.8105 - lr: 1.7900e-04
Epoch 67/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1191.0019 - lr: 1.7676e-04
Epoch 68/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1188.5791 - lr: 1.7455e-04
Epoch 69/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1181.8944 - lr: 1.7237e-04
Epoch 70/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1177.3844 - lr: 1.7021e-04
Epoch 71/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1173.5307 - lr: 1.6808e-04
Epoch 72/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1167.9763 - lr: 1.6598e-04
Epoch 73/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1165.3563 - lr: 1.6391e-04
Epoch 74/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1161.1559 - lr: 1.6186e-04
Epoch 75/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1157.3145 - lr: 1.5984e-04
Epoch 76/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1152.8596 - lr: 1.5784e-04
Epoch 77/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1149.1474 - lr: 1.5587e-04
Epoch 78/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1146.2111 - lr: 1.5392e-04
Epoch 79/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1141.7625 - lr: 1.5199e-04
Epoch 80/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1138.4678 - lr: 1.5009e-04
Epoch 81/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1133.8480 - lr: 1.4822e-04
Epoch 82/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1130.0544 - lr: 1.4636e-04
Epoch 83/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1127.2801 - lr: 1.4454e-04
Epoch 84/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1124.5246 - lr: 1.4273e-04
Epoch 85/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1120.8497 - lr: 1.4094e-04
Epoch 86/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1117.2685 - lr: 1.3918e-04
Epoch 87/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1114.7385 - lr: 1.3744e-04
Epoch 88/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1109.7079 - lr: 1.3572e-04
Epoch 89/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1108.1856 - lr: 1.3403e-04
Epoch 90/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1105.7787 - lr: 1.3235e-04
Epoch 91/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1103.3949 - lr: 1.3070e-04
Epoch 92/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1099.7167 - lr: 1.2906e-04
Epoch 93/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1096.4195 - lr: 1.2745e-04
Epoch 94/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1096.1956 - lr: 1.2586e-04
Epoch 95/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1091.7411 - lr: 1.2429e-04
Epoch 96/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1088.8564 - lr: 1.2273e-04
Epoch 97/150
16864/16864 [==============================] - 99s 6ms/sample - loss: 1086.3285 - lr: 1.2120e-04
Epoch 98/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1084.8682 - lr: 1.1968e-04
Epoch 99/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1082.6328 - lr: 1.1819e-04
Epoch 100/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1078.5742 - lr: 1.1671e-04
Epoch 101/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1076.1055 - lr: 1.1525e-04
Epoch 102/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1075.3195 - lr: 1.1381e-04
Epoch 103/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1071.9445 - lr: 1.1239e-04
Epoch 104/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1071.2659 - lr: 1.1098e-04
Epoch 105/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1067.4869 - lr: 1.0959e-04
Epoch 106/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1065.6247 - lr: 1.0822e-04
Epoch 107/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1063.1128 - lr: 1.0687e-04
Epoch 108/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1062.2260 - lr: 1.0554e-04
Epoch 109/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1060.2320 - lr: 1.0422e-04
Epoch 110/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1056.6962 - lr: 1.0291e-04
Epoch 111/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1055.1942 - lr: 1.0163e-04
Epoch 112/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1055.5654 - lr: 1.0036e-04
Epoch 113/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1052.5538 - lr: 9.9103e-05
Epoch 114/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1049.6643 - lr: 9.9103e-05
Epoch 115/150
16864/16864 [==============================] - 97s 6ms/sample - loss: 1048.9259 - lr: 9.9103e-05
Epoch 116/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1046.2663 - lr: 9.9103e-05
Epoch 117/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1045.7871 - lr: 9.9103e-05
Epoch 118/150
16864/16864 [==============================] - 104s 6ms/sample - loss: 1044.6204 - lr: 9.9103e-05
Epoch 119/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1042.0343 - lr: 9.9103e-05
Epoch 120/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1040.4665 - lr: 9.9103e-05
Epoch 121/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1040.6883 - lr: 9.9103e-05
Epoch 122/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1039.2617 - lr: 9.9103e-05
Epoch 123/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1037.6965 - lr: 9.9103e-05
Epoch 124/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1036.4590 - lr: 9.9103e-05
Epoch 125/150
16864/16864 [==============================] - 99s 6ms/sample - loss: 1035.2130 - lr: 9.9103e-05
Epoch 126/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1034.5669 - lr: 9.9103e-05
Epoch 127/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1033.4714 - lr: 9.9103e-05
Epoch 128/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1030.8762 - lr: 9.9103e-05
Epoch 129/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1030.6743 - lr: 9.9103e-05
Epoch 130/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1029.5315 - lr: 9.9103e-05
Epoch 131/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1028.5025 - lr: 9.9103e-05
Epoch 132/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1026.5739 - lr: 9.9103e-05
Epoch 133/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1027.4970 - lr: 9.9103e-05
Epoch 134/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1024.2527 - lr: 9.9103e-05
Epoch 135/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1023.1788 - lr: 9.9103e-05
Epoch 136/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1023.2885 - lr: 9.9103e-05
Epoch 137/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1022.7461 - lr: 9.9103e-05
Epoch 138/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1019.5384 - lr: 9.9103e-05
Epoch 139/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1019.7094 - lr: 9.9103e-05
Epoch 140/150
16864/16864 [==============================] - 99s 6ms/sample - loss: 1016.7765 - lr: 9.9103e-05
Epoch 141/150
16864/16864 [==============================] - 99s 6ms/sample - loss: 1018.4263 - lr: 9.9103e-05
Epoch 142/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1015.9573 - lr: 9.9103e-05
Epoch 143/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1015.1198 - lr: 9.9103e-05
Epoch 144/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1014.5123 - lr: 9.9103e-05
Epoch 145/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1012.8829 - lr: 9.9103e-05
Epoch 146/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1012.9850 - lr: 9.9103e-05
Epoch 147/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1010.6232 - lr: 9.9103e-05
Epoch 148/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1010.1878 - lr: 9.9103e-05
Epoch 149/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1008.7240 - lr: 9.9103e-05
Epoch 150/150
16864/16864 [==============================] - 98s 6ms/sample - loss: 1007.8428 - lr: 9.9103e-05
```

**60 epochs 학습 로그**
```
Epoch 1/60
2024-04-21 00:20:48.955028: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8907
2024-04-21 00:20:49.901253: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
16864/16864 [==============================] - 98s 6ms/sample - loss: 4586.3311 - lr: 6.0000e-04
Epoch 2/60
16864/16864 [==============================] - 96s 6ms/sample - loss: 2998.4116 - lr: 6.0000e-04
Epoch 3/60
16864/16864 [==============================] - 96s 6ms/sample - loss: 2765.0989 - lr: 6.0000e-04
Epoch 4/60
16864/16864 [==============================] - 97s 6ms/sample - loss: 2640.8741 - lr: 6.0000e-04
Epoch 5/60
16864/16864 [==============================] - 97s 6ms/sample - loss: 2546.9036 - lr: 5.8050e-04
Epoch 6/60
16864/16864 [==============================] - 101s 6ms/sample - loss: 2464.8724 - lr: 5.6163e-04
Epoch 7/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2398.8944 - lr: 5.4338e-04
Epoch 8/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2335.2740 - lr: 5.2572e-04
Epoch 9/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2280.4274 - lr: 5.0863e-04
Epoch 10/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2224.9886 - lr: 4.9210e-04
Epoch 11/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2172.2823 - lr: 4.7611e-04
Epoch 12/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2117.0965 - lr: 4.6064e-04
Epoch 13/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2072.7761 - lr: 4.4567e-04
Epoch 14/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 2018.3441 - lr: 4.3118e-04
Epoch 15/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1972.2839 - lr: 4.1717e-04
Epoch 16/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1923.4866 - lr: 4.0361e-04
Epoch 17/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1881.6224 - lr: 3.9049e-04
Epoch 18/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1841.0156 - lr: 3.7780e-04
Epoch 19/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1805.0519 - lr: 3.6552e-04
Epoch 20/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1765.6020 - lr: 3.5364e-04
Epoch 21/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1734.0044 - lr: 3.4215e-04
Epoch 22/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1698.5078 - lr: 3.3103e-04
Epoch 23/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1669.3223 - lr: 3.2027e-04
Epoch 24/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1642.2402 - lr: 3.0986e-04
Epoch 25/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1615.3547 - lr: 2.9979e-04
Epoch 26/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1592.1864 - lr: 2.9005e-04
Epoch 27/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1564.7816 - lr: 2.8062e-04
Epoch 28/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1546.4153 - lr: 2.7150e-04
Epoch 29/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1530.6921 - lr: 2.6268e-04
Epoch 30/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1506.7940 - lr: 2.5414e-04
Epoch 31/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1491.3829 - lr: 2.4588e-04
Epoch 32/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1472.9533 - lr: 2.3789e-04
Epoch 33/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1456.1488 - lr: 2.3016e-04
Epoch 34/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1441.9898 - lr: 2.2268e-04
Epoch 35/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1427.7318 - lr: 2.1544e-04
Epoch 36/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1415.3203 - lr: 2.0844e-04
Epoch 37/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1402.5945 - lr: 2.0167e-04
Epoch 38/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1387.2478 - lr: 1.9511e-04
Epoch 39/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1377.5018 - lr: 1.8877e-04
Epoch 40/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1364.3710 - lr: 1.8264e-04
Epoch 41/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1353.9707 - lr: 1.7670e-04
Epoch 42/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1343.4802 - lr: 1.7096e-04
Epoch 43/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1334.7965 - lr: 1.6540e-04
Epoch 44/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1325.4129 - lr: 1.6003e-04
Epoch 45/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1315.4391 - lr: 1.5483e-04
Epoch 46/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1306.9672 - lr: 1.4979e-04
Epoch 47/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1300.4252 - lr: 1.4492e-04
Epoch 48/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1293.0366 - lr: 1.4021e-04
Epoch 49/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1284.5246 - lr: 1.3566e-04
Epoch 50/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1277.3071 - lr: 1.3125e-04
Epoch 51/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1269.7002 - lr: 1.2698e-04
Epoch 52/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1263.8733 - lr: 1.2286e-04
Epoch 53/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1258.6293 - lr: 1.1886e-04
Epoch 54/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1250.5405 - lr: 1.1500e-04
Epoch 55/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1245.4476 - lr: 1.1126e-04
Epoch 56/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1240.6858 - lr: 1.0765e-04
Epoch 57/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1234.4995 - lr: 1.0415e-04
Epoch 58/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1230.6404 - lr: 1.0076e-04
Epoch 59/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1224.3601 - lr: 9.7489e-05
Epoch 60/60
16864/16864 [==============================] - 98s 6ms/sample - loss: 1220.6575 - lr: 9.7489e-05
```

### Loss 그래프
**150 epochs Loss 그래프**

![cvae_train_result](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/a93659ae-acbe-45e2-b7b0-0409a588b5d7)

**60 epochs Loss 그래프**

![cvae_train_result](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/63350f1e-5956-4d60-8140-653d28b88381)

### 생성 이미지
**150 epochs 생성 이미지**
* Final Loss : **1007.8428**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/c4fd171c-2c59-4092-8130-3edcc59ff5eb)

**60 epochs 생성 이미지**
* Final Loss : **1220.6575**

![생성이미지](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/d750f94a-4b4f-4498-8c65-74f1cfa31ba7)

**24 epochs 생성 이미지**
* Final Loss : **1606.3852**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/ff82a6fa-2cf2-48db-97e2-94223029c640)

## MODEL 28
**학습 로그**
```
Epoch 1/60
2024-04-21 10:33:53.392776: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8907
2024-04-21 10:33:54.386731: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
16864/16864 [==============================] - 159s 9ms/sample - loss: 4582.4155 - lr: 6.0000e-04
Epoch 2/60
16864/16864 [==============================] - 156s 9ms/sample - loss: 3250.5305 - lr: 6.0000e-04
Epoch 3/60
16864/16864 [==============================] - 157s 9ms/sample - loss: 2988.8389 - lr: 6.0000e-04
Epoch 4/60
16864/16864 [==============================] - 157s 9ms/sample - loss: 2825.9994 - lr: 6.0000e-04
Epoch 5/60
16864/16864 [==============================] - 157s 9ms/sample - loss: 2702.4441 - lr: 5.8050e-04
Epoch 6/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2611.5923 - lr: 5.6163e-04
Epoch 7/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2521.8533 - lr: 5.4338e-04
Epoch 8/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2443.4194 - lr: 5.2572e-04
Epoch 9/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2366.0158 - lr: 5.0863e-04
Epoch 10/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2297.8629 - lr: 4.9210e-04
Epoch 11/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2216.2333 - lr: 4.7611e-04
Epoch 12/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2146.8827 - lr: 4.6064e-04
Epoch 13/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2082.7499 - lr: 4.4567e-04
Epoch 14/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 2012.1959 - lr: 4.3118e-04
Epoch 15/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1953.7546 - lr: 4.1717e-04
Epoch 16/60
16864/16864 [==============================] - 160s 10ms/sample - loss: 1903.1536 - lr: 4.0361e-04
Epoch 17/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1848.5752 - lr: 3.9049e-04
Epoch 18/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1800.7940 - lr: 3.7780e-04
Epoch 19/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1754.9224 - lr: 3.6552e-04
Epoch 20/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1711.4150 - lr: 3.5364e-04
Epoch 21/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1672.0486 - lr: 3.4215e-04
Epoch 22/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1634.2881 - lr: 3.3103e-04
Epoch 23/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1602.0704 - lr: 3.2027e-04
Epoch 24/60
16864/16864 [==============================] - 160s 9ms/sample - loss: 1572.5690 - lr: 3.0986e-04
Epoch 25/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1539.0814 - lr: 2.9979e-04
Epoch 26/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1511.7593 - lr: 2.9005e-04
Epoch 27/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1485.5082 - lr: 2.8062e-04
Epoch 28/60
16864/16864 [==============================] - 160s 9ms/sample - loss: 1464.0146 - lr: 2.7150e-04
Epoch 29/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1436.3549 - lr: 2.6268e-04
Epoch 30/60
16864/16864 [==============================] - 160s 9ms/sample - loss: 1414.1416 - lr: 2.5414e-04
Epoch 31/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1391.6258 - lr: 2.4588e-04
Epoch 32/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1372.8395 - lr: 2.3789e-04
Epoch 33/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1354.2918 - lr: 2.3016e-04
Epoch 34/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1335.2689 - lr: 2.2268e-04
Epoch 35/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1317.6205 - lr: 2.1544e-04
Epoch 36/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1302.6564 - lr: 2.0844e-04
Epoch 37/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1286.9626 - lr: 2.0167e-04
Epoch 38/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1272.7377 - lr: 1.9511e-04
Epoch 39/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1258.9075 - lr: 1.8877e-04
Epoch 40/60
16864/16864 [==============================] - 160s 9ms/sample - loss: 1244.3913 - lr: 1.8264e-04
Epoch 41/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1229.9452 - lr: 1.7670e-04
Epoch 42/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1222.1500 - lr: 1.7096e-04
Epoch 43/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1207.6972 - lr: 1.6540e-04
Epoch 44/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1196.5454 - lr: 1.6003e-04
Epoch 45/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1185.1895 - lr: 1.5483e-04
Epoch 46/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1176.2498 - lr: 1.4979e-04
Epoch 47/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1167.2738 - lr: 1.4492e-04
Epoch 48/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1159.3958 - lr: 1.4021e-04
Epoch 49/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1149.6307 - lr: 1.3566e-04
Epoch 50/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1140.8626 - lr: 1.3125e-04
Epoch 51/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1133.0214 - lr: 1.2698e-04
Epoch 52/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1125.1854 - lr: 1.2286e-04
Epoch 53/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1117.7048 - lr: 1.1886e-04
Epoch 54/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1110.1573 - lr: 1.1500e-04
Epoch 55/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1103.5845 - lr: 1.1126e-04
Epoch 56/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1097.7344 - lr: 1.0765e-04
Epoch 57/60
16864/16864 [==============================] - 159s 9ms/sample - loss: 1093.1725 - lr: 1.0415e-04
Epoch 58/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1085.1602 - lr: 1.0076e-04
Epoch 59/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1079.1429 - lr: 9.7489e-05
Epoch 60/60
16864/16864 [==============================] - 158s 9ms/sample - loss: 1075.6455 - lr: 9.7489e-05
```

**Loss 그래프**

![cvae_train_result](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/a26e2fde-0032-4325-91f6-97c3db036684)

**60 epochs 생성 이미지**
* Final Loss : **1075.6455**

![생성이미지](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/6a6fb353-d697-47af-a112-2e2320a3431e)

**24 epochs 생성 이미지**
* Final Loss : **1499.3069**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/e5c6ed7a-085d-48f3-910f-be68faf68a3c)

## MODEL 29 info change 실험 결과

* 실행 방법 : ```test_cvae_model_info_change.py``` 파일 실행
* 실험 결론 : 다음의 info change에 대해 모두 **의도한 대로 이미지가 잘 생성된다.**
  * 머리 색 (```hair_color```) 변경
  * 입을 벌린 정도 (```mouth```) 변경
  * 눈을 뜬 정도 (```eyes```) 변경
  * 성별 (```male_prob```, ```female_prob```) 변경
* 아래 epochs 60 캡처에서 선택한 이미지는 **여성 가상인간으로 사용하기에 큰 무리가 없는 이미지**

**epochs 60 (final loss 1220.6575)**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/ecc5daa3-e436-473b-a8a8-1e4321934d1f)

**epochs 150 (final loss 1007.8428)**

![image](https://github.com/WannaBeSuperteur/AI-study/assets/32893014/306c98ae-1c12-4e2e-918f-a730a1cc5ee1)