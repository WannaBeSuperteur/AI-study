## 2024.03.15 (금)
**[동영상 생성 AI 소라, 하반기 일반인 이용 가능](https://n.news.naver.com/mnews/article/003/0012427329?sid=104)** ```AI``` ```Generative AI``` ```Sora```

ChatGPT의 개발사인 OpenAI에서 2024년 2월 공개한 동영상 제작 AI Sora (소라) 를 **일반인은 2024년 하반기부터 이용** 할 수 있을 것으로 예상된다.
* 현재는 Sora를 제한된 수의 창작자에게만 사용을 허가하고 있다.
* OpenAI에서는 Sora와 관련해서 다음을 고려하고 있다.
  * Sora가 생성하는 동영상에 대한 **음향 통합**
  * 이용자가 Sora가 생성한 영상을 편집할 수 있게 함 
* 한편, OpenAI 측은 가짜뉴스, 딥페이크 등을 방지하기 위해 Sora가 생성한 영상에는 **실제 영상과 구분하기 위한 워터마크** 가 표시될 것이라고 밝혔다.

## 2024.03.14 (목)
**[카이스트, 상황 따라 알아서 업데이트하는 AI 기술 개발](https://n.news.naver.com/mnews/article/421/0007410072?sid=102)** ```AI```

KAIST 연구팀이 **시간에 따라 데이터의 분포가 변하는 환경에서도 AI의 성능을 유지** 할 수 있는 학습 데이터 선택 기술을 개발했다.
* KAIST에 따르면 실제 사용되는 AI 모델이 성능이 시간이 지남에 따라 떨어지는 현상이 발견되고 있으며, 따라서 **시간에 따른 데이터 분포 변화 (드리프트)** 에 robust한 **지속 가능한 학습 기술** 이 필요한 시점이다.
  * 이는 AI 모델을 더 **안전하면서도 신뢰성 높게** 만드는 데 기여한다.
* 해당 연구에 사용한 기술적 요소는 다음과 같다.
  * 딥러닝에서 모델의 업데이트 방향 및 크기를 나타내는 **Gradient (그라디언트)**
  * 데이터의 변동에 따라 AI 모델을 업데이트하는 모델 중심 기술 대신, 드리프트의 원인인 **데이터 그 자체를 전처리하여 현 시점에서의 학습에 최적화** 시키는 것

## 2024.03.13 (수)
**[삼성전자 AI TV 시대 선언](https://n.news.naver.com/mnews/article/030/0003188785?sid=105)** ```AI```

* 2024.03.13일 삼성전자 서초사옥에서 "언박스 & 디스커버 2024"라는 신제품 TV 출시회를 개최했는데, 여기서 삼성전자 영상디스플레이 사업부장은 **초정밀 반도체 기술을 바탕으로 최고의 기술력을 모아 AI TV의 시대를 본격적으로 열겠다** 고 했다.
  * AI TV의 핵심 기술인 **3세대 AI 8K 프로세서 (NPU 탑재)** 는 AI를 통해 HD 또는 Full HD 영상을 업스케일링하여 4K 또는 8K 영상 수준으로 감상할 수 있게 하는 것이다.
  * AI가 배경음을 대화와 구분하여 대화 목소리가 묻히지 않도록 하는 등 음향 최적화 역할도 수행한다.
  * 삼성전자는 자막을 음성으로 바꾸는 등의 AI TV 기능을 준비 중이며, **거대 언어 모델 (LLM)** 을 통해 이 기능을 자연어 수준으로 업그레이드할 계획이라고 한다.

## 2024.03.12 (화)
**[제주도청, 정책 뉴스 홍보 위해 가상인간 아나운서 도입](https://n.news.naver.com/mnews/article/015/0004958817?sid=102)** ```AI``` ```Virtual human```

* 2024.03.12일 제주도청은 정책 뉴스 홍보를 위해 가상인간 (버추얼 휴먼) 아나운서인 제이나(J-NA) 를 도입했다고 했다.
  * **AI 및 첨단 그래픽 기술** 을 바탕으로 3D 가상 인간을 제작하여 사용하고 있다.
  * 제이나의 긴 생머리 등은 서비스 업체의 샘플을 이용한 것이다.
* 한편, 제주도는 ChatGPT 사용법 등 **공직자들의 AI 활용 능력** 향상을 통해 행정 업무를 효율적으로 처리하려고 한다.
  * 오영훈 제주도지사는 AI 활용을 통해 공직사회의 디지털 혁신을 가속화하겠다는 등 AI 활용을 통한 업무 효율화 의지를 밝혔다.

## 2024.03.11 (월)
**[샘 올트먼 OpenAI 이사회 복귀](https://n.news.naver.com/mnews/article/015/0004957909?sid=105)** ```AI``` ```OpenAI```

* ChatGPT를 개발한 OpenAI의 CEO 샘 올트먼이 2023년 11월 발생한 '올트먼 해임 사태' 이후 이사회로 복귀했다.
  * 이는 해당 사태 관련 조사에서 샘 올트먼이 해임될 만한 수준의 행위를 하지 않았다고 결론이 났기 때문이다.
  * 한편 OpenAI에서는 신임 이사 3명이 선임되었으며, 이사회가 기존 6명에서 7명으로 늘어났다.
* 샘 올트먼의 복귀로 인해 그의 리더십 및 OpenAI에 대한 장악력이 강화되었다고 평가된다.

## 2024.03.10 (일)
**[10년 내 알아서 인간 죽이는 로봇 등장](https://n.news.naver.com/mnews/article/028/0002680285?sid=105)** ```AI```

**딥러닝 기술을 개척** 하여 AI 분야의 대부로 불리는 토론토 대학교 명예교수 제프리 힌턴이 **10년 이내에 자율적으로 인간을 죽이는 로봇이 등장할 것** 이라고 하면서 AI의 위험성에 대해 경고했다.
* AI가 인간을 위협할 만한 근거는 **AI가 임무를 수행할 때 인간에게 나쁜 방법을 사용** 할 수 있기 때문이다.
  * 예를 들어, 기후 변화 해결 과제를 받은 AI가 인간 배제를 결정하고 이를 실행한다는 것이다.
* 한편 그는 GPT-4와 같은 **거대 언어 모델 (LLM) 은 인간과 동일하게 언어를 이해하고 있다** 고 주장했다.

## 2024.03.09 (토)
**[AI PC, 30년 만의 혁명적 변화](https://n.news.naver.com/mnews/article/032/0003283396?sid=101)** ```AI```

엔비디아 CEO 젠슨 황은 2024.03.07일 휴렛팩커드 (HP) 의 행사 "앰플리파이 파트너 콘퍼런스" 에서 **"AI PC가 Windows 95 이후 30년 만의 혁명적 변화"** 라고 했다.
* 그는 AI PC는 가속 컴퓨팅 기술을 이용하여 **효율이 10~15배** 올랐다고 했다.
* 또한 그는 PC에 **데이터센터 현대화 기술** 이 도입되는 등 위대한 르네상스가 시작되었다고도 했다.
* 그는 과거 소프트웨어 개발, 콘텐츠 제작 시에는 프로그래밍 언어를 배워서 이용해야 했지만, 현재는 **사람의 언어로 거대 언어 모델 (LLM) 에게 지시하기만 하면 된다** 고 했다.

## 2024.03.08 (금)
**[롯데 AI 전환 박차, 관련 CEO 콘퍼런스도](https://n.news.naver.com/mnews/article/001/0014550383?sid=101)** ```AI```

롯데그룹은 2024.03.07일 롯데월드타워에서 CEO의 특명 아래 "AI+X 시대를 준비하는 롯데" 라는 주제의 콘퍼런스를 열었다.
* **AI + X** 는 AI를 다양한 분야에서 활용할 수 있다는 것을 의미한다.
* 이 콘퍼런스에서는 **생성형 AI 등 최신 AI 트렌드 및 롯데그룹의 전략적 방향** 등이 논의되었다.
* 롯데는 그룹 전체적으로 AI 기술 개발에 투자하고 있는데, 업무 효율성을 증진할 뿐만 아니라 **핵심 사업 경쟁력을 혁신의 관점에서 높이는 수준** 을 목표로 기술력 향상에 힘을 쓰고 있다.
* 콘퍼런스에 등장한 AI의 구체적인 사례는 다음과 같다.
  * 생성형 AI 플랫폼 아이멤버 (Aimember)
  * AI 관련 스타트업의 기술 체험 (스페이스비전AI, 에스투더블유 등)

## 2024.03.07 (목)
**[협업툴 플로우, 생성형 AI로 사용성 향상](https://n.news.naver.com/mnews/article/092/0002323779?sid=105)** ```AI``` ```Generative AI```

서비스형 소프트웨어 (SaaS) 및 on-premise 형태로 제공되는 기업 내 협업 플랫폼 '플로우'가 **생성형 AI를 통해 업무 진행의 효율성을 높였다.**
* 탑재한 생성형 AI 언어 모델은 ChatGPT에 사용된 **GPT-4** 와 메타의 **LLaMa-2** 이다.
* 생성형 AI를 통해 제공되는 플로우의 기능은 다음과 같다.
  * AI 프로젝트 템플릿 및 AI 에디터 템플릿
    * 업종별, 부서별 프로젝트 생성 자동화
    * 사용자가 **프로젝트 주제 입력** 시, 플로우가 **제목명, 템플릿 구성** 생성
  * AI 하위 업무
  * AI 업무 필터
  * AI 업무 일지
  * AI 담당자 추천

## 2024.03.06 (수)
**[대한민국, AI 반도체 기술 세계 최초 개발](https://n.news.naver.com/mnews/article/003/0012409871?sid=105)** ```AI``` ```Large Language Model```

KAIST 연구진이 **가로 세로 길이 각각 4.5mm 정도의 AI 반도체 칩 하나로 거대 언어 모델 (LLM) 을 초저전력으로 구현 가능한 기술** 을 대한민국 최초이자 세계 최초로 개발했다.
* 이 반도체는 '상보형 트랜스포머'로, **400mW의 초저전력 + 0.4초의 초고속** 으로 LLM을 처리할 수 있다.
  * 상보형 트랜스포머는 **입력 데이터의 크기** 에 따라 **SNN (스파이킹 뉴럴 네트워크)** 와 DNN (Deep Neural Network) 의 선택적 사용을 통해 트랜스포머의 기능을 구현하며, 이를 통해 데이터를 서로 다른 인공신경망에 할당, 전력 소모를 최소화한다.
    * 이는 인간의 뇌에서 생각할 것이 많을수록 에너지를 많이 소모하는 것을 모방한 것이다.
* 기존 뉴로모픽 컴퓨팅 기술과 비교하면 다음과 같다.

||기존 뉴로모픽 컴퓨팅|상보형 트랜스포머|
|---|---|---|
|정확도|합성곱 신경망 (CNN) 보다 부정확|CNN과 동일 수준|
|가능 작업|간단한 이미지 분류|다양한 응용 분야 (상보형 심층신경망, C-DNN)|

* GPT-2 모델의 약 7억 개의 파라미터를 이 기술을 통해 약 2억 개로 줄일 수 있는 등 **파라미터의 개수를 줄일 수 있다** 고 했다.
  * 이와 같은 압축을 통해 파라미터를 불러오는 작업에 필요한 전력 소모를 70% 정도 줄였다.
* 이번 연구가 획기적인 것은 LLM의 파라미터를 줄이는 최근 연구 트렌드에서 다소 벗어났지만 **전력 소비를 크게 줄인 뉴로모픽 컴퓨팅** 을 LLM에 적용했다는 점이다.

## 2024.03.05 (화)
**[서울시-구글 AI 인재 6천명 양성](https://n.news.naver.com/mnews/article/015/0004955826?sid=102)** ```AI```

서울시와 구글은 2024.03.05일부터 4월 9일까지 6주간 AI 분야 초기, 예비 창업자 6000명을 대상으로 교육을 실시한다.
* 구글 운영, 서울시가 지원하는 **인공지능 (AI) 스타트업 스쿨 위드 서울** 프로그램의 일환으로 매주 화요일에 열린다.
* 스타트업 스쿨은 2015년부터 구글에서 전 세계적으로 운영하는 커뮤니티이며, 학생들은 AI 기술 등 다양한 역량을 기를 수 있다. (AI 제품 개발 등)
* 구글코리아 김경훈 사장은 **서울 청년의 AI 기술 이해도 향상 및 우수 스타트업 육성을 위해 서울시와 협업** 한다면서, **이번 일을 계기로 우리나라 AI 스타트업 생태계가 강화** 되기를 바란다고 했다.

## 2024.03.04 (월)
**[믿을 수 없을 만큼 똑똑한 동시에 멍청한 AI](https://n.news.naver.com/mnews/article/028/0002679323?sid=105)** ```AI``` ```Generative AI```

2024.02.15일 OpenAI에서 공개한 영상 제작 생성형 AI '소라'와 같은 최신 AI가 **물리 법칙을 이해한 것처럼 범용 인공지능 (AGI) 로 가는 길을 단축했다** 고 평가되지만, 과연 **진짜로 '이해'하고 있는지 의문** 이라는 평가도 있다.
* '소라'의 영상 중 일부에서는 사물이 거꾸로 날아가거나, 쿠키를 한 입 베어 물었지만 쿠키가 작아지지 않는 등 **물리 법칙에 어긋나거나 인과관계를 제대로 묘사하지 못하는 듯한 현상** 이 발생해서, 소라의 이해 능력에 의문이 생겼다.
* ChatGPT와 같은 언어 모델은 **통계적으로 확률이 가장 높은 답을 제시** 한다는 점에서 **응용 통계학에 불과** 하다는 이야기가 있다.
  * 단, '이해'를 하는 듯한 생성형 AI로 만들기 위해 기존과 약간 다른 '재료'로 구성되어 있을 뿐이다.
* 뉴욕대의 마커스 명예교수는 **인간과 거대 언어 모델 (LLM) 의 차이는 세계 모델에 있다** 고 하면서, 인간은 눈을 감아도 사물의 위치를 알 수 있는 등 **세계 모델** 을 가지고 있다고 했다. 반면 AI는 이러한 세계 모델이 부재하다고 했다.
  * 또한 AI 모델이 진실에 이르기 위해서는 **딥러닝 대신 딥 언더스탠딩** 이 필요하다고 했다.

## 2024.03.03 (일)
**[AI 그림에는 저작권이 없다](https://n.news.naver.com/mnews/article/055/0001135485?sid=101)** ```AI``` ```Generative AI```

AI 그림에는 **저작권이 없기** 때문에, AI 그림으로 돈을 번다든지 하는 것은 현실적으로 어렵다.
* AI 그림을 창작하기 위한 프롬프트를 제공했다고 해도, 이를 통해 만들어진 그림을 창작물로 인정할 수 있을지 미지수이다.
* **AI로 생성된 작품의 저작권 소유주** 에 관련된 논쟁도 있다.
  * AI 소프트웨어 개발자 또는 프롬프트를 제공한 사람, AI 자체가 저작권을 가져야 한다는 이야기가 있으나 기존 저작권법의 원칙과 충돌하는 등 논란이 있을 것이다. 
* **AI로 생성된 작품의 저작권이 인정되지 않으면 경제적 가치를 창출하기 어려우므로, 생성형 AI 산업 동력도 약해지는 문제** 가 있다. 이런 **저작권 문제를 해결하면서 동시에 AI 산업을 발전** 시켜야 하는 과제가 우리에게 있다.

## 2024.03.02 (토)
**[일론 머스크, OpenAI 계약 위반으로 고소](https://n.news.naver.com/mnews/article/014/0005149960?sid=101)** ```AI``` ```OpenAI```

2024.02.29일 테슬라 CEO 일론 머스크가 ChatGPT를 개발한 OpenAI와 그 CEO 샘 올트먼을 고소했다.
* 일론 머스크는 2015년에 OpenAI를 설립한 공동 창업자이며, 그는 샘 올트먼은 인류의 공동 이익 대신 개인의 이익을 추구하고 있다고 했다.
* 구체적으로, **OpenAI와 Microsoft가 긴밀한 관계를 보이면서, OpenAI의 설립 시에 했던 약속인 오픈소스 AI에 반하는 행동을 하고 있다** 고 주장했다.
  * 실제로 OpenAI의 ChatGPT에 사용되는 거대 언어 모델 (LLM) 인 GPT-4는 그 **데이터, 모델 구축용 코드를 제3자가 확인할 수 없는, 이른바 블랙박스** 이다.
  * Microsoft는 2019년 OpenAI 투자를 시작해서 2023년부터는 OpenAI와 본격적으로 협업하기 시작했다. 또한 OpenAI의 지분의 약 50%를 확보했다.
  * 이에 대해 일론 머스크는 "OpenAI가 MS의 자회사처럼 움직이면서, **모든 인류에게 혜택을 주는 AGI (범용 AI) 개발** 이라는 OpenAI 설립 합의를 위반하고 있다" 고 주장했다.

## 2024.03.01 (금)
**[구글 Gemini 1.5](https://n.news.naver.com/mnews/article/018/0005674892?sid=105)** ```AI``` ```Generative AI```

2024.02.16일 구글이 자사 초거대 인공지능인 Gemini의 신규 버전인 Gemini 1.5를 공개했다.
* Gemini 1.5의 특징은 다음과 같다.
  * 기존 **Gemini 1.0 Pro에 비해 정보 처리 능력 향상** : Gemini 1.5는 동시 정보 처리 능력의 향상으로 보다 긴 문맥을 이해할 수 있다.
    * 모델이 한번에 처리할 수 있는 정보의 양을 나타내는 **Context Window** 와 그 정보의 구성 요소의 단위를 나타내는 용어인 **token** 을 기준으로, Gemini 1.5는 기존 Gemini 1.0 Pro의 32,000개의 약 30배에 해당하는 100만 개의 토큰까지 처리할 수 있다.
    * 이는 OpenAI의 GPT-4 Turbo의 128,000개의 약 8배에 달하며, 영상 1시간, 음성 11시간, 코드 3만 줄, 단어 70만 개 분량에 해당한다.
  * 주어진 질문에 답하기 위해 방대한 양의 콘텐츠를 매끄럽게 분류 및 요약
  * **코드 해석 능력** 등 향상 : 10만 줄 이상의 코드를 질문해도 추론 및 유용한 수정 사항을 제안하여, 코드의 작동을 설명할 수 있다.
  * **NIAH (Needle In A Haystack)** 평가 : 특정 정보를 담은 작은 텍스트를 긴 텍스트 안에 의도적으로 배치하는 테스트인데, 긴 텍스트가 100만 개의 토큰으로 구성된 경우에도 배치된 작은 텍스트를 **99%의 정확도** 로 찾아낼 수 있다.
  * **문맥 기반 학습 (in-context learning)** : 추가적 fine-tuning 없이, 프롬프트 내의 주어진 정보에서 새로운 기술 학습 가능
