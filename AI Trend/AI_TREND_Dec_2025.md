## 2025.12.24 (수)
**[AI 기본법, 유예기간 1년 이상 연장 가능성](https://n.news.naver.com/mnews/article/003/0013675868?sid=105)** ```AI```

* 2025.12.24일 과학기술정보통신부가 **AI 기본법 시행령 설명회** 를 개최하여 다음과 같이 밝혔다.
  * AI 기본법은 **AI G3 지향 생태계 조성 (지원, 진흥 목적)** 을 위한 법률
  * **계도 기간 및 규제 유예 1년 이상 적용 예정** (이진수 과기정통부 인공지능정책관 발언)
* 상세 내용은 다음과 같다.
  * 규제 유예 기간이 1년 이상인 이유는 **해외 동향 및 기술 발전 속도 등을 고려** 하기 위한 유연한 조치
  * AI 기본법에서의 **명확한 용어 정의** 필요 (AI사업자, 배포자 등)
  * 투명성 및 안전성 의무 관련

| 투명성 의무                     | 안전성 의무                                                                    |
|----------------------------|---------------------------------------------------------------------------|
| 산업계와 일반 시민사회가 **서로 다른 의견** | - 산업계: 누적 연산량 대신 **다른 기준** 필요<br>- 시민사회: **안전성 의무 적용 대상 AI 시스템 범위 확대** 요구 |

## 2025.12.23 (화)
**[KT 자체 개발 LLM '믿:음', 국내 최초 'AI 신뢰성 인증' 부여](https://n.news.naver.com/mnews/article/003/0013672517?sid=105)** ```AI``` ```Large Language Model```

* KT에서 자체 개발한 LLM인 '믿:음 K2.0 B베이스'가 **국내 최초로 'LLM 대상 인공지능 신뢰성 인증 (CAT)'을 받았다.**
  * CAT는 AI 기술의 윤리성 향상 및 AI 산업 경쟁력 강화를 위한, **한국정보통신기술협회 (TTA) 의 민간 자율 인증 제도** 이다.
* TTA가 운영 중인 인증 체계는 다음과 같다.

| ISO/IEC 23894 | ISO/IEC 42001 | ISO/IEC 38507 |
|---------------|---------------|---------------|
| AI 위험관리       | AI 경영시스템      | AI 거버넌스       |

* '믿:음 K2.0 B베이스'는 **한국어 데이터 분류, 질의응답, 생성 등 다양한 작업** 을 수행 가능하다.
  * 해당 모델은 오픈소스로 HuggingFace 에 공개되어 있으며, **11.5B 규모** 이다.
* TTA 회장은 **생성형 AI의 핵심은 LLM 신뢰성 확보이고, 이는 책임 있는 AI 활용 및 사용자 불안 해소의 기반** 이라고 말했다.

## 2025.12.22 (월)
**[NC AI, AI 기반 음성/번역 서비스 2종 출시](https://n.news.naver.com/mnews/article/001/0015807650?sid=105)** ```AI```

* 2025.12.22일 NC AI가 다음과 같은 서비스를 출시했다고 밝혔다.

| 서비스        | 설명            | 특징                                                    |
|------------|---------------|-------------------------------------------------------|
| 바르코 보이스    | 맞춤형 음성 생성 서비스 | 기존 TTS에 비해 **보다 자연스러움 (배우의 목소리, 감정 등 재현)**            |
| 바르코 트랜스레이션 | 실시간 번역 서비스    | **문화적 특성 및 문맥을 고려한 번역** 을 통해, 기존 번역에 비해 **의미 왜곡 최소화** |

* 이 서비스의 기대 효과는 다음과 같다.
  * 두 서비스의 결합을 통한, **원작의 감정과 몰입을 해외 시청자에게 그대로 전달** 하는 효과 구현 가능 
  * 이를 통한 **창작 효율, 품질, 콘텐츠 경쟁력 향상**

## 2025.12.21 (일)
**[메타, 영상 생성 AI 모델 '망고' 개발 중](https://n.news.naver.com/mnews/article/366/0001131235?sid=105)** ```AI``` ```Meta AI``` ```Generative AI``` ```Large Language Model```

* 인스타그램 운영사 메타 (Meta) 가 최근 **영상 생성 AI 모델인 '망고'를 개발** 하고 있다.
  * 이는 경쟁 모델인 구글의 '나노바나나', OpenAI의 '소라' 등과 영상 생성 AI 분야에서 경쟁하는 것을 의미한다.
* '망고' 모델 외에도 **'아보카도'라는 모델** 이 있는데, '아보카도'의 특징은 다음과 같다.
  * **코딩 능력** 개선
  * 오픈소스 (LLaMA 등) 가 아닌 **폐쇄형 출시** 예정
* '망고'와 '아보카도' 모델은 **2026년 상반기** 출시 예정이다.
* 한편, 메타는 LLM 계열 생성형 AI 모델 외에도 물리적 세계 이해를 위한 **월드 모델 (world model)** 관련 연구도 진행 중이다.

## 2025.12.20 (토)
**[AI 잘 쓰는 법, 이제는 '컨텍스트 엔지니어링'](https://n.news.naver.com/mnews/article/003/0013668721?sid=105)** ```AI``` ```Large Language Model``` 

* ChatGPT 이후 LLM의 프롬프트를 잘 설계하는 ['프롬프트 엔지니어링'](../AI%20Basics/LLM%20Basics/LLM_기초_Prompt_Engineering.md) 에 이어 이제는 **'컨텍스트 엔지니어링'** 이 주목받고 있다.
  * 컨텍스트 엔지니어링은 **AI의 성능을 최대한으로 향상시키는 환경을 만드는 것** 을 말한다.
* 주요 개념

| 개념             | 설명                                                                                                             |
|----------------|----------------------------------------------------------------------------------------------------------------|
| 컨텍스트 (Context) | AI 모델이 참고하는 **지식, 대화 히스토리, 가이드라인 등**<br>- **컨텍스트의 크기는 제한적** 이라는 것이 문제점                                         |
| 컨텍스트 엔지니어링     | 크기가 제한된 컨텍스트를 **어떤 정보로 채울지** 결정하는 것<br>- 프롬프트 엔지니어링이 '질문을 잘 하는 방법'이라면, **컨텍스트 엔지니어링은 '답변 환경을 구성하는 법'의 개념** 이다. |

* 컨텍스트 엔지니어링은 **기업들의 성과를 향상** 시키는 등 이미 효과를 보고 있다.
  * 예를 들어 법률 AI 기업 '하비'가 **법률 개념, 판례, 사건 간 관계 등을 연계하는 자체 컨텍스트 시스템을 보유** 하여 법률 연구 및 문서 분석 시간을 단축시키고 있다.

## 2025.12.19 (금)
**[OpenAI, GPT-이미지 1.5 출시](https://n.news.naver.com/mnews/article/022/0004090909?sid=105)** ```AI``` ```OpenAI``` ```ChatGPT```

* 2025.12.16일 (현지시각) 2025년 봄에 지브리풍 이미지 등 열풍으로 인기를 끈 **ChatGPT Image Generation** 이 **GPT-이미지 1.5** 로 업그레이드되어 출시되었다.
  * 이는 경쟁사 구글의 모델인 '나노바나나 프로'를 의식한 것으로 보인다. 
* GPT-이미지 1.5의 특징은 다음과 같다.
  * **정밀한 편집 기능** (핵심 요소 유지, 특정 부분만 편집 가능) 
  * **기능적 완성도** 향상 (특정 조건의 표 그리기 등)
  * **문자 표현** 기능 향상
* 한편, OpenAI는 GPT-이미지 1.5의 출시로 '코드 레드'를 해제하지는 않는다.

## 2025.12.18 (목)
**[구글, 제미나이3 플래시 출시](https://n.news.naver.com/mnews/article/421/0008667135?sid=105)** ```AI``` ```Gemini```

* 2025.12.17일 (현지시각) 구글이 Gemini-3의 경량 버전인 **제미나이-3 플래시 (Gemini-3 Flash)** 를 출시했다.
  * 이 모델의 특징은 **답변 속도 향상 및 운영비 절감** 이다.
* 구글이 밝힌 Gemini-3 Flash 의 특징은 다음과 같다.
  * 고급 **추론 능력**
  * **지연 시간** 단축
  * 이를 통한 효율성 및 경제성의 구현
* Gemini-3 Flash의 벤치마크 성능은 다음과 같다.
  * 전체적으로 **Gemini-3 Pro 와 비슷한 수준의 성능** 을 보인다. 

| 벤치마크 데이터셋                   | 성능        | Gemini-3 Pro 성능 |
|-----------------------------|-----------|-----------------|
| MMLU-Pro (일반 지식 테스트)        | **81.2%** | 81%             |
| SWE-벤치 베리파이드                | **78%**   | 76.2%           |
| GPQA 다이아몬드 (과학 지식)          | **90.4%** | 91.9%           |
| HLE (고난도 종합 평가, 인류의 마지막 시험) | **33.7%** | 37.5%           |

* 한편, 구글 측은 **정교한 대형 모델과 빠르지만 단순한 모델 간 양자택일을 Gemini-3 플래시가 끝낼 것** 이라고 말했다.

## 2025.12.17 (수)
**[AI 무비판적 사용, 사고력 약화시킨다](https://n.news.naver.com/mnews/article/047/0002498728?sid=101)** ```AI```

* 현대의 AI는 반복적 작업의 빠른 처리, 생성 등 **여러 가지 장점** 이 있다.
  * 하지만 **AI가 실제로 인간의 인지적 작업량을 줄이고, 인간이 창의/혁신적 작업에 몰두하게 하는지는 추가 검토가 필요** 하다.
  * 최근 연구에서는 **AI의 인지 활동 대행으로 인해 인간의 인지 능력이 오히려 약화** 된다는 이야기가 있다.
* AI가 장기적으로 **창의성과 비판적 사고력을 약화** 시킨다는 것을 보여준 대학생 대상 실험이 있다.
  * 각 그룹별 **뇌의 신경 네트워크 연결성** 측정

| 생성형 AI 사용 그룹                              | 검색엔진 사용 그룹 | 도구 미사용 그룹               |
|-------------------------------------------|------------|-------------------------|
| - 최대 55% 감소<br>- 83%는 방금 작성한 에세이를 기억하지 못함 |            | 스스로 사고한 그룹 (망각률 11% 하락) |

* 최근 청년 세대는 **AI, 스마트폰 등에 익숙해져 사고력이 저하된 편** 이다.
  * 심지어 **AI를 교육 도구로 사용할 때 학습 능력이 오히려 떨어지는** 사례도 있다.

## 2025.12.16 (화)
**[AI 모델 경쟁, 매일 바뀌는 1위 모델](https://n.news.naver.com/mnews/article/023/0003947292?sid=105)** ```AI``` ```Large Language Model``` ```Generative AI```

* 2022년 11월 말 ChatGPT 등장 이후 **6개월 ~ 1년 단위로** 신규 모델이 출시되던 경향성이 이제는 **1~2개월, 심하면 주 단위로** 모델이 출시되고 있다.
  * 이와 함께 **신규 모델 출시 직후 '벤치마크 성능 평가 1위 모델'이 바뀌는** 경우 역시 흔하다.
* 그 동안의 AI 모델 업데이트 트렌드는 다음과 같다.
  * OpenAI는 GPT-3.5 (2022.11) 이후 GPT-4 (2023.03), GPT-4o (2024.05) 순으로 **1년에 1~2번의 모델 업데이트** 가 있었으나, 최근에는 **2025년 한 해에만 총 4번의 AI 모델 업데이트** 가 있었다.
  * Google Gemini, 앤트로픽의 클로드 등 타사 역시 마찬가지이다.
* 이에 최근에는 '벤치마크 마케팅 회의론'이 있다.
  * 이는 **AI 벤치마크가 객관적으로 AI 모델의 성능을 평가할 수 있는지에 대한 의문** 에서 비롯된 것이다.  
  * AI 모델 벤치마크 (수능 등) 는 실질적으로 **모델 홍보 수단** 으로 쓰이고 있으며, **사용자의 체감 성능과 괴리가 있을 수 있다** 는 점이 핵심이다.

## 2025.12.15 (월)
**[국내 AI 모델, 수능 수학 성적이 저조하다?](https://n.news.naver.com/mnews/article/032/0003415178?sid=102)** ```AI``` ```Large Language Model```

* 국내 국가대표 AI 정예팀이라고 불리는 5개 팀에서 개발한 거대 언어 모델 (LLM) 이 **수능 및 논술의 수학 문제를 해외 LLM에 비해 잘 풀지 못한다** 는 결과가 나왔다.
  * 이에 대해 LG 측은 **해당 LLM의 특성을 고려하지 않은 시험** 이라고 반박했다.
* 시험 방법은 다음과 같다.
  * 시험 문제
    * **수능 수학 20문제 (공통, 확통, 미적분, 기하 각각 고난도 5문항)** 와 **수학 논술 30문항** 의 총 50문항
  * 테스트 대상 **국내** 모델
    * 솔라 프로-2 (업스테이지), 엑사원 4.0.1 (LG AI연구원), HCX-007 (네이버) 등
  * 테스트 대상 **해외** 모델
    * GPT-5.1, Gemini-3 Pro Preview, DeepSeek V3.2 등
* 시험 결과

| 국내 모델                     | 해외 모델     |
|---------------------------|-----------|
| 보통 20점대, 최고 58점 (솔라 프로-2) | 76점 ~ 92점 |

* 한편, LG AI연구원의 반박 근거 중 하나는 **추론 기능을 작동시키기 위한 특정 프롬프트가 필요하다** 는 것이다.

## 2025.12.14 (일)
**[OpenAI, '입사 즉시 스톡옵션 지급'한다](https://n.news.naver.com/mnews/article/015/0005224145?sid=105)** ```AI``` ```OpenAI```

* OpenAI가 신규 입사자에게 **일정 기간을 기다리지 않아도, 입사 즉시 스톡옵션을 지급** 하는 정책을 시행한다.
  * 이는 **AI 분야 인재 영입 경쟁에서 우위를 차지하려는** 전략으로 보인다.
* 직원이 스톡옵션 등을 행사하기 위한 최소 재직 기간을 **베스팅 클리프** 라고 한다.
  * 일반적으로 장기 근속 유도를 위해 **베스팅 클리프를 1년** 으로 한다.
  * 하지만 OpenAI는 이를 2025년 4월 **6개월** 로 단축한 적 있고, 이번에 **아예 폐지** 할 예정이다.

## 2025.12.13 (토)
**[과기정통부, 내년 세계 10위권 AI 모델 개발](https://n.news.naver.com/mnews/article/277/0005692841?sid=105)** ```AI```

* 배경훈 과학기술정보통신부 장관이 대통령실 업무보고에서 다음 내용을 포함한 **2026년도 과기정통부 업무계획** 을 발표했다.
  * 세계 10위권 수준의 AI 모델 개발 **(국내 파운데이션 모델)**
  * 2026년 3월 '전 국민 AI 경진대회' 개최
* 상세 계획은 다음과 같다.

| 계획                  | 설명                                                  |
|---------------------|-----------------------------------------------------|
| AI 예산 확대 및 인프라 확보   | - AI 예산 **9조 9000억 원** 규모로 확대<br>- GPU **26만 장** 확보 |
| 세계 10위권 수준 AI 모델 개발 | - 세계 10위권 수준의 AI 모델을 **독자적으로 개발 및 오픈소스로 공개**        |
| 전 국민 AI 경진대회        | - AI 인재 발굴 및 창업 연계                                  |
| 기타                  | - 4대 권역 AI 혁신 사업 추진 (전북 AI 팩토리 등)<br>- AI 영재학교 설립   |

## 2025.12.12 (금)
**[OpenAI, GPT-5.2 모델 공개](https://n.news.naver.com/mnews/article/001/0015792345?sid=104)** ```AI``` ```OpenAI``` ```ChatGPT```

* 2025.12.11일 (현지시각) OpenAI가 **GPT-5.2** 모델을 발표했다.
  * GPT-5.2는 이전 버전인 GPT-5.1이 출시된 지 **불과 1개월 만에 출시된 버전** 이다. 
* GPT-5.2의 특징은 다음과 같다.
  * 즉답 (Instant), 사고 (Thinking) 모드 외에도 **프로 모드** 추가 
    * 프로 모드는 **비교적 오래 소요되는 작업** 에 최적화되어 있다고 한다.
  * 추론 및 코딩 능력 향상
  * 환각 현상 감소
  * 민감한 대화 응답 개선 및 **연령 예측 모델 (18세 미만 미성년자 보호)** 적용
* GPT-5.2의 벤치마크 성능은 다음과 같다.

| 벤치마크 데이터셋            | 성능                                                              |
|----------------------|-----------------------------------------------------------------|
| GDPval (전문 업무 역량 평가) | **70.9%** (사고 모드), **74.1%** (프로 모드)<br>- **인간 전문가 또는 그 이상** 수준 |
| SWE (소프트웨어 엔지니어링)    | **80%** (Gemini-3 Pro는 76.2%)                                   |

* 한편, GPT-5.2 출시에 따라 **GPT-5.1은 향후 3개월간만 제공되며, 그 이후에는 서비스가 종료** 된다.

## 2025.12.11 (목)
**[KAIST, AI 단과대학 신설](https://n.news.naver.com/mnews/article/023/0003946412?sid=105)** ```AI```

* KAIST가 2026년부터 AI 단과대학을 신설하여 학생을 모집한다.
  * 이 AI 단과대학은 **300명 규모** 로, **학부 100명, 석사 150명, 박사 50명** 으로 구성된다.
* 이 대학의 산하 학과는 다음과 같다.
  * AI학부
  * AI컴퓨팅학과
  * AI시스템학과
  * AX (AI 전환) 학과
  * AI미래학과
* 석사/박사는 2026년 가을학기부터 모집 예정이다.
* 한편, 정부는 KAIST에 이어 2027년 GIST, DGIST, UNIST 등에도 AI 단과대학을 신설하여 역량 있는 인재를 육성할 예정이다.

## 2025.12.10 (수)
**[OpenAI, 슬랙 CEO 영입](https://n.news.naver.com/mnews/article/009/0005603634?sid=101)** ```AI``` ```OpenAI```

* ChatGPT 개발사 OpenAI가 최근 슬랙 (Slack) CEO인 데니스 드레서를 영입했다.
  * 데니스 드레서는 **OpenAI의 최고매출책임자 (CRO)** 로 영입되었다. 
  * 데니스 드레서 CRO는 **OpenAI의 수익 전략 총괄 및 기업 고객 AI 도입 지원** 을 담당한다.
* 한편, OpenAI는 현재 기업 가치 5000억 달러 정도이지만, **AI 인프라 등 투자로 인해 재정적 압박** 이 있는 상태이다.
  * 또한, 경쟁 AI 모델인 Google의 Gemini-3 Pro의 이용자 수 상승 추이 역시 위기이다.

## 2025.12.09 (화)
**[알파고, 바둑 국가대표 훈련용 AI가 되다](https://m.sports.naver.com/general/article/056/0012081928)** ```AI```

* 약 10년 전 2016년 3월에 이세돌 9단을 이긴 **알파고 (AlphaGo)** 가 **바둑 국가대표 훈련에 사용되는 AI** 로 거듭났다.
  * 2026년 3월 9일은 알파고와 이세돌의 '구글 딥마인드 챌린지 매치' 대결 **10주년** 이다. 
* 바둑 국가대표 선수들은 요즘 **컴퓨터 앞에서, AI를 이용하여 바둑 연습** 을 한다.
  * 즉, **2016년 당시에는 바둑계의 '적'이었지만, 2025년 현재는 '동반자' (바둑을 두는 수준을 높여주는 도구) 가 된 셈** 이다.
  * 신진서 9단은 **AI는 바둑의 신에 가까워지고 있는 만큼, 지금은 친구/스승으로 생각해야 한다** 고 말했다.
* 한편, 한국기원은 **이세돌 vs. 알파고 대결 10주년** 인 2026년에 **신진서 9단과 알파고의 바둑 대결** 을 추진하고 있다.
  * 이때 사용되는 알파고는 2016년 3월 버전이다.

## 2025.12.08 (월)
**[초인공지능 (ASI), 하정우 미래기획수석이 말한 6가지](https://n.news.naver.com/mnews/article/014/0005445403?sid=105)** ```AI```

* 이재명 대통령과 손정의 소프트뱅크 회장과의 2025.12.05일 회동에서 **초인공지능 (ASI)** 이 언급되었다.
  * 이 'ASI' 개념에 대해 **하정우 AI 미래기획수석** 이 이와 관련된 6가지 사항을 언급했다. 
* 하정우 수석이 언급한 사항들은 다음과 같다.

| 항목           | 설명                                            |
|--------------|-----------------------------------------------|
| 손 회장의 외침     | 브로드밴드 3회 + **AI 3회 + ASI 3회**                 |
| 반도체          | 메모리 중심 구조인 ASI 특성상, 한국의 **최대 장점** 으로 언급       |
| 에너지 문제       | ASI 개발을 위해 **가장 해결하기 어려운 문제** 로 언급            |
| 접근성 및 활용성    | ASI는 **누구나 접근, 활용 가능** 해야 함                   |
| 데이터 규제       | **데이터와 관련된 과도한 규제** 를 제거하고 **규제 혁신** 을 실행해야 함 |
| 교육, 활용 방안 마련 | ASI에 대한 교육 및 활용 방안은 **국가 차원** 에서 마련해야 함       |

## 2025.12.07 (일)
**['에너지 괴물' 된 AI](https://n.news.naver.com/mnews/article/009/0005602274?sid=101)** ```AI```

* 향후 5년 이내에 AI 인프라의 핵심인 데이터센터와 관련된 전력 소비가 **주요 국가들의 전력 소비 수준 이상** 이 될 것으로 예측된다.
  * 전 세계 데이터센터를 하나의 국가로 보았을 때, **세계 3위 국가 수준** 으로 예상된다.
* 전 세계 데이터센터 전력 소비 추이 예상은 다음과 같다.

| 연도    | 전력 소비량              | 비고                  |
|-------|---------------------|---------------------|
| 2023년 | 300TWh              |                     |
| 2030년 | **1500TWh (4배 증가)** | 전 세계 3위 전력 소비 국가 수준 |

* 데이터센터 전력 소비가 가장 많을 것으로 예상되는 국가는 **미국 (2024년 185TWh → 2030년 425TWh)** 이다.
* 문제는 **데이터센터가 국가 또는 지역 전체 전력 소비량의 상당수를 차지하여 전력 수급 부담이 생기는** 경우가 있다는 것이다.
  * 미국 버지니아주는 그 비중이 **4분의 1** 이고, 아일랜드는 **5분의 1** 수준이다. 

## 2025.12.06 (토)
**[초인공지능 (ASI) 의 실현 가능성](https://n.news.naver.com/mnews/article/003/0013642661?sid=105)** ```AI```

* 최근 들어 AI 업계의 화두가 **생성형 AI** 를 넘어서 **범용 인공지능 (AGI)** 을 거쳐서, **초인공지능 (ASI)** 으로 이동하고 있다.
  * 초인공지능 (ASI) 은 **인간 지능의 1만 배 수준에 이르는 AI** 를 말한다.
* 초인공지능의 실현 가능성에 대한 전망은 다음과 같다.
  * 글로벌 빅테크 기업들은 ASI 시장 선점 경쟁에 이미 돌입
    * 이를 위해 AI 인프라 구축 등 노력
  * 손정의 소프트뱅크그룹 회장은 **ASI의 도래 시점을 10년 이내** 로 전망
* 한편, 일각에서는 **AGI도 나오지 않은 현 시점에서 ASI는 시기상조이며, 마케팅 용어에 불과** 하다는 주장이 있다.
  * 현재의 Transformer 기반 거대 언어 모델 (LLM) 은 결국 **확률적인 Next Token Prediction** 기반이므로, 한계점이 있다는 주장이다.

## 2025.12.05 (금)
**[이 대통령, 'AI 기본사회' 구상](https://n.news.naver.com/mnews/article/374/0000479015?sid=101)** ```AI```

* 2025.12.05일 이재명 대통령이 손정의 소프트뱅크 회장과의 회동을 가졌다.
  * 이 회동에서 이 대통령은 **AI 기본사회** 를 언급했고, 손 회장은 **초인공지능** 을 언급했다.
* AI 기본사회와 초인공지능의 개념은 다음과 같다.

| 개념      | 언급한 사람       | 개념 설명                                                                                                    |
|---------|--------------|----------------------------------------------------------------------------------------------------------|
| AI 기본사회 | 이재명 대통령      | 전 국민, 기업 등이 **AI를 최소 기본적인 수준으로 활용** 하는 사회                                                                |
| 초인공지능   | 손정의 소프트뱅크 회장 | 인간의 능력을 **1만 배 수준** 으로 뛰어넘는 AI<br>- 범용 인공지능 (AGI) 이 **인간과 동일한 수준** 이라면, 초인공지능 (ASI) 은 **인간보다 훨씬 뛰어난 AI** |

## 2025.12.04 (목)
**[이 대통령, 내일 손정의 소프트뱅크 회장 회동](https://n.news.naver.com/mnews/article/052/0002282669?sid=100)** ```AI```

* 2025.12.05일 이재명 대통령이 손정의 소프트뱅크 회장과의 만남을 가질 예정이다.
  * 이는 **AI 관련 협력 네트워크 관계를 맺는 데 집중하는** 것으로 풀이된다. 
* 이번 회동에서는 **국내 AI 인프라 및 반도체 관련 협력 논의** 가 이루어질 것으로 보인다.
* 이번 회동의 의의는 다음과 같다.
  * **세계 3대 AI 강국** 을 목표로 한 협력 논의
  * AI를 **대한민국의 미래 산업으로 육성** 하려는 의지
  * 민생 및 경제 성장 의지

## 2025.12.03 (수)
**[AI, 해킹 무기로 악용되다](https://n.news.naver.com/mnews/article/003/0013635434?sid=105)** ```AI``` ```Generative AI```

* 최근 생성형 AI 등 AI 기술이 **해커들에게 해킹 무기로 악용** 되고 있다.
  * '2025 AI 보안 인사이트' 보고서에 따르면 **AI 기반 사이버 공격은 현재 초당 36,000건 정도 발생** 한다.
* 해커의 '생산성 향상'을 유발하는 것은 AI 기술이다.
  * DarkGPT 등 **해킹용 LLM** 을 통해 초보 해커도 해킹 공격을 쉽게 시도할 수 있다.
  * 피싱에 AI가 악용되는 경우, **기존에 16시간 걸렸던 준비 작업을 5분 만에 끝낼** 수 있다고 한다.
* 또한, **해킹의 대상은 AI가 될 수도 있다.** (AI가 AI를 해킹)
  * 다른 AI뿐만 아니라 **자기 자신도 공격 대상** 이 될 수 있다.

## 2025.12.02 (화)
**[LLM 버블, 2026년 붕괴된다](https://n.news.naver.com/mnews/article/421/0008624491?sid=105)** ```AI``` ```Large Language Model```

* 최근 HuggingFace CEO가 **거대 언어 모델 등에 관심이 지나치게 집중되어서 오히려 비효율적인 상황** 이라고 언급했다.
  * 이와 함께 **거대 언어 모델 (LLM) 버블이 2026년에 붕괴될 수 있다** 고 말했다.
* LLM 버블 붕괴 예측의 상세 근거는 다음과 같다.
  * 범용 거대 모델 (LLM 등) 을 통해 **모든 문제를 해결할 수 있다는 아이디어에 관심이 집중** 된 상태
  * 실제 현실에서는 **분야별로 특화된 모델을 통해 문제를 해결** 하게 될 것이기 때문
  * LLM 관심 집중과 같은 **단기적인 접근은 일종의 '사이클'**
* LLM 버블 붕괴 예측의 핵심은 **각 분야에 특화된 '버티컬 AI'** 가 중요하다는 것이다.
  * 실제로 시장조사기관 보고서에서도 버티컬 AI 시장의 성장 추이가 확인된다. 
* 한편, 향후 소프트웨어 분야의 비즈니스는 **독립 앱보다는 AI 에이전트 탑재 방식의 버티컬 AI로 재편** 된다는 전망이 있다.

## 2025.12.01 (월)
**[안과 분야, 이제 AI가 의사보다 임상 역량 우수](https://n.news.naver.com/mnews/article/003/0013631408?sid=102)**

* 안과 분야 임상과 관련된 **고난이도 문제 풀이** 를 시킨 결과, **AI가 의사보다 정확도가 높았다** 는 연구 결과가 발표되었다.
  * 심지어 **의사가 인공지능을 활용한 경우** 보다도 **AI 혼자서 문제를 풀었을 때의 성적이 더 높다** 고 나왔다.
* 해당 연구 결과에 대한 정보는 다음과 같다.

| 구분      | 설명                                             |
|---------|------------------------------------------------|
| 학술대회 명칭 | 아시아 망막학회 국제학술대회 (The 5th Asia Retina Congress) |
| 연구 명칭   | 임상 추론에서의 인간과 인공지능의 협력 (HAC) 의 성공과 실패           |

* 연구에 대한 상세 정보는 다음과 같다.

| 연구 정보    | 설명                                                                                                                |
|----------|-------------------------------------------------------------------------------------------------------------------|
| 임상 문제 수  | 30문항 (적절한 진단/처치법 4지선다형)                                                                                           |
| 비교 대상 방법 | 인간 의사 단독, AI 단독, 의사-AI 간 협업 (HAC) 의 3가지                                                                           |
| 연구 성과    | 의사와 AI 간 **협업 시 성능 저하 원인** 규명<br>- 그 원인은 **인간의 잘못된 판단을 AI가 무비판적으로 수용하거나, 반대로 AI의 오류를 인간이 무비판적으로 수용** 하는 경우가 있기 때문 |
| 사용 AI 모델 | Claude-3.5                                                                                                        |

* 각 Case 별 정확도는 다음과 같다.

| 인간 의사 단독 | AI 단독 | 의사-AI 간 협업 |
|----------|-------|------------|
| 45%      | 70%   | 60%        |