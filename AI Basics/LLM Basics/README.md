 * LLM 기초 정리
   * RAG, 양자화 등 LLM 관련 기초 기술 정리
   * 향후 DeepSeek 모델 Deep Dive 및 미니 프로젝트 시 도움이 될 것으로 예상

## Large Language Model (LLM) Basics

* 🌱 **기본 개념**
  * [LLM 기본](LLM_기초_LLM_basics.md)
  * [추론형 모델](LLM_기초_추론형_모델.md)
  * [LLM 의 Decoding (텍스트 생성) 전략](LLM_기초_Decoding_Strategies.md)
  * [LLM 의 성능 평가 (벤치마크 등)](LLM_기초_LLM의_성능_평가.md)

* 👱‍♀️ **LLM 의 Fine-Tuning**
  * [LLM Fine-Tuning 기본](LLM_기초_Fine_Tuning.md)
  * [DPO & ORPO](LLM_기초_Fine_Tuning_DPO_ORPO.md)
  * [LoRA (Low-Rank Adaption) & QLoRA](LLM_기초_Fine_Tuning_LoRA_QLoRA.md)
  * [PEFT (Parameter-Efficient Fine-Tuning)](LLM_기초_Fine_Tuning_PEFT.md)
  * [SFT (Supervised Fine-Tuning)](LLM_기초_Fine_Tuning_SFT.md)

* 🤖 **LLM 에서 사용되는 기술**
  * [LangChain](LLM_기초_Langchain.md)
  * [Mixture of Experts (MoE)](LLM_기초_Mixture_of_Experts.md)
  * [Prompt Engineering](LLM_기초_Prompt_Engineering.md)
  * [Quantization](LLM_기초_Quantization.md)
  * [RAG (Retrieval-Augmented Generation)](LLM_기초_RAG.md)
  * [Chain of Thought (CoT)](LLM_기초_Chain_of_Thought.md)

* 🌐 **LLM 관련 웹사이트**
  * [HuggingFace 소개](LLM_기초_HuggingFace.md)

* 🚨 **LLM 의 이슈**
  * [환각 현상 (Hallucination)](LLM_기초_환각_현상.md)
