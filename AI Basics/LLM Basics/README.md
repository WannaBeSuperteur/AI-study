 * LLM ê¸°ì´ˆ ì •ë¦¬
   * RAG, ì–‘ìí™” ë“± LLM ê´€ë ¨ ê¸°ì´ˆ ê¸°ìˆ  ì •ë¦¬
   * í–¥í›„ DeepSeek ëª¨ë¸ Deep Dive ë° ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ ì‹œ ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒ

## Large Language Model (LLM) Basics

* ğŸŒ± **ê¸°ë³¸ ê°œë…**
  * [LLM ê¸°ë³¸](LLM_ê¸°ì´ˆ_LLM_basics.md)
  * [ì¶”ë¡ í˜• ëª¨ë¸](LLM_ê¸°ì´ˆ_ì¶”ë¡ í˜•_ëª¨ë¸.md)
  * [LLM ì˜ Decoding (í…ìŠ¤íŠ¸ ìƒì„±) ì „ëµ](LLM_ê¸°ì´ˆ_Decoding_Strategies.md)
  * [LLM ì˜ ì„±ëŠ¥ í‰ê°€ (ë²¤ì¹˜ë§ˆí¬ ë“±)](LLM_ê¸°ì´ˆ_LLMì˜_ì„±ëŠ¥_í‰ê°€.md)

* ğŸ‘±â€â™€ï¸ **LLM ì˜ Fine-Tuning**
  * [LLM Fine-Tuning ê¸°ë³¸](LLM_ê¸°ì´ˆ_Fine_Tuning.md)
  * [DPO & ORPO](LLM_ê¸°ì´ˆ_Fine_Tuning_DPO_ORPO.md)
  * [LoRA (Low-Rank Adaption) & QLoRA](LLM_ê¸°ì´ˆ_Fine_Tuning_LoRA_QLoRA.md)
  * [PEFT (Parameter-Efficient Fine-Tuning)](LLM_ê¸°ì´ˆ_Fine_Tuning_PEFT.md)
  * [SFT (Supervised Fine-Tuning)](LLM_ê¸°ì´ˆ_Fine_Tuning_SFT.md)

* ğŸ¤– **LLM ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ **
  * [LangChain](LLM_ê¸°ì´ˆ_Langchain.md)
  * [Mixture of Experts (MoE)](LLM_ê¸°ì´ˆ_Mixture_of_Experts.md)
  * [Prompt Engineering](LLM_ê¸°ì´ˆ_Prompt_Engineering.md)
  * [Quantization](LLM_ê¸°ì´ˆ_Quantization.md)
  * [RAG (Retrieval-Augmented Generation)](LLM_ê¸°ì´ˆ_RAG.md)
  * [Chain of Thought (CoT)](LLM_ê¸°ì´ˆ_Chain_of_Thought.md)

* ğŸŒ **LLM ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸**
  * [HuggingFace ì†Œê°œ](LLM_ê¸°ì´ˆ_HuggingFace.md)

* ğŸš¨ **LLM ì˜ ì´ìŠˆ**
  * [í™˜ê° í˜„ìƒ (Hallucination)](LLM_ê¸°ì´ˆ_í™˜ê°_í˜„ìƒ.md)
