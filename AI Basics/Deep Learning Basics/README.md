
## Deep Learning (DL) Basics

* ğŸŒ± **ê¸°ë³¸ ê°œë…**
  * [AI, ML (ë¨¸ì‹ ëŸ¬ë‹), DL (ë”¥ëŸ¬ë‹)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_AI_ML_DL.md)
  * [ì¸ê³µì‹ ê²½ë§ (ANN)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_ì¸ê³µì‹ ê²½ë§.md)
  * [í¼ì…‰íŠ¸ë¡  (Perceptron)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_í¼ì…‰íŠ¸ë¡ .md)

* âš¡ **í•™ìŠµ í”„ë¡œì„¸ìŠ¤ & ëª¨ë¸ ê¸°ë³¸ ì„¤ì •**
  * [Early Stopping](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Early_Stopping.md)
  * [Learning Rate](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Learning_Rate.md)
    * [Learning Rate Scheduler](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Learning_Rate_Scheduler.md)
  * [Optimizer](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Optimizer.md)
  * [Regularization](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Regularization.md)
  * [Weight Initialization](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Weight_initialization.md)
  * [Shared Backbone & Shared Head](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Shared_Backbone_Head.md) ([ì¶”ê°€ ì‹¤í—˜](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Shared_Backbone_Head_2.md))

* ğŸ”® **ë”¥ëŸ¬ë‹ í•™ìŠµì— ì“°ì´ëŠ” í•¨ìˆ˜**
  * [Loss Function](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Loss_function.md)
    * [Loss Function ì„ ì˜ëª» ì‚¬ìš©í•˜ë©´?](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Loss_Function_Misuse.md)
  * [í™œì„±í™” í•¨ìˆ˜ (Activation Function)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_í™œì„±í™”_í•¨ìˆ˜.md)
    * [í™œì„±í™” í•¨ìˆ˜ë¥¼ ì˜ëª» ì‚¬ìš©í•˜ë©´?](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_í™œì„±í™”_í•¨ìˆ˜_Misuse.md)

* ğŸš¨ **ë”¥ëŸ¬ë‹ í•™ìŠµ ì‹œ ì´ìŠˆ**
  * [Overfitting (+ í•´ê²° ë°©ë²•: Dropout)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Overfitting_Dropout.md)

* ğŸ’» **ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬**
  * [TensorFlow vs. PyTorch](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_TensorFlow_vs_PyTorch.md)

* ğŸ“¥ **ë‹¤ë¥¸ ëª¨ë¸ì„ ì´ìš©í•œ í•™ìŠµ**
  * [Transfer Learning (ì „ì´í•™ìŠµ)](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Transfer_Learning.md)
  * [Knowledge Distillation](ë”¥ëŸ¬ë‹_ê¸°ì´ˆ_Knowledge_Distillation.md)

* ğŸ‘¨â€ğŸ’» **ë”¥ëŸ¬ë‹ ì‹¤ë¬´ (PyTorch)**
  * [state dict ì‚¬ìš©ë²•](ë”¥ëŸ¬ë‹_ì‹¤ë¬´_PyTorch_state_dict_ì‚¬ìš©ë²•.md)
  * [ë ˆì´ì–´ ê°€ì¤‘ì¹˜ ë° ì¶œë ¥ í™•ì¸ ë°©ë²•](ë”¥ëŸ¬ë‹_ì‹¤ë¬´_PyTorch_ë ˆì´ì–´_ê°€ì¤‘ì¹˜_ë°_ì¶œë ¥_í™•ì¸.md)
  * [ëª¨ë¸ êµ¬ì¡° ì‹œê°í™” ë°©ë²•](ë”¥ëŸ¬ë‹_ì‹¤ë¬´_PyTorch_ëª¨ë¸_êµ¬ì¡°_ì‹œê°í™”.md)
