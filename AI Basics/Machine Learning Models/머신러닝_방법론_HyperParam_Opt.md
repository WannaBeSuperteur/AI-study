## 목차
* [1. 하이퍼파라미터 (Hyper-parameter)](#1-하이퍼파라미터-hyper-parameter)
* [2. 하이퍼파라미터 최적화 (튜닝)](#2-하이퍼파라미터-최적화-튜닝)
* [3. 하이퍼파라미터 최적화 방법론](#3-하이퍼파라미터-최적화-방법론)
  * [3-1. Grid Search, Random Search](#3-1-grid-search-random-search)
  * [3-2. Bayesian 최적화](#3-2-bayesian-최적화)
* [4. 하이퍼파라미터 최적화 라이브러리](#4-하이퍼파라미터-최적화-라이브러리)
  * [4-1. HyperOpt](#4-1-hyperopt)
  * [4-2. Optuna](#4-2-optuna)
  * [4-3. HyperOpt vs. Optuna](#4-3-hyperopt-vs-optuna)

## 1. 하이퍼파라미터 (Hyper-parameter)
**하이퍼파라미터 (Hyper-parameter)** 는 머신러닝 알고리즘을 통해 직접 찾는 값이 아닌, **해당 알고리즘을 설계하는 데 있어서의 설정값** 을 의미한다.

대표적인 하이퍼파라미터는 다음과 같다.

| 구분                   | 하이퍼파라미터                                                                                                                                                                                                |
|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 딥 러닝 (Deep Learning) | - hidden layer의 개수 및 각 layer에 있는 뉴런 개수<br>- 학습률 (Learning Rate)<br>- weight decay<br>- [L1, L2 Regularization](../Deep%20Learning%20Basics/딥러닝_기초_Regularization.md#l1-l2-regularization) 에서의 lambda 값 |
| 트리 기반 모델             | - 트리의 최대 깊이<br>- 각 Tree가 갖는 leaf node의 최대 개수                                                                                                                                                           |                                                                                                                                      
| 기타 주요 머신러닝 모델        | - [k-NN](머신러닝_모델_KNN.md) 에서의 K 값<br> - [K-means Clustering](머신러닝_모델_K-means_Clustering.md) 에서의 K 값                                                                                                     |                                                                                                                                                            
| 모델별 하이퍼파라미터          | 각 모델별, 해당 모델에서 사용하는 하이퍼파라미터                                                                                                                                                                            |                                                                                                                                                                           

## 2. 하이퍼파라미터 최적화 (튜닝)

하이퍼파라미터 최적화는 **하이퍼파라미터 튜닝 (Hyper-parameter tuning)** 이라고도 하며, **모델의 하이퍼파라미터를 특정 데이터셋에 최적화** 하는 것이다.

하이퍼파라미터 최적화가 필요한 이유는 다음과 같다.
* 각 하이퍼파라미터의 기본 설정값 또는 관습적으로 설정하는 값은 **원하는 데이터셋에 최적화가 되어 있지 않기** 때문이다.
* 각 데이터셋 별로 그 특성에 따라 **최적의 하이퍼파라미터가 다를 수 있기** 때문이다.
  * 데이터셋 크기에 따라 overfitting 방지를 위해 설정하는 특정 하이퍼파라미터의 최적 값이 다를 수 있다. 

**하이퍼파라미터 최적화는 test dataset 이 아닌 valid dataset 에서 해야 한다.**
* 이를 위해 valid dataset을 다음과 같이 구분할 수도 있다.
  * 특정 하이퍼파라미터 조합 하에서의 모델 학습용
  * 하이퍼파라미터 최적화 용
* **test dataset 으로 하이퍼파라미터를 최적화** 하면 **하이퍼파라미터에 대한 overfitting** 이 발생할 수도 있다. 

## 3. 하이퍼파라미터 최적화 방법론

널리 알려진 하이퍼파라미터 최적화 방법론은 다음과 같다.

| 방법론                   | 설명                                                                               |
|-----------------------|----------------------------------------------------------------------------------|
| Grid Search           | 지정된 하이퍼파라미터 범위 내에서 **바둑판 or 격자점 형태로 모든** 하이퍼파라미터 조합에 대해 테스트                      |
| Random Search         | 지정된 하이퍼파라미터 범위 내에서 **특정 횟수만큼 랜덤하게 하이퍼파라미터 조합을 생성** 하고, 그 조합에 대해 테스트              |
| Bayesian Optimization | **성능이 좋았던 하이퍼파라미터 조합과 거리가 가까운** 조합 위주로 탐색<br>- 확률적으로 성능이 좋을 것으로 예상되는 하이퍼파라미터를 탐색 |

### 3-1. Grid Search, Random Search

**Grid Search**
* 지정된 범위 내에서 바둑판 (격자점) 형태로 모든 하이퍼파라미터의 조합에 대해서 성능을 탐색한다.
* 이들 중 성능이 가장 높은 최적의 조합을 찾는다.
* **테스트할 하이퍼파라미터 개수가 커질수록 최적화 시간이 기하급수적으로 늘어난다.**

**Random Search**
* 지정된 범위 내에서 특정 횟수만큼 랜덤하게 하이퍼파라미터 조합을 생성한다.
* 생성된 조합들 중 마찬가지로 성능이 가장 높은 최적의 조합을 찾는다.

![image](images/Hyperparam_Opt.PNG)

### 3-2. Bayesian 최적화

**Bayesian 최적화 (Bayesian Optimization)** 의 핵심 아이디어는 다음과 같다.
* 지금까지의 통계에 근거하여, 성능이 가장 좋았던 하이퍼파라미터의 조합과 거리가 가까운 조합 위주로 탐색한다.
* 이것은 **확률적으로 성능이 좋을 것으로 예상되는** 하이퍼파라미터이다.

Bayesian 최적화는 성능이 좋을 것으로 예상되는 쪽으로 하이퍼파라미터를 탐색하므로, **빠른 시간 내에 최적 성능에 가까운 하이퍼파라미터를 찾을 수 있다** 는 장점이 있다. 

----

Bayesian 최적화를 이해하기 위한 핵심 개념은 다음과 같다.

| 개념                               | 설명                                                                                                                                                                               |
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Surrogate Model                  | 하이퍼파라미터 조합을 입력값, 성능 metric 값을 출력값으로 하는 모델                                                                                                                                        |
| Acquisiton Function              | Surrogate Model의 학습 데이터로 추가할 **다음 하이퍼파라미터 조합을 생성** 하는 함수<br>- Exploitation : 현재까지 **확률적으로 성능지표 값이 높았던 조합과 가까운** 거리의 조합으로 생성<br>- Exploration : 그 외의 **불확실성이 높은** 하이퍼파라미터 조합으로 생성 |

Acquisition Function에는 대표적으로 **EI (Expected Improvement)** 와 **POI (Probability of Improvement)** 가 있다.

**1. EI (Expected Improvement)**

* 해당 하이퍼파라미터 조합으로 성능이 어느 정도 개선될지를 확률적으로 계산

**2. POI (Probability of Improvement)**

* 새로운 하이퍼파라미터 조합에 의한 예측 성능값 분포의 평균이 현재까지의 성능값의 최댓값보다 더 클 확률을 계산

## 4. 하이퍼파라미터 최적화 라이브러리
### 4-1. HyperOpt

### 4-2. Optuna

### 4-3. HyperOpt vs. Optuna