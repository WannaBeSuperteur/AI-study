{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iq9O5OhCDs8",
        "outputId": "1853ad8f-24b5-4903-effe-36d87315b3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score # f1_score, recall_score\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "WqCsd7NGIwOK"
      },
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 학습 데이터 생성**"
      ],
      "metadata": {
        "id": "Rb4OMsLAJU_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 가져오기\n",
        "\n",
        "data = datasets.fetch_covtype()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "_9nx8zT-Ifeq"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤한 1500 개의 데이터를 학습\n",
        "\n",
        "num_samples = 1500\n",
        "np.random.seed(2025)\n",
        "indices = np.random.choice(X.shape[0], num_samples, replace=False)\n",
        "\n",
        "X = X[indices]\n",
        "y = y[indices]"
      ],
      "metadata": {
        "id": "iPfWYvcNbDe9"
      },
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인하기\n",
        "\n",
        "X = pd.DataFrame(X, columns=data.feature_names)"
      ],
      "metadata": {
        "id": "kG3OFgoMJITk"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "KxYhhMH7JrGO",
        "outputId": "1a4d4ac4-588b-42e2-9c72-148c542e7d64"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0        3197.0   229.0   15.0                             547.0   \n",
              "1        2483.0    21.0    8.0                             218.0   \n",
              "2        2856.0    63.0    7.0                             150.0   \n",
              "3        3129.0   100.0   19.0                             339.0   \n",
              "4        2607.0    69.0   15.0                              90.0   \n",
              "...         ...     ...    ...                               ...   \n",
              "1495     2625.0   341.0   16.0                             350.0   \n",
              "1496     2441.0    10.0   14.0                             255.0   \n",
              "1497     2709.0   103.0    6.0                             124.0   \n",
              "1498     2300.0   288.0   12.0                              85.0   \n",
              "1499     2977.0   349.0   28.0                             323.0   \n",
              "\n",
              "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               88.0                            450.0   \n",
              "1                               40.0                            150.0   \n",
              "2                                8.0                           1271.0   \n",
              "3                               68.0                           1693.0   \n",
              "4                              -18.0                           1020.0   \n",
              "...                              ...                              ...   \n",
              "1495                            19.0                           2741.0   \n",
              "1496                            50.0                            499.0   \n",
              "1497                            18.0                           1641.0   \n",
              "1498                            20.0                           1448.0   \n",
              "1499                            87.0                           1853.0   \n",
              "\n",
              "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0             196.0           253.0          191.0   \n",
              "1             215.0           223.0          145.0   \n",
              "2             227.0           225.0          132.0   \n",
              "3             248.0           211.0           84.0   \n",
              "4             234.0           210.0          103.0   \n",
              "...             ...             ...            ...   \n",
              "1495          184.0           214.0          168.0   \n",
              "1496          203.0           210.0          142.0   \n",
              "1497          231.0           232.0          134.0   \n",
              "1498          187.0           239.0          192.0   \n",
              "1499          158.0           183.0          156.0   \n",
              "\n",
              "      Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
              "0                                 2960.0  ...           1.0           0.0   \n",
              "1                                 1771.0  ...           0.0           0.0   \n",
              "2                                 2311.0  ...           0.0           0.0   \n",
              "3                                 2755.0  ...           0.0           0.0   \n",
              "4                                  765.0  ...           0.0           0.0   \n",
              "...                                  ...  ...           ...           ...   \n",
              "1495                              2635.0  ...           0.0           0.0   \n",
              "1496                              1194.0  ...           0.0           0.0   \n",
              "1497                              3463.0  ...           0.0           0.0   \n",
              "1498                               721.0  ...           0.0           0.0   \n",
              "1499                              1537.0  ...           0.0           0.0   \n",
              "\n",
              "      Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
              "0              0.0           0.0           0.0           0.0           0.0   \n",
              "1              0.0           0.0           0.0           0.0           0.0   \n",
              "2              0.0           0.0           0.0           0.0           0.0   \n",
              "3              0.0           0.0           0.0           0.0           0.0   \n",
              "4              0.0           0.0           0.0           0.0           0.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1495           0.0           0.0           0.0           0.0           0.0   \n",
              "1496           0.0           0.0           0.0           0.0           0.0   \n",
              "1497           0.0           0.0           0.0           0.0           0.0   \n",
              "1498           0.0           0.0           0.0           0.0           0.0   \n",
              "1499           1.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
              "0              0.0           0.0           0.0  \n",
              "1              0.0           0.0           0.0  \n",
              "2              0.0           0.0           0.0  \n",
              "3              0.0           0.0           0.0  \n",
              "4              0.0           0.0           0.0  \n",
              "...            ...           ...           ...  \n",
              "1495           0.0           0.0           0.0  \n",
              "1496           0.0           0.0           0.0  \n",
              "1497           0.0           0.0           0.0  \n",
              "1498           0.0           0.0           0.0  \n",
              "1499           0.0           0.0           0.0  \n",
              "\n",
              "[1500 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-793588f8-f4ce-4643-bb7d-e9ef2409c120\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type_30</th>\n",
              "      <th>Soil_Type_31</th>\n",
              "      <th>Soil_Type_32</th>\n",
              "      <th>Soil_Type_33</th>\n",
              "      <th>Soil_Type_34</th>\n",
              "      <th>Soil_Type_35</th>\n",
              "      <th>Soil_Type_36</th>\n",
              "      <th>Soil_Type_37</th>\n",
              "      <th>Soil_Type_38</th>\n",
              "      <th>Soil_Type_39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3197.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>547.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>2960.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2483.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>1771.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2856.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1271.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2311.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3129.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>339.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1693.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2755.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2607.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>765.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>2625.0</td>\n",
              "      <td>341.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2741.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>2635.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>2441.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>2709.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1641.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>3463.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>2300.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1448.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>721.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>2977.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1853.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 54 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-793588f8-f4ce-4643-bb7d-e9ef2409c120')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-793588f8-f4ce-4643-bb7d-e9ef2409c120 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-793588f8-f4ce-4643-bb7d-e9ef2409c120');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-05a4d924-f327-48a3-b28b-f231eeb8c865\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05a4d924-f327-48a3-b28b-f231eeb8c865')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-05a4d924-f327-48a3-b28b-f231eeb8c865 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_71eaa80c-97b2-45d9-8217-a08ea404e1d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_71eaa80c-97b2-45d9-8217-a08ea404e1d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y, columns=['target'])"
      ],
      "metadata": {
        "id": "N2I-080cJX4n"
      },
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "k8pEIshgJsxl",
        "outputId": "8c136c31-b9af-4b1b-ea45-c9712ab04b66"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target\n",
              "0          2\n",
              "1          3\n",
              "2          2\n",
              "3          2\n",
              "4          2\n",
              "...      ...\n",
              "1495       2\n",
              "1496       6\n",
              "1497       2\n",
              "1498       6\n",
              "1499       2\n",
              "\n",
              "[1500 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87f17d63-8401-41a0-9a61-b011ee98044b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87f17d63-8401-41a0-9a61-b011ee98044b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87f17d63-8401-41a0-9a61-b011ee98044b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87f17d63-8401-41a0-9a61-b011ee98044b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69eabd63-de0c-44e2-b802-d35b6ca57a48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69eabd63-de0c-44e2-b802-d35b6ca57a48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69eabd63-de0c-44e2-b802-d35b6ca57a48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_84ed96a2-0712-4c66-9003-a1e9f9b64ba3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_84ed96a2-0712-4c66-9003-a1e9f9b64ba3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 분포 확인\n",
        "\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "yjUgKUX8JxWo",
        "outputId": "bd480791-dfda-4125-ef44-75bb55c206ed"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "2         716\n",
              "1         547\n",
              "3          82\n",
              "7          62\n",
              "6          55\n",
              "5          26\n",
              "4          12\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test_hpo, test_new 데이터셋으로 Split\n",
        "# overfitting 여부를 판단하려면 y의 class 분포를 일치시키는 것이 비교적 좋음\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# [ Entire Dataset ] ---> [ Train ] / [ Test_hpo ] / [ Test_new ]\n",
        "X_train, X_test_new, y_train, y_test_new =\\\n",
        "    train_test_split(X, y,\n",
        "                     test_size=0.2,\n",
        "                     stratify=y,  # overfitting 여부 판단에 도움\n",
        "                     random_state=2027)\n",
        "\n",
        "X_train_, X_test_hpo, y_train_, y_test_hpo =\\\n",
        "    train_test_split(X_train, y_train,\n",
        "                     test_size=0.2,\n",
        "                     stratify=y_train,  # overfitting 여부 판단에 도움\n",
        "                     random_state=2027)"
      ],
      "metadata": {
        "id": "LD8Jgt_VJ0Zv"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data 확인\n",
        "\n",
        "X_train_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "sxfs1z8FL1mp",
        "outputId": "d0bc74e3-b8ed-405f-f340-672d44daaa46"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "131      2646.0   139.0   16.0                             283.0   \n",
              "562      2602.0     0.0    6.0                             306.0   \n",
              "696      3371.0   279.0   10.0                             421.0   \n",
              "782      3028.0    98.0    8.0                              85.0   \n",
              "87       2419.0    80.0   15.0                             309.0   \n",
              "...         ...     ...    ...                               ...   \n",
              "1348     2945.0    71.0    9.0                              90.0   \n",
              "1049     3029.0   350.0    7.0                              67.0   \n",
              "545      2815.0   210.0   16.0                              30.0   \n",
              "540      3365.0    67.0   17.0                             258.0   \n",
              "708      3060.0   225.0   11.0                             570.0   \n",
              "\n",
              "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "131                              6.0                            875.0   \n",
              "562                             84.0                           2407.0   \n",
              "696                             31.0                           3142.0   \n",
              "782                             10.0                           1805.0   \n",
              "87                              83.0                            598.0   \n",
              "...                              ...                              ...   \n",
              "1348                            16.0                           4918.0   \n",
              "1049                             3.0                           4662.0   \n",
              "545                             -4.0                           1140.0   \n",
              "540                             43.0                           2058.0   \n",
              "708                            193.0                           5995.0   \n",
              "\n",
              "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "131           242.0           233.0          115.0   \n",
              "562           212.0           229.0          155.0   \n",
              "696           192.0           242.0          189.0   \n",
              "782           234.0           228.0          126.0   \n",
              "87            239.0           211.0           98.0   \n",
              "...             ...             ...            ...   \n",
              "1348          231.0           222.0          124.0   \n",
              "1049          208.0           229.0          159.0   \n",
              "545           206.0           253.0          179.0   \n",
              "540           235.0           205.0           97.0   \n",
              "708           205.0           251.0          182.0   \n",
              "\n",
              "      Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
              "131                                598.0  ...           0.0           0.0   \n",
              "562                                488.0  ...           0.0           0.0   \n",
              "696                               1832.0  ...           0.0           0.0   \n",
              "782                               1683.0  ...           0.0           0.0   \n",
              "87                                1364.0  ...           0.0           0.0   \n",
              "...                                  ...  ...           ...           ...   \n",
              "1348                              6234.0  ...           0.0           0.0   \n",
              "1049                               842.0  ...           0.0           0.0   \n",
              "545                               1749.0  ...           0.0           0.0   \n",
              "540                               3387.0  ...           0.0           0.0   \n",
              "708                               3909.0  ...           0.0           0.0   \n",
              "\n",
              "      Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
              "131            0.0           0.0           0.0           0.0           0.0   \n",
              "562            0.0           0.0           0.0           0.0           0.0   \n",
              "696            0.0           0.0           0.0           0.0           0.0   \n",
              "782            0.0           0.0           0.0           0.0           0.0   \n",
              "87             0.0           0.0           0.0           0.0           0.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1348           0.0           0.0           0.0           0.0           0.0   \n",
              "1049           0.0           0.0           0.0           0.0           0.0   \n",
              "545            0.0           0.0           0.0           0.0           0.0   \n",
              "540            0.0           0.0           0.0           0.0           0.0   \n",
              "708            0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
              "131            0.0           0.0           0.0  \n",
              "562            0.0           0.0           0.0  \n",
              "696            0.0           1.0           0.0  \n",
              "782            0.0           0.0           0.0  \n",
              "87             0.0           0.0           0.0  \n",
              "...            ...           ...           ...  \n",
              "1348           0.0           0.0           0.0  \n",
              "1049           0.0           0.0           0.0  \n",
              "545            0.0           0.0           0.0  \n",
              "540            1.0           0.0           0.0  \n",
              "708            0.0           0.0           0.0  \n",
              "\n",
              "[960 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6ac0536-caaa-43c8-b969-6c97ee82827a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type_30</th>\n",
              "      <th>Soil_Type_31</th>\n",
              "      <th>Soil_Type_32</th>\n",
              "      <th>Soil_Type_33</th>\n",
              "      <th>Soil_Type_34</th>\n",
              "      <th>Soil_Type_35</th>\n",
              "      <th>Soil_Type_36</th>\n",
              "      <th>Soil_Type_37</th>\n",
              "      <th>Soil_Type_38</th>\n",
              "      <th>Soil_Type_39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>2646.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>875.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>2602.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2407.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>3371.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3142.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>1832.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>3028.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1805.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>1683.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>2419.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>309.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>1364.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>2945.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4918.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>6234.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049</th>\n",
              "      <td>3029.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4662.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>842.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>2815.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>1749.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>3365.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2058.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>3387.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>3060.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>5995.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>3909.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>960 rows × 54 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6ac0536-caaa-43c8-b969-6c97ee82827a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6ac0536-caaa-43c8-b969-6c97ee82827a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6ac0536-caaa-43c8-b969-6c97ee82827a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8240e8f-f11c-400f-82df-09bedd690a79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8240e8f-f11c-400f-82df-09bedd690a79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8240e8f-f11c-400f-82df-09bedd690a79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d341e541-27b7-44e7-bd64-3fb6ba3bcbc6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train_')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d341e541-27b7-44e7-bd64-3fb6ba3bcbc6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train_');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_"
            }
          },
          "metadata": {},
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GIHLabGVOvb_",
        "outputId": "1647f6d4-655e-439a-8a52-0cebf4104713"
      },
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target\n",
              "131        3\n",
              "562        3\n",
              "696        1\n",
              "782        1\n",
              "87         6\n",
              "...      ...\n",
              "1348       2\n",
              "1049       2\n",
              "545        2\n",
              "540        7\n",
              "708        2\n",
              "\n",
              "[960 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c40e6ad-b9a8-4b7e-91a2-37c59f1a848a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>960 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c40e6ad-b9a8-4b7e-91a2-37c59f1a848a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c40e6ad-b9a8-4b7e-91a2-37c59f1a848a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c40e6ad-b9a8-4b7e-91a2-37c59f1a848a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-121b7db1-e58d-4c83-af88-311f63c604ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-121b7db1-e58d-4c83-af88-311f63c604ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-121b7db1-e58d-4c83-af88-311f63c604ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0b7edb91-b9d2-423f-afc7-0402f34e3b30\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_train_')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0b7edb91-b9d2-423f-afc7-0402f34e3b30 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_train_');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_train_",
              "summary": "{\n  \"name\": \"y_train_\",\n  \"rows\": 960,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3,\n          1,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_count = y_train_.value_counts()\n",
        "y_train_normalized = y_train_.value_counts(normalize=True)\n",
        "\n",
        "y_train_distrib = pd.DataFrame({'count': y_train_count, 'percentage': 100 * y_train_normalized})\n",
        "y_train_distrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3V9o4SckO1L5",
        "outputId": "9051cb17-0588-4f7a-9c0a-b9104223956f"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        count  percentage\n",
              "target                   \n",
              "2         458   47.708333\n",
              "1         350   36.458333\n",
              "3          53    5.520833\n",
              "7          40    4.166667\n",
              "6          35    3.645833\n",
              "5          17    1.770833\n",
              "4           7    0.729167"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd640ee6-3119-4525-be33-d1b176eacd4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>458</td>\n",
              "      <td>47.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>350</td>\n",
              "      <td>36.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>5.520833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>40</td>\n",
              "      <td>4.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35</td>\n",
              "      <td>3.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17</td>\n",
              "      <td>1.770833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>0.729167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd640ee6-3119-4525-be33-d1b176eacd4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd640ee6-3119-4525-be33-d1b176eacd4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd640ee6-3119-4525-be33-d1b176eacd4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b29401fe-e38e-4b5c-b8b3-b740e61a135f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b29401fe-e38e-4b5c-b8b3-b740e61a135f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b29401fe-e38e-4b5c-b8b3-b740e61a135f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c8e52fe6-e7f8-45eb-86cb-0f5b099d2ce0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_train_distrib')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c8e52fe6-e7f8-45eb-86cb-0f5b099d2ce0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_train_distrib');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_train_distrib",
              "summary": "{\n  \"name\": \"y_train_distrib\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185,\n        \"min\": 7,\n        \"max\": 458,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          458,\n          350,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.32840766652236,\n        \"min\": 0.7291666666666666,\n        \"max\": 47.708333333333336,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          47.708333333333336,\n          36.45833333333333,\n          1.7708333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_hpo 데이터 확인 (HPO 성능 최적화를 위한 metric 값 도출용)\n",
        "\n",
        "X_test_hpo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "e8sHqx3jOveV",
        "outputId": "deb2eca5-509f-4c7a-92cb-f2b9c0c84067"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "733      2662.0    99.0   19.0                             162.0   \n",
              "847      3005.0   307.0    5.0                              85.0   \n",
              "945      3023.0   103.0   19.0                             630.0   \n",
              "518      3134.0   336.0    9.0                             240.0   \n",
              "1364     3251.0   126.0   17.0                             395.0   \n",
              "...         ...     ...    ...                               ...   \n",
              "676      2940.0   111.0    4.0                             127.0   \n",
              "970      3301.0   135.0    5.0                             469.0   \n",
              "960      2926.0   255.0    5.0                             391.0   \n",
              "1387     2592.0    90.0   14.0                             218.0   \n",
              "395      2704.0    41.0   14.0                             408.0   \n",
              "\n",
              "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "733                             49.0                           2318.0   \n",
              "847                              6.0                           4230.0   \n",
              "945                            216.0                            641.0   \n",
              "518                            -12.0                            633.0   \n",
              "1364                           -70.0                            488.0   \n",
              "...                              ...                              ...   \n",
              "676                              8.0                           3362.0   \n",
              "970                            121.0                           5272.0   \n",
              "960                             23.0                           5504.0   \n",
              "1387                           -16.0                            342.0   \n",
              "395                             47.0                            446.0   \n",
              "\n",
              "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "733           247.0           211.0           85.0   \n",
              "847           207.0           237.0          169.0   \n",
              "945           248.0           212.0           84.0   \n",
              "518           199.0           227.0          167.0   \n",
              "1364          246.0           226.0          102.0   \n",
              "...             ...             ...            ...   \n",
              "676           227.0           235.0          143.0   \n",
              "970           229.0           238.0          143.0   \n",
              "960           207.0           243.0          174.0   \n",
              "1387          241.0           216.0          101.0   \n",
              "395           221.0           209.0          121.0   \n",
              "\n",
              "      Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
              "733                               2432.0  ...           0.0           0.0   \n",
              "847                                636.0  ...           0.0           0.0   \n",
              "945                                977.0  ...           0.0           0.0   \n",
              "518                               1273.0  ...           0.0           0.0   \n",
              "1364                              4062.0  ...           0.0           0.0   \n",
              "...                                  ...  ...           ...           ...   \n",
              "676                               2546.0  ...           0.0           0.0   \n",
              "970                               1140.0  ...           0.0           0.0   \n",
              "960                               3856.0  ...           0.0           0.0   \n",
              "1387                              1224.0  ...           0.0           0.0   \n",
              "395                                819.0  ...           0.0           0.0   \n",
              "\n",
              "      Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
              "733            0.0           0.0           0.0           0.0           0.0   \n",
              "847            0.0           0.0           0.0           0.0           0.0   \n",
              "945            0.0           0.0           0.0           0.0           0.0   \n",
              "518            0.0           0.0           0.0           0.0           0.0   \n",
              "1364           0.0           0.0           0.0           0.0           0.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "676            0.0           0.0           0.0           0.0           0.0   \n",
              "970            0.0           0.0           0.0           0.0           0.0   \n",
              "960            0.0           0.0           0.0           0.0           0.0   \n",
              "1387           0.0           0.0           0.0           0.0           0.0   \n",
              "395            0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
              "733            0.0           0.0           0.0  \n",
              "847            0.0           0.0           0.0  \n",
              "945            0.0           0.0           0.0  \n",
              "518            0.0           0.0           0.0  \n",
              "1364           0.0           0.0           0.0  \n",
              "...            ...           ...           ...  \n",
              "676            0.0           0.0           0.0  \n",
              "970            0.0           0.0           0.0  \n",
              "960            0.0           0.0           0.0  \n",
              "1387           0.0           0.0           0.0  \n",
              "395            0.0           0.0           0.0  \n",
              "\n",
              "[240 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69b31f7e-d500-4928-b849-3f4d2bb8341e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type_30</th>\n",
              "      <th>Soil_Type_31</th>\n",
              "      <th>Soil_Type_32</th>\n",
              "      <th>Soil_Type_33</th>\n",
              "      <th>Soil_Type_34</th>\n",
              "      <th>Soil_Type_35</th>\n",
              "      <th>Soil_Type_36</th>\n",
              "      <th>Soil_Type_37</th>\n",
              "      <th>Soil_Type_38</th>\n",
              "      <th>Soil_Type_39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>2662.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2318.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2432.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>3005.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4230.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>3023.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>630.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>641.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>977.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>3134.0</td>\n",
              "      <td>336.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>633.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>1273.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>3251.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>4062.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>2940.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3362.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>2546.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>3301.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>5272.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>2926.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>5504.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>3856.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>2592.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>342.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>2704.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>408.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>446.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>819.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240 rows × 54 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69b31f7e-d500-4928-b849-3f4d2bb8341e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69b31f7e-d500-4928-b849-3f4d2bb8341e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69b31f7e-d500-4928-b849-3f4d2bb8341e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62de3b28-7537-47c0-894e-005715e2f831\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62de3b28-7537-47c0-894e-005715e2f831')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62de3b28-7537-47c0-894e-005715e2f831 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f07d80d3-cf61-407e-a63e-8d117de78166\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_test_hpo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f07d80d3-cf61-407e-a63e-8d117de78166 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_test_hpo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_hpo"
            }
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hpo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ssoc0HHYOvhf",
        "outputId": "c0f5e0d1-ef75-44c1-bdfb-fc8944fdeff3"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target\n",
              "733        3\n",
              "847        2\n",
              "945        2\n",
              "518        1\n",
              "1364       2\n",
              "...      ...\n",
              "676        2\n",
              "970        2\n",
              "960        2\n",
              "1387       2\n",
              "395        2\n",
              "\n",
              "[240 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d1d8895-7929-4a3c-afc0-ca82bf3c4934\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d1d8895-7929-4a3c-afc0-ca82bf3c4934')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d1d8895-7929-4a3c-afc0-ca82bf3c4934 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d1d8895-7929-4a3c-afc0-ca82bf3c4934');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-110f27bf-1f9e-435a-9f45-a36d1db0d150\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-110f27bf-1f9e-435a-9f45-a36d1db0d150')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-110f27bf-1f9e-435a-9f45-a36d1db0d150 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b9f793ab-3b83-42b3-a21c-c5122a2bb92c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_test_hpo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b9f793ab-3b83-42b3-a21c-c5122a2bb92c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_test_hpo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_test_hpo",
              "summary": "{\n  \"name\": \"y_test_hpo\",\n  \"rows\": 240,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 453
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hpo_count = y_test_hpo.value_counts()\n",
        "y_test_hpo_normalized = y_test_hpo.value_counts(normalize=True)\n",
        "\n",
        "y_test_hpo_distrib = pd.DataFrame({'count': y_test_hpo_count, 'percentage': 100 * y_test_hpo_normalized})\n",
        "y_test_hpo_distrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kM1AmTzIOo0Y",
        "outputId": "afc5657f-260f-4124-af1e-84dfa1790d28"
      },
      "execution_count": 454,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        count  percentage\n",
              "target                   \n",
              "2         115   47.916667\n",
              "1          87   36.250000\n",
              "3          13    5.416667\n",
              "7          10    4.166667\n",
              "6           9    3.750000\n",
              "5           4    1.666667\n",
              "4           2    0.833333"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92387481-517e-4335-bcc2-669bab3391a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115</td>\n",
              "      <td>47.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87</td>\n",
              "      <td>36.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>5.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>4.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9</td>\n",
              "      <td>3.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92387481-517e-4335-bcc2-669bab3391a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92387481-517e-4335-bcc2-669bab3391a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92387481-517e-4335-bcc2-669bab3391a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92d4c1fd-9eb7-4584-82ef-34f33f052422\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92d4c1fd-9eb7-4584-82ef-34f33f052422')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92d4c1fd-9eb7-4584-82ef-34f33f052422 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_282b25dc-e897-4124-981d-0261c6813a0b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_test_hpo_distrib')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_282b25dc-e897-4124-981d-0261c6813a0b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_test_hpo_distrib');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_test_hpo_distrib",
              "summary": "{\n  \"name\": \"y_test_hpo_distrib\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 2,\n        \"max\": 115,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          115,\n          87,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.346550627024477,\n        \"min\": 0.8333333333333334,\n        \"max\": 47.91666666666667,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          47.91666666666667,\n          36.25,\n          1.6666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_new 데이터 확인 (HPO 완료한 후 최적의 모델을 테스트할 새로운 데이터)\n",
        "\n",
        "X_test_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "pGy6bhHoOo2z",
        "outputId": "ba1d2943-f0ed-4b76-c6ba-53c2fc710c08"
      },
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "211      3339.0   102.0   16.0                             391.0   \n",
              "531      2653.0   186.0    2.0                             190.0   \n",
              "1198     2961.0   175.0   22.0                             324.0   \n",
              "1076     2847.0   350.0   22.0                             175.0   \n",
              "1309     3034.0    40.0    4.0                             541.0   \n",
              "...         ...     ...    ...                               ...   \n",
              "459      3022.0   340.0   15.0                             127.0   \n",
              "504      3071.0   336.0   35.0                             335.0   \n",
              "349      3140.0   214.0   12.0                             242.0   \n",
              "718      3259.0     9.0    6.0                             309.0   \n",
              "792      3164.0    90.0   21.0                             603.0   \n",
              "\n",
              "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "211                              6.0                            976.0   \n",
              "531                              1.0                            819.0   \n",
              "1198                            30.0                           1717.0   \n",
              "1076                            67.0                           3091.0   \n",
              "1309                            50.0                           4310.0   \n",
              "...                              ...                              ...   \n",
              "459                             30.0                            150.0   \n",
              "504                            183.0                            395.0   \n",
              "349                             -2.0                           2642.0   \n",
              "718                             25.0                            218.0   \n",
              "792                            228.0                           1358.0   \n",
              "\n",
              "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "211           245.0           217.0           95.0   \n",
              "531           219.0           240.0          157.0   \n",
              "1198          226.0           245.0          140.0   \n",
              "1076          176.0           198.0          157.0   \n",
              "1309          220.0           231.0          147.0   \n",
              "...             ...             ...            ...   \n",
              "459           188.0           217.0          168.0   \n",
              "504           123.0           170.0          173.0   \n",
              "349           209.0           251.0          177.0   \n",
              "718           214.0           228.0          152.0   \n",
              "792           247.0           202.0           74.0   \n",
              "\n",
              "      Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
              "211                               3630.0  ...           0.0           1.0   \n",
              "531                               1682.0  ...           0.0           0.0   \n",
              "1198                              1129.0  ...           0.0           0.0   \n",
              "1076                               484.0  ...           0.0           0.0   \n",
              "1309                              1500.0  ...           0.0           0.0   \n",
              "...                                  ...  ...           ...           ...   \n",
              "459                               1365.0  ...           1.0           0.0   \n",
              "504                               2040.0  ...           0.0           0.0   \n",
              "349                                671.0  ...           0.0           1.0   \n",
              "718                                853.0  ...           0.0           1.0   \n",
              "792                               2477.0  ...           0.0           0.0   \n",
              "\n",
              "      Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
              "211            0.0           0.0           0.0           0.0           0.0   \n",
              "531            0.0           0.0           0.0           0.0           0.0   \n",
              "1198           0.0           0.0           0.0           0.0           0.0   \n",
              "1076           0.0           0.0           0.0           0.0           0.0   \n",
              "1309           0.0           0.0           0.0           0.0           0.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "459            0.0           0.0           0.0           0.0           0.0   \n",
              "504            0.0           0.0           0.0           0.0           0.0   \n",
              "349            0.0           0.0           0.0           0.0           0.0   \n",
              "718            0.0           0.0           0.0           0.0           0.0   \n",
              "792            1.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
              "211            0.0           0.0           0.0  \n",
              "531            0.0           0.0           0.0  \n",
              "1198           0.0           0.0           0.0  \n",
              "1076           0.0           0.0           0.0  \n",
              "1309           0.0           0.0           0.0  \n",
              "...            ...           ...           ...  \n",
              "459            0.0           0.0           0.0  \n",
              "504            0.0           0.0           0.0  \n",
              "349            0.0           0.0           0.0  \n",
              "718            0.0           0.0           0.0  \n",
              "792            0.0           0.0           0.0  \n",
              "\n",
              "[300 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d551d200-5b28-45de-847a-35a033126971\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type_30</th>\n",
              "      <th>Soil_Type_31</th>\n",
              "      <th>Soil_Type_32</th>\n",
              "      <th>Soil_Type_33</th>\n",
              "      <th>Soil_Type_34</th>\n",
              "      <th>Soil_Type_35</th>\n",
              "      <th>Soil_Type_36</th>\n",
              "      <th>Soil_Type_37</th>\n",
              "      <th>Soil_Type_38</th>\n",
              "      <th>Soil_Type_39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>3339.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>3630.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>819.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1682.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>2961.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1717.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1076</th>\n",
              "      <td>2847.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3091.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>484.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>3034.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4310.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>3022.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>1365.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>3071.0</td>\n",
              "      <td>336.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>2040.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>3140.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>2642.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>3259.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>309.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>853.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>3164.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>603.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>1358.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2477.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 54 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d551d200-5b28-45de-847a-35a033126971')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d551d200-5b28-45de-847a-35a033126971 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d551d200-5b28-45de-847a-35a033126971');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df6abfaf-6f3c-40b4-9f6c-e20d1127503c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df6abfaf-6f3c-40b4-9f6c-e20d1127503c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df6abfaf-6f3c-40b4-9f6c-e20d1127503c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0faba6e4-0a90-4ac4-9eb1-115c6f61fcae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_test_new')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0faba6e4-0a90-4ac4-9eb1-115c6f61fcae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_test_new');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_new"
            }
          },
          "metadata": {},
          "execution_count": 455
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8er0rwe-PEZw",
        "outputId": "15dc8a1d-db56-40e6-ae39-945c8666ad2a"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target\n",
              "211        1\n",
              "531        2\n",
              "1198       2\n",
              "1076       2\n",
              "1309       2\n",
              "...      ...\n",
              "459        2\n",
              "504        1\n",
              "349        2\n",
              "718        1\n",
              "792        1\n",
              "\n",
              "[300 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-182b389a-6e81-4caa-a97d-5e1fcdba53f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1076</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-182b389a-6e81-4caa-a97d-5e1fcdba53f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-182b389a-6e81-4caa-a97d-5e1fcdba53f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-182b389a-6e81-4caa-a97d-5e1fcdba53f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-391532d7-8347-4ada-817e-1761aab63034\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-391532d7-8347-4ada-817e-1761aab63034')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-391532d7-8347-4ada-817e-1761aab63034 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_79d66701-13c4-4c1a-9ee7-8fc3eef8e461\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_test_new')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_79d66701-13c4-4c1a-9ee7-8fc3eef8e461 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_test_new');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_test_new",
              "summary": "{\n  \"name\": \"y_test_new\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 456
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test_new 의 class 분포가 y_test_old 와 최대한 비슷해야 overfitting 여부 판별에 비교적 도움이 됨\n",
        "\n",
        "y_test_new_count = y_test_new.value_counts()\n",
        "y_test_new_normalized = y_test_new.value_counts(normalize=True)\n",
        "\n",
        "y_test_new_distrib = pd.DataFrame({'count': y_test_new_count, 'percentage': 100 * y_test_new_normalized})\n",
        "y_test_new_distrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wOyUfzmoPEby",
        "outputId": "eeedbb15-7e8c-42eb-e00f-daeb2f6a36f9"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        count  percentage\n",
              "target                   \n",
              "2         143   47.666667\n",
              "1         110   36.666667\n",
              "3          16    5.333333\n",
              "7          12    4.000000\n",
              "6          11    3.666667\n",
              "5           5    1.666667\n",
              "4           3    1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0192b310-0bad-4e83-8adf-afa904647364\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>143</td>\n",
              "      <td>47.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110</td>\n",
              "      <td>36.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>3.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0192b310-0bad-4e83-8adf-afa904647364')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0192b310-0bad-4e83-8adf-afa904647364 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0192b310-0bad-4e83-8adf-afa904647364');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c371950e-3507-4bd5-bc5d-bb79a5f0ad69\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c371950e-3507-4bd5-bc5d-bb79a5f0ad69')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c371950e-3507-4bd5-bc5d-bb79a5f0ad69 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4f2813d1-15df-41e5-a66f-36477ee68f9f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_test_new_distrib')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4f2813d1-15df-41e5-a66f-36477ee68f9f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_test_new_distrib');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_test_new_distrib",
              "summary": "{\n  \"name\": \"y_test_new_distrib\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58,\n        \"min\": 3,\n        \"max\": 143,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          143,\n          110,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.363413927864038,\n        \"min\": 1.0,\n        \"max\": 47.66666666666667,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          47.66666666666667,\n          36.666666666666664,\n          1.6666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 data의 corr-coef 분석\n",
        "\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Show corr-coef chart for given dataset\n",
        "#\n",
        "# args\n",
        "# - X         : data to visualize\n",
        "# - data_name : name for corr-coef chart title\n",
        "\n",
        "def visualize_corr(X, data_name):\n",
        "    corr = X.corr()\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(\n",
        "                z=corr.round(decimals=2).to_numpy(),\n",
        "                x=corr.columns.tolist(),\n",
        "                y=corr.index.tolist(),\n",
        "                xgap=1,\n",
        "                ygap=1,\n",
        "                zmax=1,\n",
        "                zmin=-1,\n",
        "                showscale=True,\n",
        "                colorscale=['#F53', '#BBC', '#57F'],\n",
        "                hoverongaps=True)\n",
        "\n",
        "    fig.update_layout(title=f'correlation of {data_name}',\n",
        "                      width=1500,\n",
        "                      height=1100)\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "FixnJPnaMArg"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data 분포 확인 (생략)\n",
        "\n",
        "# XY_train_ = pd.concat([X_train_, y_train_], axis=1)\n",
        "# visualize_corr(XY_train_, data_name='train data')"
      ],
      "metadata": {
        "id": "d-w2rr3qMoey"
      },
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HPO test data 분포 확인 (생략)\n",
        "\n",
        "# XY_test_hpo = pd.concat([X_test_hpo, y_test_hpo], axis=1)\n",
        "# visualize_corr(XY_test_hpo, data_name='test data (for HPO)')"
      ],
      "metadata": {
        "id": "DqpzxEZ6Pfez"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW test data 분포 확인 (생략)\n",
        "\n",
        "# XY_test_new = pd.concat([X_test_new, y_test_new], axis=1)\n",
        "# visualize_corr(XY_test_new, data_name='test data (NEW test data)')"
      ],
      "metadata": {
        "id": "OKW1o6vrPfhJ"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 향후 정확도 측정용\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "qifCBqNDP5Kt"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. HyperOpt 를 이용한 성능 테스트**"
      ],
      "metadata": {
        "id": "2G8nNu_J4Eay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Domain Space 정의\n",
        "\n",
        "domain_space = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(1.0)),\n",
        "    'max_depth': hp.quniform('max_depth', 1, 100, q=1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 50, 4000, q=1),\n",
        "    'min_data_in_leaf': hp.quniform('min_data_in_leaf', 1, 100, q=1),\n",
        "    'lambda_l1': hp.uniform('lambda_l1', 0.0, 1.0),\n",
        "    'lambda_l2': hp.uniform('lambda_l2', 0.0, 5.0)\n",
        "}"
      ],
      "metadata": {
        "id": "fABE6r2KP6NT"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective Function 정의\n",
        "\n",
        "models = []\n",
        "\n",
        "def objective_hyperopt(params):\n",
        "    for param_name in ['max_depth', 'num_leaves', 'min_data_in_leaf']:\n",
        "        params[param_name] = int(params[param_name])\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective='multiclass',\n",
        "        metric='multi_logloss',\n",
        "        boosting_type='gbdt',\n",
        "        num_iterations=10,  # 일반적으로 너무 작은 값이나, 여기서는 빠른 실험을 위해 사용\n",
        "        verbosity=-1,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    # LigthGBM 용 valid set 인 X_valid_lgbm, y_valid_lgbm 로 데이터를 분리\n",
        "    X_train__, X_valid_lgbm, y_train__, y_valid_lgbm =\\\n",
        "        train_test_split(X_train_, y_train_,\n",
        "                         test_size=0.25,\n",
        "                         random_state=2025)\n",
        "\n",
        "    # X_valid_lgbm, y_valid_lgbm 를 이용하여 LightGBM 모델을 valid\n",
        "    model.fit(X_train__, y_train__,\n",
        "              eval_set=[(X_valid_lgbm, y_valid_lgbm)])\n",
        "\n",
        "    # HPO 용 test set인 X_test_hpo, y_test_hpo 를 이용하여 하이퍼파라미터 조합 성능 테스트\n",
        "    preds_hpo = model.predict(X_test_hpo)\n",
        "\n",
        "    accuracy_hpo = accuracy_score(preds_hpo, y_test_hpo)\n",
        "#    f1_hpo = f1_score(preds_hpo, y_test_hpo)\n",
        "#    recall_hpo = recall_score(preds_hpo, y_test_hpo)\n",
        "\n",
        "    acc = f'{(100 * accuracy_hpo):6.2f}'\n",
        "#    f1 = f'{(100 * f1_hpo):6.2f}'\n",
        "#    reca = f'{(100 * recall_hpo):6.2f}'\n",
        "\n",
        "    print(f'[HPO] metrics with {params} : acc={acc}%') #, f1={f1}%, recall={reca}%')\n",
        "\n",
        "    # 학습한 모델을 최종 테스트를 위해 배열에 저장\n",
        "    models.append(model)\n",
        "\n",
        "    # Accuracy 를 최대화 하도록 Loss 반환\n",
        "    return {\"loss\": (-1) * accuracy_hpo, \"status\": STATUS_OK}"
      ],
      "metadata": {
        "id": "CZqPnZ5pRm8z"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디버깅 중 불필요한 warning 메시지 미표시\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "yKObswWdjoXE"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 최적화 실시\n",
        "\n",
        "TRIAL_COUNT = 3000\n",
        "\n",
        "trials = Trials()\n",
        "best_params_hyperopt = fmin(fn=objective_hyperopt,\n",
        "                            space=domain_space,\n",
        "                            algo=tpe.suggest, # tpe = Tree-Structured Parzen Estimator\n",
        "                            max_evals=TRIAL_COUNT,\n",
        "                            trials=trials)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P_OFSn7UiA1",
        "outputId": "91dd7869-c6f0-4238-8506-743481ed6943"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HPO] metrics with {'lambda_l1': 0.017374955863332153, 'lambda_l2': 3.6749066668538037, 'learning_rate': 0.02567790850932432, 'max_depth': 36, 'min_data_in_leaf': 2, 'num_leaves': 1969} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.28272711350148716, 'lambda_l2': 3.740656150509951, 'learning_rate': 0.9771002245814376, 'max_depth': 36, 'min_data_in_leaf': 88, 'num_leaves': 2198} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3327672217424602, 'lambda_l2': 1.235292345817427, 'learning_rate': 0.007154759400669562, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 3717} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8093069026098728, 'lambda_l2': 4.4907279520598244, 'learning_rate': 0.0019122450896481295, 'max_depth': 18, 'min_data_in_leaf': 88, 'num_leaves': 2703} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.17013795018158295, 'lambda_l2': 1.1645869106231965, 'learning_rate': 0.016377417865204046, 'max_depth': 11, 'min_data_in_leaf': 93, 'num_leaves': 2837} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5533667552365334, 'lambda_l2': 0.492854307740091, 'learning_rate': 0.1001245131645947, 'max_depth': 24, 'min_data_in_leaf': 53, 'num_leaves': 3009} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4548204975614779, 'lambda_l2': 0.21358089121833457, 'learning_rate': 0.7609138712010556, 'max_depth': 76, 'min_data_in_leaf': 68, 'num_leaves': 1174} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4854974529801023, 'lambda_l2': 2.168660352252594, 'learning_rate': 0.41180303318661243, 'max_depth': 36, 'min_data_in_leaf': 65, 'num_leaves': 2820} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.2198057374088982, 'lambda_l2': 4.596918835662375, 'learning_rate': 0.0496929227765232, 'max_depth': 18, 'min_data_in_leaf': 82, 'num_leaves': 235} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.3790889784328201, 'lambda_l2': 4.874544624260021, 'learning_rate': 0.1858035668000694, 'max_depth': 75, 'min_data_in_leaf': 86, 'num_leaves': 1838} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6760512870033489, 'lambda_l2': 2.7940719092557362, 'learning_rate': 0.2568250095611946, 'max_depth': 10, 'min_data_in_leaf': 75, 'num_leaves': 2460} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5749125567818522, 'lambda_l2': 1.600788902229926, 'learning_rate': 0.35615437050558474, 'max_depth': 46, 'min_data_in_leaf': 69, 'num_leaves': 3022} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5523320903403587, 'lambda_l2': 0.46448323376710676, 'learning_rate': 0.014467109064189888, 'max_depth': 86, 'min_data_in_leaf': 31, 'num_leaves': 2148} : acc= 52.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3354225817998219, 'lambda_l2': 1.013595447676992, 'learning_rate': 0.12598239094154232, 'max_depth': 37, 'min_data_in_leaf': 37, 'num_leaves': 2703} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.13883730536928762, 'lambda_l2': 1.7502174714410068, 'learning_rate': 0.004135848626296345, 'max_depth': 61, 'min_data_in_leaf': 29, 'num_leaves': 929} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3927901745258925, 'lambda_l2': 2.687978877469374, 'learning_rate': 0.0273294914551936, 'max_depth': 86, 'min_data_in_leaf': 10, 'num_leaves': 3093} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.10370610917334189, 'lambda_l2': 0.3842465740983775, 'learning_rate': 0.003441671794702016, 'max_depth': 39, 'min_data_in_leaf': 27, 'num_leaves': 2453} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7449395571334932, 'lambda_l2': 1.783627604594478, 'learning_rate': 0.06181434122305215, 'max_depth': 4, 'min_data_in_leaf': 90, 'num_leaves': 2839} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.22464074097462627, 'lambda_l2': 4.785126169522321, 'learning_rate': 0.18301582237634942, 'max_depth': 4, 'min_data_in_leaf': 34, 'num_leaves': 1437} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.40414963303939755, 'lambda_l2': 2.661723732018552, 'learning_rate': 0.1304444689067616, 'max_depth': 23, 'min_data_in_leaf': 97, 'num_leaves': 1092} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9695969218295427, 'lambda_l2': 2.0802817247992227, 'learning_rate': 0.40577129423179625, 'max_depth': 54, 'min_data_in_leaf': 57, 'num_leaves': 3555} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9361143289408664, 'lambda_l2': 2.1667173298038755, 'learning_rate': 0.4892731583769531, 'max_depth': 58, 'min_data_in_leaf': 49, 'num_leaves': 3928} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8770114451332826, 'lambda_l2': 3.3992142648567656, 'learning_rate': 0.596947880543525, 'max_depth': 56, 'min_data_in_leaf': 55, 'num_leaves': 3568} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6307511792646153, 'lambda_l2': 2.253595084149632, 'learning_rate': 0.9082099530142843, 'max_depth': 65, 'min_data_in_leaf': 62, 'num_leaves': 3386} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9979426519876952, 'lambda_l2': 3.1382087516687545, 'learning_rate': 0.3715007118584906, 'max_depth': 98, 'min_data_in_leaf': 44, 'num_leaves': 3975} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7129343432450015, 'lambda_l2': 2.207744287312048, 'learning_rate': 0.05703125609479215, 'max_depth': 48, 'min_data_in_leaf': 59, 'num_leaves': 3383} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.47293769067038466, 'lambda_l2': 0.8388708231563125, 'learning_rate': 0.001000717026474483, 'max_depth': 29, 'min_data_in_leaf': 77, 'num_leaves': 3334} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8041197938424725, 'lambda_l2': 4.027700042740794, 'learning_rate': 0.2806006266476187, 'max_depth': 72, 'min_data_in_leaf': 45, 'num_leaves': 3724} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8084432209695483, 'lambda_l2': 4.073954218856811, 'learning_rate': 0.09065554515985123, 'max_depth': 70, 'min_data_in_leaf': 47, 'num_leaves': 3967} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6273699182861918, 'lambda_l2': 4.144776424471504, 'learning_rate': 0.20466004626373546, 'max_depth': 100, 'min_data_in_leaf': 41, 'num_leaves': 1796} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8107775371757397, 'lambda_l2': 3.115204719737328, 'learning_rate': 0.0398318093165015, 'max_depth': 41, 'min_data_in_leaf': 3, 'num_leaves': 2311} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9018959661469621, 'lambda_l2': 3.7080945254988085, 'learning_rate': 0.9757549314726921, 'max_depth': 31, 'min_data_in_leaf': 19, 'num_leaves': 3732} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.025118210479814107, 'lambda_l2': 3.4266709933968036, 'learning_rate': 0.016583265515911785, 'max_depth': 80, 'min_data_in_leaf': 67, 'num_leaves': 501} : acc= 51.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5138449596442127, 'lambda_l2': 4.108889513628132, 'learning_rate': 0.6634020686352246, 'max_depth': 92, 'min_data_in_leaf': 20, 'num_leaves': 2024} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7600387563476982, 'lambda_l2': 1.405290884493816, 'learning_rate': 0.009302785456236978, 'max_depth': 64, 'min_data_in_leaf': 75, 'num_leaves': 1644} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.29944732443599675, 'lambda_l2': 2.4380652816322264, 'learning_rate': 0.2734143245120411, 'max_depth': 46, 'min_data_in_leaf': 40, 'num_leaves': 3138} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.041590731632510536, 'lambda_l2': 3.0119344578894833, 'learning_rate': 0.24965893186475058, 'max_depth': 71, 'min_data_in_leaf': 24, 'num_leaves': 3690} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6438235298862887, 'lambda_l2': 4.398136783220822, 'learning_rate': 0.07172542384218619, 'max_depth': 52, 'min_data_in_leaf': 12, 'num_leaves': 2640} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.2584970114765089, 'lambda_l2': 3.4079152142820646, 'learning_rate': 0.10750644733941225, 'max_depth': 81, 'min_data_in_leaf': 39, 'num_leaves': 3240} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3488001185371168, 'lambda_l2': 3.850669726228941, 'learning_rate': 0.0359088329684599, 'max_depth': 44, 'min_data_in_leaf': 12, 'num_leaves': 3808} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.2812078657719945, 'lambda_l2': 2.3638635621383086, 'learning_rate': 0.2854222361814647, 'max_depth': 68, 'min_data_in_leaf': 51, 'num_leaves': 3175} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4414976274879842, 'lambda_l2': 1.9413725163758033, 'learning_rate': 0.019885455685129404, 'max_depth': 31, 'min_data_in_leaf': 2, 'num_leaves': 2926} : acc= 57.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.1478767570317335, 'lambda_l2': 2.86633498710552, 'learning_rate': 0.1556092240720265, 'max_depth': 93, 'min_data_in_leaf': 44, 'num_leaves': 2539} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.30478378758475644, 'lambda_l2': 1.4355648549735738, 'learning_rate': 0.49667430847530025, 'max_depth': 14, 'min_data_in_leaf': 64, 'num_leaves': 1414} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.08815265460958485, 'lambda_l2': 0.9938919912963327, 'learning_rate': 0.08569422040923948, 'max_depth': 25, 'min_data_in_leaf': 83, 'num_leaves': 2109} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5741143908388939, 'lambda_l2': 0.7194405920489446, 'learning_rate': 0.6786953886819727, 'max_depth': 76, 'min_data_in_leaf': 72, 'num_leaves': 2303} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5243670626466334, 'lambda_l2': 2.5076203475847745, 'learning_rate': 0.8693131797481419, 'max_depth': 36, 'min_data_in_leaf': 80, 'num_leaves': 2741} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2319972733817035, 'lambda_l2': 4.993549908950073, 'learning_rate': 0.008914274498439043, 'max_depth': 50, 'min_data_in_leaf': 34, 'num_leaves': 3045} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.1744381381165521, 'lambda_l2': 4.404817453785341, 'learning_rate': 0.04557368627842256, 'max_depth': 42, 'min_data_in_leaf': 24, 'num_leaves': 3459} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4373915832088036, 'lambda_l2': 2.505755766512655, 'learning_rate': 0.02335422124788071, 'max_depth': 58, 'min_data_in_leaf': 36, 'num_leaves': 773} : acc= 55.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6809538989145997, 'lambda_l2': 4.699004052704297, 'learning_rate': 0.0024764703402863054, 'max_depth': 19, 'min_data_in_leaf': 96, 'num_leaves': 2900} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8359924182441913, 'lambda_l2': 1.8609135677706625, 'learning_rate': 0.005517539057454966, 'max_depth': 35, 'min_data_in_leaf': 62, 'num_leaves': 2366} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5881579251595889, 'lambda_l2': 0.10059149370124043, 'learning_rate': 0.14444375656479583, 'max_depth': 10, 'min_data_in_leaf': 88, 'num_leaves': 1891} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3804869934404919, 'lambda_l2': 1.663975010025823, 'learning_rate': 0.48274192806317723, 'max_depth': 47, 'min_data_in_leaf': 53, 'num_leaves': 1484} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.30316145839990677, 'lambda_l2': 3.5723516058205975, 'learning_rate': 0.32329718521326345, 'max_depth': 61, 'min_data_in_leaf': 32, 'num_leaves': 3817} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.18704830166054448, 'lambda_l2': 3.8887367925650818, 'learning_rate': 0.07568658677292188, 'max_depth': 88, 'min_data_in_leaf': 27, 'num_leaves': 190} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7508414943696307, 'lambda_l2': 3.260917027663481, 'learning_rate': 0.0011796792523307276, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 3569} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.06547112817225526, 'lambda_l2': 2.9015137247904597, 'learning_rate': 0.2185072678661999, 'max_depth': 61, 'min_data_in_leaf': 33, 'num_leaves': 3221} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.318897178162403, 'lambda_l2': 3.483779108293349, 'learning_rate': 0.3323825780165392, 'max_depth': 60, 'min_data_in_leaf': 41, 'num_leaves': 3857} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.11942427894469554, 'lambda_l2': 3.603292526063531, 'learning_rate': 0.11941518123549312, 'max_depth': 52, 'min_data_in_leaf': 16, 'num_leaves': 2583} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.487281168269965, 'lambda_l2': 2.701296808548509, 'learning_rate': 0.17104075956752807, 'max_depth': 8, 'min_data_in_leaf': 57, 'num_leaves': 53} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9600219582208814, 'lambda_l2': 1.3049626068526958, 'learning_rate': 0.05430247954976998, 'max_depth': 71, 'min_data_in_leaf': 46, 'num_leaves': 2983} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8688302369227423, 'lambda_l2': 2.363180114171108, 'learning_rate': 0.027463197985048905, 'max_depth': 77, 'min_data_in_leaf': 70, 'num_leaves': 3660} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5383064877887166, 'lambda_l2': 4.948389669565924, 'learning_rate': 0.012434680540878908, 'max_depth': 65, 'min_data_in_leaf': 30, 'num_leaves': 3983} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.35114973552125645, 'lambda_l2': 4.575864870292388, 'learning_rate': 0.5279799858570942, 'max_depth': 96, 'min_data_in_leaf': 6, 'num_leaves': 638} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4146133141183881, 'lambda_l2': 4.326429910482036, 'learning_rate': 0.30450875068882816, 'max_depth': 55, 'min_data_in_leaf': 38, 'num_leaves': 3490} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48449177264072246, 'lambda_l2': 2.02191918877642, 'learning_rate': 0.4033078399386502, 'max_depth': 25, 'min_data_in_leaf': 65, 'num_leaves': 2838} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.20857280619088892, 'lambda_l2': 3.1961029114020874, 'learning_rate': 0.21461955314391365, 'max_depth': 74, 'min_data_in_leaf': 49, 'num_leaves': 3849} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2613996066570257, 'lambda_l2': 2.368152361926846, 'learning_rate': 0.7893403519856436, 'max_depth': 39, 'min_data_in_leaf': 59, 'num_leaves': 2730} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.008225028406148027, 'lambda_l2': 4.269442646708202, 'learning_rate': 0.10368996702238849, 'max_depth': 64, 'min_data_in_leaf': 26, 'num_leaves': 3348} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.36027962860887097, 'lambda_l2': 3.9463590942012994, 'learning_rate': 0.23679147195475028, 'max_depth': 68, 'min_data_in_leaf': 42, 'num_leaves': 3122} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.40853095371232934, 'lambda_l2': 1.520412049279122, 'learning_rate': 0.42379751228013796, 'max_depth': 33, 'min_data_in_leaf': 53, 'num_leaves': 2486} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.14219127754672112, 'lambda_l2': 1.126236256204227, 'learning_rate': 0.5877866521835402, 'max_depth': 44, 'min_data_in_leaf': 16, 'num_leaves': 3276} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6060909654350688, 'lambda_l2': 2.6563779070980265, 'learning_rate': 0.18360799866002933, 'max_depth': 28, 'min_data_in_leaf': 31, 'num_leaves': 2221} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.29291459100486694, 'lambda_l2': 2.9716960980269658, 'learning_rate': 0.06901653883852316, 'max_depth': 50, 'min_data_in_leaf': 21, 'num_leaves': 2425} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.46069663591296706, 'lambda_l2': 3.7921154157792376, 'learning_rate': 0.2849889366525383, 'max_depth': 73, 'min_data_in_leaf': 44, 'num_leaves': 3752} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6718546299309941, 'lambda_l2': 1.7005139358151573, 'learning_rate': 0.13680693479658015, 'max_depth': 16, 'min_data_in_leaf': 72, 'num_leaves': 3116} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.2532264560932599, 'lambda_l2': 4.010739577907386, 'learning_rate': 0.7967823065586767, 'max_depth': 85, 'min_data_in_leaf': 47, 'num_leaves': 3611} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.31937189110117015, 'lambda_l2': 3.3227666232956428, 'learning_rate': 0.3532348440416047, 'max_depth': 40, 'min_data_in_leaf': 78, 'num_leaves': 1749} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7125612494353946, 'lambda_l2': 2.1244897206661464, 'learning_rate': 0.9566663564991957, 'max_depth': 21, 'min_data_in_leaf': 57, 'num_leaves': 2130} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7855559644873986, 'lambda_l2': 3.0777526496192578, 'learning_rate': 0.04209465022062912, 'max_depth': 62, 'min_data_in_leaf': 23, 'num_leaves': 3430} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.44000172500863727, 'lambda_l2': 3.5196166982729404, 'learning_rate': 0.9960436491729885, 'max_depth': 78, 'min_data_in_leaf': 84, 'num_leaves': 3921} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5116503325963284, 'lambda_l2': 1.842703186412848, 'learning_rate': 0.6834805821508286, 'max_depth': 45, 'min_data_in_leaf': 93, 'num_leaves': 2644} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.566929481188108, 'lambda_l2': 2.750634447652275, 'learning_rate': 0.0849319351968107, 'max_depth': 2, 'min_data_in_leaf': 51, 'num_leaves': 2766} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9218278100127107, 'lambda_l2': 3.6378054923133885, 'learning_rate': 0.1568864754481676, 'max_depth': 87, 'min_data_in_leaf': 36, 'num_leaves': 3765} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3838453099546146, 'lambda_l2': 2.5335921570492, 'learning_rate': 0.0342245311512158, 'max_depth': 58, 'min_data_in_leaf': 62, 'num_leaves': 2954} : acc= 60.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.23074334054240314, 'lambda_l2': 0.8137193337002229, 'learning_rate': 0.5681939256357568, 'max_depth': 34, 'min_data_in_leaf': 33, 'num_leaves': 3265} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7219768443027001, 'lambda_l2': 4.706020870626239, 'learning_rate': 0.45253460548019364, 'max_depth': 67, 'min_data_in_leaf': 66, 'num_leaves': 3532} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8449699429137352, 'lambda_l2': 4.521321344499074, 'learning_rate': 0.06143124239366307, 'max_depth': 53, 'min_data_in_leaf': 75, 'num_leaves': 1126} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6135337633908202, 'lambda_l2': 2.249774687089381, 'learning_rate': 0.12061566473082, 'max_depth': 37, 'min_data_in_leaf': 54, 'num_leaves': 2038} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.09692922159470768, 'lambda_l2': 2.8299492159004647, 'learning_rate': 0.33382412256146476, 'max_depth': 48, 'min_data_in_leaf': 15, 'num_leaves': 3045} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2070007598330853, 'lambda_l2': 4.210752583091288, 'learning_rate': 0.28079832788955167, 'max_depth': 84, 'min_data_in_leaf': 28, 'num_leaves': 1260} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6566686651649363, 'lambda_l2': 0.5679092284475815, 'learning_rate': 0.25484573536042354, 'max_depth': 28, 'min_data_in_leaf': 99, 'num_leaves': 2254} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9896281875747612, 'lambda_l2': 3.707912803841307, 'learning_rate': 0.09278758581908353, 'max_depth': 57, 'min_data_in_leaf': 49, 'num_leaves': 3895} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5368293585625094, 'lambda_l2': 3.322704477131907, 'learning_rate': 0.6602422079816336, 'max_depth': 93, 'min_data_in_leaf': 60, 'num_leaves': 3996} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.04495511656297019, 'lambda_l2': 4.767328536564816, 'learning_rate': 0.18609313215104345, 'max_depth': 79, 'min_data_in_leaf': 31, 'num_leaves': 3666} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.1636344795175888, 'lambda_l2': 3.561482498932712, 'learning_rate': 0.013635262427874897, 'max_depth': 83, 'min_data_in_leaf': 41, 'num_leaves': 3388} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.12224843785497125, 'lambda_l2': 4.870384015086422, 'learning_rate': 0.10848171847683151, 'max_depth': 73, 'min_data_in_leaf': 39, 'num_leaves': 3196} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.42517938510904807, 'lambda_l2': 1.5552916900635925, 'learning_rate': 0.05184145485455207, 'max_depth': 30, 'min_data_in_leaf': 35, 'num_leaves': 1928} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.2775566548327649, 'lambda_l2': 1.282062486116064, 'learning_rate': 0.0013766402440392653, 'max_depth': 38, 'min_data_in_leaf': 70, 'num_leaves': 2877} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3335785367335419, 'lambda_l2': 4.048022227772461, 'learning_rate': 0.018576781529464192, 'max_depth': 91, 'min_data_in_leaf': 18, 'num_leaves': 3811} : acc= 54.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.470461570745947, 'lambda_l2': 2.026746360854483, 'learning_rate': 0.006578860788802947, 'max_depth': 43, 'min_data_in_leaf': 68, 'num_leaves': 1595} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4987733418915619, 'lambda_l2': 2.364943511174176, 'learning_rate': 0.003673183875280139, 'max_depth': 23, 'min_data_in_leaf': 80, 'num_leaves': 2796} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.35914157660762636, 'lambda_l2': 4.407505483483268, 'learning_rate': 0.023774124621781044, 'max_depth': 69, 'min_data_in_leaf': 45, 'num_leaves': 3517} : acc= 56.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.17970657887985209, 'lambda_l2': 3.764609250631301, 'learning_rate': 0.02874752541332124, 'max_depth': 55, 'min_data_in_leaf': 23, 'num_leaves': 3619} : acc= 58.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5927836894122699, 'lambda_l2': 2.6140033702809653, 'learning_rate': 0.07784629869958225, 'max_depth': 62, 'min_data_in_leaf': 90, 'num_leaves': 2547} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5483105146993323, 'lambda_l2': 0.33972081338670623, 'learning_rate': 0.20676990630863334, 'max_depth': 48, 'min_data_in_leaf': 56, 'num_leaves': 2647} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3960650268420231, 'lambda_l2': 1.0098136043132817, 'learning_rate': 0.42643636281198294, 'max_depth': 13, 'min_data_in_leaf': 11, 'num_leaves': 3333} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.19804364469108196, 'lambda_l2': 0.20027164917399698, 'learning_rate': 0.4082049074056984, 'max_depth': 13, 'min_data_in_leaf': 5, 'num_leaves': 3081} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.3975449146524966, 'lambda_l2': 3.9561372965035484, 'learning_rate': 0.15550506605685027, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 3303} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2546201284886764, 'lambda_l2': 1.020878587891569, 'learning_rate': 0.8439610671453701, 'max_depth': 6, 'min_data_in_leaf': 9, 'num_leaves': 3438} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.30066814909090633, 'lambda_l2': 2.9657265820932754, 'learning_rate': 0.002593207442861858, 'max_depth': 32, 'min_data_in_leaf': 14, 'num_leaves': 369} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.37049114891373036, 'lambda_l2': 0.5739465578772568, 'learning_rate': 0.709213416575456, 'max_depth': 16, 'min_data_in_leaf': 73, 'num_leaves': 2307} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6958664385786361, 'lambda_l2': 1.4110665945341339, 'learning_rate': 0.5041925363340386, 'max_depth': 2, 'min_data_in_leaf': 85, 'num_leaves': 3024} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7778313747573357, 'lambda_l2': 0.011510825111682443, 'learning_rate': 0.4917205242785456, 'max_depth': 1, 'min_data_in_leaf': 87, 'num_leaves': 999} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7308343107857203, 'lambda_l2': 1.1714955223766728, 'learning_rate': 0.3833162730272988, 'max_depth': 4, 'min_data_in_leaf': 2, 'num_leaves': 2366} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6275659665780466, 'lambda_l2': 1.1333400226834092, 'learning_rate': 0.37249188858538523, 'max_depth': 5, 'min_data_in_leaf': 1, 'num_leaves': 2462} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6471176485541, 'lambda_l2': 1.1414502707960634, 'learning_rate': 0.6026181373526969, 'max_depth': 5, 'min_data_in_leaf': 2, 'num_leaves': 1720} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8832366956752222, 'lambda_l2': 0.9223604223135324, 'learning_rate': 0.8937621119956839, 'max_depth': 12, 'min_data_in_leaf': 4, 'num_leaves': 1256} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6249918153708766, 'lambda_l2': 0.6397810941334869, 'learning_rate': 0.36767449482767667, 'max_depth': 20, 'min_data_in_leaf': 7, 'num_leaves': 1614} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.821867274474617, 'lambda_l2': 1.1638919435950223, 'learning_rate': 0.229275061506396, 'max_depth': 5, 'min_data_in_leaf': 13, 'num_leaves': 1713} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7733666407777504, 'lambda_l2': 0.26513644482385157, 'learning_rate': 0.5977463647452047, 'max_depth': 10, 'min_data_in_leaf': 3, 'num_leaves': 1443} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7283060404281249, 'lambda_l2': 0.7436333678120748, 'learning_rate': 0.12460701460082346, 'max_depth': 7, 'min_data_in_leaf': 2, 'num_leaves': 1829} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6464201080793991, 'lambda_l2': 1.768850454673686, 'learning_rate': 0.005011527151142533, 'max_depth': 16, 'min_data_in_leaf': 18, 'num_leaves': 810} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9396910816702231, 'lambda_l2': 0.4539482203596844, 'learning_rate': 0.17605141142288647, 'max_depth': 26, 'min_data_in_leaf': 8, 'num_leaves': 1330} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8547813199305784, 'lambda_l2': 0.08645663539682458, 'learning_rate': 0.009395733294163123, 'max_depth': 8, 'min_data_in_leaf': 21, 'num_leaves': 2432} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6952214018474684, 'lambda_l2': 1.0521631748548181, 'learning_rate': 0.044506066450398174, 'max_depth': 18, 'min_data_in_leaf': 12, 'num_leaves': 2081} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7418915997242833, 'lambda_l2': 0.9039094548066746, 'learning_rate': 0.0683166062696342, 'max_depth': 22, 'min_data_in_leaf': 10, 'num_leaves': 2204} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5781529231924245, 'lambda_l2': 1.6069528544634988, 'learning_rate': 0.6280250662427025, 'max_depth': 3, 'min_data_in_leaf': 6, 'num_leaves': 1526} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8937998731592727, 'lambda_l2': 1.2283051904671756, 'learning_rate': 0.9670101535631648, 'max_depth': 8, 'min_data_in_leaf': 4, 'num_leaves': 2009} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6768205926583126, 'lambda_l2': 1.8474166253445214, 'learning_rate': 0.7842793198060161, 'max_depth': 10, 'min_data_in_leaf': 17, 'num_leaves': 890} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.45459570445221786, 'lambda_l2': 1.3550110119646153, 'learning_rate': 0.038125312872046686, 'max_depth': 14, 'min_data_in_leaf': 20, 'num_leaves': 1920} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7983991800623826, 'lambda_l2': 1.487528666251448, 'learning_rate': 0.2525560187493565, 'max_depth': 5, 'min_data_in_leaf': 1, 'num_leaves': 654} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7566534459258589, 'lambda_l2': 1.9459539330986013, 'learning_rate': 0.1416187686922716, 'max_depth': 17, 'min_data_in_leaf': 25, 'num_leaves': 2382} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.517458412566131, 'lambda_l2': 0.39159960578386077, 'learning_rate': 0.01090164984434161, 'max_depth': 26, 'min_data_in_leaf': 29, 'num_leaves': 1040} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6023084391451858, 'lambda_l2': 0.18974462708383155, 'learning_rate': 0.3033921174025988, 'max_depth': 12, 'min_data_in_leaf': 10, 'num_leaves': 1710} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6595411031935765, 'lambda_l2': 0.7957307678147811, 'learning_rate': 0.09970059556752497, 'max_depth': 21, 'min_data_in_leaf': 14, 'num_leaves': 1841} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8257995906773878, 'lambda_l2': 1.638179250767783, 'learning_rate': 0.198740125177698, 'max_depth': 4, 'min_data_in_leaf': 1, 'num_leaves': 1553} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6949158997370889, 'lambda_l2': 0.6239826301382542, 'learning_rate': 0.5446271290857869, 'max_depth': 24, 'min_data_in_leaf': 22, 'num_leaves': 1373} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5608391056387112, 'lambda_l2': 2.1694423428832676, 'learning_rate': 0.3856048459389437, 'max_depth': 15, 'min_data_in_leaf': 7, 'num_leaves': 2506} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6370302252561382, 'lambda_l2': 1.1752544545763886, 'learning_rate': 0.345234081750198, 'max_depth': 9, 'min_data_in_leaf': 27, 'num_leaves': 2142} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9232963804913338, 'lambda_l2': 0.4828089725427631, 'learning_rate': 0.032476611275161396, 'max_depth': 19, 'min_data_in_leaf': 16, 'num_leaves': 2684} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9672471488880905, 'lambda_l2': 0.8804337412431134, 'learning_rate': 0.7344872598999613, 'max_depth': 2, 'min_data_in_leaf': 19, 'num_leaves': 2357} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5038568971694778, 'lambda_l2': 0.005953906955365351, 'learning_rate': 0.019776118830551394, 'max_depth': 11, 'min_data_in_leaf': 5, 'num_leaves': 2944} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9997321552542922, 'lambda_l2': 0.99424457777774, 'learning_rate': 0.08457584490755375, 'max_depth': 27, 'min_data_in_leaf': 12, 'num_leaves': 2262} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5363933450491741, 'lambda_l2': 0.6712039401647435, 'learning_rate': 0.4296256392657165, 'max_depth': 6, 'min_data_in_leaf': 9, 'num_leaves': 1173} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7383177694825657, 'lambda_l2': 1.1093949915354728, 'learning_rate': 0.45386567510698805, 'max_depth': 14, 'min_data_in_leaf': 2, 'num_leaves': 1988} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6143643408263842, 'lambda_l2': 1.2751394812985397, 'learning_rate': 0.9934225799749792, 'max_depth': 3, 'min_data_in_leaf': 1, 'num_leaves': 2553} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7133191953031661, 'lambda_l2': 1.4734472165614823, 'learning_rate': 0.23615252840770543, 'max_depth': 18, 'min_data_in_leaf': 7, 'num_leaves': 1744} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5593662971098731, 'lambda_l2': 1.7361461153523812, 'learning_rate': 0.3015083164607612, 'max_depth': 1, 'min_data_in_leaf': 15, 'num_leaves': 2838} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.48703073336322705, 'lambda_l2': 1.918949759666345, 'learning_rate': 0.16693946421668052, 'max_depth': 12, 'min_data_in_leaf': 3, 'num_leaves': 2169} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.587225344027844, 'lambda_l2': 0.34321980262136187, 'learning_rate': 0.5649684272809343, 'max_depth': 7, 'min_data_in_leaf': 11, 'num_leaves': 1867} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7988558797269126, 'lambda_l2': 0.3279549965503395, 'learning_rate': 0.5890607582075742, 'max_depth': 7, 'min_data_in_leaf': 25, 'num_leaves': 1681} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5830942246767898, 'lambda_l2': 0.11378255880261406, 'learning_rate': 0.813984544157126, 'max_depth': 35, 'min_data_in_leaf': 11, 'num_leaves': 1863} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6642352522816786, 'lambda_l2': 0.5472400555997725, 'learning_rate': 0.6874026780242835, 'max_depth': 23, 'min_data_in_leaf': 5, 'num_leaves': 2063} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.63842742833549, 'lambda_l2': 0.7461035986556901, 'learning_rate': 0.2798912132544177, 'max_depth': 29, 'min_data_in_leaf': 14, 'num_leaves': 1945} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4125484468634973, 'lambda_l2': 0.42440077926317876, 'learning_rate': 0.11350924639565216, 'max_depth': 1, 'min_data_in_leaf': 23, 'num_leaves': 1295} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4479128152644223, 'lambda_l2': 0.9521179026693105, 'learning_rate': 0.4593584753483993, 'max_depth': 10, 'min_data_in_leaf': 18, 'num_leaves': 1495} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7667867479414927, 'lambda_l2': 0.22975655444404838, 'learning_rate': 0.5387437536699287, 'max_depth': 13, 'min_data_in_leaf': 8, 'num_leaves': 1446} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8407888262485661, 'lambda_l2': 0.25388299908616574, 'learning_rate': 0.20550994491838734, 'max_depth': 20, 'min_data_in_leaf': 21, 'num_leaves': 585} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7749807178360242, 'lambda_l2': 0.21457500480680522, 'learning_rate': 0.2054532003245714, 'max_depth': 32, 'min_data_in_leaf': 37, 'num_leaves': 131} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8649773359514397, 'lambda_l2': 0.01662799348838112, 'learning_rate': 0.5013992827065842, 'max_depth': 15, 'min_data_in_leaf': 28, 'num_leaves': 1111} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9084910606356615, 'lambda_l2': 0.8244613711771336, 'learning_rate': 0.35188731788948435, 'max_depth': 4, 'min_data_in_leaf': 8, 'num_leaves': 1195} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9452785685321968, 'lambda_l2': 0.5281473341881796, 'learning_rate': 0.14458726339305275, 'max_depth': 9, 'min_data_in_leaf': 9, 'num_leaves': 872} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8991719987032961, 'lambda_l2': 0.13142630959373092, 'learning_rate': 0.8881425906055295, 'max_depth': 17, 'min_data_in_leaf': 16, 'num_leaves': 398} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.813821373489601, 'lambda_l2': 0.8490673343253428, 'learning_rate': 0.34286551706857255, 'max_depth': 3, 'min_data_in_leaf': 34, 'num_leaves': 1417} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.905843117262633, 'lambda_l2': 0.37687422986917757, 'learning_rate': 0.2550842648591513, 'max_depth': 41, 'min_data_in_leaf': 13, 'num_leaves': 755} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9523874811710343, 'lambda_l2': 0.008353530087293143, 'learning_rate': 0.9986981556313085, 'max_depth': 24, 'min_data_in_leaf': 26, 'num_leaves': 1231} : acc= 56.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8647328654258604, 'lambda_l2': 0.7174080964742829, 'learning_rate': 0.13544117108255954, 'max_depth': 7, 'min_data_in_leaf': 19, 'num_leaves': 317} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7633791470439892, 'lambda_l2': 0.6356032959973534, 'learning_rate': 0.0015843194382498887, 'max_depth': 30, 'min_data_in_leaf': 7, 'num_leaves': 695} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7959358483122904, 'lambda_l2': 0.335707723113011, 'learning_rate': 0.055486101839938996, 'max_depth': 12, 'min_data_in_leaf': 5, 'num_leaves': 1003} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7479064381360787, 'lambda_l2': 1.3521458034222285, 'learning_rate': 0.5431975698054383, 'max_depth': 21, 'min_data_in_leaf': 29, 'num_leaves': 517} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9782182331665843, 'lambda_l2': 0.5235299675757646, 'learning_rate': 0.7826906709621815, 'max_depth': 1, 'min_data_in_leaf': 32, 'num_leaves': 1607} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6938943647418301, 'lambda_l2': 0.7932285259378575, 'learning_rate': 0.17953379951105058, 'max_depth': 4, 'min_data_in_leaf': 9, 'num_leaves': 936} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9177105794744088, 'lambda_l2': 0.08707557380824549, 'learning_rate': 0.3258781461506924, 'max_depth': 19, 'min_data_in_leaf': 21, 'num_leaves': 1769} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8772444152383092, 'lambda_l2': 0.2649053289423383, 'learning_rate': 0.6667150890277371, 'max_depth': 8, 'min_data_in_leaf': 17, 'num_leaves': 1373} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7177830463808618, 'lambda_l2': 0.4509452400928633, 'learning_rate': 0.06261010913641676, 'max_depth': 15, 'min_data_in_leaf': 4, 'num_leaves': 1083} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8387180151605048, 'lambda_l2': 1.2254066121318155, 'learning_rate': 0.4049818831204986, 'max_depth': 27, 'min_data_in_leaf': 13, 'num_leaves': 1482} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9838637234010378, 'lambda_l2': 2.0393707881435628, 'learning_rate': 0.27383166671188197, 'max_depth': 11, 'min_data_in_leaf': 42, 'num_leaves': 1300} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6760757055165088, 'lambda_l2': 1.5724864724671832, 'learning_rate': 0.161780005957166, 'max_depth': 22, 'min_data_in_leaf': 23, 'num_leaves': 1651} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8178023727792776, 'lambda_l2': 1.0490321395548126, 'learning_rate': 0.23757039638181296, 'max_depth': 14, 'min_data_in_leaf': 11, 'num_leaves': 1206} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5982029584929841, 'lambda_l2': 0.9193369868055332, 'learning_rate': 0.5534872184470321, 'max_depth': 33, 'min_data_in_leaf': 7, 'num_leaves': 937} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7889887986687389, 'lambda_l2': 0.689104016185894, 'learning_rate': 0.09924835155651972, 'max_depth': 6, 'min_data_in_leaf': 1, 'num_leaves': 1813} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.735160773147783, 'lambda_l2': 2.270466274296871, 'learning_rate': 0.12601098861934995, 'max_depth': 1, 'min_data_in_leaf': 25, 'num_leaves': 1570} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7098555138250211, 'lambda_l2': 1.4020605154929384, 'learning_rate': 0.07543992963108123, 'max_depth': 18, 'min_data_in_leaf': 15, 'num_leaves': 818} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8851066931418965, 'lambda_l2': 1.6798041280684757, 'learning_rate': 0.8810789511087198, 'max_depth': 25, 'min_data_in_leaf': 19, 'num_leaves': 1990} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9992081317451351, 'lambda_l2': 0.8141127828417223, 'learning_rate': 0.0161553369094077, 'max_depth': 97, 'min_data_in_leaf': 3, 'num_leaves': 2226} : acc= 56.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7641471455558663, 'lambda_l2': 0.336485137202765, 'learning_rate': 0.47097849899165106, 'max_depth': 9, 'min_data_in_leaf': 38, 'num_leaves': 467} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.92645982139756, 'lambda_l2': 0.12365127045548925, 'learning_rate': 0.7208395758594961, 'max_depth': 37, 'min_data_in_leaf': 30, 'num_leaves': 2343} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.82592140368543, 'lambda_l2': 0.015494666358829567, 'learning_rate': 0.007245585147585763, 'max_depth': 4, 'min_data_in_leaf': 8, 'num_leaves': 1162} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5272785867655777, 'lambda_l2': 1.293049187578378, 'learning_rate': 0.3597912839055124, 'max_depth': 17, 'min_data_in_leaf': 13, 'num_leaves': 2107} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6178494534647645, 'lambda_l2': 0.5968058182745295, 'learning_rate': 0.9886287109205117, 'max_depth': 13, 'min_data_in_leaf': 17, 'num_leaves': 2603} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8610612612241824, 'lambda_l2': 0.4453549594821631, 'learning_rate': 0.2927730622074956, 'max_depth': 6, 'min_data_in_leaf': 5, 'num_leaves': 1410} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8579071042729701, 'lambda_l2': 1.534562390141636, 'learning_rate': 0.002661347207202552, 'max_depth': 100, 'min_data_in_leaf': 5, 'num_leaves': 1858} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9009142511131502, 'lambda_l2': 1.0982639224634034, 'learning_rate': 0.09020613833448436, 'max_depth': 7, 'min_data_in_leaf': 10, 'num_leaves': 1334} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6559689394419184, 'lambda_l2': 0.0022611428227561348, 'learning_rate': 0.048526053259571565, 'max_depth': 29, 'min_data_in_leaf': 3, 'num_leaves': 1465} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7826155395804523, 'lambda_l2': 0.44507844992385953, 'learning_rate': 0.622345180794702, 'max_depth': 51, 'min_data_in_leaf': 20, 'num_leaves': 1915} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9616976365380225, 'lambda_l2': 1.7782560414089255, 'learning_rate': 0.11301582262670531, 'max_depth': 2, 'min_data_in_leaf': 1, 'num_leaves': 1539} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5546052663453622, 'lambda_l2': 0.19801071583025315, 'learning_rate': 0.21822588397468135, 'max_depth': 10, 'min_data_in_leaf': 48, 'num_leaves': 2746} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9420187018194608, 'lambda_l2': 0.9166548164816103, 'learning_rate': 0.1799969084920984, 'max_depth': 20, 'min_data_in_leaf': 6, 'num_leaves': 979} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.913217023354833, 'lambda_l2': 1.9321527301399097, 'learning_rate': 0.024313131115348066, 'max_depth': 16, 'min_data_in_leaf': 24, 'num_leaves': 841} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.85243871131212, 'lambda_l2': 1.2308107781333066, 'learning_rate': 0.40328773973438903, 'max_depth': 39, 'min_data_in_leaf': 27, 'num_leaves': 716} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8884025252631184, 'lambda_l2': 0.7380189792706375, 'learning_rate': 0.3002737938220319, 'max_depth': 23, 'min_data_in_leaf': 90, 'num_leaves': 297} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9784583168172832, 'lambda_l2': 2.4421142544541596, 'learning_rate': 0.029655918293399898, 'max_depth': 35, 'min_data_in_leaf': 15, 'num_leaves': 587} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7295918643756273, 'lambda_l2': 1.0234415754425925, 'learning_rate': 0.14183675476261665, 'max_depth': 5, 'min_data_in_leaf': 35, 'num_leaves': 81} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6817938787977542, 'lambda_l2': 0.2846398818348728, 'learning_rate': 0.7805532171969072, 'max_depth': 12, 'min_data_in_leaf': 96, 'num_leaves': 2417} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4727208418287714, 'lambda_l2': 0.5793687279410838, 'learning_rate': 0.5405531258513182, 'max_depth': 8, 'min_data_in_leaf': 11, 'num_leaves': 2028} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8049360196650673, 'lambda_l2': 1.4176447453926713, 'learning_rate': 0.2611299691879902, 'max_depth': 1, 'min_data_in_leaf': 51, 'num_leaves': 1088} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801582998802218, 'lambda_l2': 2.584238583027685, 'learning_rate': 0.19366319679758798, 'max_depth': 46, 'min_data_in_leaf': 22, 'num_leaves': 1668} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7001991036322097, 'lambda_l2': 0.17998624218086007, 'learning_rate': 0.46209284927925576, 'max_depth': 42, 'min_data_in_leaf': 4, 'num_leaves': 2181} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9994657098681676, 'lambda_l2': 0.48118545563886167, 'learning_rate': 0.0685790944521479, 'max_depth': 59, 'min_data_in_leaf': 3, 'num_leaves': 2290} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6318775721676553, 'lambda_l2': 0.39863547058637483, 'learning_rate': 0.0010363116019323467, 'max_depth': 26, 'min_data_in_leaf': 31, 'num_leaves': 1401} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7050648575341958, 'lambda_l2': 0.1548251709723105, 'learning_rate': 0.03841058266349919, 'max_depth': 55, 'min_data_in_leaf': 100, 'num_leaves': 2498} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5058447003539737, 'lambda_l2': 0.008344778530550323, 'learning_rate': 0.22889593934748212, 'max_depth': 75, 'min_data_in_leaf': 81, 'num_leaves': 2181} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7506913593807264, 'lambda_l2': 0.23171016745023376, 'learning_rate': 0.4948678001497828, 'max_depth': 66, 'min_data_in_leaf': 6, 'num_leaves': 1785} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.833852544949218, 'lambda_l2': 0.6523828920830137, 'learning_rate': 0.4357968419194722, 'max_depth': 42, 'min_data_in_leaf': 14, 'num_leaves': 2653} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8661920717322462, 'lambda_l2': 0.6675080391035131, 'learning_rate': 0.15929408574858758, 'max_depth': 44, 'min_data_in_leaf': 13, 'num_leaves': 2957} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8321307615671524, 'lambda_l2': 0.9766150438041987, 'learning_rate': 0.3023328764991082, 'max_depth': 50, 'min_data_in_leaf': 44, 'num_leaves': 2813} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.959063615099053, 'lambda_l2': 0.8728090119169871, 'learning_rate': 0.6531678996730921, 'max_depth': 32, 'min_data_in_leaf': 40, 'num_leaves': 2081} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9316482098552816, 'lambda_l2': 2.7618482535066695, 'learning_rate': 0.4026752640847627, 'max_depth': 40, 'min_data_in_leaf': 64, 'num_leaves': 3115} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9060707414864558, 'lambda_l2': 1.8407242699460113, 'learning_rate': 0.10244094352640627, 'max_depth': 63, 'min_data_in_leaf': 17, 'num_leaves': 2649} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6030919684932369, 'lambda_l2': 1.1845081614125146, 'learning_rate': 0.08378233330986823, 'max_depth': 71, 'min_data_in_leaf': 78, 'num_leaves': 2723} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8131640668771496, 'lambda_l2': 2.1062759877398807, 'learning_rate': 0.999355716780421, 'max_depth': 48, 'min_data_in_leaf': 4, 'num_leaves': 2593} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8401924669562478, 'lambda_l2': 1.3245722884654356, 'learning_rate': 0.004543829437686292, 'max_depth': 56, 'min_data_in_leaf': 9, 'num_leaves': 3199} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6502123316404178, 'lambda_l2': 1.6164825075623754, 'learning_rate': 0.8725105249300666, 'max_depth': 94, 'min_data_in_leaf': 93, 'num_leaves': 2903} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7723305745710112, 'lambda_l2': 0.5580284835696223, 'learning_rate': 0.1277492521430491, 'max_depth': 52, 'min_data_in_leaf': 19, 'num_leaves': 2387} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8728043353374235, 'lambda_l2': 2.247914717634565, 'learning_rate': 0.33704599852059003, 'max_depth': 38, 'min_data_in_leaf': 15, 'num_leaves': 3005} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9971225721822523, 'lambda_l2': 0.7362855940898919, 'learning_rate': 0.057121690882276185, 'max_depth': 31, 'min_data_in_leaf': 1, 'num_leaves': 1963} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9472139630954746, 'lambda_l2': 1.4826079611901042, 'learning_rate': 0.260203142206571, 'max_depth': 77, 'min_data_in_leaf': 33, 'num_leaves': 178} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.895809610709864, 'lambda_l2': 0.8154929310041765, 'learning_rate': 0.35799314919215464, 'max_depth': 29, 'min_data_in_leaf': 27, 'num_leaves': 1233} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7904253367760554, 'lambda_l2': 1.402508148733797, 'learning_rate': 0.20518992578033576, 'max_depth': 46, 'min_data_in_leaf': 37, 'num_leaves': 2465} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9700010311350444, 'lambda_l2': 1.6909624571068775, 'learning_rate': 0.15266855192754913, 'max_depth': 42, 'min_data_in_leaf': 28, 'num_leaves': 1253} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.848451324784117, 'lambda_l2': 1.2847784300202583, 'learning_rate': 0.11577574232645903, 'max_depth': 44, 'min_data_in_leaf': 46, 'num_leaves': 453} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8792653086019219, 'lambda_l2': 1.063106852834797, 'learning_rate': 0.3791229168840718, 'max_depth': 36, 'min_data_in_leaf': 30, 'num_leaves': 2258} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9217855774582753, 'lambda_l2': 1.1479476781357636, 'learning_rate': 0.1820709181814237, 'max_depth': 48, 'min_data_in_leaf': 26, 'num_leaves': 1015} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7385262026385422, 'lambda_l2': 3.0590733965936208, 'learning_rate': 0.042248575956816, 'max_depth': 28, 'min_data_in_leaf': 21, 'num_leaves': 1612} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8242290650607933, 'lambda_l2': 0.9534564335491765, 'learning_rate': 0.29239645739361314, 'max_depth': 33, 'min_data_in_leaf': 43, 'num_leaves': 2547} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8057381411963397, 'lambda_l2': 2.0215399706452004, 'learning_rate': 0.6876357643832798, 'max_depth': 34, 'min_data_in_leaf': 34, 'num_leaves': 2787} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8920455372812356, 'lambda_l2': 0.6646356245977206, 'learning_rate': 0.05111801341856965, 'max_depth': 54, 'min_data_in_leaf': 24, 'num_leaves': 2682} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9365850353605493, 'lambda_l2': 0.7994392853637796, 'learning_rate': 0.2360601583058401, 'max_depth': 39, 'min_data_in_leaf': 32, 'num_leaves': 564} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9785874964168249, 'lambda_l2': 0.45107100229550223, 'learning_rate': 0.062297821745979774, 'max_depth': 30, 'min_data_in_leaf': 60, 'num_leaves': 1767} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8529021991434543, 'lambda_l2': 1.599729784101568, 'learning_rate': 0.0944165213954869, 'max_depth': 37, 'min_data_in_leaf': 19, 'num_leaves': 748} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7549961507567604, 'lambda_l2': 1.0571721580810505, 'learning_rate': 0.33113575784031357, 'max_depth': 49, 'min_data_in_leaf': 52, 'num_leaves': 2120} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.9999418279864163, 'lambda_l2': 1.8112432293561131, 'learning_rate': 0.07900824154957123, 'max_depth': 59, 'min_data_in_leaf': 22, 'num_leaves': 3256} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7302314720463987, 'lambda_l2': 2.331235033813695, 'learning_rate': 0.4636703508348921, 'max_depth': 41, 'min_data_in_leaf': 39, 'num_leaves': 1145} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6818759538143151, 'lambda_l2': 0.5209574133204831, 'learning_rate': 0.022426899440320336, 'max_depth': 24, 'min_data_in_leaf': 36, 'num_leaves': 2319} : acc= 55.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7861129426057741, 'lambda_l2': 1.4566353323588128, 'learning_rate': 0.7896553565405475, 'max_depth': 43, 'min_data_in_leaf': 12, 'num_leaves': 908} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9481148244505648, 'lambda_l2': 0.8627042734067227, 'learning_rate': 0.012510868430570355, 'max_depth': 52, 'min_data_in_leaf': 27, 'num_leaves': 2866} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8830470888752407, 'lambda_l2': 3.164692276323242, 'learning_rate': 0.006117143401862326, 'max_depth': 45, 'min_data_in_leaf': 17, 'num_leaves': 1541} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.823010955217687, 'lambda_l2': 1.9689302719406756, 'learning_rate': 0.1343852612562094, 'max_depth': 34, 'min_data_in_leaf': 49, 'num_leaves': 3378} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6665329070686943, 'lambda_l2': 2.9063475969781183, 'learning_rate': 0.03459016294938031, 'max_depth': 28, 'min_data_in_leaf': 14, 'num_leaves': 1365} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7155851570335803, 'lambda_l2': 0.0956043602592016, 'learning_rate': 0.997725135357988, 'max_depth': 61, 'min_data_in_leaf': 56, 'num_leaves': 1671} : acc= 57.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9199826534895115, 'lambda_l2': 0.36941554340660465, 'learning_rate': 0.4291532087340702, 'max_depth': 21, 'min_data_in_leaf': 10, 'num_leaves': 3056} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9621305052892987, 'lambda_l2': 1.1853879513851098, 'learning_rate': 0.22573955759709233, 'max_depth': 25, 'min_data_in_leaf': 24, 'num_leaves': 257} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8613291388807865, 'lambda_l2': 2.481922491144344, 'learning_rate': 0.17016967886109646, 'max_depth': 57, 'min_data_in_leaf': 54, 'num_leaves': 1074} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7664428126994776, 'lambda_l2': 0.6434945578785501, 'learning_rate': 0.0030634994926623874, 'max_depth': 31, 'min_data_in_leaf': 6, 'num_leaves': 1902} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8033281829624268, 'lambda_l2': 1.3466113824933565, 'learning_rate': 0.280782221020551, 'max_depth': 64, 'min_data_in_leaf': 15, 'num_leaves': 1271} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8359342962755467, 'lambda_l2': 0.256407847985452, 'learning_rate': 0.525583147692846, 'max_depth': 18, 'min_data_in_leaf': 8, 'num_leaves': 1400} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8903397291107489, 'lambda_l2': 0.7871468810967686, 'learning_rate': 0.32976173948275433, 'max_depth': 3, 'min_data_in_leaf': 2, 'num_leaves': 1200} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7717356524891541, 'lambda_l2': 0.02469726985022891, 'learning_rate': 0.6230725230792266, 'max_depth': 15, 'min_data_in_leaf': 9, 'num_leaves': 1504} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7605786314892735, 'lambda_l2': 0.3048922994234848, 'learning_rate': 0.5948508166676968, 'max_depth': 22, 'min_data_in_leaf': 12, 'num_leaves': 2014} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6905314189006012, 'lambda_l2': 0.5429184472583013, 'learning_rate': 0.3967572244432235, 'max_depth': 41, 'min_data_in_leaf': 4, 'num_leaves': 2230} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6055322963210743, 'lambda_l2': 0.4226795370472106, 'learning_rate': 0.5872982514850749, 'max_depth': 11, 'min_data_in_leaf': 18, 'num_leaves': 1812} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7177396405249336, 'lambda_l2': 0.11859540937988022, 'learning_rate': 0.46591339805976073, 'max_depth': 47, 'min_data_in_leaf': 5, 'num_leaves': 2353} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5541347064567766, 'lambda_l2': 0.9638664384911453, 'learning_rate': 0.0018822420334014902, 'max_depth': 7, 'min_data_in_leaf': 11, 'num_leaves': 1705} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.788879153938928, 'lambda_l2': 0.7198395728336138, 'learning_rate': 0.7687584265554772, 'max_depth': 36, 'min_data_in_leaf': 20, 'num_leaves': 664} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6992499662443409, 'lambda_l2': 0.20116954100769105, 'learning_rate': 0.2646085730303408, 'max_depth': 54, 'min_data_in_leaf': 1, 'num_leaves': 2204} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5745776370971019, 'lambda_l2': 0.34653496092079705, 'learning_rate': 0.8688933769191647, 'max_depth': 9, 'min_data_in_leaf': 16, 'num_leaves': 1851} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9069189435823394, 'lambda_l2': 1.076071176667605, 'learning_rate': 0.368029723317589, 'max_depth': 4, 'min_data_in_leaf': 8, 'num_leaves': 867} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9334876624332252, 'lambda_l2': 0.9038086045029824, 'learning_rate': 0.19501579774568312, 'max_depth': 17, 'min_data_in_leaf': 14, 'num_leaves': 960} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.972576727511028, 'lambda_l2': 0.8386183690238278, 'learning_rate': 0.1508076096730816, 'max_depth': 14, 'min_data_in_leaf': 7, 'num_leaves': 1185} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7470498074564195, 'lambda_l2': 0.6043501216041844, 'learning_rate': 0.7250358922111554, 'max_depth': 20, 'min_data_in_leaf': 22, 'num_leaves': 1439} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6261353741255317, 'lambda_l2': 0.459610385256392, 'learning_rate': 0.43301476563281716, 'max_depth': 23, 'min_data_in_leaf': 29, 'num_leaves': 2451} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5320276967505796, 'lambda_l2': 0.003909436295692181, 'learning_rate': 0.5543709711640474, 'max_depth': 27, 'min_data_in_leaf': 11, 'num_leaves': 1558} : acc= 59.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8717433514077696, 'lambda_l2': 1.5198309021178442, 'learning_rate': 0.2332860317321469, 'max_depth': 19, 'min_data_in_leaf': 1, 'num_leaves': 820} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6505541913071208, 'lambda_l2': 0.6458847237311832, 'learning_rate': 0.9658029440590303, 'max_depth': 6, 'min_data_in_leaf': 25, 'num_leaves': 1967} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8476808342177896, 'lambda_l2': 0.28592783498679886, 'learning_rate': 0.3067696872502553, 'max_depth': 13, 'min_data_in_leaf': 7, 'num_leaves': 1362} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6695320116341656, 'lambda_l2': 1.2446564264625712, 'learning_rate': 0.1086287492014165, 'max_depth': 49, 'min_data_in_leaf': 3, 'num_leaves': 2583} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7409150358211342, 'lambda_l2': 0.5300792915508208, 'learning_rate': 0.7131339369291498, 'max_depth': 29, 'min_data_in_leaf': 13, 'num_leaves': 2076} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7124931388400826, 'lambda_l2': 0.11709773174871527, 'learning_rate': 0.49506179855382965, 'max_depth': 43, 'min_data_in_leaf': 4, 'num_leaves': 2795} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8115756731041679, 'lambda_l2': 0.7233492846802063, 'learning_rate': 0.37185792470070356, 'max_depth': 39, 'min_data_in_leaf': 17, 'num_leaves': 2416} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.42640907841564213, 'lambda_l2': 0.4078831725776421, 'learning_rate': 0.20389492227101755, 'max_depth': 10, 'min_data_in_leaf': 20, 'num_leaves': 1896} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9859043830016992, 'lambda_l2': 1.675703541959742, 'learning_rate': 0.17324763333222246, 'max_depth': 16, 'min_data_in_leaf': 9, 'num_leaves': 1012} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9056112283285163, 'lambda_l2': 1.109502557306096, 'learning_rate': 0.26452514422437223, 'max_depth': 2, 'min_data_in_leaf': 23, 'num_leaves': 1079} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9990556035310746, 'lambda_l2': 1.1061291125037866, 'learning_rate': 0.13610701203775674, 'max_depth': 33, 'min_data_in_leaf': 33, 'num_leaves': 647} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8208657791527554, 'lambda_l2': 0.9811957852333718, 'learning_rate': 0.8678337293407673, 'max_depth': 51, 'min_data_in_leaf': 1, 'num_leaves': 2543} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7844804591346628, 'lambda_l2': 0.16700722719683442, 'learning_rate': 0.323148350139882, 'max_depth': 45, 'min_data_in_leaf': 5, 'num_leaves': 2687} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8403058728526502, 'lambda_l2': 0.06452438070624456, 'learning_rate': 0.3231522309521569, 'max_depth': 45, 'min_data_in_leaf': 6, 'num_leaves': 2709} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8614219313065161, 'lambda_l2': 1.3072140328933373, 'learning_rate': 0.4989174621793437, 'max_depth': 26, 'min_data_in_leaf': 15, 'num_leaves': 1440} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7318572273528691, 'lambda_l2': 0.7805442434971936, 'learning_rate': 0.9991879467743732, 'max_depth': 69, 'min_data_in_leaf': 10, 'num_leaves': 2192} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9505150430458534, 'lambda_l2': 1.5279146514544362, 'learning_rate': 0.25927815325533277, 'max_depth': 1, 'min_data_in_leaf': 40, 'num_leaves': 350} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6932989248248742, 'lambda_l2': 0.47066527016288334, 'learning_rate': 0.4197622339178978, 'max_depth': 41, 'min_data_in_leaf': 3, 'num_leaves': 2927} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.49429869554707456, 'lambda_l2': 0.8914586343896944, 'learning_rate': 0.6502843836088947, 'max_depth': 36, 'min_data_in_leaf': 27, 'num_leaves': 2088} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8039944671914926, 'lambda_l2': 0.5720477491154433, 'learning_rate': 0.20369132907192739, 'max_depth': 38, 'min_data_in_leaf': 13, 'num_leaves': 2333} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8835210491290606, 'lambda_l2': 1.364560049328264, 'learning_rate': 0.12063752750039707, 'max_depth': 38, 'min_data_in_leaf': 22, 'num_leaves': 3016} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5841232017164231, 'lambda_l2': 2.1433982786906354, 'learning_rate': 0.6245354832852862, 'max_depth': 12, 'min_data_in_leaf': 30, 'num_leaves': 1669} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9254239277096821, 'lambda_l2': 0.9793497849161019, 'learning_rate': 0.09576391221367468, 'max_depth': 30, 'min_data_in_leaf': 13, 'num_leaves': 2322} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8080910758628177, 'lambda_l2': 0.6601679232623759, 'learning_rate': 0.15876371091586558, 'max_depth': 35, 'min_data_in_leaf': 25, 'num_leaves': 3189} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8380898797220118, 'lambda_l2': 1.1915388506792626, 'learning_rate': 0.19532956775041832, 'max_depth': 32, 'min_data_in_leaf': 20, 'num_leaves': 2476} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8970267227339265, 'lambda_l2': 1.6977057643000688, 'learning_rate': 0.0696574644853924, 'max_depth': 3, 'min_data_in_leaf': 31, 'num_leaves': 1269} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4671985298121867, 'lambda_l2': 0.35597811700225634, 'learning_rate': 0.8619017910042138, 'max_depth': 24, 'min_data_in_leaf': 18, 'num_leaves': 1760} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.637825374617015, 'lambda_l2': 1.8866223740427053, 'learning_rate': 0.3813622560734716, 'max_depth': 7, 'min_data_in_leaf': 17, 'num_leaves': 1587} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9604706232264398, 'lambda_l2': 1.7780405708371116, 'learning_rate': 0.26443633345637774, 'max_depth': 5, 'min_data_in_leaf': 36, 'num_leaves': 1114} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9189960051322158, 'lambda_l2': 0.8498221735764857, 'learning_rate': 0.010108604514544055, 'max_depth': 9, 'min_data_in_leaf': 7, 'num_leaves': 438} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5432006904295267, 'lambda_l2': 0.7193664821991799, 'learning_rate': 0.7601578087739662, 'max_depth': 19, 'min_data_in_leaf': 11, 'num_leaves': 1992} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5999678796277387, 'lambda_l2': 0.25534860791758607, 'learning_rate': 0.007941471393938734, 'max_depth': 14, 'min_data_in_leaf': 16, 'num_leaves': 2125} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.0001534275823469322, 'lambda_l2': 0.17545250852786054, 'learning_rate': 0.457956998754785, 'max_depth': 53, 'min_data_in_leaf': 3, 'num_leaves': 2625} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7545851882539525, 'lambda_l2': 3.4399179315730635, 'learning_rate': 0.5024733605776267, 'max_depth': 58, 'min_data_in_leaf': 5, 'num_leaves': 2242} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8701451864613132, 'lambda_l2': 1.4597847755009778, 'learning_rate': 0.23146779682165153, 'max_depth': 22, 'min_data_in_leaf': 28, 'num_leaves': 768} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.9871464383637081, 'lambda_l2': 1.2282631622089117, 'learning_rate': 0.3513380692196063, 'max_depth': 11, 'min_data_in_leaf': 8, 'num_leaves': 1309} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9068674292091833, 'lambda_l2': 1.066677690758956, 'learning_rate': 0.07820115246170951, 'max_depth': 16, 'min_data_in_leaf': 41, 'num_leaves': 518} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6337382492901483, 'lambda_l2': 0.36971186047401566, 'learning_rate': 0.29895337306496633, 'max_depth': 28, 'min_data_in_leaf': 10, 'num_leaves': 1853} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9435959694535233, 'lambda_l2': 1.5646536118580037, 'learning_rate': 0.10826179027910808, 'max_depth': 81, 'min_data_in_leaf': 19, 'num_leaves': 950} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8553181909020943, 'lambda_l2': 2.058955770024205, 'learning_rate': 0.13744692748712753, 'max_depth': 47, 'min_data_in_leaf': 46, 'num_leaves': 1104} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6655522890808002, 'lambda_l2': 0.0052698051298701865, 'learning_rate': 0.017923851419638342, 'max_depth': 21, 'min_data_in_leaf': 26, 'num_leaves': 1641} : acc= 53.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.969020517490642, 'lambda_l2': 1.4161861028840854, 'learning_rate': 0.17722263379485956, 'max_depth': 9, 'min_data_in_leaf': 15, 'num_leaves': 881} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7784518904652493, 'lambda_l2': 0.5062234545296456, 'learning_rate': 0.43202880391107557, 'max_depth': 66, 'min_data_in_leaf': 2, 'num_leaves': 3112} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8287169985232896, 'lambda_l2': 0.6194279642594295, 'learning_rate': 0.5800816219877231, 'max_depth': 25, 'min_data_in_leaf': 1, 'num_leaves': 1488} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7582514861981342, 'lambda_l2': 0.2751241984844228, 'learning_rate': 0.5578929532381233, 'max_depth': 19, 'min_data_in_leaf': 58, 'num_leaves': 1718} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8087727855950313, 'lambda_l2': 0.5752936122069828, 'learning_rate': 0.22518102217332298, 'max_depth': 56, 'min_data_in_leaf': 23, 'num_leaves': 2865} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7862480735280517, 'lambda_l2': 0.005797490611860079, 'learning_rate': 0.09032605538860794, 'max_depth': 60, 'min_data_in_leaf': 61, 'num_leaves': 3503} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5702435814712448, 'lambda_l2': 0.9820919730220528, 'learning_rate': 0.9618839732367787, 'max_depth': 7, 'min_data_in_leaf': 11, 'num_leaves': 1762} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9268091339485991, 'lambda_l2': 1.28449757403135, 'learning_rate': 0.30512090101428596, 'max_depth': 4, 'min_data_in_leaf': 14, 'num_leaves': 1259} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7264288173956802, 'lambda_l2': 0.11812779936515794, 'learning_rate': 0.6630839698578461, 'max_depth': 50, 'min_data_in_leaf': 5, 'num_leaves': 2168} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8700424251113387, 'lambda_l2': 0.8279150715059878, 'learning_rate': 0.3611269419850371, 'max_depth': 17, 'min_data_in_leaf': 9, 'num_leaves': 1167} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.938652024575808, 'lambda_l2': 1.1231380318787894, 'learning_rate': 0.12274995396459472, 'max_depth': 34, 'min_data_in_leaf': 38, 'num_leaves': 642} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8894767624583676, 'lambda_l2': 3.2978543249908947, 'learning_rate': 0.16956856333588205, 'max_depth': 11, 'min_data_in_leaf': 21, 'num_leaves': 718} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8426692836026551, 'lambda_l2': 0.79530540764819, 'learning_rate': 0.04909013455581991, 'max_depth': 43, 'min_data_in_leaf': 35, 'num_leaves': 2355} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7713536674868648, 'lambda_l2': 2.643349176090746, 'learning_rate': 0.24951474173722157, 'max_depth': 62, 'min_data_in_leaf': 71, 'num_leaves': 2699} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7829196206731397, 'lambda_l2': 0.4339397460995495, 'learning_rate': 0.026791555659353063, 'max_depth': 46, 'min_data_in_leaf': 5, 'num_leaves': 3279} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.040090478347980296, 'lambda_l2': 0.2289511938607699, 'learning_rate': 0.42243965931783045, 'max_depth': 53, 'min_data_in_leaf': 1, 'num_leaves': 2611} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6847672332400996, 'lambda_l2': 0.9137235223410606, 'learning_rate': 0.506744544364269, 'max_depth': 40, 'min_data_in_leaf': 12, 'num_leaves': 2763} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.10057519066093368, 'lambda_l2': 0.15211252488349525, 'learning_rate': 0.7690622319258699, 'max_depth': 55, 'min_data_in_leaf': 3, 'num_leaves': 3138} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7390563931887331, 'lambda_l2': 0.5340311560102697, 'learning_rate': 0.058432290793347455, 'max_depth': 47, 'min_data_in_leaf': 7, 'num_leaves': 2967} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.704567607005577, 'lambda_l2': 0.7065400794260599, 'learning_rate': 0.8759395054705754, 'max_depth': 41, 'min_data_in_leaf': 18, 'num_leaves': 2507} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7954534336381868, 'lambda_l2': 1.0139821350646765, 'learning_rate': 0.1473330267271905, 'max_depth': 38, 'min_data_in_leaf': 13, 'num_leaves': 2363} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8223373607528623, 'lambda_l2': 1.1766173027301063, 'learning_rate': 0.07115482418508162, 'max_depth': 36, 'min_data_in_leaf': 32, 'num_leaves': 2042} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7164408649539442, 'lambda_l2': 0.6461531664948713, 'learning_rate': 0.7084245423068536, 'max_depth': 27, 'min_data_in_leaf': 43, 'num_leaves': 1358} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8548994384309699, 'lambda_l2': 0.33748382335888516, 'learning_rate': 0.30610330779816414, 'max_depth': 50, 'min_data_in_leaf': 24, 'num_leaves': 3686} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9905648476189793, 'lambda_l2': 2.351611829098309, 'learning_rate': 0.26670845907853424, 'max_depth': 1, 'min_data_in_leaf': 28, 'num_leaves': 1042} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5231803622008901, 'lambda_l2': 0.4532029201291106, 'learning_rate': 0.3863086818186674, 'max_depth': 22, 'min_data_in_leaf': 74, 'num_leaves': 1901} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.12871680722945378, 'lambda_l2': 0.04493908362540233, 'learning_rate': 0.20439414794017358, 'max_depth': 72, 'min_data_in_leaf': 68, 'num_leaves': 3343} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6128018741426972, 'lambda_l2': 0.7726780321843594, 'learning_rate': 0.613591946206743, 'max_depth': 15, 'min_data_in_leaf': 17, 'num_leaves': 1547} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8816473725303862, 'lambda_l2': 1.6195989866674578, 'learning_rate': 0.04462024770370939, 'max_depth': 37, 'min_data_in_leaf': 21, 'num_leaves': 2800} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9989723671147047, 'lambda_l2': 1.4189888426506787, 'learning_rate': 0.34436795766406564, 'max_depth': 4, 'min_data_in_leaf': 7, 'num_leaves': 826} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.03785530588422053, 'lambda_l2': 0.9180604741711382, 'learning_rate': 0.47645793178087337, 'max_depth': 53, 'min_data_in_leaf': 1, 'num_leaves': 3061} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.3069313092946404, 'lambda_l2': 1.7478897310708859, 'learning_rate': 0.22864691951555294, 'max_depth': 64, 'min_data_in_leaf': 3, 'num_leaves': 3422} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.21212798699067226, 'lambda_l2': 0.22456174579429722, 'learning_rate': 0.1577863684830027, 'max_depth': 67, 'min_data_in_leaf': 63, 'num_leaves': 2941} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6658410802300491, 'lambda_l2': 0.08568574163240072, 'learning_rate': 0.10354261442416027, 'max_depth': 57, 'min_data_in_leaf': 9, 'num_leaves': 2864} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3426324182783812, 'lambda_l2': 1.2560719238849294, 'learning_rate': 0.9978322049933608, 'max_depth': 61, 'min_data_in_leaf': 10, 'num_leaves': 3782} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6459330569036849, 'lambda_l2': 4.204472701967546, 'learning_rate': 0.4442345579122847, 'max_depth': 43, 'min_data_in_leaf': 15, 'num_leaves': 2279} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8104821218486321, 'lambda_l2': 2.1963795514169684, 'learning_rate': 0.1987778760828229, 'max_depth': 31, 'min_data_in_leaf': 49, 'num_leaves': 2469} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.736201214058672, 'lambda_l2': 0.3605668111958979, 'learning_rate': 0.7055869397762501, 'max_depth': 49, 'min_data_in_leaf': 6, 'num_leaves': 1936} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.758967529154615, 'lambda_l2': 0.7105030485710856, 'learning_rate': 0.5398161317190173, 'max_depth': 43, 'min_data_in_leaf': 16, 'num_leaves': 2044} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7059225241519347, 'lambda_l2': 0.555606467638124, 'learning_rate': 0.1216495810918736, 'max_depth': 33, 'min_data_in_leaf': 26, 'num_leaves': 2405} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6725692969005065, 'lambda_l2': 4.955681773679452, 'learning_rate': 0.2850806825374964, 'max_depth': 30, 'min_data_in_leaf': 13, 'num_leaves': 2155} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3792045427864653, 'lambda_l2': 1.0511668605116737, 'learning_rate': 0.9128727109541336, 'max_depth': 13, 'min_data_in_leaf': 30, 'num_leaves': 1851} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.24259184864003755, 'lambda_l2': 1.8522195510088113, 'learning_rate': 0.41326443835267745, 'max_depth': 58, 'min_data_in_leaf': 1, 'num_leaves': 3002} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9535047621888, 'lambda_l2': 1.347408104324877, 'learning_rate': 0.0020786885589479617, 'max_depth': 5, 'min_data_in_leaf': 20, 'num_leaves': 1195} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.02322363046734213, 'lambda_l2': 0.4779380298266081, 'learning_rate': 0.8480040771106145, 'max_depth': 74, 'min_data_in_leaf': 3, 'num_leaves': 2671} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6218823668568203, 'lambda_l2': 0.6159113711064736, 'learning_rate': 0.08244985003714816, 'max_depth': 51, 'min_data_in_leaf': 18, 'num_leaves': 1624} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9086610420993207, 'lambda_l2': 0.8399317407527663, 'learning_rate': 0.33053935918371863, 'max_depth': 45, 'min_data_in_leaf': 11, 'num_leaves': 3579} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.07713997769446895, 'lambda_l2': 0.26958042292876283, 'learning_rate': 0.0034725002009672046, 'max_depth': 39, 'min_data_in_leaf': 23, 'num_leaves': 2563} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8347407957106149, 'lambda_l2': 0.16709506006534958, 'learning_rate': 0.014549970531435471, 'max_depth': 90, 'min_data_in_leaf': 5, 'num_leaves': 3181} : acc= 55.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6888442999064504, 'lambda_l2': 0.9143281353826417, 'learning_rate': 0.17807994859411638, 'max_depth': 35, 'min_data_in_leaf': 15, 'num_leaves': 2273} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.447826500940054, 'lambda_l2': 1.95505995429072, 'learning_rate': 0.6105987372715139, 'max_depth': 63, 'min_data_in_leaf': 8, 'num_leaves': 2644} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.724878186347042, 'lambda_l2': 1.1164050048784775, 'learning_rate': 0.9976990343832303, 'max_depth': 41, 'min_data_in_leaf': 34, 'num_leaves': 2122} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8926946134717576, 'lambda_l2': 2.8500705362789924, 'learning_rate': 0.22968540859250763, 'max_depth': 46, 'min_data_in_leaf': 12, 'num_leaves': 2832} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9339158610054312, 'lambda_l2': 1.2109138072032515, 'learning_rate': 0.14434305696231312, 'max_depth': 1, 'min_data_in_leaf': 36, 'num_leaves': 1032} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7906443910866368, 'lambda_l2': 1.5119338165557792, 'learning_rate': 0.06348997676487055, 'max_depth': 48, 'min_data_in_leaf': 19, 'num_leaves': 2561} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9771652148591199, 'lambda_l2': 1.6316391708899642, 'learning_rate': 0.5182281392301213, 'max_depth': 83, 'min_data_in_leaf': 25, 'num_leaves': 3990} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.49216762677993203, 'lambda_l2': 0.018040820250180778, 'learning_rate': 0.03125281179065734, 'max_depth': 8, 'min_data_in_leaf': 32, 'num_leaves': 1810} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8682010938532335, 'lambda_l2': 0.392872589917772, 'learning_rate': 0.7456489027323162, 'max_depth': 23, 'min_data_in_leaf': 9, 'num_leaves': 1475} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.760958959089655, 'lambda_l2': 0.7366630774260303, 'learning_rate': 0.6268603124751542, 'max_depth': 26, 'min_data_in_leaf': 66, 'num_leaves': 1365} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.05351858971015866, 'lambda_l2': 1.3197105083992149, 'learning_rate': 0.4810465401130442, 'max_depth': 55, 'min_data_in_leaf': 2, 'num_leaves': 3012} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8514896119858038, 'lambda_l2': 0.540292342028878, 'learning_rate': 0.18743923654640987, 'max_depth': 32, 'min_data_in_leaf': 76, 'num_leaves': 2298} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.823022364339946, 'lambda_l2': 1.017964114582035, 'learning_rate': 0.0947866386673078, 'max_depth': 36, 'min_data_in_leaf': 22, 'num_leaves': 2744} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9108743039199703, 'lambda_l2': 1.4767682025578364, 'learning_rate': 0.39468761196380425, 'max_depth': 17, 'min_data_in_leaf': 29, 'num_leaves': 916} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.36141764670071774, 'lambda_l2': 1.7494499833087487, 'learning_rate': 0.02131360567643515, 'max_depth': 70, 'min_data_in_leaf': 1, 'num_leaves': 3447} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5932420787474831, 'lambda_l2': 0.8772368196583826, 'learning_rate': 0.2828739579674818, 'max_depth': 11, 'min_data_in_leaf': 17, 'num_leaves': 1725} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9599435272325341, 'lambda_l2': 3.8526361044400192, 'learning_rate': 0.33611062602419833, 'max_depth': 2, 'min_data_in_leaf': 47, 'num_leaves': 57} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7990660363560952, 'lambda_l2': 0.588709489419811, 'learning_rate': 0.12509298516418565, 'max_depth': 29, 'min_data_in_leaf': 39, 'num_leaves': 1978} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9995562598231844, 'lambda_l2': 1.1772461896997264, 'learning_rate': 0.038944883817965285, 'max_depth': 20, 'min_data_in_leaf': 55, 'num_leaves': 184} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.875733331877742, 'lambda_l2': 0.01661487958179697, 'learning_rate': 0.2467948331433787, 'max_depth': 60, 'min_data_in_leaf': 6, 'num_leaves': 2448} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7464776011466502, 'lambda_l2': 0.30623724881145997, 'learning_rate': 0.7684458118130221, 'max_depth': 44, 'min_data_in_leaf': 13, 'num_leaves': 2060} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.42133096908740675, 'lambda_l2': 0.43748095744067633, 'learning_rate': 0.591833863797053, 'max_depth': 25, 'min_data_in_leaf': 27, 'num_leaves': 1651} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.660132540129448, 'lambda_l2': 0.6868509468931945, 'learning_rate': 0.36738138120614877, 'max_depth': 41, 'min_data_in_leaf': 5, 'num_leaves': 2163} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6529372824629986, 'lambda_l2': 0.9743205466674779, 'learning_rate': 0.16934240228281527, 'max_depth': 39, 'min_data_in_leaf': 15, 'num_leaves': 1981} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5465749935507209, 'lambda_l2': 1.3969012420375146, 'learning_rate': 0.21334632978834273, 'max_depth': 51, 'min_data_in_leaf': 44, 'num_leaves': 2208} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6847555880058749, 'lambda_l2': 0.7781071430283795, 'learning_rate': 0.390231467868202, 'max_depth': 28, 'min_data_in_leaf': 51, 'num_leaves': 1555} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.711799258048313, 'lambda_l2': 2.103284030824348, 'learning_rate': 0.11360145366985329, 'max_depth': 32, 'min_data_in_leaf': 10, 'num_leaves': 2414} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6184504295556433, 'lambda_l2': 0.677884265037751, 'learning_rate': 0.13628240481560178, 'max_depth': 34, 'min_data_in_leaf': 8, 'num_leaves': 2541} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6545907038792724, 'lambda_l2': 2.7409700774887216, 'learning_rate': 0.2952049568691381, 'max_depth': 49, 'min_data_in_leaf': 20, 'num_leaves': 1816} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7708487537753109, 'lambda_l2': 1.104601888367643, 'learning_rate': 0.2514166908655056, 'max_depth': 30, 'min_data_in_leaf': 5, 'num_leaves': 1432} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6363354849682608, 'lambda_l2': 2.4848498246455537, 'learning_rate': 0.0042352782088736435, 'max_depth': 41, 'min_data_in_leaf': 11, 'num_leaves': 1296} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6740699338886124, 'lambda_l2': 1.6228920242062272, 'learning_rate': 0.4280181867702424, 'max_depth': 38, 'min_data_in_leaf': 14, 'num_leaves': 1944} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5145756570355173, 'lambda_l2': 1.25980957715758, 'learning_rate': 0.0012960314402011026, 'max_depth': 47, 'min_data_in_leaf': 42, 'num_leaves': 2144} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8332011810729041, 'lambda_l2': 1.0241695648121674, 'learning_rate': 0.15101123346262282, 'max_depth': 27, 'min_data_in_leaf': 24, 'num_leaves': 2496} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6091251946910452, 'lambda_l2': 1.5419659054965216, 'learning_rate': 0.3560437995597506, 'max_depth': 53, 'min_data_in_leaf': 4, 'num_leaves': 2253} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7424891496594208, 'lambda_l2': 0.8079343228409408, 'learning_rate': 0.05288543069870113, 'max_depth': 43, 'min_data_in_leaf': 98, 'num_leaves': 568} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8533977968030116, 'lambda_l2': 3.6991258821424173, 'learning_rate': 0.08050142725261146, 'max_depth': 34, 'min_data_in_leaf': 7, 'num_leaves': 1737} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5944401153284834, 'lambda_l2': 0.354468069566094, 'learning_rate': 0.558748019813066, 'max_depth': 6, 'min_data_in_leaf': 12, 'num_leaves': 1926} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5687917332215097, 'lambda_l2': 0.6596653495630845, 'learning_rate': 0.47811774617356395, 'max_depth': 9, 'min_data_in_leaf': 9, 'num_leaves': 2046} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.697307679547482, 'lambda_l2': 0.16519204404559162, 'learning_rate': 0.3096149081763738, 'max_depth': 42, 'min_data_in_leaf': 3, 'num_leaves': 2167} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.16788783995694964, 'lambda_l2': 0.9767522237818401, 'learning_rate': 0.6667963288615913, 'max_depth': 56, 'min_data_in_leaf': 2, 'num_leaves': 3063} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7300060754613397, 'lambda_l2': 0.4523952078693133, 'learning_rate': 0.5310502569399221, 'max_depth': 15, 'min_data_in_leaf': 7, 'num_leaves': 1501} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7808323877045842, 'lambda_l2': 0.2803694977778147, 'learning_rate': 0.7898318723764086, 'max_depth': 18, 'min_data_in_leaf': 17, 'num_leaves': 1230} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.9248854830485831, 'lambda_l2': 0.1226982968699285, 'learning_rate': 0.3639143944657775, 'max_depth': 51, 'min_data_in_leaf': 1, 'num_leaves': 2646} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8868527225268921, 'lambda_l2': 0.8698345284946789, 'learning_rate': 0.20842066363751952, 'max_depth': 5, 'min_data_in_leaf': 5, 'num_leaves': 1135} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.2598780404335225, 'lambda_l2': 0.5329299789615006, 'learning_rate': 0.4391010194794071, 'max_depth': 58, 'min_data_in_leaf': 4, 'num_leaves': 2613} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8453224993239136, 'lambda_l2': 0.8859917574525242, 'learning_rate': 0.27500451482886673, 'max_depth': 48, 'min_data_in_leaf': 9, 'num_leaves': 3359} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7943758078590455, 'lambda_l2': 0.6103437263098216, 'learning_rate': 0.1847484071911288, 'max_depth': 37, 'min_data_in_leaf': 13, 'num_leaves': 2422} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8166171506950884, 'lambda_l2': 1.1749702554047587, 'learning_rate': 0.46131798366471927, 'max_depth': 68, 'min_data_in_leaf': 2, 'num_leaves': 3232} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8293596749110813, 'lambda_l2': 1.3491115343318036, 'learning_rate': 0.6535628564405248, 'max_depth': 86, 'min_data_in_leaf': 11, 'num_leaves': 3692} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8037825177816139, 'lambda_l2': 0.7460878444059041, 'learning_rate': 0.2495039875316398, 'max_depth': 45, 'min_data_in_leaf': 19, 'num_leaves': 2357} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7148754725321703, 'lambda_l2': 0.21893584837443178, 'learning_rate': 0.32969494674648686, 'max_depth': 40, 'min_data_in_leaf': 7, 'num_leaves': 2122} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7682170572721676, 'lambda_l2': 0.41019194204949605, 'learning_rate': 0.2240665759624882, 'max_depth': 53, 'min_data_in_leaf': 5, 'num_leaves': 2774} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7619122760930941, 'lambda_l2': 0.2954462682396798, 'learning_rate': 0.5363269869271484, 'max_depth': 13, 'min_data_in_leaf': 14, 'num_leaves': 1615} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.002477731627716347, 'lambda_l2': 0.057178064976874374, 'learning_rate': 0.39272208937866426, 'max_depth': 55, 'min_data_in_leaf': 16, 'num_leaves': 2887} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6590931702152987, 'lambda_l2': 0.513573798570277, 'learning_rate': 0.8436758646148564, 'max_depth': 43, 'min_data_in_leaf': 6, 'num_leaves': 2206} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6865546961489852, 'lambda_l2': 0.7804659974656606, 'learning_rate': 0.6794729632910482, 'max_depth': 35, 'min_data_in_leaf': 9, 'num_leaves': 1857} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.32478639260020226, 'lambda_l2': 1.090367546280251, 'learning_rate': 0.2840789667590321, 'max_depth': 53, 'min_data_in_leaf': 1, 'num_leaves': 3248} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.11295514936952855, 'lambda_l2': 0.9334206377918781, 'learning_rate': 0.47469163808704257, 'max_depth': 64, 'min_data_in_leaf': 1, 'num_leaves': 3131} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8952442530511585, 'lambda_l2': 1.243812243515333, 'learning_rate': 0.3670325862544952, 'max_depth': 49, 'min_data_in_leaf': 10, 'num_leaves': 2913} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8221634784130413, 'lambda_l2': 1.4684293822726053, 'learning_rate': 0.9490191899659541, 'max_depth': 81, 'min_data_in_leaf': 3, 'num_leaves': 3462} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8747567642484702, 'lambda_l2': 0.5139703396556542, 'learning_rate': 0.1923641054058922, 'max_depth': 38, 'min_data_in_leaf': 21, 'num_leaves': 2311} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7439583873681419, 'lambda_l2': 0.5901085389716461, 'learning_rate': 0.2304470232807253, 'max_depth': 32, 'min_data_in_leaf': 23, 'num_leaves': 2375} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9566055330680776, 'lambda_l2': 1.8544736440200873, 'learning_rate': 0.30165908624549637, 'max_depth': 10, 'min_data_in_leaf': 30, 'num_leaves': 701} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4042854607270058, 'lambda_l2': 0.9407671890555916, 'learning_rate': 0.5955126259768503, 'max_depth': 61, 'min_data_in_leaf': 7, 'num_leaves': 3094} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.1455699127381999, 'lambda_l2': 0.8465024246665827, 'learning_rate': 0.16444125023869005, 'max_depth': 59, 'min_data_in_leaf': 1, 'num_leaves': 2814} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8610800226571889, 'lambda_l2': 0.6549975677932005, 'learning_rate': 0.13018510859040536, 'max_depth': 39, 'min_data_in_leaf': 19, 'num_leaves': 2484} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5610562605513457, 'lambda_l2': 0.41606688735154074, 'learning_rate': 0.7378133074114868, 'max_depth': 24, 'min_data_in_leaf': 15, 'num_leaves': 1687} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.27252713391629896, 'lambda_l2': 0.02846847619173365, 'learning_rate': 0.9977831101183015, 'max_depth': 45, 'min_data_in_leaf': 11, 'num_leaves': 2612} : acc= 43.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7890536631127905, 'lambda_l2': 0.11690969909861615, 'learning_rate': 0.34032287183099597, 'max_depth': 46, 'min_data_in_leaf': 5, 'num_leaves': 2686} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4612055450192612, 'lambda_l2': 4.61303097577567, 'learning_rate': 0.4430951053622108, 'max_depth': 65, 'min_data_in_leaf': 3, 'num_leaves': 2721} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9162458241668479, 'lambda_l2': 0.001742732092117838, 'learning_rate': 0.30464198857222563, 'max_depth': 40, 'min_data_in_leaf': 12, 'num_leaves': 2525} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.22532341105398174, 'lambda_l2': 1.0257444211194438, 'learning_rate': 0.5226569508751161, 'max_depth': 57, 'min_data_in_leaf': 8, 'num_leaves': 3566} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8111763185650014, 'lambda_l2': 0.741101915245621, 'learning_rate': 0.19742103663753577, 'max_depth': 36, 'min_data_in_leaf': 25, 'num_leaves': 2304} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7930069679742641, 'lambda_l2': 0.19312115780999817, 'learning_rate': 0.005663114794260175, 'max_depth': 48, 'min_data_in_leaf': 17, 'num_leaves': 2735} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5229757908587029, 'lambda_l2': 0.37328716717028904, 'learning_rate': 0.7754553728401219, 'max_depth': 21, 'min_data_in_leaf': 18, 'num_leaves': 1563} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.726974637631989, 'lambda_l2': 0.3310470186120497, 'learning_rate': 0.5487261218682871, 'max_depth': 13, 'min_data_in_leaf': 15, 'num_leaves': 1286} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5787375519541439, 'lambda_l2': 0.6856412983211152, 'learning_rate': 0.39705744951030164, 'max_depth': 3, 'min_data_in_leaf': 21, 'num_leaves': 1815} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9128005776846342, 'lambda_l2': 1.1561667419718429, 'learning_rate': 0.2485183774358614, 'max_depth': 6, 'min_data_in_leaf': 14, 'num_leaves': 999} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9752013851588303, 'lambda_l2': 1.7366663601962586, 'learning_rate': 0.2639248734488465, 'max_depth': 3, 'min_data_in_leaf': 33, 'num_leaves': 865} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9458180164636922, 'lambda_l2': 1.3453121740044174, 'learning_rate': 0.1088234503045305, 'max_depth': 8, 'min_data_in_leaf': 37, 'num_leaves': 439} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7804599046199352, 'lambda_l2': 0.142881553539574, 'learning_rate': 0.14928893109812666, 'max_depth': 50, 'min_data_in_leaf': 6, 'num_leaves': 2883} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.839081600656438, 'lambda_l2': 0.634045676574146, 'learning_rate': 0.10222371014321865, 'max_depth': 30, 'min_data_in_leaf': 28, 'num_leaves': 2101} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7560945005072198, 'lambda_l2': 0.23169314596014123, 'learning_rate': 0.1729849452384877, 'max_depth': 44, 'min_data_in_leaf': 10, 'num_leaves': 2490} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6319565198418959, 'lambda_l2': 0.10774461787598137, 'learning_rate': 0.20932269916889543, 'max_depth': 46, 'min_data_in_leaf': 5, 'num_leaves': 2685} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9011327646298687, 'lambda_l2': 1.0323735570199601, 'learning_rate': 0.3245007582196467, 'max_depth': 18, 'min_data_in_leaf': 12, 'num_leaves': 1149} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8755196626801174, 'lambda_l2': 0.5258008403365061, 'learning_rate': 0.14333309423396254, 'max_depth': 33, 'min_data_in_leaf': 22, 'num_leaves': 1995} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9371616626352062, 'lambda_l2': 1.2856110630142492, 'learning_rate': 0.6458408988796023, 'max_depth': 55, 'min_data_in_leaf': 8, 'num_leaves': 2982} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8448213672982838, 'lambda_l2': 1.584169185087616, 'learning_rate': 0.8633977471956341, 'max_depth': 88, 'min_data_in_leaf': 83, 'num_leaves': 3522} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.07023595859324094, 'lambda_l2': 0.9298812876856052, 'learning_rate': 0.4528268486650945, 'max_depth': 51, 'min_data_in_leaf': 1, 'num_leaves': 3058} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7067161156575388, 'lambda_l2': 0.008422174995784848, 'learning_rate': 0.3827039489619866, 'max_depth': 22, 'min_data_in_leaf': 86, 'num_leaves': 1396} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.18406221342376222, 'lambda_l2': 0.45067287753831525, 'learning_rate': 0.42619583630510144, 'max_depth': 53, 'min_data_in_leaf': 4, 'num_leaves': 2593} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7557768190374217, 'lambda_l2': 0.7872618654745995, 'learning_rate': 0.3288668903530347, 'max_depth': 40, 'min_data_in_leaf': 13, 'num_leaves': 2386} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8072194417010592, 'lambda_l2': 1.1242202926418443, 'learning_rate': 0.2305949138928466, 'max_depth': 37, 'min_data_in_leaf': 19, 'num_leaves': 2237} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6761951460556053, 'lambda_l2': 0.26372674284025943, 'learning_rate': 0.26445518857759565, 'max_depth': 42, 'min_data_in_leaf': 17, 'num_leaves': 2421} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8210613905446164, 'lambda_l2': 1.4090774036232094, 'learning_rate': 0.4915016138575878, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 3647} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.501079399529774, 'lambda_l2': 0.34633318342665037, 'learning_rate': 0.5944559699306696, 'max_depth': 67, 'min_data_in_leaf': 3, 'num_leaves': 2799} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5478781664862464, 'lambda_l2': 2.005828454309663, 'learning_rate': 0.7200757195517864, 'max_depth': 62, 'min_data_in_leaf': 2, 'num_leaves': 3178} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9985473044437942, 'lambda_l2': 1.10352948989303, 'learning_rate': 0.9938445889531246, 'max_depth': 11, 'min_data_in_leaf': 24, 'num_leaves': 783} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7297012266903156, 'lambda_l2': 2.998597034637892, 'learning_rate': 0.09384618037401794, 'max_depth': 44, 'min_data_in_leaf': 7, 'num_leaves': 2928} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7717558765985614, 'lambda_l2': 0.5979737672484244, 'learning_rate': 0.011688688302789619, 'max_depth': 31, 'min_data_in_leaf': 11, 'num_leaves': 2285} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6541279883291164, 'lambda_l2': 0.45371129655924924, 'learning_rate': 0.35664879335869415, 'max_depth': 47, 'min_data_in_leaf': 26, 'num_leaves': 2063} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6047423772487255, 'lambda_l2': 0.7321351395218454, 'learning_rate': 0.8418598794515809, 'max_depth': 27, 'min_data_in_leaf': 92, 'num_leaves': 2210} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9313389636823101, 'lambda_l2': 2.3098270283693934, 'learning_rate': 0.6691329303806327, 'max_depth': 78, 'min_data_in_leaf': 59, 'num_leaves': 1905} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8659432215106686, 'lambda_l2': 0.8226180371622249, 'learning_rate': 0.16271678142648535, 'max_depth': 42, 'min_data_in_leaf': 16, 'num_leaves': 2627} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8996840055852411, 'lambda_l2': 1.937208672835235, 'learning_rate': 0.07242874749398162, 'max_depth': 2, 'min_data_in_leaf': 31, 'num_leaves': 1036} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8598195133980849, 'lambda_l2': 1.68932218968028, 'learning_rate': 0.2733128206368621, 'max_depth': 2, 'min_data_in_leaf': 40, 'num_leaves': 961} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9650871591764512, 'lambda_l2': 2.2098063920618047, 'learning_rate': 0.18618757255858745, 'max_depth': 16, 'min_data_in_leaf': 34, 'num_leaves': 1332} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.89404554646108, 'lambda_l2': 1.5360085605974145, 'learning_rate': 0.12113558629110152, 'max_depth': 14, 'min_data_in_leaf': 26, 'num_leaves': 1068} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.47517992657890334, 'lambda_l2': 0.2128348268587814, 'learning_rate': 0.4304676344868483, 'max_depth': 52, 'min_data_in_leaf': 4, 'num_leaves': 2579} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5543017658679256, 'lambda_l2': 0.6844850302193825, 'learning_rate': 0.00826405752332499, 'max_depth': 19, 'min_data_in_leaf': 20, 'num_leaves': 1591} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.28865616476715555, 'lambda_l2': 4.343743838385953, 'learning_rate': 0.5453391456510354, 'max_depth': 72, 'min_data_in_leaf': 14, 'num_leaves': 2453} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6331982600134698, 'lambda_l2': 0.5027297066412322, 'learning_rate': 0.3753036010092963, 'max_depth': 35, 'min_data_in_leaf': 6, 'num_leaves': 2004} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.745560211156634, 'lambda_l2': 0.07480797316289656, 'learning_rate': 0.22024318939552356, 'max_depth': 47, 'min_data_in_leaf': 9, 'num_leaves': 2852} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6962919664991719, 'lambda_l2': 0.001916549155160041, 'learning_rate': 0.994140964827026, 'max_depth': 30, 'min_data_in_leaf': 12, 'num_leaves': 1782} : acc= 52.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8335962073060594, 'lambda_l2': 0.9128996918159697, 'learning_rate': 0.5011757189150923, 'max_depth': 60, 'min_data_in_leaf': 3, 'num_leaves': 2123} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6745080624942361, 'lambda_l2': 1.0127816463174928, 'learning_rate': 0.30576690331368744, 'max_depth': 75, 'min_data_in_leaf': 1, 'num_leaves': 3889} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6202172944856379, 'lambda_l2': 1.1754868057784584, 'learning_rate': 0.2962078282200389, 'max_depth': 25, 'min_data_in_leaf': 7, 'num_leaves': 1499} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6530302005352528, 'lambda_l2': 0.956447773859635, 'learning_rate': 0.13312454274320845, 'max_depth': 69, 'min_data_in_leaf': 10, 'num_leaves': 3898} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5875177213591055, 'lambda_l2': 1.3112422030406083, 'learning_rate': 0.16222662839078575, 'max_depth': 92, 'min_data_in_leaf': 16, 'num_leaves': 3913} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6851166209509771, 'lambda_l2': 1.030142786277351, 'learning_rate': 0.22059548569095566, 'max_depth': 84, 'min_data_in_leaf': 1, 'num_leaves': 1665} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7244591467726545, 'lambda_l2': 1.1983620060973865, 'learning_rate': 0.083831288464021, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 1431} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7099850542553496, 'lambda_l2': 1.2683176815853212, 'learning_rate': 0.25010083055730825, 'max_depth': 90, 'min_data_in_leaf': 5, 'num_leaves': 3766} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6718376123125821, 'lambda_l2': 1.4307008609559655, 'learning_rate': 0.06155885902612558, 'max_depth': 77, 'min_data_in_leaf': 22, 'num_leaves': 3819} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.567808892352113, 'lambda_l2': 1.7684029513716573, 'learning_rate': 0.3062644333092004, 'max_depth': 71, 'min_data_in_leaf': 8, 'num_leaves': 3966} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5298706822412208, 'lambda_l2': 2.563769153878873, 'learning_rate': 0.10824828146969401, 'max_depth': 86, 'min_data_in_leaf': 14, 'num_leaves': 1234} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6101111429330337, 'lambda_l2': 0.8624746205466831, 'learning_rate': 0.1838451628108352, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 1706} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6457530573142823, 'lambda_l2': 1.4889048544322367, 'learning_rate': 0.37403685408768916, 'max_depth': 80, 'min_data_in_leaf': 1, 'num_leaves': 533} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6946768236538332, 'lambda_l2': 0.7658211875075225, 'learning_rate': 0.6124573528408117, 'max_depth': 28, 'min_data_in_leaf': 13, 'num_leaves': 1493} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7421912546652508, 'lambda_l2': 1.048789173541089, 'learning_rate': 0.15098200948214807, 'max_depth': 84, 'min_data_in_leaf': 11, 'num_leaves': 1913} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7764395745024164, 'lambda_l2': 3.164606027135161, 'learning_rate': 0.27059939632486707, 'max_depth': 73, 'min_data_in_leaf': 57, 'num_leaves': 1756} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.673326935589522, 'lambda_l2': 1.3678114370069063, 'learning_rate': 0.20142253843418664, 'max_depth': 94, 'min_data_in_leaf': 28, 'num_leaves': 1333} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.715253681860383, 'lambda_l2': 2.4112963532091087, 'learning_rate': 0.4211502367674022, 'max_depth': 74, 'min_data_in_leaf': 5, 'num_leaves': 613} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5868613013261307, 'lambda_l2': 4.035108548810584, 'learning_rate': 0.3326529437596693, 'max_depth': 99, 'min_data_in_leaf': 4, 'num_leaves': 368} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6224614335571741, 'lambda_l2': 3.3189546852077685, 'learning_rate': 0.8549814566031224, 'max_depth': 95, 'min_data_in_leaf': 3, 'num_leaves': 148} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6563191485240628, 'lambda_l2': 2.419606915461499, 'learning_rate': 0.7131240911063821, 'max_depth': 74, 'min_data_in_leaf': 78, 'num_leaves': 258} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8050027971865433, 'lambda_l2': 3.012774637554734, 'learning_rate': 0.39836389332849237, 'max_depth': 82, 'min_data_in_leaf': 45, 'num_leaves': 581} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4377233642731702, 'lambda_l2': 3.554795619220191, 'learning_rate': 0.5055642810688563, 'max_depth': 66, 'min_data_in_leaf': 1, 'num_leaves': 116} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6384144471055541, 'lambda_l2': 2.6432806264555504, 'learning_rate': 0.0010712480149777433, 'max_depth': 74, 'min_data_in_leaf': 6, 'num_leaves': 615} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7425475916507632, 'lambda_l2': 1.6582549496185381, 'learning_rate': 0.09269836495903669, 'max_depth': 33, 'min_data_in_leaf': 69, 'num_leaves': 1588} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7831673596656986, 'lambda_l2': 1.229759300467583, 'learning_rate': 0.13003990623812578, 'max_depth': 23, 'min_data_in_leaf': 20, 'num_leaves': 1849} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8506131287946072, 'lambda_l2': 0.7003064651745592, 'learning_rate': 0.2406101715967191, 'max_depth': 37, 'min_data_in_leaf': 52, 'num_leaves': 3331} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5151936136694371, 'lambda_l2': 3.1057297251414555, 'learning_rate': 0.014480777201420702, 'max_depth': 79, 'min_data_in_leaf': 7, 'num_leaves': 322} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.54510870498171, 'lambda_l2': 1.8250048147578786, 'learning_rate': 0.03587522616639825, 'max_depth': 75, 'min_data_in_leaf': 9, 'num_leaves': 458} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7131154037386426, 'lambda_l2': 1.8750048233279637, 'learning_rate': 0.1675766034342654, 'max_depth': 91, 'min_data_in_leaf': 3, 'num_leaves': 58} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6936343535372483, 'lambda_l2': 2.838733167689159, 'learning_rate': 0.6055664887292066, 'max_depth': 76, 'min_data_in_leaf': 5, 'num_leaves': 3836} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8163857528678142, 'lambda_l2': 3.412091272516993, 'learning_rate': 0.4458203979579191, 'max_depth': 100, 'min_data_in_leaf': 16, 'num_leaves': 853} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4828633195060902, 'lambda_l2': 2.1045574161513088, 'learning_rate': 0.2979693178150488, 'max_depth': 71, 'min_data_in_leaf': 48, 'num_leaves': 493} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7563727984333127, 'lambda_l2': 4.132503745551578, 'learning_rate': 0.7929174512988445, 'max_depth': 41, 'min_data_in_leaf': 24, 'num_leaves': 704} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6058078365407147, 'lambda_l2': 2.7628431297958094, 'learning_rate': 0.11726751842987922, 'max_depth': 69, 'min_data_in_leaf': 54, 'num_leaves': 220} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.668840458232786, 'lambda_l2': 2.3901738676371624, 'learning_rate': 0.9964150484421402, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 2033} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.879308673265302, 'lambda_l2': 2.2631399426563696, 'learning_rate': 0.4130965873065119, 'max_depth': 58, 'min_data_in_leaf': 21, 'num_leaves': 735} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5705579265248913, 'lambda_l2': 2.039606235680659, 'learning_rate': 0.04642536469085588, 'max_depth': 79, 'min_data_in_leaf': 64, 'num_leaves': 1130} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7161089818273206, 'lambda_l2': 4.465690540924766, 'learning_rate': 0.6769240981887766, 'max_depth': 87, 'min_data_in_leaf': 95, 'num_leaves': 2179} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6346833782682231, 'lambda_l2': 3.5983077774641345, 'learning_rate': 0.5445245270970105, 'max_depth': 68, 'min_data_in_leaf': 1, 'num_leaves': 3593} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5917878470797595, 'lambda_l2': 3.2099300966059876, 'learning_rate': 0.20684110985859958, 'max_depth': 75, 'min_data_in_leaf': 81, 'num_leaves': 2299} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.726479012760277, 'lambda_l2': 4.7328900090909105, 'learning_rate': 0.2573602442155268, 'max_depth': 85, 'min_data_in_leaf': 8, 'num_leaves': 306} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.925343339444468, 'lambda_l2': 1.069912904802976, 'learning_rate': 0.0029669210560161288, 'max_depth': 50, 'min_data_in_leaf': 12, 'num_leaves': 1224} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6785169490626216, 'lambda_l2': 4.842014321628023, 'learning_rate': 0.33820651737953883, 'max_depth': 66, 'min_data_in_leaf': 4, 'num_leaves': 2099} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7863016594737124, 'lambda_l2': 3.90066059379132, 'learning_rate': 0.025475967194752827, 'max_depth': 25, 'min_data_in_leaf': 14, 'num_leaves': 638} : acc= 58.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8469912065376314, 'lambda_l2': 2.9583282961070902, 'learning_rate': 0.8939124538325768, 'max_depth': 29, 'min_data_in_leaf': 18, 'num_leaves': 414} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7615881603113303, 'lambda_l2': 0.5884259062463708, 'learning_rate': 0.0746272187374542, 'max_depth': 39, 'min_data_in_leaf': 10, 'num_leaves': 1415} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9801706802046404, 'lambda_l2': 0.8449442933981091, 'learning_rate': 0.15081878131416118, 'max_depth': 32, 'min_data_in_leaf': 12, 'num_leaves': 1654} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8318035482117593, 'lambda_l2': 1.6188053702638254, 'learning_rate': 0.17669968161731986, 'max_depth': 55, 'min_data_in_leaf': 29, 'num_leaves': 1948} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7986285213822496, 'lambda_l2': 2.5463882010458363, 'learning_rate': 0.5594203996451994, 'max_depth': 36, 'min_data_in_leaf': 16, 'num_leaves': 822} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7026109204733789, 'lambda_l2': 2.2537564996573725, 'learning_rate': 0.0067096023735221935, 'max_depth': 77, 'min_data_in_leaf': 6, 'num_leaves': 2382} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9495694166390003, 'lambda_l2': 1.9754126082681827, 'learning_rate': 0.7306679614520565, 'max_depth': 63, 'min_data_in_leaf': 24, 'num_leaves': 909} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5363714414408205, 'lambda_l2': 1.5097297176585185, 'learning_rate': 0.29235570682184103, 'max_depth': 81, 'min_data_in_leaf': 3, 'num_leaves': 995} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8772485471835842, 'lambda_l2': 0.9738931781542994, 'learning_rate': 0.23641156333268556, 'max_depth': 20, 'min_data_in_leaf': 19, 'num_leaves': 1788} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9023436903726116, 'lambda_l2': 2.1658519261776785, 'learning_rate': 0.3685217572232706, 'max_depth': 44, 'min_data_in_leaf': 35, 'num_leaves': 778} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7411943678400882, 'lambda_l2': 0.39948428379052214, 'learning_rate': 0.47989561680476783, 'max_depth': 34, 'min_data_in_leaf': 22, 'num_leaves': 533} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8655919018428646, 'lambda_l2': 0.5875943775910367, 'learning_rate': 0.19675232941702409, 'max_depth': 27, 'min_data_in_leaf': 10, 'num_leaves': 1530} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6566495024606722, 'lambda_l2': 3.7769625261358426, 'learning_rate': 0.13182975900471808, 'max_depth': 83, 'min_data_in_leaf': 50, 'num_leaves': 953} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6287049471073461, 'lambda_l2': 1.4249730233738092, 'learning_rate': 0.00213166939711483, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 242} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8223631816337246, 'lambda_l2': 2.7027545953235492, 'learning_rate': 0.6236722746114058, 'max_depth': 49, 'min_data_in_leaf': 26, 'num_leaves': 2549} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6129266715662313, 'lambda_l2': 2.4869050005334943, 'learning_rate': 0.4341005278111165, 'max_depth': 70, 'min_data_in_leaf': 73, 'num_leaves': 3690} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9262069314048315, 'lambda_l2': 1.154410754180503, 'learning_rate': 0.01700062477611257, 'max_depth': 40, 'min_data_in_leaf': 31, 'num_leaves': 1374} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5124567834298902, 'lambda_l2': 3.6751340739216536, 'learning_rate': 0.1047995450900184, 'max_depth': 78, 'min_data_in_leaf': 38, 'num_leaves': 1072} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7695489187567426, 'lambda_l2': 3.2931970891889994, 'learning_rate': 0.8854272370830153, 'max_depth': 43, 'min_data_in_leaf': 42, 'num_leaves': 2257} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7982517295706208, 'lambda_l2': 2.819785606157427, 'learning_rate': 0.4959544365381903, 'max_depth': 52, 'min_data_in_leaf': 16, 'num_leaves': 621} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8869702171631219, 'lambda_l2': 1.3283361592553802, 'learning_rate': 0.3343140634924635, 'max_depth': 57, 'min_data_in_leaf': 8, 'num_leaves': 1711} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7321874111503736, 'lambda_l2': 0.8333039263349544, 'learning_rate': 0.05609836666789202, 'max_depth': 24, 'min_data_in_leaf': 12, 'num_leaves': 1323} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8427566211538868, 'lambda_l2': 0.4816555274744896, 'learning_rate': 0.06670859419893052, 'max_depth': 46, 'min_data_in_leaf': 14, 'num_leaves': 1867} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7678648821454981, 'lambda_l2': 0.6837516001726354, 'learning_rate': 0.7788705573424173, 'max_depth': 35, 'min_data_in_leaf': 19, 'num_leaves': 675} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6852530091928567, 'lambda_l2': 1.8356383802648946, 'learning_rate': 0.2723947859461206, 'max_depth': 89, 'min_data_in_leaf': 5, 'num_leaves': 2013} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.642631964776406, 'lambda_l2': 1.7482631012498477, 'learning_rate': 0.21881033966024815, 'max_depth': 76, 'min_data_in_leaf': 7, 'num_leaves': 1214} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5902951284202113, 'lambda_l2': 3.406924392453754, 'learning_rate': 0.42839090740938474, 'max_depth': 65, 'min_data_in_leaf': 2, 'num_leaves': 3277} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.39107320291770736, 'lambda_l2': 1.629174059104958, 'learning_rate': 0.36793470920225124, 'max_depth': 81, 'min_data_in_leaf': 45, 'num_leaves': 1155} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5593426002184118, 'lambda_l2': 1.9169158191452813, 'learning_rate': 0.560500236519185, 'max_depth': 72, 'min_data_in_leaf': 88, 'num_leaves': 3972} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9584285830857892, 'lambda_l2': 1.1057345646337575, 'learning_rate': 0.08441551423634767, 'max_depth': 60, 'min_data_in_leaf': 11, 'num_leaves': 1603} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.912952774506742, 'lambda_l2': 0.924532817953759, 'learning_rate': 0.2972930050963362, 'max_depth': 38, 'min_data_in_leaf': 9, 'num_leaves': 1924} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.979037280672552, 'lambda_l2': 0.2848565113749309, 'learning_rate': 0.0015582345356498794, 'max_depth': 29, 'min_data_in_leaf': 22, 'num_leaves': 1491} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8117893909589582, 'lambda_l2': 3.053387625159316, 'learning_rate': 0.9889645223916694, 'max_depth': 21, 'min_data_in_leaf': 15, 'num_leaves': 761} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7058047383130555, 'lambda_l2': 4.586419958383459, 'learning_rate': 0.23800254763661435, 'max_depth': 85, 'min_data_in_leaf': 4, 'num_leaves': 343} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4604054133576984, 'lambda_l2': 1.6859027135311693, 'learning_rate': 0.19874926747466662, 'max_depth': 67, 'min_data_in_leaf': 6, 'num_leaves': 932} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7885937552700276, 'lambda_l2': 3.489724375763842, 'learning_rate': 0.673611303895317, 'max_depth': 16, 'min_data_in_leaf': 28, 'num_leaves': 2517} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8615784822460076, 'lambda_l2': 2.0840282867095623, 'learning_rate': 0.3698167112872257, 'max_depth': 97, 'min_data_in_leaf': 17, 'num_leaves': 2337} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8339565888531821, 'lambda_l2': 0.3503250242793067, 'learning_rate': 0.4722502764318074, 'max_depth': 32, 'min_data_in_leaf': 14, 'num_leaves': 2751} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9331613678685969, 'lambda_l2': 0.7643865336093146, 'learning_rate': 0.17084576810442553, 'max_depth': 7, 'min_data_in_leaf': 62, 'num_leaves': 1763} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8922673817091635, 'lambda_l2': 3.996510500928743, 'learning_rate': 0.561491604652386, 'max_depth': 26, 'min_data_in_leaf': 20, 'num_leaves': 2187} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7543638643253556, 'lambda_l2': 1.0101333954405796, 'learning_rate': 0.32613488906422744, 'max_depth': 42, 'min_data_in_leaf': 10, 'num_leaves': 1263} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7769979364280386, 'lambda_l2': 1.2125699650557813, 'learning_rate': 0.13928109678323675, 'max_depth': 12, 'min_data_in_leaf': 23, 'num_leaves': 2122} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7236800142258146, 'lambda_l2': 0.5874923253808274, 'learning_rate': 0.613575561965341, 'max_depth': 55, 'min_data_in_leaf': 18, 'num_leaves': 68} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9996603124783732, 'lambda_l2': 0.8642922734498517, 'learning_rate': 0.0048987783127736936, 'max_depth': 31, 'min_data_in_leaf': 33, 'num_leaves': 1996} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8547099966292598, 'lambda_l2': 4.233912694917225, 'learning_rate': 0.4199612998173429, 'max_depth': 48, 'min_data_in_leaf': 12, 'num_leaves': 2440} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8106574372428419, 'lambda_l2': 2.595068889390781, 'learning_rate': 0.8063725123964867, 'max_depth': 18, 'min_data_in_leaf': 27, 'num_leaves': 2724} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6753217533503719, 'lambda_l2': 0.5055756244574204, 'learning_rate': 0.10895577134873718, 'max_depth': 10, 'min_data_in_leaf': 8, 'num_leaves': 1435} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4926024548913802, 'lambda_l2': 2.8811732384216717, 'learning_rate': 0.030620529211881516, 'max_depth': 62, 'min_data_in_leaf': 3, 'num_leaves': 3460} : acc= 60.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6167898125810755, 'lambda_l2': 1.5242882473861634, 'learning_rate': 0.1508056964150979, 'max_depth': 73, 'min_data_in_leaf': 5, 'num_leaves': 428} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6944894988223466, 'lambda_l2': 1.3877308133901847, 'learning_rate': 0.23949131202606502, 'max_depth': 92, 'min_data_in_leaf': 1, 'num_leaves': 3382} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5336927034527694, 'lambda_l2': 1.4353710881924204, 'learning_rate': 0.09398352957005925, 'max_depth': 77, 'min_data_in_leaf': 66, 'num_leaves': 864} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9068533596574203, 'lambda_l2': 2.3951075748859023, 'learning_rate': 0.7377361439884687, 'max_depth': 45, 'min_data_in_leaf': 13, 'num_leaves': 2267} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8312195984002795, 'lambda_l2': 0.39290481829922635, 'learning_rate': 0.5113810858825538, 'max_depth': 37, 'min_data_in_leaf': 10, 'num_leaves': 1032} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7374024816507194, 'lambda_l2': 0.6943215687553372, 'learning_rate': 0.2675401108941544, 'max_depth': 64, 'min_data_in_leaf': 7, 'num_leaves': 1833} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.722447075469556, 'lambda_l2': 1.1008304030867728, 'learning_rate': 0.38607502252696724, 'max_depth': 69, 'min_data_in_leaf': 3, 'num_leaves': 2056} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6618932218237072, 'lambda_l2': 0.9553565346367155, 'learning_rate': 0.32364127210201954, 'max_depth': 74, 'min_data_in_leaf': 7, 'num_leaves': 546} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6648282902213317, 'lambda_l2': 1.2692983776452482, 'learning_rate': 0.30739021428676677, 'max_depth': 71, 'min_data_in_leaf': 6, 'num_leaves': 224} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.653284060674841, 'lambda_l2': 1.0330888220588943, 'learning_rate': 0.2824233664763242, 'max_depth': 83, 'min_data_in_leaf': 2, 'num_leaves': 510} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7511617967630506, 'lambda_l2': 0.653517661905268, 'learning_rate': 0.4489810412705567, 'max_depth': 68, 'min_data_in_leaf': 1, 'num_leaves': 810} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.57897363230511, 'lambda_l2': 1.2256347603380657, 'learning_rate': 0.3342852730310053, 'max_depth': 74, 'min_data_in_leaf': 4, 'num_leaves': 402} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.639489073259475, 'lambda_l2': 0.897282056502456, 'learning_rate': 0.4020089794862384, 'max_depth': 77, 'min_data_in_leaf': 8, 'num_leaves': 124} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7151121257720614, 'lambda_l2': 0.7288805526539843, 'learning_rate': 0.21607024485555193, 'max_depth': 59, 'min_data_in_leaf': 9, 'num_leaves': 1106} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7774142935395283, 'lambda_l2': 0.5099470397948911, 'learning_rate': 0.3594530886750393, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 185} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7953488086516655, 'lambda_l2': 0.30668193693869594, 'learning_rate': 0.1867558903586333, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2349} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.699579931191633, 'lambda_l2': 0.514730248040702, 'learning_rate': 0.5083414157195462, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 177} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7559929090321434, 'lambda_l2': 0.1314387064408844, 'learning_rate': 0.26486483803492405, 'max_depth': 90, 'min_data_in_leaf': 5, 'num_leaves': 290} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7335221878416625, 'lambda_l2': 0.22594790309715274, 'learning_rate': 0.638723749977773, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 57} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7810142763343112, 'lambda_l2': 0.39657531684847414, 'learning_rate': 0.457471768469205, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 124} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6841521464413134, 'lambda_l2': 0.7846923695876024, 'learning_rate': 0.3547749997821707, 'max_depth': 94, 'min_data_in_leaf': 8, 'num_leaves': 581} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5976224604016035, 'lambda_l2': 0.6111685365327995, 'learning_rate': 0.25213501948871175, 'max_depth': 83, 'min_data_in_leaf': 6, 'num_leaves': 363} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6592452343583931, 'lambda_l2': 0.9881802741045356, 'learning_rate': 0.18698055523020543, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 483} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7701046162869003, 'lambda_l2': 0.4940481012898096, 'learning_rate': 0.39709839715022194, 'max_depth': 80, 'min_data_in_leaf': 1, 'num_leaves': 158} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8737841856277118, 'lambda_l2': 0.4124854702589449, 'learning_rate': 0.5713216925351743, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 680} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.629163140139395, 'lambda_l2': 0.9175696757852244, 'learning_rate': 0.3011040950688703, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 253} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.569219177379765, 'lambda_l2': 0.8014658804449757, 'learning_rate': 0.22568259353265813, 'max_depth': 71, 'min_data_in_leaf': 7, 'num_leaves': 61} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6716108030553383, 'lambda_l2': 1.1688704503537048, 'learning_rate': 0.16191786549369797, 'max_depth': 73, 'min_data_in_leaf': 10, 'num_leaves': 347} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7444624295195913, 'lambda_l2': 0.6416054913574176, 'learning_rate': 0.32730730528499935, 'max_depth': 86, 'min_data_in_leaf': 9, 'num_leaves': 2177} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6937326456493227, 'lambda_l2': 0.21853565996554836, 'learning_rate': 0.3680150139719604, 'max_depth': 89, 'min_data_in_leaf': 4, 'num_leaves': 225} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8147350919983978, 'lambda_l2': 0.2880447611610825, 'learning_rate': 0.7236082694331376, 'max_depth': 40, 'min_data_in_leaf': 21, 'num_leaves': 428} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.703330877883695, 'lambda_l2': 0.8035266447011202, 'learning_rate': 0.5058326584979742, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 532} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7960217925044601, 'lambda_l2': 1.3197977547704254, 'learning_rate': 0.24560756188938085, 'max_depth': 75, 'min_data_in_leaf': 12, 'num_leaves': 611} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8543269810154108, 'lambda_l2': 0.5820343613410909, 'learning_rate': 0.2123645302176101, 'max_depth': 50, 'min_data_in_leaf': 25, 'num_leaves': 2642} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7171623661095301, 'lambda_l2': 1.0943534807297106, 'learning_rate': 0.12277776538978288, 'max_depth': 79, 'min_data_in_leaf': 5, 'num_leaves': 771} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6110901269658339, 'lambda_l2': 1.5813817474348906, 'learning_rate': 0.27956428211903744, 'max_depth': 83, 'min_data_in_leaf': 1, 'num_leaves': 303} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8447210640303124, 'lambda_l2': 0.47713640389535156, 'learning_rate': 0.13645691548308905, 'max_depth': 92, 'min_data_in_leaf': 17, 'num_leaves': 786} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8265158020068687, 'lambda_l2': 0.6998751346210257, 'learning_rate': 0.883282993660113, 'max_depth': 100, 'min_data_in_leaf': 15, 'num_leaves': 2541} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7205898102312306, 'lambda_l2': 1.1793659649913024, 'learning_rate': 0.11562496082837777, 'max_depth': 79, 'min_data_in_leaf': 6, 'num_leaves': 876} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5575394107180631, 'lambda_l2': 0.8911576352438875, 'learning_rate': 0.18689161260866727, 'max_depth': 70, 'min_data_in_leaf': 3, 'num_leaves': 410} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6402141887648369, 'lambda_l2': 0.9475134557205586, 'learning_rate': 0.3199047753692345, 'max_depth': 73, 'min_data_in_leaf': 1, 'num_leaves': 203} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5882698296171845, 'lambda_l2': 1.040534120247271, 'learning_rate': 0.1617046902488554, 'max_depth': 77, 'min_data_in_leaf': 8, 'num_leaves': 69} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.766304191863879, 'lambda_l2': 0.03659255100899328, 'learning_rate': 0.6136156580788712, 'max_depth': 67, 'min_data_in_leaf': 1, 'num_leaves': 2442} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7476588367022639, 'lambda_l2': 0.10507313155889764, 'learning_rate': 0.019877639375587695, 'max_depth': 84, 'min_data_in_leaf': 5, 'num_leaves': 689} : acc= 58.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.680500711768478, 'lambda_l2': 1.3083762691472196, 'learning_rate': 0.04465402746009319, 'max_depth': 81, 'min_data_in_leaf': 2, 'num_leaves': 715} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.711070243000381, 'lambda_l2': 1.47312806270461, 'learning_rate': 0.0761936241051162, 'max_depth': 91, 'min_data_in_leaf': 4, 'num_leaves': 465} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6518292177745073, 'lambda_l2': 1.4131275172022157, 'learning_rate': 0.12724474644875808, 'max_depth': 79, 'min_data_in_leaf': 7, 'num_leaves': 345} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8864275193475499, 'lambda_l2': 0.31423761380951637, 'learning_rate': 0.48846250869684255, 'max_depth': 6, 'min_data_in_leaf': 23, 'num_leaves': 2491} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7282661493761615, 'lambda_l2': 1.2479862229783867, 'learning_rate': 0.09501229764552145, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 522} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9478649774520767, 'lambda_l2': 0.5826448660534075, 'learning_rate': 0.3832060515310203, 'max_depth': 34, 'min_data_in_leaf': 19, 'num_leaves': 1911} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.781297264245419, 'lambda_l2': 1.1066972293749764, 'learning_rate': 0.20899281802556074, 'max_depth': 87, 'min_data_in_leaf': 10, 'num_leaves': 1181} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6199839539635252, 'lambda_l2': 0.7310999760285399, 'learning_rate': 0.9911069863432413, 'max_depth': 65, 'min_data_in_leaf': 13, 'num_leaves': 3729} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8684142879673342, 'lambda_l2': 0.38204464214954914, 'learning_rate': 0.6994403693889073, 'max_depth': 52, 'min_data_in_leaf': 17, 'num_leaves': 2240} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7981286896920616, 'lambda_l2': 0.0007107821337608566, 'learning_rate': 0.11894970848588965, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2082} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.660019280769404, 'lambda_l2': 1.0735652318771418, 'learning_rate': 0.18090471415188136, 'max_depth': 85, 'min_data_in_leaf': 3, 'num_leaves': 55} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5984195221449882, 'lambda_l2': 0.4970878835911858, 'learning_rate': 0.2972551337237322, 'max_depth': 75, 'min_data_in_leaf': 7, 'num_leaves': 2966} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6173584173088349, 'lambda_l2': 1.5581440414938275, 'learning_rate': 0.13819688275214204, 'max_depth': 90, 'min_data_in_leaf': 4, 'num_leaves': 578} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7653526333093765, 'lambda_l2': 0.8182927143601577, 'learning_rate': 0.0631146478884627, 'max_depth': 94, 'min_data_in_leaf': 37, 'num_leaves': 1077} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6845805748328982, 'lambda_l2': 0.9885380003003816, 'learning_rate': 0.16427664591617652, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 951} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.9096955113249244, 'lambda_l2': 0.17275866077086555, 'learning_rate': 0.45304153025946664, 'max_depth': 42, 'min_data_in_leaf': 30, 'num_leaves': 1965} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7022289196131569, 'lambda_l2': 1.7560217319719458, 'learning_rate': 0.051343589313390225, 'max_depth': 70, 'min_data_in_leaf': 6, 'num_leaves': 609} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8149331413552354, 'lambda_l2': 0.43532486947097115, 'learning_rate': 0.4280276928107112, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 889} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6863332846479124, 'lambda_l2': 1.358013302583206, 'learning_rate': 0.08474450503256795, 'max_depth': 96, 'min_data_in_leaf': 5, 'num_leaves': 735} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9247449519935751, 'lambda_l2': 0.661052703910071, 'learning_rate': 0.2604002245577704, 'max_depth': 8, 'min_data_in_leaf': 21, 'num_leaves': 993} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.743484231636369, 'lambda_l2': 0.8712279891165752, 'learning_rate': 0.21237712852970175, 'max_depth': 79, 'min_data_in_leaf': 11, 'num_leaves': 781} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7785888485936177, 'lambda_l2': 2.1786171779455716, 'learning_rate': 0.39314136687074175, 'max_depth': 63, 'min_data_in_leaf': 41, 'num_leaves': 1314} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.804072644758525, 'lambda_l2': 1.969992162115008, 'learning_rate': 0.5495110948835871, 'max_depth': 85, 'min_data_in_leaf': 9, 'num_leaves': 700} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6419196425179128, 'lambda_l2': 0.5879529082106366, 'learning_rate': 0.23082676770579105, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 1741} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8314556652077842, 'lambda_l2': 2.301403064418041, 'learning_rate': 0.3608746567960503, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 1038} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5030820274802772, 'lambda_l2': 0.9824670837847963, 'learning_rate': 0.16115417476948893, 'max_depth': 82, 'min_data_in_leaf': 3, 'num_leaves': 968} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5727903042371219, 'lambda_l2': 0.7361057725641423, 'learning_rate': 0.32960541666234294, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2783} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.588509358976095, 'lambda_l2': 0.2668528175740503, 'learning_rate': 0.5963701694590301, 'max_depth': 75, 'min_data_in_leaf': 12, 'num_leaves': 3884} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5422470655561812, 'lambda_l2': 0.7261122175220749, 'learning_rate': 0.28058637914065737, 'max_depth': 98, 'min_data_in_leaf': 19, 'num_leaves': 3557} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5227866060153488, 'lambda_l2': 0.1794143073360457, 'learning_rate': 0.6720626484348333, 'max_depth': 83, 'min_data_in_leaf': 16, 'num_leaves': 2804} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4527446613747059, 'lambda_l2': 0.5561011970352365, 'learning_rate': 0.311501616368517, 'max_depth': 76, 'min_data_in_leaf': 8, 'num_leaves': 2374} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4314573401562791, 'lambda_l2': 0.4000071784690357, 'learning_rate': 0.8439493210700273, 'max_depth': 45, 'min_data_in_leaf': 25, 'num_leaves': 2653} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.47903381192944594, 'lambda_l2': 0.3185627656383027, 'learning_rate': 0.1797083365542739, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 265} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3951867622377178, 'lambda_l2': 0.05976558720534608, 'learning_rate': 0.14751447037282764, 'max_depth': 94, 'min_data_in_leaf': 12, 'num_leaves': 124} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.46576591647183996, 'lambda_l2': 0.15676637703732377, 'learning_rate': 0.2470913483942073, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 179} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.42379070879276304, 'lambda_l2': 0.3068019970137787, 'learning_rate': 0.1899149795711678, 'max_depth': 99, 'min_data_in_leaf': 9, 'num_leaves': 3172} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5019839375452918, 'lambda_l2': 0.013287000087680079, 'learning_rate': 0.48520539118212835, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 263} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.33034802608468933, 'lambda_l2': 0.22129786251640882, 'learning_rate': 0.5561231381751474, 'max_depth': 99, 'min_data_in_leaf': 19, 'num_leaves': 2998} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4846994925486976, 'lambda_l2': 0.32962532284561596, 'learning_rate': 0.21992683813760988, 'max_depth': 96, 'min_data_in_leaf': 17, 'num_leaves': 3323} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4047586302413958, 'lambda_l2': 0.47687161474912165, 'learning_rate': 0.3398204718482607, 'max_depth': 91, 'min_data_in_leaf': 13, 'num_leaves': 248} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.44111620269961377, 'lambda_l2': 0.1598509903330424, 'learning_rate': 0.10606423215666058, 'max_depth': 88, 'min_data_in_leaf': 10, 'num_leaves': 369} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3832646313435553, 'lambda_l2': 0.5369215970812925, 'learning_rate': 0.26190028288862693, 'max_depth': 94, 'min_data_in_leaf': 15, 'num_leaves': 131} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3605727129273013, 'lambda_l2': 0.01250632869020507, 'learning_rate': 0.010234452459778392, 'max_depth': 96, 'min_data_in_leaf': 7, 'num_leaves': 3607} : acc= 49.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4439225769031926, 'lambda_l2': 0.34545386260328836, 'learning_rate': 0.35302774870610404, 'max_depth': 91, 'min_data_in_leaf': 23, 'num_leaves': 2575} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5336739950130529, 'lambda_l2': 0.7605816042502367, 'learning_rate': 0.17640361526584114, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 290} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4770948798923363, 'lambda_l2': 0.6503674431341524, 'learning_rate': 0.2818433460088881, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 2866} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5719973605596266, 'lambda_l2': 0.08420966629340476, 'learning_rate': 0.1097446174555702, 'max_depth': 88, 'min_data_in_leaf': 3, 'num_leaves': 2749} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5083983937626659, 'lambda_l2': 0.4509750217551328, 'learning_rate': 0.24107572806232752, 'max_depth': 84, 'min_data_in_leaf': 12, 'num_leaves': 466} : acc= 73.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.470879182749135, 'lambda_l2': 0.0009892527418488561, 'learning_rate': 0.14746940591575453, 'max_depth': 98, 'min_data_in_leaf': 19, 'num_leaves': 3040} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5118163970983983, 'lambda_l2': 0.0007570151902915878, 'learning_rate': 0.20368573194795117, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 93} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3473377658263288, 'lambda_l2': 0.43033117898540363, 'learning_rate': 0.14342011151440293, 'max_depth': 95, 'min_data_in_leaf': 21, 'num_leaves': 191} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.31104926403080096, 'lambda_l2': 0.19168123526210043, 'learning_rate': 0.08963426537872554, 'max_depth': 100, 'min_data_in_leaf': 15, 'num_leaves': 2902} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.24198871658891652, 'lambda_l2': 0.29233305318079017, 'learning_rate': 0.033957628105331324, 'max_depth': 95, 'min_data_in_leaf': 22, 'num_leaves': 60} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.42775689576904163, 'lambda_l2': 0.1292075905415011, 'learning_rate': 0.23488699635197854, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 496} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.38139456870254695, 'lambda_l2': 0.4927918640891402, 'learning_rate': 0.178854300445745, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 2490} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4066568160905484, 'lambda_l2': 0.41288756241600677, 'learning_rate': 0.06762044300733362, 'max_depth': 91, 'min_data_in_leaf': 21, 'num_leaves': 195} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.35220593863561855, 'lambda_l2': 0.2892077529838273, 'learning_rate': 0.055759718491612424, 'max_depth': 98, 'min_data_in_leaf': 26, 'num_leaves': 401} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4160482746636313, 'lambda_l2': 0.08987807685332716, 'learning_rate': 0.09578911680060304, 'max_depth': 100, 'min_data_in_leaf': 24, 'num_leaves': 339} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.49841646834987713, 'lambda_l2': 0.5540223008504872, 'learning_rate': 0.12933446058927922, 'max_depth': 85, 'min_data_in_leaf': 11, 'num_leaves': 2829} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4855944023853264, 'lambda_l2': 0.2473721646650369, 'learning_rate': 0.21149366971714553, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2259} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.20563403431817295, 'lambda_l2': 0.0012048811979563645, 'learning_rate': 0.07145757507467568, 'max_depth': 95, 'min_data_in_leaf': 29, 'num_leaves': 2399} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.44268240999100017, 'lambda_l2': 0.41878781326415865, 'learning_rate': 0.14381263662288646, 'max_depth': 97, 'min_data_in_leaf': 21, 'num_leaves': 2737} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.3304376610582432, 'lambda_l2': 0.659851260242243, 'learning_rate': 0.10962066418606473, 'max_depth': 99, 'min_data_in_leaf': 14, 'num_leaves': 2593} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2792419427063249, 'lambda_l2': 0.3740187784699616, 'learning_rate': 0.07707313951849533, 'max_depth': 93, 'min_data_in_leaf': 18, 'num_leaves': 448} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5531921544476306, 'lambda_l2': 0.8086965165340794, 'learning_rate': 0.41460685987251905, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 280} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5302270828744514, 'lambda_l2': 0.2328649657533448, 'learning_rate': 0.2520709864337449, 'max_depth': 87, 'min_data_in_leaf': 12, 'num_leaves': 2343} : acc= 74.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4576697186809571, 'lambda_l2': 0.12107439716921742, 'learning_rate': 0.16607863660656924, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 2212} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5237414997849289, 'lambda_l2': 0.2676316503894031, 'learning_rate': 0.12176329571608778, 'max_depth': 92, 'min_data_in_leaf': 91, 'num_leaves': 2328} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.47861779930643167, 'lambda_l2': 0.1750959740249291, 'learning_rate': 0.04180425280561597, 'max_depth': 86, 'min_data_in_leaf': 9, 'num_leaves': 2464} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5448695287586437, 'lambda_l2': 0.09155960483756623, 'learning_rate': 0.1901133456792783, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2114} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5008969013493655, 'lambda_l2': 0.01445115041352929, 'learning_rate': 0.23675441358726418, 'max_depth': 82, 'min_data_in_leaf': 6, 'num_leaves': 2326} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5213212361030488, 'lambda_l2': 0.6392785092854998, 'learning_rate': 0.2928676472977751, 'max_depth': 88, 'min_data_in_leaf': 16, 'num_leaves': 2529} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.45100601564497544, 'lambda_l2': 0.26643540086148343, 'learning_rate': 0.2587486722941889, 'max_depth': 96, 'min_data_in_leaf': 24, 'num_leaves': 2643} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.37740507731660106, 'lambda_l2': 0.0005309551721603967, 'learning_rate': 0.10198722740148228, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2255} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4154740461374823, 'lambda_l2': 0.341639305360413, 'learning_rate': 0.17645981564493968, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 2395} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5580465375438997, 'lambda_l2': 0.4807746733593926, 'learning_rate': 0.15652460747231772, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 3138} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5136434705866164, 'lambda_l2': 0.5573839734300855, 'learning_rate': 0.19958746534769886, 'max_depth': 89, 'min_data_in_leaf': 6, 'num_leaves': 2173} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5458121601853297, 'lambda_l2': 0.7408821970857303, 'learning_rate': 0.08676984898291926, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 2923} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4715992666290194, 'lambda_l2': 0.19486744242959744, 'learning_rate': 0.12610741372257858, 'max_depth': 78, 'min_data_in_leaf': 18, 'num_leaves': 2047} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4953836231006053, 'lambda_l2': 0.8717842846251123, 'learning_rate': 0.2293558102362576, 'max_depth': 87, 'min_data_in_leaf': 27, 'num_leaves': 2592} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.36632075686840404, 'lambda_l2': 0.6472352799664302, 'learning_rate': 0.29423326178902165, 'max_depth': 90, 'min_data_in_leaf': 15, 'num_leaves': 2706} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5677506631500947, 'lambda_l2': 0.35715417304613883, 'learning_rate': 0.023858964635943267, 'max_depth': 95, 'min_data_in_leaf': 13, 'num_leaves': 2449} : acc= 57.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.433233367402618, 'lambda_l2': 0.11404497115047951, 'learning_rate': 0.24772792179732983, 'max_depth': 97, 'min_data_in_leaf': 5, 'num_leaves': 2333} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5233556397560869, 'lambda_l2': 0.7378828859624454, 'learning_rate': 0.38751898539913243, 'max_depth': 80, 'min_data_in_leaf': 3, 'num_leaves': 2146} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4553949881637844, 'lambda_l2': 0.4895569959228625, 'learning_rate': 0.32698290840318806, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 2525} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5332264648655219, 'lambda_l2': 0.569546358564389, 'learning_rate': 0.4641846285327446, 'max_depth': 1, 'min_data_in_leaf': 20, 'num_leaves': 2827} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4870272379754171, 'lambda_l2': 0.22430948488657831, 'learning_rate': 0.15674515121494528, 'max_depth': 85, 'min_data_in_leaf': 23, 'num_leaves': 3074} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5662513087636976, 'lambda_l2': 0.0020608364734004403, 'learning_rate': 0.21058021165958166, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 2666} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.38835505393217973, 'lambda_l2': 0.37825583339813085, 'learning_rate': 0.2724657073077891, 'max_depth': 100, 'min_data_in_leaf': 17, 'num_leaves': 1996} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4180896818033723, 'lambda_l2': 0.8647929433503957, 'learning_rate': 0.13595245484492366, 'max_depth': 90, 'min_data_in_leaf': 13, 'num_leaves': 2770} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5823309789755173, 'lambda_l2': 0.4511106093681412, 'learning_rate': 0.19002253194226798, 'max_depth': 77, 'min_data_in_leaf': 32, 'num_leaves': 2081} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4634072023575345, 'lambda_l2': 0.6641788895658778, 'learning_rate': 0.5214575891630204, 'max_depth': 100, 'min_data_in_leaf': 85, 'num_leaves': 2975} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5119718557629283, 'lambda_l2': 0.21750451259437814, 'learning_rate': 0.347577192829076, 'max_depth': 81, 'min_data_in_leaf': 4, 'num_leaves': 2289} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.399433201703621, 'lambda_l2': 0.7723496588687253, 'learning_rate': 0.4148434246923844, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 2208} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5414165947330295, 'lambda_l2': 0.09145069639096368, 'learning_rate': 0.11486554210358653, 'max_depth': 98, 'min_data_in_leaf': 15, 'num_leaves': 2407} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6005634420650607, 'lambda_l2': 0.5725336232582163, 'learning_rate': 0.012933547719887976, 'max_depth': 95, 'min_data_in_leaf': 8, 'num_leaves': 1900} : acc= 52.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5013405451954582, 'lambda_l2': 0.3112968547210696, 'learning_rate': 0.28126254991018457, 'max_depth': 4, 'min_data_in_leaf': 71, 'num_leaves': 2568} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4872005476927976, 'lambda_l2': 0.007522730083007273, 'learning_rate': 0.16872648449865435, 'max_depth': 72, 'min_data_in_leaf': 6, 'num_leaves': 2699} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5709176321716503, 'lambda_l2': 0.44595084100755833, 'learning_rate': 0.028609875636714723, 'max_depth': 83, 'min_data_in_leaf': 22, 'num_leaves': 3223} : acc= 60.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5483473075885852, 'lambda_l2': 0.8951925014358162, 'learning_rate': 0.23343607217359558, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 2884} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.44084959367630794, 'lambda_l2': 0.7276663662019773, 'learning_rate': 0.32530341068025515, 'max_depth': 78, 'min_data_in_leaf': 25, 'num_leaves': 1825} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4701375184027403, 'lambda_l2': 0.20610377915859637, 'learning_rate': 0.09539356239862883, 'max_depth': 87, 'min_data_in_leaf': 18, 'num_leaves': 2126} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.533263057056624, 'lambda_l2': 0.6015393326275081, 'learning_rate': 0.6296505841756935, 'max_depth': 80, 'min_data_in_leaf': 9, 'num_leaves': 2416} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5988796233008001, 'lambda_l2': 0.35420742802002114, 'learning_rate': 0.49360772781957574, 'max_depth': 91, 'min_data_in_leaf': 3, 'num_leaves': 2513} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.36465696509912493, 'lambda_l2': 0.8223097048061871, 'learning_rate': 0.2041882476021608, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2809} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5773629533547956, 'lambda_l2': 0.11515887949651998, 'learning_rate': 0.06183327254598278, 'max_depth': 97, 'min_data_in_leaf': 16, 'num_leaves': 2004} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4285594830749817, 'lambda_l2': 1.1482559216677148, 'learning_rate': 0.7864844680609427, 'max_depth': 88, 'min_data_in_leaf': 14, 'num_leaves': 2274} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5208562261707395, 'lambda_l2': 0.2733810049572912, 'learning_rate': 0.14655773843407632, 'max_depth': 90, 'min_data_in_leaf': 6, 'num_leaves': 2628} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6099830663172421, 'lambda_l2': 0.9740994042291024, 'learning_rate': 0.4081465176734885, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 2319} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.40700883800733045, 'lambda_l2': 0.4710278414433943, 'learning_rate': 0.26807228168935665, 'max_depth': 85, 'min_data_in_leaf': 28, 'num_leaves': 2225} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5501601881121959, 'lambda_l2': 0.6051012663270774, 'learning_rate': 0.07735272186727023, 'max_depth': 1, 'min_data_in_leaf': 10, 'num_leaves': 1951} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4939556326084263, 'lambda_l2': 0.7174607826925075, 'learning_rate': 0.3244245946970813, 'max_depth': 77, 'min_data_in_leaf': 1, 'num_leaves': 2444} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.34417926959586326, 'lambda_l2': 0.3866043598229688, 'learning_rate': 0.4473912895005074, 'max_depth': 5, 'min_data_in_leaf': 5, 'num_leaves': 3015} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5807893066927711, 'lambda_l2': 0.13081317451218794, 'learning_rate': 0.17798780356850635, 'max_depth': 14, 'min_data_in_leaf': 79, 'num_leaves': 2051} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4724359707725618, 'lambda_l2': 0.899781928420649, 'learning_rate': 0.9921904328594566, 'max_depth': 94, 'min_data_in_leaf': 8, 'num_leaves': 2152} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.31503641179273134, 'lambda_l2': 0.546511519429246, 'learning_rate': 0.23547879867577007, 'max_depth': 72, 'min_data_in_leaf': 3, 'num_leaves': 2712} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.45746528930029995, 'lambda_l2': 0.8216999404004396, 'learning_rate': 0.10399716367109624, 'max_depth': 96, 'min_data_in_leaf': 12, 'num_leaves': 2552} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5099450082949943, 'lambda_l2': 1.0602945746718135, 'learning_rate': 0.5475642524488729, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 1875} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6247688899417485, 'lambda_l2': 0.24672126466141786, 'learning_rate': 0.3652651270151288, 'max_depth': 92, 'min_data_in_leaf': 14, 'num_leaves': 3093} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5348021666482539, 'lambda_l2': 0.6611194791879105, 'learning_rate': 0.12609179150977592, 'max_depth': 84, 'min_data_in_leaf': 30, 'num_leaves': 2942} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5622863844922108, 'lambda_l2': 0.009359224601496352, 'learning_rate': 0.2089798969112248, 'max_depth': 11, 'min_data_in_leaf': 76, 'num_leaves': 2392} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4337538899007837, 'lambda_l2': 0.43730325719536006, 'learning_rate': 0.6983990595060653, 'max_depth': 100, 'min_data_in_leaf': 22, 'num_leaves': 2775} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5893639427913993, 'lambda_l2': 0.34725308920535675, 'learning_rate': 0.30132243354750626, 'max_depth': 87, 'min_data_in_leaf': 9, 'num_leaves': 2345} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.47682486855439554, 'lambda_l2': 0.09423342590464179, 'learning_rate': 0.2601266699224226, 'max_depth': 69, 'min_data_in_leaf': 26, 'num_leaves': 1654} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6175605332808003, 'lambda_l2': 0.9437755202273761, 'learning_rate': 0.038565535129433316, 'max_depth': 79, 'min_data_in_leaf': 4, 'num_leaves': 2505} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5082861487477652, 'lambda_l2': 0.7806915436167714, 'learning_rate': 0.1577945749294676, 'max_depth': 8, 'min_data_in_leaf': 1, 'num_leaves': 1792} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.2982392944696919, 'lambda_l2': 0.5154670282030067, 'learning_rate': 0.05240863974677831, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2207} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.390088711133299, 'lambda_l2': 1.162970614709106, 'learning_rate': 0.4614428134000418, 'max_depth': 73, 'min_data_in_leaf': 7, 'num_leaves': 2585} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.45607991499046036, 'lambda_l2': 0.21620004270044058, 'learning_rate': 0.5843917896797782, 'max_depth': 93, 'min_data_in_leaf': 20, 'num_leaves': 2104} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5963822264481567, 'lambda_l2': 0.6713350724349554, 'learning_rate': 0.37781698947573894, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 2675} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5637643461778119, 'lambda_l2': 1.022081789442696, 'learning_rate': 0.223206428337576, 'max_depth': 84, 'min_data_in_leaf': 24, 'num_leaves': 1994} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5331532569970696, 'lambda_l2': 0.36467494799336053, 'learning_rate': 0.17592875745374936, 'max_depth': 98, 'min_data_in_leaf': 5, 'num_leaves': 2827} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4137025141001707, 'lambda_l2': 0.010354799469878717, 'learning_rate': 0.12134994631240378, 'max_depth': 3, 'min_data_in_leaf': 35, 'num_leaves': 2448} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5567377368787294, 'lambda_l2': 0.8563703329613372, 'learning_rate': 0.1404237731465341, 'max_depth': 86, 'min_data_in_leaf': 10, 'num_leaves': 2898} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6338917885764355, 'lambda_l2': 0.5435047138972563, 'learning_rate': 0.009082672575371972, 'max_depth': 90, 'min_data_in_leaf': 13, 'num_leaves': 2320} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.49239953329334113, 'lambda_l2': 0.004626486572948507, 'learning_rate': 0.7928400978350332, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 1718} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.44707387549733935, 'lambda_l2': 0.29355976364084446, 'learning_rate': 0.291472235718107, 'max_depth': 10, 'min_data_in_leaf': 99, 'num_leaves': 2155} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.604980577488856, 'lambda_l2': 0.1667246623815848, 'learning_rate': 0.08248654363265058, 'max_depth': 66, 'min_data_in_leaf': 17, 'num_leaves': 1906} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.521612519292037, 'lambda_l2': 0.7684411448701391, 'learning_rate': 0.004026042210242185, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2646} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5834745688227184, 'lambda_l2': 0.629409747067617, 'learning_rate': 0.19358889690487457, 'max_depth': 95, 'min_data_in_leaf': 4, 'num_leaves': 3185} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3607082168373963, 'lambda_l2': 1.1938895883704523, 'learning_rate': 0.6655103661695928, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 2246} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3730170587393451, 'lambda_l2': 0.4333389286190049, 'learning_rate': 0.5036025137132945, 'max_depth': 100, 'min_data_in_leaf': 14, 'num_leaves': 2378} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.48164589505379657, 'lambda_l2': 1.2706151109585109, 'learning_rate': 0.33738040755857934, 'max_depth': 6, 'min_data_in_leaf': 59, 'num_leaves': 2482} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.547413245550537, 'lambda_l2': 1.0940414817048993, 'learning_rate': 0.3783636441842863, 'max_depth': 16, 'min_data_in_leaf': 9, 'num_leaves': 2045} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5038998903952925, 'lambda_l2': 0.8987889304945301, 'learning_rate': 0.2549604531545516, 'max_depth': 80, 'min_data_in_leaf': 3, 'num_leaves': 2754} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.632202140438203, 'lambda_l2': 0.5171931946609237, 'learning_rate': 0.09967454177555142, 'max_depth': 97, 'min_data_in_leaf': 20, 'num_leaves': 3078} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4259345298693874, 'lambda_l2': 0.09689933098386197, 'learning_rate': 0.41840417217895376, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 1844} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6092893789110517, 'lambda_l2': 0.22449045145815646, 'learning_rate': 0.5442765917915079, 'max_depth': 13, 'min_data_in_leaf': 23, 'num_leaves': 2956} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5738580853479166, 'lambda_l2': 0.706610458444479, 'learning_rate': 0.22231137469583484, 'max_depth': 71, 'min_data_in_leaf': 94, 'num_leaves': 1950} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5328751988686198, 'lambda_l2': 0.34130778101742476, 'learning_rate': 0.30704796108743626, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 3269} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6433851801151729, 'lambda_l2': 0.9586653353068448, 'learning_rate': 0.015926179611867663, 'max_depth': 76, 'min_data_in_leaf': 18, 'num_leaves': 2613} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.47869410900286113, 'lambda_l2': 0.5816178894533749, 'learning_rate': 0.17053897211206354, 'max_depth': 83, 'min_data_in_leaf': 1, 'num_leaves': 1611} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4461000447827115, 'lambda_l2': 0.43768246620186035, 'learning_rate': 0.612670565967812, 'max_depth': 68, 'min_data_in_leaf': 11, 'num_leaves': 2216} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.33481039017584957, 'lambda_l2': 0.0020087016055450324, 'learning_rate': 0.9103786241249133, 'max_depth': 9, 'min_data_in_leaf': 6, 'num_leaves': 2109} : acc= 50.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6205026406491801, 'lambda_l2': 0.7608719574567888, 'learning_rate': 0.1411390419593313, 'max_depth': 91, 'min_data_in_leaf': 27, 'num_leaves': 2529} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5160217546701467, 'lambda_l2': 1.0506323081512794, 'learning_rate': 0.45420322116845613, 'max_depth': 94, 'min_data_in_leaf': 16, 'num_leaves': 2372} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.40561260900860124, 'lambda_l2': 0.28537749584610356, 'learning_rate': 0.26573763617429524, 'max_depth': 4, 'min_data_in_leaf': 9, 'num_leaves': 2823} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5716425157746134, 'lambda_l2': 0.16835114096692916, 'learning_rate': 0.06984647017303051, 'max_depth': 74, 'min_data_in_leaf': 32, 'num_leaves': 1764} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5588228697522054, 'lambda_l2': 0.6238287990206319, 'learning_rate': 0.34756851718611964, 'max_depth': 81, 'min_data_in_leaf': 2, 'num_leaves': 2256} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.38376510277727105, 'lambda_l2': 1.2654191155256518, 'learning_rate': 0.1907900517921779, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2030} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.45916659041055047, 'lambda_l2': 0.8606031364795721, 'learning_rate': 0.11612518669850978, 'max_depth': 2, 'min_data_in_leaf': 4, 'num_leaves': 2668} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5871715739840272, 'lambda_l2': 0.4932690031004676, 'learning_rate': 0.7301523178044725, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 1549} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6479178922113897, 'lambda_l2': 0.09114835482137473, 'learning_rate': 0.23844866364438919, 'max_depth': 78, 'min_data_in_leaf': 22, 'num_leaves': 2308} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5433757929514571, 'lambda_l2': 1.1279613939451467, 'learning_rate': 0.41441092563976456, 'max_depth': 100, 'min_data_in_leaf': 8, 'num_leaves': 2726} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4921807922499974, 'lambda_l2': 0.38433514486986087, 'learning_rate': 0.1503081503329013, 'max_depth': 1, 'min_data_in_leaf': 6, 'num_leaves': 2535} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5239102884363439, 'lambda_l2': 0.7025304905437845, 'learning_rate': 0.08611538131188616, 'max_depth': 62, 'min_data_in_leaf': 11, 'num_leaves': 2164} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6034434590696091, 'lambda_l2': 0.8118504513413481, 'learning_rate': 0.49389139627004364, 'max_depth': 95, 'min_data_in_leaf': 29, 'num_leaves': 3014} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6307324314723323, 'lambda_l2': 0.278446258082286, 'learning_rate': 0.04668856208540774, 'max_depth': 89, 'min_data_in_leaf': 55, 'num_leaves': 2881} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4664706829261528, 'lambda_l2': 0.9886762466897807, 'learning_rate': 0.31129325161254157, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 2443} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.42232673252274483, 'lambda_l2': 0.3098053462562422, 'learning_rate': 0.2578098813569578, 'max_depth': 4, 'min_data_in_leaf': 10, 'num_leaves': 3144} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.298755008195936, 'lambda_l2': 0.20039033055681432, 'learning_rate': 0.2654195983529824, 'max_depth': 7, 'min_data_in_leaf': 9, 'num_leaves': 2803} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6731608353600065, 'lambda_l2': 0.4994762564554865, 'learning_rate': 0.3777879291685781, 'max_depth': 80, 'min_data_in_leaf': 12, 'num_leaves': 74} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6617091519413696, 'lambda_l2': 0.5461566444314364, 'learning_rate': 0.33652634373354706, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 139} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.3529942320883951, 'lambda_l2': 0.44703979548958045, 'learning_rate': 0.2188719020188359, 'max_depth': 9, 'min_data_in_leaf': 5, 'num_leaves': 3361} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.31198116072725657, 'lambda_l2': 0.4048092034371394, 'learning_rate': 0.15075703769059318, 'max_depth': 92, 'min_data_in_leaf': 20, 'num_leaves': 231} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.22103369811001616, 'lambda_l2': 0.6476151865144546, 'learning_rate': 0.133802086102063, 'max_depth': 96, 'min_data_in_leaf': 17, 'num_leaves': 384} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.15291643662420767, 'lambda_l2': 0.40508175005777936, 'learning_rate': 0.1866135076613133, 'max_depth': 94, 'min_data_in_leaf': 14, 'num_leaves': 472} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6652322478750919, 'lambda_l2': 0.6025443562183226, 'learning_rate': 0.36638892343923024, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 158} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6455517463306278, 'lambda_l2': 0.7011400214254683, 'learning_rate': 0.2956236202438827, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 310} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.3264044299573127, 'lambda_l2': 0.11260716244560887, 'learning_rate': 0.21207537897081374, 'max_depth': 96, 'min_data_in_leaf': 21, 'num_leaves': 62} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5050720588799965, 'lambda_l2': 0.8060845714287371, 'learning_rate': 0.43235833510774835, 'max_depth': 88, 'min_data_in_leaf': 12, 'num_leaves': 291} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3764134781690235, 'lambda_l2': 0.2796967441646506, 'learning_rate': 0.27281335239775845, 'max_depth': 3, 'min_data_in_leaf': 4, 'num_leaves': 2897} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6162685874034476, 'lambda_l2': 0.5421864585721796, 'learning_rate': 0.5389456662238803, 'max_depth': 78, 'min_data_in_leaf': 8, 'num_leaves': 544} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.33253181069101173, 'lambda_l2': 0.4493521892586235, 'learning_rate': 0.17552368226935894, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 185} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5826237834029215, 'lambda_l2': 0.8949302120167582, 'learning_rate': 0.3485609688550077, 'max_depth': 85, 'min_data_in_leaf': 10, 'num_leaves': 420} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.27527117791017364, 'lambda_l2': 0.0006935950111011668, 'learning_rate': 0.2396295587952676, 'max_depth': 5, 'min_data_in_leaf': 3, 'num_leaves': 2797} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.23144372817579129, 'lambda_l2': 0.7051560019242238, 'learning_rate': 0.10120139901682333, 'max_depth': 99, 'min_data_in_leaf': 15, 'num_leaves': 67} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5613346685348961, 'lambda_l2': 0.189574861522845, 'learning_rate': 0.45639533104989294, 'max_depth': 82, 'min_data_in_leaf': 6, 'num_leaves': 649} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3514073861350998, 'lambda_l2': 0.38771372733085097, 'learning_rate': 0.1488661963582168, 'max_depth': 93, 'min_data_in_leaf': 14, 'num_leaves': 355} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5395304065927724, 'lambda_l2': 0.5706781240631469, 'learning_rate': 0.6150899000749773, 'max_depth': 75, 'min_data_in_leaf': 12, 'num_leaves': 522} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.2906931156006896, 'lambda_l2': 0.09459468463859566, 'learning_rate': 0.12191077974507515, 'max_depth': 97, 'min_data_in_leaf': 18, 'num_leaves': 208} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3974440771757096, 'lambda_l2': 0.0010024537986381143, 'learning_rate': 0.2042111401063206, 'max_depth': 11, 'min_data_in_leaf': 8, 'num_leaves': 3027} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6273727361952569, 'lambda_l2': 0.7552880928477429, 'learning_rate': 0.4127555185880849, 'max_depth': 86, 'min_data_in_leaf': 3, 'num_leaves': 305} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.09281799350729114, 'lambda_l2': 0.3364584335115457, 'learning_rate': 0.17825078792048424, 'max_depth': 91, 'min_data_in_leaf': 25, 'num_leaves': 648} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.25064400675748477, 'lambda_l2': 0.21485140881564374, 'learning_rate': 0.13900058697522336, 'max_depth': 94, 'min_data_in_leaf': 21, 'num_leaves': 410} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.13635865269534841, 'lambda_l2': 0.46605180950121117, 'learning_rate': 0.16462146217244034, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 147} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.34899736241658547, 'lambda_l2': 0.0013319373526517464, 'learning_rate': 0.10805957982120833, 'max_depth': 95, 'min_data_in_leaf': 16, 'num_leaves': 2302} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.17355943713984434, 'lambda_l2': 0.2103131818833569, 'learning_rate': 0.2061841784088626, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 434} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2097854074220301, 'lambda_l2': 0.11960211532790249, 'learning_rate': 0.2944510114269661, 'max_depth': 100, 'min_data_in_leaf': 9, 'num_leaves': 552} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.44111888144083644, 'lambda_l2': 0.9596608748954834, 'learning_rate': 0.2332320565817918, 'max_depth': 92, 'min_data_in_leaf': 6, 'num_leaves': 267} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7065357997463791, 'lambda_l2': 0.6342647703997161, 'learning_rate': 0.3385720537442059, 'max_depth': 76, 'min_data_in_leaf': 1, 'num_leaves': 79} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.31875850714130194, 'lambda_l2': 0.8705335952172, 'learning_rate': 0.2518710475605004, 'max_depth': 90, 'min_data_in_leaf': 22, 'num_leaves': 2423} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4698961764286026, 'lambda_l2': 0.35501291642531274, 'learning_rate': 0.15908602609683245, 'max_depth': 97, 'min_data_in_leaf': 14, 'num_leaves': 1933} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.12562049123023378, 'lambda_l2': 0.006200470421983878, 'learning_rate': 0.12371981488722893, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 671} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.39466816248087594, 'lambda_l2': 0.507010185676624, 'learning_rate': 0.05842443110039746, 'max_depth': 95, 'min_data_in_leaf': 16, 'num_leaves': 2068} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4097623490405952, 'lambda_l2': 0.2734458697728558, 'learning_rate': 0.2898429569543995, 'max_depth': 6, 'min_data_in_leaf': 5, 'num_leaves': 2922} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.24557128803325134, 'lambda_l2': 0.1739069170052604, 'learning_rate': 0.09565477980819638, 'max_depth': 93, 'min_data_in_leaf': 20, 'num_leaves': 842} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.03849693223124162, 'lambda_l2': 0.1471575869610975, 'learning_rate': 0.11021548259537742, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 1188} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.59649610967416, 'lambda_l2': 0.008285646657263002, 'learning_rate': 0.06982094983413199, 'max_depth': 90, 'min_data_in_leaf': 24, 'num_leaves': 912} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2525020836431691, 'lambda_l2': 0.29760062126903897, 'learning_rate': 0.08888970527438073, 'max_depth': 84, 'min_data_in_leaf': 9, 'num_leaves': 822} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.25826068802764185, 'lambda_l2': 0.10288606553660823, 'learning_rate': 0.040487061316099804, 'max_depth': 92, 'min_data_in_leaf': 3, 'num_leaves': 704} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5502369219942244, 'lambda_l2': 0.6119501157038214, 'learning_rate': 0.08129839242491647, 'max_depth': 82, 'min_data_in_leaf': 8, 'num_leaves': 574} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.1646705876980285, 'lambda_l2': 0.005046760711328202, 'learning_rate': 0.19061692097075286, 'max_depth': 99, 'min_data_in_leaf': 14, 'num_leaves': 819} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.23327278022869966, 'lambda_l2': 0.18123726289456285, 'learning_rate': 0.09092765351931376, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 1044} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.19509547848487857, 'lambda_l2': 0.7506879855787658, 'learning_rate': 0.0644642103256448, 'max_depth': 98, 'min_data_in_leaf': 5, 'num_leaves': 862} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.10466782743219516, 'lambda_l2': 0.3591483435522308, 'learning_rate': 0.22131886460961106, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 732} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.06554261719708909, 'lambda_l2': 0.5069803546714805, 'learning_rate': 0.0482979794805851, 'max_depth': 87, 'min_data_in_leaf': 1, 'num_leaves': 1126} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.1800626574429572, 'lambda_l2': 0.6749584127062749, 'learning_rate': 0.13220655326027883, 'max_depth': 84, 'min_data_in_leaf': 16, 'num_leaves': 947} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.14066086988751303, 'lambda_l2': 0.4345855391033578, 'learning_rate': 0.19032240762707292, 'max_depth': 90, 'min_data_in_leaf': 10, 'num_leaves': 1399} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.606651940870098, 'lambda_l2': 0.27718531587858675, 'learning_rate': 0.3153234765915004, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 611} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5777894839047738, 'lambda_l2': 1.0282182798483204, 'learning_rate': 0.1649732410384035, 'max_depth': 79, 'min_data_in_leaf': 27, 'num_leaves': 487} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5218160352529028, 'lambda_l2': 0.8260059952034281, 'learning_rate': 0.2508074210669449, 'max_depth': 100, 'min_data_in_leaf': 18, 'num_leaves': 1505} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.27168350843876343, 'lambda_l2': 0.5759221995146266, 'learning_rate': 0.20814385216333786, 'max_depth': 86, 'min_data_in_leaf': 3, 'num_leaves': 813} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.11426584575693022, 'lambda_l2': 0.18459324296289426, 'learning_rate': 0.035629095238438054, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 1693} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4875323879814568, 'lambda_l2': 0.4467211190511895, 'learning_rate': 0.10340467968617278, 'max_depth': 92, 'min_data_in_leaf': 23, 'num_leaves': 746} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.05568935352564611, 'lambda_l2': 0.10375221148565406, 'learning_rate': 0.3951416686448732, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 1286} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.014109728850240172, 'lambda_l2': 0.9475608105002193, 'learning_rate': 0.07674554385530068, 'max_depth': 97, 'min_data_in_leaf': 5, 'num_leaves': 622} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5597891312404325, 'lambda_l2': 0.7076400839374212, 'learning_rate': 0.2793633479843705, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 920} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6364898679315621, 'lambda_l2': 0.3124409273050247, 'learning_rate': 0.11624310863685375, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 1835} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5055563162595992, 'lambda_l2': 1.1344457774405456, 'learning_rate': 0.15936600621329045, 'max_depth': 81, 'min_data_in_leaf': 10, 'num_leaves': 512} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.652311433855443, 'lambda_l2': 0.5793661689024986, 'learning_rate': 0.05597614080639245, 'max_depth': 72, 'min_data_in_leaf': 16, 'num_leaves': 1009} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6095017376786068, 'lambda_l2': 0.00935726033803741, 'learning_rate': 0.31644017937427515, 'max_depth': 15, 'min_data_in_leaf': 8, 'num_leaves': 347} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5908195484280397, 'lambda_l2': 0.2271924000360801, 'learning_rate': 0.22796308248721214, 'max_depth': 91, 'min_data_in_leaf': 25, 'num_leaves': 1972} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5762712601168365, 'lambda_l2': 0.7820120518743336, 'learning_rate': 0.031033017040239336, 'max_depth': 77, 'min_data_in_leaf': 3, 'num_leaves': 2105} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6869554998623945, 'lambda_l2': 0.3478526311490947, 'learning_rate': 0.13621635278781022, 'max_depth': 95, 'min_data_in_leaf': 11, 'num_leaves': 477} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5374637517749293, 'lambda_l2': 0.521060987955398, 'learning_rate': 0.4702179828544851, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 1590} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.0006273982836544623, 'lambda_l2': 0.9193441969277494, 'learning_rate': 0.18522879565571143, 'max_depth': 83, 'min_data_in_leaf': 6, 'num_leaves': 2188} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.20128838817616565, 'lambda_l2': 0.11108535202363845, 'learning_rate': 0.019622466610821083, 'max_depth': 100, 'min_data_in_leaf': 19, 'num_leaves': 1383} : acc= 56.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.08678371497240339, 'lambda_l2': 0.6664170503542475, 'learning_rate': 0.38229771010401037, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 1143} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5171169886154369, 'lambda_l2': 0.39589063374460737, 'learning_rate': 0.26083613017114354, 'max_depth': 90, 'min_data_in_leaf': 9, 'num_leaves': 2586} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6272147517529837, 'lambda_l2': 1.0547592357093214, 'learning_rate': 0.5275877597292556, 'max_depth': 93, 'min_data_in_leaf': 17, 'num_leaves': 675} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.48714085267695345, 'lambda_l2': 0.8093033523273923, 'learning_rate': 0.09963828335023421, 'max_depth': 79, 'min_data_in_leaf': 5, 'num_leaves': 866} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6594869643813868, 'lambda_l2': 0.2287038390032216, 'learning_rate': 0.3398095031979603, 'max_depth': 98, 'min_data_in_leaf': 47, 'num_leaves': 1689} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.44430269441672166, 'lambda_l2': 0.08516370374446253, 'learning_rate': 0.1623722501254621, 'max_depth': 70, 'min_data_in_leaf': 22, 'num_leaves': 572} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5574086832695727, 'lambda_l2': 0.6168445097824975, 'learning_rate': 0.23275957651999005, 'max_depth': 74, 'min_data_in_leaf': 39, 'num_leaves': 2342} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5946806166712197, 'lambda_l2': 0.48535543735491493, 'learning_rate': 0.2957670219787275, 'max_depth': 18, 'min_data_in_leaf': 2, 'num_leaves': 380} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.42632146242369684, 'lambda_l2': 1.2689812994861727, 'learning_rate': 0.20277524000765162, 'max_depth': 12, 'min_data_in_leaf': 12, 'num_leaves': 1873} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.529906726235934, 'lambda_l2': 0.011001857276942723, 'learning_rate': 0.11924449113126075, 'max_depth': 85, 'min_data_in_leaf': 30, 'num_leaves': 1448} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.46696873736149314, 'lambda_l2': 1.1710115352535588, 'learning_rate': 0.42626952399518, 'max_depth': 82, 'min_data_in_leaf': 7, 'num_leaves': 2480} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.28881180842239695, 'lambda_l2': 0.30955377979703413, 'learning_rate': 0.3594822814097323, 'max_depth': 89, 'min_data_in_leaf': 1, 'num_leaves': 1782} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5005713941788691, 'lambda_l2': 0.874289680444211, 'learning_rate': 0.1472605092459578, 'max_depth': 1, 'min_data_in_leaf': 15, 'num_leaves': 773} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6680515022632663, 'lambda_l2': 0.41664594768375196, 'learning_rate': 0.2706722077064011, 'max_depth': 94, 'min_data_in_leaf': 4, 'num_leaves': 2194} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6390154518774476, 'lambda_l2': 0.7454145292811488, 'learning_rate': 0.4756382132669619, 'max_depth': 80, 'min_data_in_leaf': 10, 'num_leaves': 2046} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6147919231200374, 'lambda_l2': 0.19220007570640274, 'learning_rate': 0.18354784452223888, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 1234} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.15755611588396928, 'lambda_l2': 0.5770440474890897, 'learning_rate': 0.6356822008438826, 'max_depth': 65, 'min_data_in_leaf': 13, 'num_leaves': 461} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5750106543948842, 'lambda_l2': 0.9910157439310019, 'learning_rate': 0.22926032041273015, 'max_depth': 96, 'min_data_in_leaf': 18, 'num_leaves': 2623} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5381809172201727, 'lambda_l2': 0.6962341128330014, 'learning_rate': 0.09043366259426386, 'max_depth': 87, 'min_data_in_leaf': 8, 'num_leaves': 2398} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.18637608808438114, 'lambda_l2': 0.5026502201940242, 'learning_rate': 0.31542452494330786, 'max_depth': 77, 'min_data_in_leaf': 34, 'num_leaves': 2296} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4531578837143191, 'lambda_l2': 1.3506853594471648, 'learning_rate': 0.1377738449849745, 'max_depth': 91, 'min_data_in_leaf': 51, 'num_leaves': 612} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6852212745849751, 'lambda_l2': 0.2828194658922816, 'learning_rate': 0.5746148389873889, 'max_depth': 73, 'min_data_in_leaf': 26, 'num_leaves': 2502} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5462195859494884, 'lambda_l2': 0.13599430400322565, 'learning_rate': 0.3864833524865326, 'max_depth': 93, 'min_data_in_leaf': 5, 'num_leaves': 2142} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5117136953997174, 'lambda_l2': 1.0820456297936687, 'learning_rate': 0.1641536486202882, 'max_depth': 99, 'min_data_in_leaf': 23, 'num_leaves': 1074} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.02067730622594738, 'lambda_l2': 0.4007100085613137, 'learning_rate': 0.025416933434365376, 'max_depth': 88, 'min_data_in_leaf': 1, 'num_leaves': 1341} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6041511029872786, 'lambda_l2': 0.8283161357681356, 'learning_rate': 0.20565483803104787, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 1640} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4811802831949727, 'lambda_l2': 0.6444398436305322, 'learning_rate': 0.07179622149764607, 'max_depth': 8, 'min_data_in_leaf': 16, 'num_leaves': 1971} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.568122862738228, 'lambda_l2': 0.08930487837692225, 'learning_rate': 0.27966970095850047, 'max_depth': 20, 'min_data_in_leaf': 3, 'num_leaves': 2691} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.37233099536753567, 'lambda_l2': 0.9219429510200002, 'learning_rate': 0.5118324474312248, 'max_depth': 91, 'min_data_in_leaf': 67, 'num_leaves': 2248} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6944293790033208, 'lambda_l2': 4.9690094473877195, 'learning_rate': 0.11627786574878146, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 968} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6566555139801693, 'lambda_l2': 0.3289374850336473, 'learning_rate': 0.24734696784681565, 'max_depth': 95, 'min_data_in_leaf': 6, 'num_leaves': 754} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.2689678079445695, 'lambda_l2': 0.5227332501015445, 'learning_rate': 0.330266345218793, 'max_depth': 13, 'min_data_in_leaf': 8, 'num_leaves': 1868} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6234555404903905, 'lambda_l2': 0.012587021642755408, 'learning_rate': 0.4305137874546409, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2391} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.41571358934280955, 'lambda_l2': 0.22321622971705124, 'learning_rate': 0.7128615062023683, 'max_depth': 86, 'min_data_in_leaf': 21, 'num_leaves': 1557} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.592389364929827, 'lambda_l2': 0.6594526664301504, 'learning_rate': 0.18665286467350914, 'max_depth': 98, 'min_data_in_leaf': 43, 'num_leaves': 268} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5237915070737343, 'lambda_l2': 1.207161654518039, 'learning_rate': 0.3749042919735734, 'max_depth': 67, 'min_data_in_leaf': 18, 'num_leaves': 367} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6797221125623916, 'lambda_l2': 0.7763041942694973, 'learning_rate': 0.06052154960808372, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 875} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4344894109965543, 'lambda_l2': 0.4393449562892928, 'learning_rate': 0.131772064635725, 'max_depth': 90, 'min_data_in_leaf': 53, 'num_leaves': 2083} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7283924219429663, 'lambda_l2': 0.006393985042841721, 'learning_rate': 0.2329704118995159, 'max_depth': 85, 'min_data_in_leaf': 28, 'num_leaves': 2563} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5547861442078661, 'lambda_l2': 1.019114643966999, 'learning_rate': 0.2992933528758855, 'max_depth': 94, 'min_data_in_leaf': 3, 'num_leaves': 1779} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.07812555573346708, 'lambda_l2': 1.4533745564726317, 'learning_rate': 0.09559733881812059, 'max_depth': 69, 'min_data_in_leaf': 7, 'num_leaves': 461} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6319775627248335, 'lambda_l2': 0.5358056926003469, 'learning_rate': 0.1687517554853858, 'max_depth': 79, 'min_data_in_leaf': 12, 'num_leaves': 2257} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4610799296105919, 'lambda_l2': 0.3366918743534866, 'learning_rate': 0.5621585745066232, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 683} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4936430933179794, 'lambda_l2': 0.003751648472668012, 'learning_rate': 0.4714456629832087, 'max_depth': 97, 'min_data_in_leaf': 5, 'num_leaves': 552} : acc= 73.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.36189078687935194, 'lambda_l2': 0.010197482098301087, 'learning_rate': 0.8531024903462107, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 593} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.3837599909041113, 'lambda_l2': 0.15251862298202393, 'learning_rate': 0.5951018345565551, 'max_depth': 98, 'min_data_in_leaf': 17, 'num_leaves': 489} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4939769706883182, 'lambda_l2': 0.11891712083061955, 'learning_rate': 0.6834869709780224, 'max_depth': 99, 'min_data_in_leaf': 19, 'num_leaves': 785} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4114582578464857, 'lambda_l2': 0.0594054842379218, 'learning_rate': 0.7868136751578644, 'max_depth': 96, 'min_data_in_leaf': 23, 'num_leaves': 373} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.30605643439966784, 'lambda_l2': 0.1566521090584207, 'learning_rate': 0.42391416512026175, 'max_depth': 99, 'min_data_in_leaf': 4, 'num_leaves': 553} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.43895191025911695, 'lambda_l2': 0.0823298751351184, 'learning_rate': 0.5132312995533126, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 685} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4103176075644176, 'lambda_l2': 0.2503612069750798, 'learning_rate': 0.4572994286892499, 'max_depth': 100, 'min_data_in_leaf': 2, 'num_leaves': 847} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.41006267335963037, 'lambda_l2': 0.0390104762887562, 'learning_rate': 0.9475093843056585, 'max_depth': 100, 'min_data_in_leaf': 2, 'num_leaves': 819} : acc= 60.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5761119392927608, 'lambda_l2': 0.20764721201084602, 'learning_rate': 0.750914827117909, 'max_depth': 60, 'min_data_in_leaf': 6, 'num_leaves': 1052} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.47391148381238307, 'lambda_l2': 0.25996282698708606, 'learning_rate': 0.05015748700795101, 'max_depth': 94, 'min_data_in_leaf': 14, 'num_leaves': 918} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4486029737270219, 'lambda_l2': 0.3385671718853007, 'learning_rate': 0.34983337573547296, 'max_depth': 95, 'min_data_in_leaf': 11, 'num_leaves': 321} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3326322788123548, 'lambda_l2': 0.021269308157093297, 'learning_rate': 0.6366584941788029, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 1144} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7022895321202356, 'lambda_l2': 0.576051283528964, 'learning_rate': 0.7011761797425, 'max_depth': 15, 'min_data_in_leaf': 5, 'num_leaves': 964} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3554766649925468, 'lambda_l2': 0.4063673472008903, 'learning_rate': 0.47584015236040894, 'max_depth': 100, 'min_data_in_leaf': 7, 'num_leaves': 615} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3345520674535982, 'lambda_l2': 0.19230185190710852, 'learning_rate': 0.4781013696314751, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 846} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.28636244989800663, 'lambda_l2': 0.0030784033567863855, 'learning_rate': 0.8549066662430621, 'max_depth': 99, 'min_data_in_leaf': 57, 'num_leaves': 755} : acc= 50.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6141518197152951, 'lambda_l2': 0.8639876257088894, 'learning_rate': 0.6280566280733112, 'max_depth': 57, 'min_data_in_leaf': 1, 'num_leaves': 2481} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.42657705203978796, 'lambda_l2': 0.2879527435068049, 'learning_rate': 0.26972085348468583, 'max_depth': 10, 'min_data_in_leaf': 4, 'num_leaves': 210} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.3876745810899248, 'lambda_l2': 0.2465590242566984, 'learning_rate': 0.9756518853862136, 'max_depth': 97, 'min_data_in_leaf': 2, 'num_leaves': 1085} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6591935004077387, 'lambda_l2': 0.6875880393330988, 'learning_rate': 0.5445695574299494, 'max_depth': 22, 'min_data_in_leaf': 8, 'num_leaves': 1269} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.23294741122898102, 'lambda_l2': 0.09596887107622538, 'learning_rate': 0.41521509694450165, 'max_depth': 99, 'min_data_in_leaf': 5, 'num_leaves': 992} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3995847785543453, 'lambda_l2': 0.007104562357833827, 'learning_rate': 0.3662284789468417, 'max_depth': 6, 'min_data_in_leaf': 83, 'num_leaves': 383} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3211226744111738, 'lambda_l2': 0.006113226315024783, 'learning_rate': 0.8034603527902674, 'max_depth': 97, 'min_data_in_leaf': 2, 'num_leaves': 1006} : acc= 59.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3761462466326587, 'lambda_l2': 0.40425299288386574, 'learning_rate': 0.204363397451625, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 519} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3414303922585444, 'lambda_l2': 0.15744515060561828, 'learning_rate': 0.07776809104394855, 'max_depth': 96, 'min_data_in_leaf': 4, 'num_leaves': 694} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4290820193176047, 'lambda_l2': 0.10187282059581199, 'learning_rate': 0.47723498120158786, 'max_depth': 94, 'min_data_in_leaf': 62, 'num_leaves': 913} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4830778347396643, 'lambda_l2': 0.4464516887205596, 'learning_rate': 0.14990625121071696, 'max_depth': 90, 'min_data_in_leaf': 21, 'num_leaves': 404} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2879391649575996, 'lambda_l2': 0.22736152148201616, 'learning_rate': 0.7377178016661392, 'max_depth': 100, 'min_data_in_leaf': 31, 'num_leaves': 852} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.24326585297322334, 'lambda_l2': 0.36689505132046735, 'learning_rate': 0.652635702792933, 'max_depth': 100, 'min_data_in_leaf': 1, 'num_leaves': 1293} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5171016706080931, 'lambda_l2': 0.4484170171636415, 'learning_rate': 0.291170946391241, 'max_depth': 17, 'min_data_in_leaf': 9, 'num_leaves': 279} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5006151411942928, 'lambda_l2': 0.3197216153630379, 'learning_rate': 0.11059444284339148, 'max_depth': 89, 'min_data_in_leaf': 25, 'num_leaves': 590} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.46544997429807466, 'lambda_l2': 0.548701249428871, 'learning_rate': 0.31216866162966705, 'max_depth': 92, 'min_data_in_leaf': 16, 'num_leaves': 129} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.36803140501693765, 'lambda_l2': 0.1587280742240027, 'learning_rate': 0.5782869335600643, 'max_depth': 97, 'min_data_in_leaf': 6, 'num_leaves': 1206} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4425155261650733, 'lambda_l2': 0.00034580171397823566, 'learning_rate': 0.17680748647029387, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 55} : acc= 73.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4497467753860751, 'lambda_l2': 0.013705736816685165, 'learning_rate': 0.246131678493258, 'max_depth': 83, 'min_data_in_leaf': 27, 'num_leaves': 174} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.37788845451726316, 'lambda_l2': 0.024663770996595724, 'learning_rate': 0.398649679702264, 'max_depth': 94, 'min_data_in_leaf': 11, 'num_leaves': 879} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.39499286969190456, 'lambda_l2': 0.10185801082542478, 'learning_rate': 0.13506891837825036, 'max_depth': 86, 'min_data_in_leaf': 33, 'num_leaves': 741} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.30968409795279406, 'lambda_l2': 0.18258787873233268, 'learning_rate': 0.09634917619083573, 'max_depth': 87, 'min_data_in_leaf': 24, 'num_leaves': 56} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.21390602058984684, 'lambda_l2': 0.007231424560710216, 'learning_rate': 0.07297436667638561, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 223} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.30041386508907764, 'lambda_l2': 0.010805071559254142, 'learning_rate': 0.04229749012091588, 'max_depth': 91, 'min_data_in_leaf': 14, 'num_leaves': 637} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.35769675305454746, 'lambda_l2': 0.010685581681536993, 'learning_rate': 0.4448285202208671, 'max_depth': 100, 'min_data_in_leaf': 1, 'num_leaves': 1048} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.40809253878892876, 'lambda_l2': 4.419738414014676, 'learning_rate': 0.9758420616061649, 'max_depth': 95, 'min_data_in_leaf': 49, 'num_leaves': 1148} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.43577829334371015, 'lambda_l2': 0.0009350081599133475, 'learning_rate': 0.23106394282334558, 'max_depth': 14, 'min_data_in_leaf': 12, 'num_leaves': 485} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.27427223516035193, 'lambda_l2': 0.2245050650199833, 'learning_rate': 0.5406502055487421, 'max_depth': 92, 'min_data_in_leaf': 3, 'num_leaves': 814} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.316813848901521, 'lambda_l2': 0.11943070036452547, 'learning_rate': 0.39357062891924155, 'max_depth': 98, 'min_data_in_leaf': 10, 'num_leaves': 721} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.502314511394258, 'lambda_l2': 0.49303056987494626, 'learning_rate': 0.2056178440455523, 'max_depth': 75, 'min_data_in_leaf': 18, 'num_leaves': 1463} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.45016593085080747, 'lambda_l2': 0.299120757535547, 'learning_rate': 0.1097943714557004, 'max_depth': 90, 'min_data_in_leaf': 36, 'num_leaves': 348} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2479748939527332, 'lambda_l2': 0.23694344037415244, 'learning_rate': 0.27129998544835815, 'max_depth': 100, 'min_data_in_leaf': 5, 'num_leaves': 786} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.47522940822448567, 'lambda_l2': 0.39837203176901803, 'learning_rate': 0.17659797611546993, 'max_depth': 80, 'min_data_in_leaf': 22, 'num_leaves': 421} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.39628025812159173, 'lambda_l2': 0.0013062516635863053, 'learning_rate': 0.051544555362158795, 'max_depth': 93, 'min_data_in_leaf': 15, 'num_leaves': 268} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5421963838366186, 'lambda_l2': 0.5379585158105127, 'learning_rate': 0.33510871950838683, 'max_depth': 71, 'min_data_in_leaf': 29, 'num_leaves': 156} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.20383246011649525, 'lambda_l2': 0.18225741547009483, 'learning_rate': 0.5178922584855572, 'max_depth': 100, 'min_data_in_leaf': 8, 'num_leaves': 1129} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.3406687326682407, 'lambda_l2': 0.0009616967771129744, 'learning_rate': 0.0829253692174714, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 493} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5300067003614843, 'lambda_l2': 0.36544277695740296, 'learning_rate': 0.02208458047193851, 'max_depth': 85, 'min_data_in_leaf': 26, 'num_leaves': 548} : acc= 56.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.3925654325248055, 'lambda_l2': 0.0748898285950984, 'learning_rate': 0.15603010098141215, 'max_depth': 95, 'min_data_in_leaf': 12, 'num_leaves': 684} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4566842494470734, 'lambda_l2': 0.12245842814949388, 'learning_rate': 0.06675705032104197, 'max_depth': 88, 'min_data_in_leaf': 17, 'num_leaves': 288} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.1747973191355196, 'lambda_l2': 0.27848272818710795, 'learning_rate': 0.12436196363514573, 'max_depth': 90, 'min_data_in_leaf': 10, 'num_leaves': 63} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5125291802396587, 'lambda_l2': 0.6521318685134572, 'learning_rate': 0.21199410717952952, 'max_depth': 77, 'min_data_in_leaf': 20, 'num_leaves': 102} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.486762702801612, 'lambda_l2': 0.4972973600643741, 'learning_rate': 0.3344744426211734, 'max_depth': 81, 'min_data_in_leaf': 24, 'num_leaves': 487} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.25900230353011094, 'lambda_l2': 0.21092327639549913, 'learning_rate': 0.26521554937163716, 'max_depth': 97, 'min_data_in_leaf': 7, 'num_leaves': 925} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5261506662384603, 'lambda_l2': 0.6104083677678527, 'learning_rate': 0.23497837076724298, 'max_depth': 3, 'min_data_in_leaf': 13, 'num_leaves': 1849} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.42434094101938796, 'lambda_l2': 0.10190145271595924, 'learning_rate': 0.06136166757043819, 'max_depth': 92, 'min_data_in_leaf': 19, 'num_leaves': 653} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5538128361798488, 'lambda_l2': 0.43294432490771123, 'learning_rate': 0.19033707341018738, 'max_depth': 74, 'min_data_in_leaf': 21, 'num_leaves': 1330} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.12080082804742542, 'lambda_l2': 0.7751827578675743, 'learning_rate': 0.14974984549369674, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 431} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.36953304342078175, 'lambda_l2': 0.3419802383177847, 'learning_rate': 0.0819132021628658, 'max_depth': 87, 'min_data_in_leaf': 9, 'num_leaves': 57} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4670851388913996, 'lambda_l2': 0.3108964399303806, 'learning_rate': 0.10359789087904131, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 221} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.44463490790144405, 'lambda_l2': 0.15748707664484835, 'learning_rate': 0.1311467891036126, 'max_depth': 85, 'min_data_in_leaf': 11, 'num_leaves': 137} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.15070114739549662, 'lambda_l2': 0.006158764896364632, 'learning_rate': 0.41815390938427677, 'max_depth': 94, 'min_data_in_leaf': 64, 'num_leaves': 958} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3510044009151242, 'lambda_l2': 0.25403501022948466, 'learning_rate': 0.08610083637791567, 'max_depth': 96, 'min_data_in_leaf': 15, 'num_leaves': 548} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.48506461558090375, 'lambda_l2': 4.651421945870752, 'learning_rate': 0.16836636857719273, 'max_depth': 91, 'min_data_in_leaf': 69, 'num_leaves': 303} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5097630943884369, 'lambda_l2': 0.5985674968357523, 'learning_rate': 0.3052150731083749, 'max_depth': 80, 'min_data_in_leaf': 23, 'num_leaves': 1241} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.503131148137256, 'lambda_l2': 0.10263026402645375, 'learning_rate': 0.11267348529051993, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 361} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.42619385185842185, 'lambda_l2': 0.7474074378882785, 'learning_rate': 0.03485742532024402, 'max_depth': 79, 'min_data_in_leaf': 32, 'num_leaves': 587} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4695909838693302, 'lambda_l2': 0.3403694707384309, 'learning_rate': 0.13009207424059527, 'max_depth': 84, 'min_data_in_leaf': 22, 'num_leaves': 224} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.10114138573712012, 'lambda_l2': 0.5006670239032676, 'learning_rate': 0.24304937742982619, 'max_depth': 72, 'min_data_in_leaf': 29, 'num_leaves': 454} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3781770807386032, 'lambda_l2': 0.09928908320309043, 'learning_rate': 0.19142110204252932, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 135} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.30552562302805897, 'lambda_l2': 0.0012026596487733163, 'learning_rate': 0.8137536798560787, 'max_depth': 100, 'min_data_in_leaf': 4, 'num_leaves': 755} : acc= 57.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4365350213343961, 'lambda_l2': 0.21333177653634056, 'learning_rate': 0.09124048844563475, 'max_depth': 86, 'min_data_in_leaf': 27, 'num_leaves': 280} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5397783334436814, 'lambda_l2': 2.7162345733784106, 'learning_rate': 0.3527385251901244, 'max_depth': 76, 'min_data_in_leaf': 87, 'num_leaves': 3204} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4108917672026069, 'lambda_l2': 0.2536076558843689, 'learning_rate': 0.49989352424135736, 'max_depth': 92, 'min_data_in_leaf': 38, 'num_leaves': 1097} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.48465400949782306, 'lambda_l2': 0.3905996095705215, 'learning_rate': 0.11971802294678685, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 78} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5652808326353447, 'lambda_l2': 3.2472795868474726, 'learning_rate': 0.28977113699355755, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 2707} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.2563365403970089, 'lambda_l2': 0.10097837857658104, 'learning_rate': 0.028035364878631914, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 851} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.33406974534812695, 'lambda_l2': 0.18360699007031436, 'learning_rate': 0.09498831609090125, 'max_depth': 94, 'min_data_in_leaf': 11, 'num_leaves': 656} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.2297459280296849, 'lambda_l2': 0.4498666535879414, 'learning_rate': 0.14663251426439966, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 344} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4173597840010976, 'lambda_l2': 0.30189828008911407, 'learning_rate': 0.6324763042736034, 'max_depth': 88, 'min_data_in_leaf': 25, 'num_leaves': 1200} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5792287821200922, 'lambda_l2': 0.6927258044088906, 'learning_rate': 0.20662185311872439, 'max_depth': 63, 'min_data_in_leaf': 16, 'num_leaves': 574} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.39747942597345753, 'lambda_l2': 0.1854829755499631, 'learning_rate': 0.057051233346807895, 'max_depth': 96, 'min_data_in_leaf': 9, 'num_leaves': 415} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5309585744054708, 'lambda_l2': 0.5859387770673219, 'learning_rate': 0.29509196149263434, 'max_depth': 68, 'min_data_in_leaf': 13, 'num_leaves': 1623} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.49375255151830716, 'lambda_l2': 0.5917220011698985, 'learning_rate': 0.1688604904856602, 'max_depth': 70, 'min_data_in_leaf': 21, 'num_leaves': 1427} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.19104732705634625, 'lambda_l2': 0.07897152908013047, 'learning_rate': 0.45756993845463917, 'max_depth': 68, 'min_data_in_leaf': 14, 'num_leaves': 1521} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5313950927354921, 'lambda_l2': 0.5098306416652512, 'learning_rate': 0.25857593605681345, 'max_depth': 66, 'min_data_in_leaf': 25, 'num_leaves': 1561} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.05078841030350334, 'lambda_l2': 0.4733784486464714, 'learning_rate': 0.20834125457421984, 'max_depth': 72, 'min_data_in_leaf': 31, 'num_leaves': 1364} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.509554936712161, 'lambda_l2': 0.6123821857955125, 'learning_rate': 0.2879516709461646, 'max_depth': 64, 'min_data_in_leaf': 17, 'num_leaves': 1661} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4624430168459296, 'lambda_l2': 0.3934967276947229, 'learning_rate': 0.06715971265459593, 'max_depth': 74, 'min_data_in_leaf': 19, 'num_leaves': 1486} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5230400309228942, 'lambda_l2': 4.310819188201574, 'learning_rate': 0.3766393960354235, 'max_depth': 59, 'min_data_in_leaf': 12, 'num_leaves': 1611} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3490052149737155, 'lambda_l2': 0.01343329590258141, 'learning_rate': 0.23233113904880384, 'max_depth': 65, 'min_data_in_leaf': 15, 'num_leaves': 1385} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5541104878279177, 'lambda_l2': 3.7533117939607505, 'learning_rate': 0.1503825784625105, 'max_depth': 78, 'min_data_in_leaf': 23, 'num_leaves': 1441} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4981722323429046, 'lambda_l2': 0.8369028692933919, 'learning_rate': 0.18272584569734665, 'max_depth': 62, 'min_data_in_leaf': 41, 'num_leaves': 1726} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5576874292200668, 'lambda_l2': 0.7630253011678787, 'learning_rate': 0.3257052581659482, 'max_depth': 73, 'min_data_in_leaf': 28, 'num_leaves': 1538} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.44538095831083085, 'lambda_l2': 0.9749287440193705, 'learning_rate': 0.22182694259980548, 'max_depth': 61, 'min_data_in_leaf': 12, 'num_leaves': 1677} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.53871679088697, 'lambda_l2': 0.6159209344600022, 'learning_rate': 0.16483407210756093, 'max_depth': 66, 'min_data_in_leaf': 17, 'num_leaves': 1757} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.27426492937688507, 'lambda_l2': 0.25249277935641345, 'learning_rate': 0.43569969636834055, 'max_depth': 94, 'min_data_in_leaf': 15, 'num_leaves': 1296} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.46619076925294606, 'lambda_l2': 0.3784088010711081, 'learning_rate': 0.24972402286054401, 'max_depth': 70, 'min_data_in_leaf': 19, 'num_leaves': 1573} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.31628541816954137, 'lambda_l2': 0.17814903320420547, 'learning_rate': 0.5945711757175952, 'max_depth': 56, 'min_data_in_leaf': 7, 'num_leaves': 1199} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.29299765198834793, 'lambda_l2': 0.0085617779248027, 'learning_rate': 0.9884036758971004, 'max_depth': 75, 'min_data_in_leaf': 11, 'num_leaves': 995} : acc= 49.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.43763188630289207, 'lambda_l2': 0.855351272685425, 'learning_rate': 0.38380556892137224, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 1488} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.48546347661340455, 'lambda_l2': 0.4960097927506099, 'learning_rate': 0.3174280777435734, 'max_depth': 78, 'min_data_in_leaf': 23, 'num_leaves': 1273} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.0759346735583977, 'lambda_l2': 0.34780968786409405, 'learning_rate': 0.279548372584984, 'max_depth': 70, 'min_data_in_leaf': 74, 'num_leaves': 1349} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4072154019158022, 'lambda_l2': 3.920250062630143, 'learning_rate': 0.6811243422433606, 'max_depth': 100, 'min_data_in_leaf': 6, 'num_leaves': 1040} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.3654896843461661, 'lambda_l2': 4.824994306755908, 'learning_rate': 0.11806635777978322, 'max_depth': 87, 'min_data_in_leaf': 20, 'num_leaves': 65} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.0337194994440681, 'lambda_l2': 0.5314500276030067, 'learning_rate': 0.14158535979567732, 'max_depth': 68, 'min_data_in_leaf': 27, 'num_leaves': 1191} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.14553316089446355, 'lambda_l2': 1.0945842162416657, 'learning_rate': 0.19186566215867862, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 1757} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5893575532040998, 'lambda_l2': 0.4594036109026013, 'learning_rate': 0.36048356932918185, 'max_depth': 54, 'min_data_in_leaf': 35, 'num_leaves': 1909} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5194376634821806, 'lambda_l2': 0.6891531741462433, 'learning_rate': 0.2604677221305637, 'max_depth': 68, 'min_data_in_leaf': 10, 'num_leaves': 1817} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.213245473123848, 'lambda_l2': 0.7000820604329137, 'learning_rate': 0.10465114300228809, 'max_depth': 58, 'min_data_in_leaf': 18, 'num_leaves': 1663} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4231592862601092, 'lambda_l2': 0.10006277096003552, 'learning_rate': 0.49851601846611443, 'max_depth': 97, 'min_data_in_leaf': 45, 'num_leaves': 953} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.45953331718100277, 'lambda_l2': 0.5851637761143671, 'learning_rate': 0.002427326203511205, 'max_depth': 60, 'min_data_in_leaf': 14, 'num_leaves': 1420} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3202845295974096, 'lambda_l2': 0.2355953859262017, 'learning_rate': 0.016224047593349503, 'max_depth': 92, 'min_data_in_leaf': 5, 'num_leaves': 881} : acc= 57.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5473616211570643, 'lambda_l2': 0.9348528600123509, 'learning_rate': 0.21356673581709457, 'max_depth': 79, 'min_data_in_leaf': 25, 'num_leaves': 1112} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.48362298269068854, 'lambda_l2': 4.124529415089844, 'learning_rate': 0.16776442997777807, 'max_depth': 63, 'min_data_in_leaf': 8, 'num_leaves': 1477} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.16359873360273453, 'lambda_l2': 0.004464982158679909, 'learning_rate': 0.13936714035003378, 'max_depth': 68, 'min_data_in_leaf': 16, 'num_leaves': 1649} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.13103938923952885, 'lambda_l2': 0.29111586009873885, 'learning_rate': 0.099014051995592, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 338} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3822312586902298, 'lambda_l2': 0.3406637355738448, 'learning_rate': 0.11903208477717203, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 528} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5160872274983681, 'lambda_l2': 0.4144497697086242, 'learning_rate': 0.18281095653800816, 'max_depth': 58, 'min_data_in_leaf': 21, 'num_leaves': 1588} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.44810658699572803, 'lambda_l2': 0.12851084309179303, 'learning_rate': 0.00173095247998604, 'max_depth': 81, 'min_data_in_leaf': 10, 'num_leaves': 189} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.34048971579660764, 'lambda_l2': 0.1732271942008794, 'learning_rate': 0.4630361047671739, 'max_depth': 98, 'min_data_in_leaf': 5, 'num_leaves': 1086} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5275542443387432, 'lambda_l2': 0.6839316140631124, 'learning_rate': 0.25939046231366203, 'max_depth': 53, 'min_data_in_leaf': 10, 'num_leaves': 1778} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.41867469001624297, 'lambda_l2': 0.2736058990654786, 'learning_rate': 0.22407644110814662, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 740} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4932249889472482, 'lambda_l2': 0.45521315117363487, 'learning_rate': 0.17876110167305265, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 227} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4721773577554363, 'lambda_l2': 0.3519798683482086, 'learning_rate': 0.207882978945254, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 389} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.43499797806097235, 'lambda_l2': 0.005609147177907892, 'learning_rate': 0.41437459632579104, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 890} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5845103535008125, 'lambda_l2': 0.8451243561625321, 'learning_rate': 0.3201910644920583, 'max_depth': 78, 'min_data_in_leaf': 12, 'num_leaves': 1829} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5664785609753912, 'lambda_l2': 0.8810230894544625, 'learning_rate': 0.31021186541484425, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 1731} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5115582586723959, 'lambda_l2': 0.7960334268963405, 'learning_rate': 0.263228868999233, 'max_depth': 67, 'min_data_in_leaf': 18, 'num_leaves': 1843} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5386526458553085, 'lambda_l2': 0.563177069855683, 'learning_rate': 0.2635014786379093, 'max_depth': 65, 'min_data_in_leaf': 14, 'num_leaves': 1701} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5877766888325351, 'lambda_l2': 0.7415140586754818, 'learning_rate': 0.3404815083566243, 'max_depth': 78, 'min_data_in_leaf': 18, 'num_leaves': 1584} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5587858207836761, 'lambda_l2': 1.1047343351100154, 'learning_rate': 0.3823484768539548, 'max_depth': 80, 'min_data_in_leaf': 8, 'num_leaves': 1983} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.39730748531647386, 'lambda_l2': 0.2432229284650898, 'learning_rate': 0.545969978726752, 'max_depth': 94, 'min_data_in_leaf': 6, 'num_leaves': 798} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4555471105725799, 'lambda_l2': 0.42223982589346487, 'learning_rate': 0.007453397799540467, 'max_depth': 72, 'min_data_in_leaf': 12, 'num_leaves': 1538} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48364825372791453, 'lambda_l2': 0.31693624399236237, 'learning_rate': 0.17115616419778965, 'max_depth': 84, 'min_data_in_leaf': 12, 'num_leaves': 58} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.513975022328736, 'lambda_l2': 0.6082276730626807, 'learning_rate': 0.28667722667775275, 'max_depth': 65, 'min_data_in_leaf': 9, 'num_leaves': 1894} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5972071381160793, 'lambda_l2': 0.6522665381737808, 'learning_rate': 0.3950829708964108, 'max_depth': 90, 'min_data_in_leaf': 4, 'num_leaves': 1991} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5351874921376313, 'lambda_l2': 0.9281755351315062, 'learning_rate': 0.234027347666892, 'max_depth': 63, 'min_data_in_leaf': 10, 'num_leaves': 1932} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5768099389677477, 'lambda_l2': 0.8997636905053641, 'learning_rate': 0.3293099268411689, 'max_depth': 74, 'min_data_in_leaf': 17, 'num_leaves': 1397} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6035894218240531, 'lambda_l2': 0.9852483009111044, 'learning_rate': 0.3013384256046671, 'max_depth': 77, 'min_data_in_leaf': 7, 'num_leaves': 2037} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.514759853092403, 'lambda_l2': 0.5154526017578929, 'learning_rate': 0.24056629318284353, 'max_depth': 57, 'min_data_in_leaf': 10, 'num_leaves': 1500} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5629465005497755, 'lambda_l2': 0.8357980199552643, 'learning_rate': 0.35780779560436404, 'max_depth': 81, 'min_data_in_leaf': 14, 'num_leaves': 1820} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.46510985478342537, 'lambda_l2': 0.15622560749544337, 'learning_rate': 0.140929941125137, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 269} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.36817495028357344, 'lambda_l2': 0.0963821801262448, 'learning_rate': 0.5483784073488802, 'max_depth': 92, 'min_data_in_leaf': 3, 'num_leaves': 1033} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5438284345470692, 'lambda_l2': 1.254227002199556, 'learning_rate': 0.313936874604697, 'max_depth': 76, 'min_data_in_leaf': 7, 'num_leaves': 1615} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4784956203583211, 'lambda_l2': 0.004189589977605657, 'learning_rate': 0.14923517607859305, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 520} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3990097408827912, 'lambda_l2': 0.248908209511341, 'learning_rate': 0.46056181057993106, 'max_depth': 95, 'min_data_in_leaf': 1, 'num_leaves': 676} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.579971407259258, 'lambda_l2': 0.7791372347658646, 'learning_rate': 0.2019440106652496, 'max_depth': 79, 'min_data_in_leaf': 19, 'num_leaves': 1727} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.49632083507981206, 'lambda_l2': 0.43477445891013655, 'learning_rate': 0.16353267776318434, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 279} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5251053602590685, 'lambda_l2': 0.6181015501963063, 'learning_rate': 0.266549019816627, 'max_depth': 71, 'min_data_in_leaf': 12, 'num_leaves': 1666} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4972439615869846, 'lambda_l2': 0.5384509168704184, 'learning_rate': 0.2150326670136008, 'max_depth': 71, 'min_data_in_leaf': 15, 'num_leaves': 1799} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6046872562130778, 'lambda_l2': 0.7113709993316605, 'learning_rate': 0.40121851721746876, 'max_depth': 85, 'min_data_in_leaf': 14, 'num_leaves': 2136} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.43029485004351775, 'lambda_l2': 0.3654121873780295, 'learning_rate': 0.7039300602930639, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 1207} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.45928501644796127, 'lambda_l2': 0.309048202142184, 'learning_rate': 0.18425395992138285, 'max_depth': 86, 'min_data_in_leaf': 23, 'num_leaves': 443} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.40973580090466427, 'lambda_l2': 0.0035150722110212362, 'learning_rate': 0.5590411065943729, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 833} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6385985756474384, 'lambda_l2': 0.5420790696052359, 'learning_rate': 0.40933191477887954, 'max_depth': 84, 'min_data_in_leaf': 5, 'num_leaves': 2137} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6046664412105094, 'lambda_l2': 0.7525603632472004, 'learning_rate': 0.37197587043752367, 'max_depth': 81, 'min_data_in_leaf': 13, 'num_leaves': 2088} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4372825356741494, 'lambda_l2': 0.10553712309663192, 'learning_rate': 0.8522152482401844, 'max_depth': 88, 'min_data_in_leaf': 9, 'num_leaves': 1152} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5029854350578427, 'lambda_l2': 1.0508574899272263, 'learning_rate': 0.2510737835224408, 'max_depth': 60, 'min_data_in_leaf': 21, 'num_leaves': 1632} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6153602910076672, 'lambda_l2': 0.6878319162773824, 'learning_rate': 0.4478942185289474, 'max_depth': 84, 'min_data_in_leaf': 11, 'num_leaves': 1988} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.541982387755259, 'lambda_l2': 0.4641975734964475, 'learning_rate': 0.33070128626300754, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 1293} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5571640641246911, 'lambda_l2': 0.8094797465467558, 'learning_rate': 0.2907123443686096, 'max_depth': 79, 'min_data_in_leaf': 23, 'num_leaves': 1899} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5495865373897225, 'lambda_l2': 0.6385945912054535, 'learning_rate': 0.40019702364357895, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 1965} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5721643987868851, 'lambda_l2': 0.9875082994813837, 'learning_rate': 0.5112491806596406, 'max_depth': 86, 'min_data_in_leaf': 21, 'num_leaves': 1373} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.641299693338395, 'lambda_l2': 0.5609044260016575, 'learning_rate': 0.6150256248540772, 'max_depth': 86, 'min_data_in_leaf': 6, 'num_leaves': 2141} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.519614822678701, 'lambda_l2': 0.43269860731871895, 'learning_rate': 0.25175313282776207, 'max_depth': 74, 'min_data_in_leaf': 14, 'num_leaves': 1885} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4796203426029224, 'lambda_l2': 0.32067825492982466, 'learning_rate': 0.1291980050566776, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 149} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4188345554749888, 'lambda_l2': 0.0014906609680879757, 'learning_rate': 0.7420274941525108, 'max_depth': 94, 'min_data_in_leaf': 9, 'num_leaves': 997} : acc= 52.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.45682922889914895, 'lambda_l2': 0.09295511319156671, 'learning_rate': 0.1554640424825174, 'max_depth': 80, 'min_data_in_leaf': 30, 'num_leaves': 605} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.603385773468929, 'lambda_l2': 0.8779028407285498, 'learning_rate': 0.30122577819173346, 'max_depth': 78, 'min_data_in_leaf': 25, 'num_leaves': 1807} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.623857692614276, 'lambda_l2': 1.338953582294892, 'learning_rate': 0.499471356601679, 'max_depth': 88, 'min_data_in_leaf': 4, 'num_leaves': 2132} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5679755884863792, 'lambda_l2': 0.7156425227433856, 'learning_rate': 0.33805593540752915, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 1436} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6251434486982778, 'lambda_l2': 0.5257843945368091, 'learning_rate': 0.4336400315710648, 'max_depth': 85, 'min_data_in_leaf': 10, 'num_leaves': 2041} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.521362307775732, 'lambda_l2': 0.6510443172704192, 'learning_rate': 0.2195388052542788, 'max_depth': 69, 'min_data_in_leaf': 14, 'num_leaves': 1550} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.47486026216140964, 'lambda_l2': 0.19366459668773842, 'learning_rate': 0.1964294554760011, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 51} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.44585385124328164, 'lambda_l2': 0.00565466343230323, 'learning_rate': 0.11249469372667349, 'max_depth': 83, 'min_data_in_leaf': 32, 'num_leaves': 536} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5829997639101088, 'lambda_l2': 0.4084546616542952, 'learning_rate': 0.3467432910158658, 'max_depth': 75, 'min_data_in_leaf': 22, 'num_leaves': 3472} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4922615918537158, 'lambda_l2': 0.2332856405298134, 'learning_rate': 0.18088972969433856, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 427} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5913016428993362, 'lambda_l2': 1.1019039164424285, 'learning_rate': 0.28512949213962796, 'max_depth': 73, 'min_data_in_leaf': 20, 'num_leaves': 1818} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5380425952357095, 'lambda_l2': 0.8255863865310566, 'learning_rate': 0.3969686046491997, 'max_depth': 78, 'min_data_in_leaf': 15, 'num_leaves': 1736} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5010641328000337, 'lambda_l2': 0.1405683530915195, 'learning_rate': 0.08403632410898067, 'max_depth': 81, 'min_data_in_leaf': 28, 'num_leaves': 660} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6428923566128679, 'lambda_l2': 0.47790652866210703, 'learning_rate': 0.6352167902397274, 'max_depth': 85, 'min_data_in_leaf': 9, 'num_leaves': 2276} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4697933696485714, 'lambda_l2': 0.33318578431784057, 'learning_rate': 0.14712118963551757, 'max_depth': 93, 'min_data_in_leaf': 13, 'num_leaves': 184} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5296494602015714, 'lambda_l2': 0.7403301619993619, 'learning_rate': 0.24235071070898803, 'max_depth': 87, 'min_data_in_leaf': 26, 'num_leaves': 1342} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5717683137294873, 'lambda_l2': 0.5855544029347297, 'learning_rate': 0.3737373931355654, 'max_depth': 82, 'min_data_in_leaf': 24, 'num_leaves': 2222} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5034300183993394, 'lambda_l2': 0.24865004018418801, 'learning_rate': 0.13440517434450355, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 316} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.38619877111252493, 'lambda_l2': 0.14640241068330156, 'learning_rate': 0.5671240119697112, 'max_depth': 98, 'min_data_in_leaf': 9, 'num_leaves': 916} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6170034915530924, 'lambda_l2': 0.9304935143710961, 'learning_rate': 0.5095178319288121, 'max_depth': 51, 'min_data_in_leaf': 6, 'num_leaves': 2187} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5250141540387747, 'lambda_l2': 1.1687432781106595, 'learning_rate': 0.21887896910432408, 'max_depth': 62, 'min_data_in_leaf': 18, 'num_leaves': 1649} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6501691278029302, 'lambda_l2': 0.9736526271048989, 'learning_rate': 0.4633151803826706, 'max_depth': 90, 'min_data_in_leaf': 4, 'num_leaves': 2393} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3614320085128584, 'lambda_l2': 0.19385881364642674, 'learning_rate': 0.6549859236182909, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 762} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4404758116073836, 'lambda_l2': 0.38363407451020803, 'learning_rate': 0.169579025686297, 'max_depth': 92, 'min_data_in_leaf': 14, 'num_leaves': 395} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.38565084297806096, 'lambda_l2': 0.09586568205673812, 'learning_rate': 0.74908016349457, 'max_depth': 96, 'min_data_in_leaf': 97, 'num_leaves': 1061} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.47448131044407615, 'lambda_l2': 0.3048301640791908, 'learning_rate': 0.12202538339216061, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 250} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4648330976880774, 'lambda_l2': 0.40781458644597496, 'learning_rate': 0.1892152598436637, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 509} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6669811625956537, 'lambda_l2': 1.3805575835698445, 'learning_rate': 0.41067486787645374, 'max_depth': 2, 'min_data_in_leaf': 2, 'num_leaves': 2069} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4230081335501252, 'lambda_l2': 0.2620692364768472, 'learning_rate': 0.8355378422913737, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 1232} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5989351357411501, 'lambda_l2': 0.638579130023387, 'learning_rate': 0.26954893579459344, 'max_depth': 84, 'min_data_in_leaf': 8, 'num_leaves': 1951} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45081975838856314, 'lambda_l2': 0.11150445140528849, 'learning_rate': 0.04158303023942877, 'max_depth': 77, 'min_data_in_leaf': 22, 'num_leaves': 686} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5479123560001697, 'lambda_l2': 0.5231044940040855, 'learning_rate': 0.3117666076029092, 'max_depth': 80, 'min_data_in_leaf': 19, 'num_leaves': 1440} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5607180957562303, 'lambda_l2': 0.6745986865393333, 'learning_rate': 0.3521804466625712, 'max_depth': 75, 'min_data_in_leaf': 11, 'num_leaves': 2003} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4951511935860907, 'lambda_l2': 0.3419248149898012, 'learning_rate': 0.09970978081922148, 'max_depth': 93, 'min_data_in_leaf': 16, 'num_leaves': 128} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6728850418573682, 'lambda_l2': 1.2227694360408736, 'learning_rate': 0.5846218283767174, 'max_depth': 86, 'min_data_in_leaf': 5, 'num_leaves': 2356} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.720998617261047, 'lambda_l2': 1.0504605331414953, 'learning_rate': 0.4509490183731958, 'max_depth': 88, 'min_data_in_leaf': 1, 'num_leaves': 2269} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4887888339682499, 'lambda_l2': 0.06580600370999201, 'learning_rate': 0.15766622698780716, 'max_depth': 81, 'min_data_in_leaf': 29, 'num_leaves': 578} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5166067750759331, 'lambda_l2': 0.777404674590413, 'learning_rate': 0.2145600317766011, 'max_depth': 72, 'min_data_in_leaf': 11, 'num_leaves': 1683} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.42293307578003037, 'lambda_l2': 0.1756916126877996, 'learning_rate': 0.07647391506550327, 'max_depth': 84, 'min_data_in_leaf': 25, 'num_leaves': 623} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5972806259503811, 'lambda_l2': 0.4844770564938146, 'learning_rate': 0.5223388384397137, 'max_depth': 89, 'min_data_in_leaf': 8, 'num_leaves': 2315} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5901173741222973, 'lambda_l2': 0.855969928729298, 'learning_rate': 0.2891635982920864, 'max_depth': 76, 'min_data_in_leaf': 18, 'num_leaves': 1741} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.536772900540049, 'lambda_l2': 0.6030592084838694, 'learning_rate': 0.2257785952794791, 'max_depth': 67, 'min_data_in_leaf': 15, 'num_leaves': 1837} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4388721220633816, 'lambda_l2': 0.37367419895154025, 'learning_rate': 0.17324871180272475, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 338} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.551268598311343, 'lambda_l2': 3.1518429380387607, 'learning_rate': 0.3695922859239072, 'max_depth': 8, 'min_data_in_leaf': 5, 'num_leaves': 2153} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5687998083335135, 'lambda_l2': 4.514434216890354, 'learning_rate': 0.29329425896187417, 'max_depth': 74, 'min_data_in_leaf': 22, 'num_leaves': 1923} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4592268353316299, 'lambda_l2': 0.05415012920465012, 'learning_rate': 0.07001454075227495, 'max_depth': 82, 'min_data_in_leaf': 24, 'num_leaves': 480} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.48244256675185504, 'lambda_l2': 0.08706311699482494, 'learning_rate': 0.16116224339462185, 'max_depth': 85, 'min_data_in_leaf': 26, 'num_leaves': 765} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7538464473598829, 'lambda_l2': 1.2013646121484989, 'learning_rate': 0.01108067861715989, 'max_depth': 4, 'min_data_in_leaf': 6, 'num_leaves': 2193} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.49749292239475157, 'lambda_l2': 0.200464587926989, 'learning_rate': 0.10481091186386746, 'max_depth': 80, 'min_data_in_leaf': 30, 'num_leaves': 682} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.26626674483818363, 'lambda_l2': 0.24736687073010746, 'learning_rate': 0.4617706594707818, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 988} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3950105485250802, 'lambda_l2': 0.011305274565822636, 'learning_rate': 0.12653022220706464, 'max_depth': 77, 'min_data_in_leaf': 35, 'num_leaves': 544} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4968029962090263, 'lambda_l2': 0.7032676054576812, 'learning_rate': 0.24705619660081948, 'max_depth': 55, 'min_data_in_leaf': 20, 'num_leaves': 1904} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.44556249163246336, 'lambda_l2': 0.0283233182400053, 'learning_rate': 0.05018066322346605, 'max_depth': 83, 'min_data_in_leaf': 28, 'num_leaves': 628} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6337543178389945, 'lambda_l2': 0.5481832640034032, 'learning_rate': 0.3494226141469506, 'max_depth': 48, 'min_data_in_leaf': 8, 'num_leaves': 2051} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5778789953893521, 'lambda_l2': 0.9299384728173852, 'learning_rate': 0.2851400299452795, 'max_depth': 78, 'min_data_in_leaf': 17, 'num_leaves': 1463} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.0007331425542381753, 'lambda_l2': 0.4370936542107167, 'learning_rate': 0.41262986725068046, 'max_depth': 90, 'min_data_in_leaf': 10, 'num_leaves': 2248} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5542747283206199, 'lambda_l2': 0.7525412147606149, 'learning_rate': 0.23690933973179693, 'max_depth': 86, 'min_data_in_leaf': 14, 'num_leaves': 1275} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4642702372508155, 'lambda_l2': 0.17576497446551959, 'learning_rate': 0.08891459014356351, 'max_depth': 83, 'min_data_in_leaf': 21, 'num_leaves': 497} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6152876190155324, 'lambda_l2': 1.0431845736745058, 'learning_rate': 0.19760625864784842, 'max_depth': 87, 'min_data_in_leaf': 89, 'num_leaves': 1328} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5965020673413377, 'lambda_l2': 0.5551108230816126, 'learning_rate': 0.9857993264962713, 'max_depth': 93, 'min_data_in_leaf': 6, 'num_leaves': 2086} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5140906985067442, 'lambda_l2': 0.3148534807773663, 'learning_rate': 0.14283602945285997, 'max_depth': 91, 'min_data_in_leaf': 13, 'num_leaves': 230} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5454326799741104, 'lambda_l2': 0.8310026809426035, 'learning_rate': 0.3222561333497513, 'max_depth': 73, 'min_data_in_leaf': 18, 'num_leaves': 1594} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5814220480438701, 'lambda_l2': 0.4688737209914938, 'learning_rate': 0.25095398163193006, 'max_depth': 78, 'min_data_in_leaf': 12, 'num_leaves': 1705} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3434813618441934, 'lambda_l2': 0.013633549736212003, 'learning_rate': 0.6671958244626911, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 871} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4043095373837568, 'lambda_l2': 0.10346552149714015, 'learning_rate': 0.13392050931169794, 'max_depth': 80, 'min_data_in_leaf': 24, 'num_leaves': 717} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.37337236322256695, 'lambda_l2': 0.028837126833136995, 'learning_rate': 0.11151520732548348, 'max_depth': 85, 'min_data_in_leaf': 32, 'num_leaves': 391} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3135681931240182, 'lambda_l2': 0.2533267555608379, 'learning_rate': 0.5969684662686716, 'max_depth': 100, 'min_data_in_leaf': 1, 'num_leaves': 1096} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5478223651815829, 'lambda_l2': 0.6847343671342174, 'learning_rate': 0.20091385512560395, 'max_depth': 63, 'min_data_in_leaf': 11, 'num_leaves': 1889} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2988002853665738, 'lambda_l2': 0.38394730792250403, 'learning_rate': 0.7270260368487356, 'max_depth': 98, 'min_data_in_leaf': 8, 'num_leaves': 1149} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7043319238126837, 'lambda_l2': 2.91298315867492, 'learning_rate': 0.3790136696206026, 'max_depth': 88, 'min_data_in_leaf': 6, 'num_leaves': 1390} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5344984772894277, 'lambda_l2': 0.646115033865774, 'learning_rate': 0.2633833553211211, 'max_depth': 59, 'min_data_in_leaf': 16, 'num_leaves': 1553} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6181571251868891, 'lambda_l2': 0.9509626640439784, 'learning_rate': 0.3019869117357264, 'max_depth': 77, 'min_data_in_leaf': 20, 'num_leaves': 1496} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.21899337411557834, 'lambda_l2': 3.4911164161051222, 'learning_rate': 0.3389586546513952, 'max_depth': 74, 'min_data_in_leaf': 14, 'num_leaves': 1828} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.566042182822648, 'lambda_l2': 0.49110036437144755, 'learning_rate': 0.48787527270800585, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 2491} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6653188416433864, 'lambda_l2': 1.4778974746333116, 'learning_rate': 0.5281362296254959, 'max_depth': 7, 'min_data_in_leaf': 3, 'num_leaves': 2320} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6488689698312589, 'lambda_l2': 1.3288938921349758, 'learning_rate': 0.8647802829383463, 'max_depth': 94, 'min_data_in_leaf': 9, 'num_leaves': 2049} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6226994332277939, 'lambda_l2': 0.5653704683796191, 'learning_rate': 0.3981906087402924, 'max_depth': 69, 'min_data_in_leaf': 5, 'num_leaves': 2156} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6959164848187448, 'lambda_l2': 1.1909142945005784, 'learning_rate': 0.4365383743349285, 'max_depth': 89, 'min_data_in_leaf': 61, 'num_leaves': 2408} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6065554940115236, 'lambda_l2': 0.7442874244273873, 'learning_rate': 0.561031499227724, 'max_depth': 71, 'min_data_in_leaf': 8, 'num_leaves': 1968} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7637785006791273, 'lambda_l2': 1.1465909196763024, 'learning_rate': 0.006148772175812787, 'max_depth': 2, 'min_data_in_leaf': 72, 'num_leaves': 2459} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6404126971643542, 'lambda_l2': 0.4296176539073108, 'learning_rate': 0.22512991328491502, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 2204} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4742931715187441, 'lambda_l2': 0.1926001547644162, 'learning_rate': 0.09317012567282645, 'max_depth': 84, 'min_data_in_leaf': 27, 'num_leaves': 450} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.45214142231490434, 'lambda_l2': 0.09703359917156977, 'learning_rate': 0.14571573673684957, 'max_depth': 80, 'min_data_in_leaf': 23, 'num_leaves': 745} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5254021792482702, 'lambda_l2': 0.5953578444073311, 'learning_rate': 0.3518471028435071, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2086} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.11350433934554488, 'lambda_l2': 0.8173397039977907, 'learning_rate': 0.19781585859068265, 'max_depth': 75, 'min_data_in_leaf': 20, 'num_leaves': 1743} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4253640328533861, 'lambda_l2': 0.3217187623876231, 'learning_rate': 0.1841801688732863, 'max_depth': 91, 'min_data_in_leaf': 10, 'num_leaves': 154} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4770574895093281, 'lambda_l2': 0.013466783714530695, 'learning_rate': 0.05829230761857294, 'max_depth': 82, 'min_data_in_leaf': 34, 'num_leaves': 564} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.19268520719178656, 'lambda_l2': 0.2629107880914192, 'learning_rate': 0.573235796558475, 'max_depth': 96, 'min_data_in_leaf': 2, 'num_leaves': 1069} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5847211806466895, 'lambda_l2': 0.8864629294693709, 'learning_rate': 0.0013240276319289584, 'max_depth': 79, 'min_data_in_leaf': 13, 'num_leaves': 1612} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3649424286392362, 'lambda_l2': 0.1820559962616059, 'learning_rate': 0.7782675182066366, 'max_depth': 98, 'min_data_in_leaf': 4, 'num_leaves': 968} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5076723529813758, 'lambda_l2': 1.0082414358047327, 'learning_rate': 0.301843092036001, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 3254} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4226492949723615, 'lambda_l2': 0.02956069545526078, 'learning_rate': 0.11588737313710079, 'max_depth': 83, 'min_data_in_leaf': 25, 'num_leaves': 809} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5107706621583236, 'lambda_l2': 0.44758501951338847, 'learning_rate': 0.26371455160275037, 'max_depth': 67, 'min_data_in_leaf': 15, 'num_leaves': 1532} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4415455832052697, 'lambda_l2': 0.34135164923627936, 'learning_rate': 0.13512911393253157, 'max_depth': 94, 'min_data_in_leaf': 10, 'num_leaves': 110} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.3968596810509904, 'lambda_l2': 0.35409038375588886, 'learning_rate': 0.16346141535512912, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 299} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5649576445051437, 'lambda_l2': 0.7609637226696723, 'learning_rate': 0.215574338288083, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 3139} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5219521491794802, 'lambda_l2': 0.6948517434888717, 'learning_rate': 0.2312563369539521, 'max_depth': 64, 'min_data_in_leaf': 17, 'num_leaves': 1775} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.32418354853491993, 'lambda_l2': 0.23760911058486572, 'learning_rate': 0.6779600484260127, 'max_depth': 100, 'min_data_in_leaf': 7, 'num_leaves': 820} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6021386537603312, 'lambda_l2': 0.5201002273822705, 'learning_rate': 0.4682820999650628, 'max_depth': 50, 'min_data_in_leaf': 6, 'num_leaves': 2235} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5291073060118084, 'lambda_l2': 0.5514995450083477, 'learning_rate': 0.2667275796108684, 'max_depth': 61, 'min_data_in_leaf': 10, 'num_leaves': 1869} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7221910579517313, 'lambda_l2': 1.0801607963494901, 'learning_rate': 0.3903016444705393, 'max_depth': 9, 'min_data_in_leaf': 4, 'num_leaves': 2359} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.49177848928023893, 'lambda_l2': 0.5996194822841759, 'learning_rate': 0.19206389983471056, 'max_depth': 57, 'min_data_in_leaf': 13, 'num_leaves': 1672} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6303796525626709, 'lambda_l2': 0.4160242605415736, 'learning_rate': 0.43357821422906256, 'max_depth': 53, 'min_data_in_leaf': 8, 'num_leaves': 1943} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4991012294499494, 'lambda_l2': 0.6617597918101272, 'learning_rate': 0.23636060868985687, 'max_depth': 55, 'min_data_in_leaf': 19, 'num_leaves': 1632} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7378945591581035, 'lambda_l2': 1.5851824902591785, 'learning_rate': 0.4965679147738264, 'max_depth': 4, 'min_data_in_leaf': 2, 'num_leaves': 2559} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6514070269193069, 'lambda_l2': 0.880912376616267, 'learning_rate': 0.3420440908084031, 'max_depth': 88, 'min_data_in_leaf': 1, 'num_leaves': 2014} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5327797179877753, 'lambda_l2': 0.4841618630477122, 'learning_rate': 0.26239722024144235, 'max_depth': 70, 'min_data_in_leaf': 15, 'num_leaves': 1465} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5674066048160585, 'lambda_l2': 0.7433295683512, 'learning_rate': 0.3173933972022607, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 1232} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5598516531144989, 'lambda_l2': 0.43556230602708473, 'learning_rate': 0.3101322282957995, 'max_depth': 76, 'min_data_in_leaf': 20, 'num_leaves': 2955} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.24621623912270835, 'lambda_l2': 1.01007982833431, 'learning_rate': 0.3801424706775935, 'max_depth': 80, 'min_data_in_leaf': 22, 'num_leaves': 3072} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.505212329228308, 'lambda_l2': 0.6069623507714544, 'learning_rate': 0.16491271060743168, 'max_depth': 67, 'min_data_in_leaf': 10, 'num_leaves': 1787} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6180503468265717, 'lambda_l2': 0.3151476390608545, 'learning_rate': 0.6085838281098933, 'max_depth': 92, 'min_data_in_leaf': 6, 'num_leaves': 2133} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.46223874251720404, 'lambda_l2': 0.0014599576440672002, 'learning_rate': 0.12963525752675994, 'max_depth': 94, 'min_data_in_leaf': 16, 'num_leaves': 53} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6829020481001801, 'lambda_l2': 0.7930166616386637, 'learning_rate': 0.01889740279597434, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 2014} : acc= 57.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5920403314147197, 'lambda_l2': 0.9317350741143893, 'learning_rate': 0.2949682388417982, 'max_depth': 73, 'min_data_in_leaf': 18, 'num_leaves': 1534} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.413096913325993, 'lambda_l2': 0.11699563623927628, 'learning_rate': 0.10214060766317865, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 59} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5440454977896869, 'lambda_l2': 0.4929785137344195, 'learning_rate': 0.41667050914139203, 'max_depth': 86, 'min_data_in_leaf': 5, 'num_leaves': 2283} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6995165022499215, 'lambda_l2': 1.9688353793920914, 'learning_rate': 0.013119730741966727, 'max_depth': 5, 'min_data_in_leaf': 3, 'num_leaves': 2372} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6657204833988715, 'lambda_l2': 2.500780357816893, 'learning_rate': 0.2231572303287665, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 2108} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5831000933113623, 'lambda_l2': 0.3997399342197889, 'learning_rate': 0.281708116857496, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2844} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9745230667546647, 'lambda_l2': 1.5030715946440871, 'learning_rate': 0.4948073940683202, 'max_depth': 92, 'min_data_in_leaf': 53, 'num_leaves': 2426} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.1622522412779296, 'lambda_l2': 1.1187960009882034, 'learning_rate': 0.33813649020372527, 'max_depth': 72, 'min_data_in_leaf': 12, 'num_leaves': 1384} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4399402304072524, 'lambda_l2': 0.13943404863323303, 'learning_rate': 0.07736410960142341, 'max_depth': 82, 'min_data_in_leaf': 27, 'num_leaves': 639} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5544173675729789, 'lambda_l2': 0.6744509976792528, 'learning_rate': 0.19857043338237948, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 3388} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5792003282438969, 'lambda_l2': 0.8619604920668305, 'learning_rate': 0.18142871558942839, 'max_depth': 78, 'min_data_in_leaf': 17, 'num_leaves': 1942} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.08149873694671478, 'lambda_l2': 0.2845066852438253, 'learning_rate': 0.03141322888244822, 'max_depth': 81, 'min_data_in_leaf': 22, 'num_leaves': 2765} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7399238176750373, 'lambda_l2': 2.3488309845630693, 'learning_rate': 0.9958154768811581, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 2613} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6062752528386569, 'lambda_l2': 1.2990831451431246, 'learning_rate': 0.3627781203918194, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 1318} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5470403348378979, 'lambda_l2': 0.5259234539422225, 'learning_rate': 0.273786263951833, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 1737} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3890722735105364, 'lambda_l2': 0.2415799381587183, 'learning_rate': 0.16229804318498953, 'max_depth': 95, 'min_data_in_leaf': 9, 'num_leaves': 216} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8645473537378725, 'lambda_l2': 0.9792427233287356, 'learning_rate': 0.8456979429998671, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 2546} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.2795763438507991, 'lambda_l2': 0.3774086106992711, 'learning_rate': 0.2353324380968187, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 1126} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4760079507608268, 'lambda_l2': 0.17084377653851968, 'learning_rate': 0.08729788605684448, 'max_depth': 84, 'min_data_in_leaf': 31, 'num_leaves': 446} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5139858491022231, 'lambda_l2': 0.7849582205759924, 'learning_rate': 0.2017090170008721, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 1383} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9408052247706868, 'lambda_l2': 1.6243738591123518, 'learning_rate': 0.6564985535634774, 'max_depth': 10, 'min_data_in_leaf': 5, 'num_leaves': 2316} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.35461221272114957, 'lambda_l2': 0.07939798576379012, 'learning_rate': 0.11108669813379965, 'max_depth': 82, 'min_data_in_leaf': 37, 'num_leaves': 582} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5260750401911791, 'lambda_l2': 0.6091649596775702, 'learning_rate': 0.0031998812084163527, 'max_depth': 89, 'min_data_in_leaf': 23, 'num_leaves': 927} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48346237030457095, 'lambda_l2': 0.006752273735439613, 'learning_rate': 0.0792409074909819, 'max_depth': 86, 'min_data_in_leaf': 25, 'num_leaves': 378} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6737479976707745, 'lambda_l2': 3.64475047520136, 'learning_rate': 0.5348451606813958, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 2205} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6382732899398239, 'lambda_l2': 0.47494799982624847, 'learning_rate': 0.4758494039283675, 'max_depth': 26, 'min_data_in_leaf': 8, 'num_leaves': 2032} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7216192943746085, 'lambda_l2': 2.6326553338188425, 'learning_rate': 0.4109347100541442, 'max_depth': 6, 'min_data_in_leaf': 3, 'num_leaves': 2509} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.18992955052441843, 'lambda_l2': 0.815494043539892, 'learning_rate': 0.3030815083311699, 'max_depth': 79, 'min_data_in_leaf': 19, 'num_leaves': 1869} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8221644020064903, 'lambda_l2': 1.2398677263494668, 'learning_rate': 0.5843941800728366, 'max_depth': 98, 'min_data_in_leaf': 5, 'num_leaves': 2220} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6209387312297739, 'lambda_l2': 0.6917542769311416, 'learning_rate': 0.7738068814625826, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 2177} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4388518405918884, 'lambda_l2': 0.15760457998287886, 'learning_rate': 0.1499657969032606, 'max_depth': 81, 'min_data_in_leaf': 25, 'num_leaves': 555} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.38209429737929873, 'lambda_l2': 0.16666265954289688, 'learning_rate': 0.06649070631933776, 'max_depth': 83, 'min_data_in_leaf': 39, 'num_leaves': 501} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.278257241629964, 'lambda_l2': 0.2717660011203707, 'learning_rate': 0.6673025374862479, 'max_depth': 100, 'min_data_in_leaf': 56, 'num_leaves': 917} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801713296635058, 'lambda_l2': 0.0011950086169767657, 'learning_rate': 0.2225685608971581, 'max_depth': 74, 'min_data_in_leaf': 16, 'num_leaves': 1623} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.32958233004567594, 'lambda_l2': 0.26501872927406417, 'learning_rate': 0.7772981769387096, 'max_depth': 98, 'min_data_in_leaf': 4, 'num_leaves': 1044} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4548052430236286, 'lambda_l2': 0.6021397994044828, 'learning_rate': 0.2511640072739019, 'max_depth': 61, 'min_data_in_leaf': 11, 'num_leaves': 1698} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4158428928960605, 'lambda_l2': 0.09902486100929339, 'learning_rate': 0.1498605346432042, 'max_depth': 87, 'min_data_in_leaf': 29, 'num_leaves': 773} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.47144998159832896, 'lambda_l2': 0.02932929648931437, 'learning_rate': 0.09473517957681905, 'max_depth': 85, 'min_data_in_leaf': 28, 'num_leaves': 702} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7553446886561158, 'lambda_l2': 2.0677711150894043, 'learning_rate': 0.4324850968026681, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 2326} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5542489272494523, 'lambda_l2': 0.4644993573852003, 'learning_rate': 0.34880705351322033, 'max_depth': 23, 'min_data_in_leaf': 9, 'num_leaves': 2093} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4036870019095745, 'lambda_l2': 0.3360685198469861, 'learning_rate': 0.1701590723332484, 'max_depth': 90, 'min_data_in_leaf': 15, 'num_leaves': 189} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.023711123310773075, 'lambda_l2': 1.007444211456123, 'learning_rate': 0.3478857207435349, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 3006} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4282760734486154, 'lambda_l2': 0.34423082057235155, 'learning_rate': 0.04531223037654599, 'max_depth': 93, 'min_data_in_leaf': 77, 'num_leaves': 318} : acc= 59.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.33661814960688496, 'lambda_l2': 0.005600449001764318, 'learning_rate': 0.8872742423187993, 'max_depth': 100, 'min_data_in_leaf': 46, 'num_leaves': 846} : acc= 47.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5366150623744712, 'lambda_l2': 1.1351869177142682, 'learning_rate': 0.3161017078771439, 'max_depth': 77, 'min_data_in_leaf': 12, 'num_leaves': 1482} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.2536821193081677, 'lambda_l2': 0.25178234238939723, 'learning_rate': 0.005254483492492624, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 1220} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3631346761344652, 'lambda_l2': 0.20000200641832067, 'learning_rate': 0.5203898119965484, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 848} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6028586036589098, 'lambda_l2': 0.00013942474432615537, 'learning_rate': 0.4142259732777699, 'max_depth': 69, 'min_data_in_leaf': 43, 'num_leaves': 1952} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9926551088444338, 'lambda_l2': 0.9599224047540087, 'learning_rate': 0.390422778208046, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 2382} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4963479360437759, 'lambda_l2': 0.3701006616359326, 'learning_rate': 0.13028337663627382, 'max_depth': 94, 'min_data_in_leaf': 13, 'num_leaves': 58} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4637621331857726, 'lambda_l2': 0.15449957842124185, 'learning_rate': 0.12010416355766189, 'max_depth': 91, 'min_data_in_leaf': 81, 'num_leaves': 395} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6548622607209817, 'lambda_l2': 0.6889097062825531, 'learning_rate': 0.2789300131059912, 'max_depth': 46, 'min_data_in_leaf': 9, 'num_leaves': 2033} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7874902786562177, 'lambda_l2': 1.80125620955542, 'learning_rate': 0.6042116930853383, 'max_depth': 14, 'min_data_in_leaf': 1, 'num_leaves': 2636} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.48950911641921463, 'lambda_l2': 0.3449757479851027, 'learning_rate': 0.17828953941518733, 'max_depth': 96, 'min_data_in_leaf': 14, 'num_leaves': 326} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5677568626833069, 'lambda_l2': 0.5388722808536375, 'learning_rate': 0.1956138629656735, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2709} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.23321577912834476, 'lambda_l2': 1.4011314757439357, 'learning_rate': 0.23721542524627456, 'max_depth': 73, 'min_data_in_leaf': 20, 'num_leaves': 1875} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5226053964256034, 'lambda_l2': 0.7283535893273347, 'learning_rate': 0.27222072517361795, 'max_depth': 80, 'min_data_in_leaf': 23, 'num_leaves': 1335} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8916184722647993, 'lambda_l2': 2.784269799640054, 'learning_rate': 0.4637177873447103, 'max_depth': 12, 'min_data_in_leaf': 5, 'num_leaves': 2272} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.14046860659828392, 'lambda_l2': 0.8240345955303522, 'learning_rate': 0.20701184438312398, 'max_depth': 84, 'min_data_in_leaf': 16, 'num_leaves': 1187} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.43214609351547284, 'lambda_l2': 0.4106241915040101, 'learning_rate': 0.1254112862117323, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 242} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3797163867868734, 'lambda_l2': 0.006100022631598034, 'learning_rate': 0.15718229816647272, 'max_depth': 94, 'min_data_in_leaf': 9, 'num_leaves': 139} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4965178717409201, 'lambda_l2': 0.5129835035857196, 'learning_rate': 0.23682659031958483, 'max_depth': 65, 'min_data_in_leaf': 14, 'num_leaves': 1666} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.44948177291178615, 'lambda_l2': 0.24791874423684557, 'learning_rate': 0.025195187233351585, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 270} : acc= 60.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4054655835888149, 'lambda_l2': 0.1756230371719631, 'learning_rate': 0.9599646979832291, 'max_depth': 95, 'min_data_in_leaf': 3, 'num_leaves': 1004} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5948797908426746, 'lambda_l2': 0.537672331785181, 'learning_rate': 0.35803710962528745, 'max_depth': 56, 'min_data_in_leaf': 6, 'num_leaves': 2148} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6135551051160759, 'lambda_l2': 0.6301200623128256, 'learning_rate': 0.5158678342623443, 'max_depth': 59, 'min_data_in_leaf': 50, 'num_leaves': 1996} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5631442150567132, 'lambda_l2': 1.0662700782507624, 'learning_rate': 0.3227397920180724, 'max_depth': 70, 'min_data_in_leaf': 17, 'num_leaves': 1764} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6803292478116791, 'lambda_l2': 0.4036627334682275, 'learning_rate': 0.4647750459143918, 'max_depth': 49, 'min_data_in_leaf': 8, 'num_leaves': 2056} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6360857575266179, 'lambda_l2': 3.3666299379541527, 'learning_rate': 0.3950159189236178, 'max_depth': 89, 'min_data_in_leaf': 6, 'num_leaves': 2135} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5398743531523174, 'lambda_l2': 0.8507497426238408, 'learning_rate': 0.20993334142462813, 'max_depth': 75, 'min_data_in_leaf': 19, 'num_leaves': 1523} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6546721465468922, 'lambda_l2': 0.6082909315143763, 'learning_rate': 0.2812118699662033, 'max_depth': 52, 'min_data_in_leaf': 12, 'num_leaves': 2250} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5125168186851901, 'lambda_l2': 0.7515146324385089, 'learning_rate': 0.19241877023280396, 'max_depth': 65, 'min_data_in_leaf': 16, 'num_leaves': 1848} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5163242321873678, 'lambda_l2': 0.9451508249939691, 'learning_rate': 0.2370380482616428, 'max_depth': 62, 'min_data_in_leaf': 10, 'num_leaves': 1446} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.46010544892141847, 'lambda_l2': 0.2578426848418589, 'learning_rate': 0.036236194633828635, 'max_depth': 92, 'min_data_in_leaf': 14, 'num_leaves': 131} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.3480830842921047, 'lambda_l2': 0.10086443952670565, 'learning_rate': 0.6759623795925667, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 980} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8348233421090985, 'lambda_l2': 1.2373180071897534, 'learning_rate': 0.5473305523386397, 'max_depth': 7, 'min_data_in_leaf': 1, 'num_leaves': 2444} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4782369243098788, 'lambda_l2': 0.12554571600997627, 'learning_rate': 0.1642762876744842, 'max_depth': 80, 'min_data_in_leaf': 26, 'num_leaves': 631} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5928936167585406, 'lambda_l2': 0.8701940405070316, 'learning_rate': 0.3188120997827372, 'max_depth': 78, 'min_data_in_leaf': 59, 'num_leaves': 1801} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4802560272075319, 'lambda_l2': 0.019532732222160707, 'learning_rate': 0.05822722090203238, 'max_depth': 80, 'min_data_in_leaf': 27, 'num_leaves': 492} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8502608113245165, 'lambda_l2': 2.992544874564426, 'learning_rate': 0.43735030087132953, 'max_depth': 1, 'min_data_in_leaf': 4, 'num_leaves': 2350} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6371897522806167, 'lambda_l2': 0.4476401288120262, 'learning_rate': 0.5903251634516447, 'max_depth': 90, 'min_data_in_leaf': 8, 'num_leaves': 1938} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3023829110490562, 'lambda_l2': 3.8197204921679586, 'learning_rate': 0.9014721913177618, 'max_depth': 99, 'min_data_in_leaf': 1, 'num_leaves': 1099} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.06021626738934446, 'lambda_l2': 0.6152424331853255, 'learning_rate': 0.2880310842970171, 'max_depth': 76, 'min_data_in_leaf': 21, 'num_leaves': 1741} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4283993521332687, 'lambda_l2': 0.28876485221905007, 'learning_rate': 0.13850210395999468, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 55} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.547059795507372, 'lambda_l2': 0.7239508092334006, 'learning_rate': 0.2451380232809903, 'max_depth': 82, 'min_data_in_leaf': 23, 'num_leaves': 3270} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6080007044027772, 'lambda_l2': 0.4693543741990854, 'learning_rate': 0.3766187363188999, 'max_depth': 54, 'min_data_in_leaf': 7, 'num_leaves': 2161} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5296360855454149, 'lambda_l2': 0.6682489142109457, 'learning_rate': 0.19578832829079162, 'max_depth': 61, 'min_data_in_leaf': 15, 'num_leaves': 1280} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3772149627231993, 'lambda_l2': 0.1833762484094445, 'learning_rate': 0.730978470372338, 'max_depth': 97, 'min_data_in_leaf': 3, 'num_leaves': 932} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5760852922451504, 'lambda_l2': 1.0727773171840322, 'learning_rate': 0.26104382198399323, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 2788} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4588558815104844, 'lambda_l2': 0.01582384224459384, 'learning_rate': 0.06622983236635917, 'max_depth': 82, 'min_data_in_leaf': 31, 'num_leaves': 691} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8036454757329603, 'lambda_l2': 1.5284809086417361, 'learning_rate': 0.3645164552822374, 'max_depth': 4, 'min_data_in_leaf': 5, 'num_leaves': 2442} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5295462178383876, 'lambda_l2': 0.3795628632598015, 'learning_rate': 0.18046781996180583, 'max_depth': 68, 'min_data_in_leaf': 11, 'num_leaves': 1533} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.32356079108904523, 'lambda_l2': 0.0036585803024922203, 'learning_rate': 0.692931911203353, 'max_depth': 96, 'min_data_in_leaf': 9, 'num_leaves': 1164} : acc= 53.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7833567096716536, 'lambda_l2': 1.4205805248283954, 'learning_rate': 0.43366976771177584, 'max_depth': 1, 'min_data_in_leaf': 5, 'num_leaves': 2544} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4176207042293198, 'lambda_l2': 0.0797654236833007, 'learning_rate': 0.0769822469307719, 'max_depth': 86, 'min_data_in_leaf': 29, 'num_leaves': 565} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.44634556578090956, 'lambda_l2': 0.014680591143355126, 'learning_rate': 0.11256648988840523, 'max_depth': 71, 'min_data_in_leaf': 34, 'num_leaves': 481} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4960329984197216, 'lambda_l2': 0.5600473464451614, 'learning_rate': 0.25734572712811227, 'max_depth': 68, 'min_data_in_leaf': 15, 'num_leaves': 1556} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.48913174721662706, 'lambda_l2': 0.47355423137231745, 'learning_rate': 0.21989811814883115, 'max_depth': 72, 'min_data_in_leaf': 10, 'num_leaves': 1670} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.39650443471341446, 'lambda_l2': 0.28922566356743856, 'learning_rate': 0.09329627693551125, 'max_depth': 93, 'min_data_in_leaf': 17, 'num_leaves': 344} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5835470500927099, 'lambda_l2': 0.9042170621439878, 'learning_rate': 0.3323608579772986, 'max_depth': 75, 'min_data_in_leaf': 21, 'num_leaves': 1617} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.17183587405885936, 'lambda_l2': 0.2444902690421289, 'learning_rate': 0.5069316803530393, 'max_depth': 100, 'min_data_in_leaf': 1, 'num_leaves': 775} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6671855195231107, 'lambda_l2': 0.7554845404667793, 'learning_rate': 0.6101452109131776, 'max_depth': 20, 'min_data_in_leaf': 12, 'num_leaves': 1959} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.47555289887769536, 'lambda_l2': 0.0024287440888656198, 'learning_rate': 0.14813436724242524, 'max_depth': 91, 'min_data_in_leaf': 18, 'num_leaves': 175} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5043478017097087, 'lambda_l2': 0.18377149867272077, 'learning_rate': 0.10255700793862663, 'max_depth': 83, 'min_data_in_leaf': 33, 'num_leaves': 657} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5610819125841824, 'lambda_l2': 1.1849493543067884, 'learning_rate': 0.32810737941749624, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 2637} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.35532583152517205, 'lambda_l2': 0.013409866895229645, 'learning_rate': 0.12583821426747044, 'max_depth': 79, 'min_data_in_leaf': 27, 'num_leaves': 591} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5500779540408606, 'lambda_l2': 2.1676560062090524, 'learning_rate': 0.29707682008074315, 'max_depth': 78, 'min_data_in_leaf': 12, 'num_leaves': 1833} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.520462057164419, 'lambda_l2': 1.0256143558488027, 'learning_rate': 0.2058757337590395, 'max_depth': 85, 'min_data_in_leaf': 24, 'num_leaves': 3075} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5853828049191383, 'lambda_l2': 0.8706228099512379, 'learning_rate': 0.17747484752044748, 'max_depth': 77, 'min_data_in_leaf': 15, 'num_leaves': 1402} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3711077674679169, 'lambda_l2': 0.0006379868490234974, 'learning_rate': 0.9824064592216453, 'max_depth': 100, 'min_data_in_leaf': 66, 'num_leaves': 912} : acc= 45.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6918408792281094, 'lambda_l2': 1.2730314048507, 'learning_rate': 0.4687035660609514, 'max_depth': 16, 'min_data_in_leaf': 7, 'num_leaves': 2283} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5145133827806682, 'lambda_l2': 0.37567268674340765, 'learning_rate': 0.21487859529459802, 'max_depth': 93, 'min_data_in_leaf': 9, 'num_leaves': 404} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4760267041973432, 'lambda_l2': 0.3745459393047382, 'learning_rate': 0.25038474112574177, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 291} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4388186675191126, 'lambda_l2': 0.537240989584618, 'learning_rate': 0.4171821083483862, 'max_depth': 94, 'min_data_in_leaf': 13, 'num_leaves': 825} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5395501027621529, 'lambda_l2': 0.6668299629066303, 'learning_rate': 0.2956253003740005, 'max_depth': 56, 'min_data_in_leaf': 10, 'num_leaves': 1933} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.415824141529762, 'lambda_l2': 0.27976816420796435, 'learning_rate': 0.17746603772555, 'max_depth': 96, 'min_data_in_leaf': 4, 'num_leaves': 734} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4585605354301702, 'lambda_l2': 0.48104012962778775, 'learning_rate': 0.4915253498829127, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 1020} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4972637582737517, 'lambda_l2': 0.4258733505518355, 'learning_rate': 0.22275157162309575, 'max_depth': 84, 'min_data_in_leaf': 11, 'num_leaves': 245} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5058708763275134, 'lambda_l2': 0.08511194746311733, 'learning_rate': 0.14084829877134183, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 473} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.56104582315832, 'lambda_l2': 0.7626312463765539, 'learning_rate': 0.3614770526450296, 'max_depth': 50, 'min_data_in_leaf': 9, 'num_leaves': 2022} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.41543688612763996, 'lambda_l2': 0.2757617380476507, 'learning_rate': 0.4310911353233721, 'max_depth': 98, 'min_data_in_leaf': 2, 'num_leaves': 828} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5438613257122565, 'lambda_l2': 0.6754049873467932, 'learning_rate': 0.2954089399914882, 'max_depth': 47, 'min_data_in_leaf': 8, 'num_leaves': 1921} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5371194362547729, 'lambda_l2': 0.8180913858071472, 'learning_rate': 0.27186618261951795, 'max_depth': 67, 'min_data_in_leaf': 16, 'num_leaves': 1560} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5741481336901471, 'lambda_l2': 0.6231491831807803, 'learning_rate': 0.37416937907237485, 'max_depth': 57, 'min_data_in_leaf': 6, 'num_leaves': 1799} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4448320593426906, 'lambda_l2': 0.3884887322152982, 'learning_rate': 0.5788782772166581, 'max_depth': 87, 'min_data_in_leaf': 12, 'num_leaves': 1290} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3985602983196753, 'lambda_l2': 0.18885122646998603, 'learning_rate': 0.44627204206415577, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 1125} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5181546575753594, 'lambda_l2': 0.9416079709827931, 'learning_rate': 0.26342213059123454, 'max_depth': 64, 'min_data_in_leaf': 13, 'num_leaves': 1735} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4781687041161157, 'lambda_l2': 0.5107361624228637, 'learning_rate': 0.16669650124599356, 'max_depth': 92, 'min_data_in_leaf': 4, 'num_leaves': 393} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6899637599794868, 'lambda_l2': 1.1186368460271332, 'learning_rate': 0.3346722002677368, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 2213} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.511428900240434, 'lambda_l2': 0.31779206401900695, 'learning_rate': 0.15709168810213756, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 319} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5640355425682783, 'lambda_l2': 0.7549613526335214, 'learning_rate': 0.24046635779422415, 'max_depth': 71, 'min_data_in_leaf': 16, 'num_leaves': 1671} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.2920665207449712, 'lambda_l2': 0.1829140945558862, 'learning_rate': 0.697608955648057, 'max_depth': 96, 'min_data_in_leaf': 2, 'num_leaves': 1060} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4864938431970526, 'lambda_l2': 0.13397278943447544, 'learning_rate': 0.14898323021032037, 'max_depth': 74, 'min_data_in_leaf': 21, 'num_leaves': 646} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4663842764828201, 'lambda_l2': 0.5393507002627886, 'learning_rate': 0.19707921446168392, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 178} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5314759957767015, 'lambda_l2': 0.36327003726717405, 'learning_rate': 0.21937017975161963, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 416} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6184221451798533, 'lambda_l2': 0.1142484954069041, 'learning_rate': 0.12977214684264404, 'max_depth': 83, 'min_data_in_leaf': 23, 'num_leaves': 527} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6071225044080866, 'lambda_l2': 0.10593978957504475, 'learning_rate': 0.14780228815115098, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 586} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5010060256857432, 'lambda_l2': 0.22536072988298222, 'learning_rate': 0.11043727609406406, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 698} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.09725949453873739, 'lambda_l2': 0.4665348383178109, 'learning_rate': 0.0010698031652555816, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 78} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8752744202844918, 'lambda_l2': 0.5643397106688447, 'learning_rate': 0.2958920666199052, 'max_depth': 91, 'min_data_in_leaf': 5, 'num_leaves': 229} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.481176480287738, 'lambda_l2': 0.2995399608118018, 'learning_rate': 0.18641845060711543, 'max_depth': 81, 'min_data_in_leaf': 23, 'num_leaves': 558} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5999577175773837, 'lambda_l2': 0.9649018701445988, 'learning_rate': 0.38837477785882957, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 2493} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5600145887160446, 'lambda_l2': 0.8038092607434352, 'learning_rate': 0.2539986145699345, 'max_depth': 70, 'min_data_in_leaf': 11, 'num_leaves': 1770} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.46358129950563814, 'lambda_l2': 0.16231112996402144, 'learning_rate': 0.1190231253880941, 'max_depth': 74, 'min_data_in_leaf': 18, 'num_leaves': 486} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4291031142264676, 'lambda_l2': 0.41766943462621037, 'learning_rate': 0.5388122592687169, 'max_depth': 95, 'min_data_in_leaf': 4, 'num_leaves': 770} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5361206389479799, 'lambda_l2': 0.6408004372863823, 'learning_rate': 0.2981902552836767, 'max_depth': 77, 'min_data_in_leaf': 15, 'num_leaves': 1606} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9198655513878649, 'lambda_l2': 0.4041140131298544, 'learning_rate': 0.18081232063707003, 'max_depth': 94, 'min_data_in_leaf': 7, 'num_leaves': 52} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.509501933577289, 'lambda_l2': 0.5838272920497855, 'learning_rate': 0.20936110601802058, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 323} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.40051678452852757, 'lambda_l2': 0.316854158311068, 'learning_rate': 0.6212398339595627, 'max_depth': 99, 'min_data_in_leaf': 3, 'num_leaves': 945} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3494209915666754, 'lambda_l2': 0.23363244598067406, 'learning_rate': 0.49806019975250887, 'max_depth': 80, 'min_data_in_leaf': 8, 'num_leaves': 894} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6304637594722133, 'lambda_l2': 0.720183937760871, 'learning_rate': 0.33478138851411793, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 2675} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5497636539190855, 'lambda_l2': 0.00582566382764119, 'learning_rate': 0.15746212702544374, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 663} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5238232525311403, 'lambda_l2': 0.33759452641062054, 'learning_rate': 0.24733706746845957, 'max_depth': 86, 'min_data_in_leaf': 10, 'num_leaves': 158} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6316766890254214, 'lambda_l2': 0.9047779032615971, 'learning_rate': 0.38200597009095455, 'max_depth': 28, 'min_data_in_leaf': 14, 'num_leaves': 2568} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7191456120071553, 'lambda_l2': 1.692257659845854, 'learning_rate': 0.4082635435910008, 'max_depth': 1, 'min_data_in_leaf': 6, 'num_leaves': 2717} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6825058665972025, 'lambda_l2': 1.1460620793707632, 'learning_rate': 0.3543563831213338, 'max_depth': 79, 'min_data_in_leaf': 8, 'num_leaves': 2102} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.226494944242364, 'lambda_l2': 0.4691416390094254, 'learning_rate': 0.4409150389031401, 'max_depth': 100, 'min_data_in_leaf': 17, 'num_leaves': 1019} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5121594858936762, 'lambda_l2': 0.5704817499852184, 'learning_rate': 0.18468065231962727, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 125} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5880258413217319, 'lambda_l2': 0.8501742572087806, 'learning_rate': 0.3196144967489031, 'max_depth': 77, 'min_data_in_leaf': 17, 'num_leaves': 1442} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.621707654240913, 'lambda_l2': 1.0446096849679813, 'learning_rate': 0.35267414413046866, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 2389} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.45051938712904943, 'lambda_l2': 0.21394551829784658, 'learning_rate': 0.5365855665529063, 'max_depth': 93, 'min_data_in_leaf': 9, 'num_leaves': 1220} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5025119713389732, 'lambda_l2': 0.4812247570124913, 'learning_rate': 0.26545197998420494, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 401} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5768576330205548, 'lambda_l2': 0.6848859295444027, 'learning_rate': 0.28010313455503655, 'max_depth': 69, 'min_data_in_leaf': 11, 'num_leaves': 1863} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.38125913038218034, 'lambda_l2': 0.08857373383001982, 'learning_rate': 0.08960089956004037, 'max_depth': 96, 'min_data_in_leaf': 21, 'num_leaves': 717} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9073813683402314, 'lambda_l2': 0.10366000665565944, 'learning_rate': 0.1475273320564356, 'max_depth': 81, 'min_data_in_leaf': 24, 'num_leaves': 2451} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5473105439703674, 'lambda_l2': 0.331837016504854, 'learning_rate': 0.2251589554142162, 'max_depth': 91, 'min_data_in_leaf': 16, 'num_leaves': 312} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4096401382726904, 'lambda_l2': 0.2502160121488215, 'learning_rate': 0.4799714614961945, 'max_depth': 100, 'min_data_in_leaf': 2, 'num_leaves': 1114} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7081288777288318, 'lambda_l2': 1.2781094081369164, 'learning_rate': 0.4106486902091984, 'max_depth': 8, 'min_data_in_leaf': 1, 'num_leaves': 2246} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.42747466109715215, 'lambda_l2': 0.0887680662668684, 'learning_rate': 0.13140374520977938, 'max_depth': 94, 'min_data_in_leaf': 19, 'num_leaves': 776} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4495716790247998, 'lambda_l2': 0.3824071867689646, 'learning_rate': 0.7907454518279394, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 951} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7588698104789492, 'lambda_l2': 0.6927740374334329, 'learning_rate': 0.29894446164827454, 'max_depth': 64, 'min_data_in_leaf': 6, 'num_leaves': 2104} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5748012975236657, 'lambda_l2': 0.9651270186294726, 'learning_rate': 0.24586470124095464, 'max_depth': 66, 'min_data_in_leaf': 10, 'num_leaves': 1901} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.534119971226443, 'lambda_l2': 0.8353231034869297, 'learning_rate': 0.31354341244272416, 'max_depth': 69, 'min_data_in_leaf': 12, 'num_leaves': 1795} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5606549244254873, 'lambda_l2': 0.651179103647822, 'learning_rate': 0.21820728462572, 'max_depth': 73, 'min_data_in_leaf': 15, 'num_leaves': 1823} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7372479632878892, 'lambda_l2': 1.3717060493498359, 'learning_rate': 0.3849326914357124, 'max_depth': 59, 'min_data_in_leaf': 5, 'num_leaves': 2317} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.26969907490648903, 'lambda_l2': 0.0023466537941982946, 'learning_rate': 0.4713150191242586, 'max_depth': 99, 'min_data_in_leaf': 7, 'num_leaves': 1154} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5977232882705928, 'lambda_l2': 0.5805080744234966, 'learning_rate': 0.25683507145966694, 'max_depth': 55, 'min_data_in_leaf': 8, 'num_leaves': 2105} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.47254288105943376, 'lambda_l2': 0.17418251126715611, 'learning_rate': 0.09830642527008472, 'max_depth': 76, 'min_data_in_leaf': 26, 'num_leaves': 603} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.654039841871484, 'lambda_l2': 1.0309846189106018, 'learning_rate': 0.5476293601329439, 'max_depth': 85, 'min_data_in_leaf': 10, 'num_leaves': 2849} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4931001209508472, 'lambda_l2': 0.4955250669594553, 'learning_rate': 0.20630083569650387, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 414} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6434407947612053, 'lambda_l2': 0.7623736537543415, 'learning_rate': 0.3526798206613536, 'max_depth': 43, 'min_data_in_leaf': 6, 'num_leaves': 1958} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4877850682029144, 'lambda_l2': 0.40040297040722717, 'learning_rate': 0.1693724641004869, 'max_depth': 92, 'min_data_in_leaf': 5, 'num_leaves': 219} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.20807741074084632, 'lambda_l2': 0.2796042946111918, 'learning_rate': 0.8187399822934399, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 882} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8435469724275774, 'lambda_l2': 0.0771665874411111, 'learning_rate': 0.11094352969376439, 'max_depth': 82, 'min_data_in_leaf': 22, 'num_leaves': 525} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.45638186155407046, 'lambda_l2': 0.5307813272674613, 'learning_rate': 0.1893417183614927, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 235} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9733490770906951, 'lambda_l2': 1.1321116027806248, 'learning_rate': 0.31609601744564575, 'max_depth': 12, 'min_data_in_leaf': 9, 'num_leaves': 2223} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4340227895007762, 'lambda_l2': 0.4390647229857001, 'learning_rate': 0.6679682546035112, 'max_depth': 62, 'min_data_in_leaf': 4, 'num_leaves': 1261} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5367591607258843, 'lambda_l2': 0.0007175422445893365, 'learning_rate': 0.22344163698857675, 'max_depth': 90, 'min_data_in_leaf': 8, 'num_leaves': 70} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5827548647132071, 'lambda_l2': 0.8428930001936012, 'learning_rate': 0.2746767285125493, 'max_depth': 72, 'min_data_in_leaf': 12, 'num_leaves': 1680} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4702995507588388, 'lambda_l2': 0.19755113737595306, 'learning_rate': 0.16254376663221187, 'max_depth': 79, 'min_data_in_leaf': 20, 'num_leaves': 477} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5627877169883458, 'lambda_l2': 0.5834308016402332, 'learning_rate': 0.3900620065210564, 'max_depth': 52, 'min_data_in_leaf': 10, 'num_leaves': 2014} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6272586473370229, 'lambda_l2': 0.7435235669984922, 'learning_rate': 0.4298263052746837, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2943} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.38694659501272466, 'lambda_l2': 0.2503647530390693, 'learning_rate': 0.19568129955037297, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 425} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.507479370687624, 'lambda_l2': 0.44186961716188716, 'learning_rate': 0.13093574658010834, 'max_depth': 91, 'min_data_in_leaf': 10, 'num_leaves': 340} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.48353375103176366, 'lambda_l2': 0.0021909775740016624, 'learning_rate': 0.15103732857771052, 'max_depth': 74, 'min_data_in_leaf': 20, 'num_leaves': 1381} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5912904966413887, 'lambda_l2': 0.8677975595996645, 'learning_rate': 0.3151847577794251, 'max_depth': 68, 'min_data_in_leaf': 17, 'num_leaves': 1713} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5239036249928412, 'lambda_l2': 0.921823788129902, 'learning_rate': 0.23811383870622452, 'max_depth': 65, 'min_data_in_leaf': 18, 'num_leaves': 1532} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3329745174944446, 'lambda_l2': 0.006831485656715625, 'learning_rate': 0.04554641070123626, 'max_depth': 94, 'min_data_in_leaf': 23, 'num_leaves': 722} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5464234375793766, 'lambda_l2': 0.3624481777083955, 'learning_rate': 0.1869613129174353, 'max_depth': 87, 'min_data_in_leaf': 12, 'num_leaves': 260} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.42069004802160753, 'lambda_l2': 0.3103333100955162, 'learning_rate': 0.5626346133454914, 'max_depth': 100, 'min_data_in_leaf': 6, 'num_leaves': 1278} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.37378638637368855, 'lambda_l2': 0.14220422429017043, 'learning_rate': 0.6282964296707776, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 647} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.49526785404049434, 'lambda_l2': 0.14853708710766467, 'learning_rate': 0.07615836725050122, 'max_depth': 78, 'min_data_in_leaf': 19, 'num_leaves': 1577} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.52590695470792, 'lambda_l2': 0.004389466533314436, 'learning_rate': 0.10596337797637634, 'max_depth': 79, 'min_data_in_leaf': 21, 'num_leaves': 562} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.36118435591164455, 'lambda_l2': 0.5190827209686562, 'learning_rate': 0.4798539251952513, 'max_depth': 81, 'min_data_in_leaf': 7, 'num_leaves': 1330} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9486687914560983, 'lambda_l2': 0.0069456153824214925, 'learning_rate': 0.121347886363071, 'max_depth': 5, 'min_data_in_leaf': 30, 'num_leaves': 2351} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.45470494667795436, 'lambda_l2': 0.23150877144348075, 'learning_rate': 0.022331264104131852, 'max_depth': 75, 'min_data_in_leaf': 25, 'num_leaves': 1448} : acc= 55.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4382041932397035, 'lambda_l2': 0.10697739869653392, 'learning_rate': 0.1370369866169778, 'max_depth': 90, 'min_data_in_leaf': 26, 'num_leaves': 444} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3076626681567495, 'lambda_l2': 0.31912099881727524, 'learning_rate': 0.7628130834755148, 'max_depth': 97, 'min_data_in_leaf': 4, 'num_leaves': 837} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6713045505538529, 'lambda_l2': 1.2174171564672478, 'learning_rate': 0.3554522428863805, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 2071} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4098955371701152, 'lambda_l2': 2.2395372938355393, 'learning_rate': 0.64357757433022, 'max_depth': 93, 'min_data_in_leaf': 15, 'num_leaves': 920} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6836298662360606, 'lambda_l2': 1.7615051943191788, 'learning_rate': 0.5450957482354467, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 2310} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7364011110303288, 'lambda_l2': 1.6957854670619286, 'learning_rate': 0.37576952282299436, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 2453} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6631895748398247, 'lambda_l2': 1.9032041451036052, 'learning_rate': 0.416158713714972, 'max_depth': 82, 'min_data_in_leaf': 14, 'num_leaves': 2188} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.25017896530491956, 'lambda_l2': 0.40379812442103824, 'learning_rate': 0.46845608044329196, 'max_depth': 94, 'min_data_in_leaf': 12, 'num_leaves': 966} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6110887628027448, 'lambda_l2': 1.273101566418771, 'learning_rate': 0.3377855054405389, 'max_depth': 79, 'min_data_in_leaf': 17, 'num_leaves': 2041} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.599943640371245, 'lambda_l2': 1.0041495954024597, 'learning_rate': 0.27348713468620817, 'max_depth': 72, 'min_data_in_leaf': 15, 'num_leaves': 1895} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4022161417592848, 'lambda_l2': 0.2546419877868089, 'learning_rate': 0.58492844453886, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 1042} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6503345936505658, 'lambda_l2': 1.3783828428361276, 'learning_rate': 0.31142405142420077, 'max_depth': 76, 'min_data_in_leaf': 19, 'num_leaves': 1995} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5756797965643591, 'lambda_l2': 1.172720930923421, 'learning_rate': 0.2706528308990158, 'max_depth': 70, 'min_data_in_leaf': 14, 'num_leaves': 1828} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5555105206962485, 'lambda_l2': 0.5838812258349466, 'learning_rate': 0.18017900984815394, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 199} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.12374251905219011, 'lambda_l2': 0.09306721159886766, 'learning_rate': 0.08801247502710825, 'max_depth': 81, 'min_data_in_leaf': 23, 'num_leaves': 527} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7655179358849676, 'lambda_l2': 1.622406572603391, 'learning_rate': 0.5103750084247979, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 2411} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.700829957150513, 'lambda_l2': 1.5351659501633739, 'learning_rate': 0.3792339868096886, 'max_depth': 85, 'min_data_in_leaf': 9, 'num_leaves': 2165} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5965472981528903, 'lambda_l2': 0.9377845700533367, 'learning_rate': 0.24895633746155318, 'max_depth': 64, 'min_data_in_leaf': 18, 'num_leaves': 1909} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6244206197296944, 'lambda_l2': 0.6592525284198718, 'learning_rate': 0.2205580290823547, 'max_depth': 75, 'min_data_in_leaf': 13, 'num_leaves': 2010} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6963455964766039, 'lambda_l2': 1.5560920981382012, 'learning_rate': 0.3531294310884792, 'max_depth': 88, 'min_data_in_leaf': 9, 'num_leaves': 2257} : acc= 73.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.705431129455475, 'lambda_l2': 1.8799307217875576, 'learning_rate': 0.42197355676315107, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 2260} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5937985753002442, 'lambda_l2': 1.5671445954823855, 'learning_rate': 0.33166006127444403, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2195} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7159157796490795, 'lambda_l2': 2.0149106022537517, 'learning_rate': 0.3673695920798739, 'max_depth': 85, 'min_data_in_leaf': 14, 'num_leaves': 2103} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6725972122689848, 'lambda_l2': 1.8136938765761754, 'learning_rate': 0.46061020255055884, 'max_depth': 90, 'min_data_in_leaf': 13, 'num_leaves': 2301} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6797222376628108, 'lambda_l2': 1.4495785543543822, 'learning_rate': 0.35113204216166244, 'max_depth': 83, 'min_data_in_leaf': 9, 'num_leaves': 2087} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6515943079358043, 'lambda_l2': 1.6542034786672117, 'learning_rate': 0.3020463549057252, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 2365} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6661456102934015, 'lambda_l2': 1.4786616951115061, 'learning_rate': 0.5335220469775963, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 2202} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7065787498651472, 'lambda_l2': 1.713671163321414, 'learning_rate': 0.43732182810951875, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 2270} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7380161234978605, 'lambda_l2': 2.1306466364250474, 'learning_rate': 0.28498846912782005, 'max_depth': 80, 'min_data_in_leaf': 21, 'num_leaves': 2095} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6460799136902894, 'lambda_l2': 1.7504057340055712, 'learning_rate': 0.39372207342260035, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2150} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6846255759421337, 'lambda_l2': 1.3979603403548195, 'learning_rate': 0.014694365156049508, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 2529} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6391697417255553, 'lambda_l2': 2.3469912563851074, 'learning_rate': 0.7110171689432858, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 2339} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6973718548287865, 'lambda_l2': 1.9360236220140186, 'learning_rate': 0.23962304766283807, 'max_depth': 86, 'min_data_in_leaf': 10, 'num_leaves': 2052} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7285621122253522, 'lambda_l2': 1.5003140888618363, 'learning_rate': 0.3306790984647964, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 2404} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6371999577091901, 'lambda_l2': 1.606707395719516, 'learning_rate': 0.28467630881717104, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 2288} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6667300443112858, 'lambda_l2': 1.9324807783806044, 'learning_rate': 0.009236325505949534, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 2179} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6179524125396161, 'lambda_l2': 2.534721075959235, 'learning_rate': 0.479723824472652, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 2484} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6750498992828273, 'lambda_l2': 2.044086657324992, 'learning_rate': 0.4099462916313873, 'max_depth': 80, 'min_data_in_leaf': 19, 'num_leaves': 2048} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7225801970468058, 'lambda_l2': 1.323174197970099, 'learning_rate': 0.6038015008694262, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 1974} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6207968312160527, 'lambda_l2': 2.2198022726730295, 'learning_rate': 0.3593510358599507, 'max_depth': 78, 'min_data_in_leaf': 6, 'num_leaves': 2243} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6540702565437451, 'lambda_l2': 2.4429123158640698, 'learning_rate': 0.5184028148634895, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 2380} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7636705594178576, 'lambda_l2': 1.7993747261572421, 'learning_rate': 0.2263410503340847, 'max_depth': 89, 'min_data_in_leaf': 10, 'num_leaves': 2163} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9990985506753585, 'lambda_l2': 1.4608239421228588, 'learning_rate': 0.29189610647448805, 'max_depth': 93, 'min_data_in_leaf': 12, 'num_leaves': 2106} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6133120419145274, 'lambda_l2': 1.3647160663619446, 'learning_rate': 0.25153768861755293, 'max_depth': 81, 'min_data_in_leaf': 17, 'num_leaves': 1958} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7443710795468137, 'lambda_l2': 1.8198318873386923, 'learning_rate': 0.8860931548507347, 'max_depth': 86, 'min_data_in_leaf': 9, 'num_leaves': 2509} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6918222030313836, 'lambda_l2': 1.6156175052768027, 'learning_rate': 0.43239378403840567, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 2257} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.663673000345524, 'lambda_l2': 1.3210811728739498, 'learning_rate': 0.027794324072772728, 'max_depth': 90, 'min_data_in_leaf': 100, 'num_leaves': 2031} : acc= 57.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7123141704953324, 'lambda_l2': 1.249078152236137, 'learning_rate': 0.3376424634243086, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 2604} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6503172873575944, 'lambda_l2': 1.5661399160873195, 'learning_rate': 0.20936408760250155, 'max_depth': 78, 'min_data_in_leaf': 14, 'num_leaves': 2326} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6199804928541404, 'lambda_l2': 2.0929534612729666, 'learning_rate': 0.7006819755741163, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 2160} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7968228420013974, 'lambda_l2': 1.4671090332020804, 'learning_rate': 0.6111475114693321, 'max_depth': 92, 'min_data_in_leaf': 15, 'num_leaves': 2429} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7759118881219236, 'lambda_l2': 1.2589926946792385, 'learning_rate': 0.281623579544603, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 2054} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.637107382808854, 'lambda_l2': 1.1557487818943422, 'learning_rate': 0.38183732381254776, 'max_depth': 85, 'min_data_in_leaf': 5, 'num_leaves': 1925} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6889478239064065, 'lambda_l2': 1.7235203974648416, 'learning_rate': 0.5170629227077187, 'max_depth': 83, 'min_data_in_leaf': 24, 'num_leaves': 2463} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6000169748614192, 'lambda_l2': 1.1071032596563732, 'learning_rate': 0.24695412794483967, 'max_depth': 91, 'min_data_in_leaf': 47, 'num_leaves': 2310} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6120831469143627, 'lambda_l2': 1.2059224597327627, 'learning_rate': 0.332810691461828, 'max_depth': 77, 'min_data_in_leaf': 22, 'num_leaves': 1894} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6759720826455687, 'lambda_l2': 1.5973939052387884, 'learning_rate': 0.2169946080990633, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2155} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7209170937724284, 'lambda_l2': 1.119530973813675, 'learning_rate': 0.30259977637296825, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 1999} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6342241917706534, 'lambda_l2': 1.3043221845411785, 'learning_rate': 0.4402449636804295, 'max_depth': 94, 'min_data_in_leaf': 19, 'num_leaves': 2098} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7476358151316659, 'lambda_l2': 1.3889151198459853, 'learning_rate': 0.20061649564135509, 'max_depth': 89, 'min_data_in_leaf': 10, 'num_leaves': 2245} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5762144490016385, 'lambda_l2': 1.322244975725656, 'learning_rate': 0.37302144768756895, 'max_depth': 83, 'min_data_in_leaf': 5, 'num_leaves': 2591} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.813301773566752, 'lambda_l2': 2.672988222597528, 'learning_rate': 0.26467516951679004, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 2231} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6522679507006757, 'lambda_l2': 2.2435312999219885, 'learning_rate': 0.548168021530101, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 2403} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5685710279963785, 'lambda_l2': 2.049794691409218, 'learning_rate': 0.7868874158297594, 'max_depth': 79, 'min_data_in_leaf': 7, 'num_leaves': 2366} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.606881934735072, 'lambda_l2': 1.081524630433878, 'learning_rate': 0.31671741075601334, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 1895} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5906437053598058, 'lambda_l2': 1.4859164500571387, 'learning_rate': 0.4878492277805086, 'max_depth': 82, 'min_data_in_leaf': 92, 'num_leaves': 2009} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6987535216057804, 'lambda_l2': 1.0441192711342586, 'learning_rate': 0.23735655844479106, 'max_depth': 95, 'min_data_in_leaf': 16, 'num_leaves': 2102} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6404993007192549, 'lambda_l2': 1.776314658588778, 'learning_rate': 0.6339083753974737, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 2555} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6683343535689047, 'lambda_l2': 1.2122494812974831, 'learning_rate': 0.1699605304320418, 'max_depth': 85, 'min_data_in_leaf': 21, 'num_leaves': 2454} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.782164961294994, 'lambda_l2': 2.336123622105829, 'learning_rate': 0.41768733857677887, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 2210} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5611214326330292, 'lambda_l2': 1.6866109211613574, 'learning_rate': 0.27743665899470044, 'max_depth': 77, 'min_data_in_leaf': 5, 'num_leaves': 2299} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6306616631512716, 'lambda_l2': 1.4043203509627251, 'learning_rate': 0.35257084560263896, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 1967} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7490462210338649, 'lambda_l2': 1.0359620150290003, 'learning_rate': 0.19780700321423086, 'max_depth': 88, 'min_data_in_leaf': 24, 'num_leaves': 2079} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6963393274099456, 'lambda_l2': 1.1647986242084598, 'learning_rate': 0.41048987631229755, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 1728} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5508425548771256, 'lambda_l2': 1.5580842369907333, 'learning_rate': 0.4731516922085424, 'max_depth': 84, 'min_data_in_leaf': 16, 'num_leaves': 2180} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5885274063615258, 'lambda_l2': 1.9155397698862537, 'learning_rate': 0.23998527728803828, 'max_depth': 90, 'min_data_in_leaf': 6, 'num_leaves': 1824} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7254729882032839, 'lambda_l2': 3.0696238771996316, 'learning_rate': 0.9921209978807529, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 1919} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6746103295549758, 'lambda_l2': 1.870958645702983, 'learning_rate': 0.5862785912236611, 'max_depth': 94, 'min_data_in_leaf': 3, 'num_leaves': 2317} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5729055744670939, 'lambda_l2': 0.789745863361995, 'learning_rate': 0.31249155371973003, 'max_depth': 96, 'min_data_in_leaf': 20, 'num_leaves': 2507} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6113410087455993, 'lambda_l2': 2.8428198727914156, 'learning_rate': 0.7199236997965462, 'max_depth': 80, 'min_data_in_leaf': 40, 'num_leaves': 1849} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5473078808577809, 'lambda_l2': 0.950503813085625, 'learning_rate': 0.20768107920548973, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2125} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.03716384208899148, 'lambda_l2': 1.2236976573347584, 'learning_rate': 0.2722808995004481, 'max_depth': 83, 'min_data_in_leaf': 1, 'num_leaves': 2416} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6551834191148737, 'lambda_l2': 1.6854450881908634, 'learning_rate': 0.17419818260140574, 'max_depth': 73, 'min_data_in_leaf': 18, 'num_leaves': 2007} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.708795469217631, 'lambda_l2': 0.9073230186884016, 'learning_rate': 0.35946963737528487, 'max_depth': 78, 'min_data_in_leaf': 9, 'num_leaves': 2597} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6264539538509424, 'lambda_l2': 1.0728292884001522, 'learning_rate': 0.5169658644920274, 'max_depth': 90, 'min_data_in_leaf': 22, 'num_leaves': 2230} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6009569993049663, 'lambda_l2': 1.433360304398524, 'learning_rate': 0.2314759091001399, 'max_depth': 93, 'min_data_in_leaf': 13, 'num_leaves': 1741} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5804944404677074, 'lambda_l2': 1.0033399375108034, 'learning_rate': 0.3124129102677879, 'max_depth': 88, 'min_data_in_leaf': 6, 'num_leaves': 2313} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5326269688480582, 'lambda_l2': 0.7709243227039833, 'learning_rate': 0.3804918466029555, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 1869} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8138204301637355, 'lambda_l2': 1.236469368895213, 'learning_rate': 0.03988073255706871, 'max_depth': 75, 'min_data_in_leaf': 15, 'num_leaves': 1628} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5604006385443497, 'lambda_l2': 0.6837270213081188, 'learning_rate': 0.44931396284891933, 'max_depth': 86, 'min_data_in_leaf': 8, 'num_leaves': 2400} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7624484734919683, 'lambda_l2': 2.003354109908961, 'learning_rate': 0.8375150621727114, 'max_depth': 91, 'min_data_in_leaf': 4, 'num_leaves': 2130} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.18120157212365207, 'lambda_l2': 1.5307542416328102, 'learning_rate': 0.27520026176176876, 'max_depth': 82, 'min_data_in_leaf': 25, 'num_leaves': 1962} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5259090473351498, 'lambda_l2': 0.847395564086299, 'learning_rate': 0.1918866597146188, 'max_depth': 96, 'min_data_in_leaf': 12, 'num_leaves': 2527} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6512010905218976, 'lambda_l2': 1.359475351734335, 'learning_rate': 0.16355886040934303, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 2182} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7370253627838288, 'lambda_l2': 0.67324603428609, 'learning_rate': 0.558181542640106, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 2052} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6879456125059348, 'lambda_l2': 0.9348492330425293, 'learning_rate': 0.3391765327073792, 'max_depth': 88, 'min_data_in_leaf': 1, 'num_leaves': 2630} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6120930621341918, 'lambda_l2': 0.49740036143229055, 'learning_rate': 0.22691626397310033, 'max_depth': 94, 'min_data_in_leaf': 20, 'num_leaves': 1767} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.09086833413584008, 'lambda_l2': 2.5870891819969604, 'learning_rate': 0.6637274005967406, 'max_depth': 85, 'min_data_in_leaf': 7, 'num_leaves': 2258} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5431472165483145, 'lambda_l2': 2.131253326275338, 'learning_rate': 0.3966814478808085, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 1972} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6671868098480045, 'lambda_l2': 0.5853968019275135, 'learning_rate': 0.26574640839246144, 'max_depth': 89, 'min_data_in_leaf': 4, 'num_leaves': 2369} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9591299407878551, 'lambda_l2': 2.4720940046795032, 'learning_rate': 0.20826699079792224, 'max_depth': 77, 'min_data_in_leaf': 14, 'num_leaves': 1853} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.002675182899468609, 'lambda_l2': 1.1454835113026913, 'learning_rate': 0.44502968836244766, 'max_depth': 95, 'min_data_in_leaf': 22, 'num_leaves': 2062} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5871861729804864, 'lambda_l2': 1.0045912423629353, 'learning_rate': 0.3014014920007104, 'max_depth': 73, 'min_data_in_leaf': 9, 'num_leaves': 1689} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.636583054430045, 'lambda_l2': 0.7910087942387845, 'learning_rate': 0.15749166508012616, 'max_depth': 97, 'min_data_in_leaf': 17, 'num_leaves': 1350} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5187770214606232, 'lambda_l2': 0.6171692140229661, 'learning_rate': 0.482923872980759, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 1212} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7079243277618467, 'lambda_l2': 0.7418417512323026, 'learning_rate': 0.3419367195630445, 'max_depth': 80, 'min_data_in_leaf': 5, 'num_leaves': 2490} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5600871482588212, 'lambda_l2': 1.290243700216159, 'learning_rate': 0.187255176740668, 'max_depth': 86, 'min_data_in_leaf': 28, 'num_leaves': 2125} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.1529594930366019, 'lambda_l2': 1.8544438048843408, 'learning_rate': 0.23978469950455114, 'max_depth': 91, 'min_data_in_leaf': 19, 'num_leaves': 2266} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5074730611379821, 'lambda_l2': 0.8822993762237143, 'learning_rate': 0.3765167142632519, 'max_depth': 88, 'min_data_in_leaf': 7, 'num_leaves': 1498} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5781021611896567, 'lambda_l2': 0.4851801748495416, 'learning_rate': 0.6047767580917656, 'max_depth': 84, 'min_data_in_leaf': 1, 'num_leaves': 1631} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7783373952088185, 'lambda_l2': 0.643906526003593, 'learning_rate': 0.05150386121292542, 'max_depth': 75, 'min_data_in_leaf': 15, 'num_leaves': 1801} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7941792840025601, 'lambda_l2': 1.0863024452764252, 'learning_rate': 0.7311609313072072, 'max_depth': 93, 'min_data_in_leaf': 3, 'num_leaves': 2344} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6279416010501979, 'lambda_l2': 0.4162584975703667, 'learning_rate': 0.28674814580245456, 'max_depth': 90, 'min_data_in_leaf': 54, 'num_leaves': 2202} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5969761670873308, 'lambda_l2': 0.7595659997868927, 'learning_rate': 0.5142202901825739, 'max_depth': 82, 'min_data_in_leaf': 10, 'num_leaves': 1945} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5416117208791713, 'lambda_l2': 0.5402521092537514, 'learning_rate': 0.25143819312690086, 'max_depth': 86, 'min_data_in_leaf': 85, 'num_leaves': 2486} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5078417999425239, 'lambda_l2': 0.33236919083563393, 'learning_rate': 0.14431927564444744, 'max_depth': 97, 'min_data_in_leaf': 24, 'num_leaves': 2032} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6119750243790074, 'lambda_l2': 1.1812870256529273, 'learning_rate': 0.4211142554481093, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2179} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6769777282880287, 'lambda_l2': 0.8976543641264266, 'learning_rate': 0.03193418720073861, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 1903} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5306373669449618, 'lambda_l2': 0.5846427387743449, 'learning_rate': 0.870863465045968, 'max_depth': 80, 'min_data_in_leaf': 17, 'num_leaves': 2653} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5608165839696303, 'lambda_l2': 1.0347526368978657, 'learning_rate': 0.2137232213737251, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 2365} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.06641325344921453, 'lambda_l2': 1.6857223802202457, 'learning_rate': 0.32312130437420283, 'max_depth': 95, 'min_data_in_leaf': 20, 'num_leaves': 1419} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6513317688879908, 'lambda_l2': 0.4469438165186099, 'learning_rate': 0.17809511356572807, 'max_depth': 84, 'min_data_in_leaf': 6, 'num_leaves': 1751} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7516135854654838, 'lambda_l2': 1.504106829159635, 'learning_rate': 0.568234049333233, 'max_depth': 72, 'min_data_in_leaf': 14, 'num_leaves': 1170} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7231743704333362, 'lambda_l2': 0.6974369644404173, 'learning_rate': 0.3678350715992861, 'max_depth': 76, 'min_data_in_leaf': 75, 'num_leaves': 2574} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8539065539401369, 'lambda_l2': 0.3541593350774169, 'learning_rate': 0.27879091135819917, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 2077} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5725862069171267, 'lambda_l2': 0.5361394532477523, 'learning_rate': 0.4512479383846614, 'max_depth': 89, 'min_data_in_leaf': 26, 'num_leaves': 784} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.49077441549546547, 'lambda_l2': 0.8175853453913561, 'learning_rate': 0.16649063054763993, 'max_depth': 86, 'min_data_in_leaf': 79, 'num_leaves': 1491} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6187019504087254, 'lambda_l2': 1.3433831536474534, 'learning_rate': 0.6621637435640702, 'max_depth': 82, 'min_data_in_leaf': 68, 'num_leaves': 2265} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6999227256024576, 'lambda_l2': 0.19350659190186031, 'learning_rate': 0.23781966027690313, 'max_depth': 93, 'min_data_in_leaf': 70, 'num_leaves': 1998} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5154609717092076, 'lambda_l2': 0.44517966283440186, 'learning_rate': 0.3144386960162733, 'max_depth': 90, 'min_data_in_leaf': 22, 'num_leaves': 2408} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5448233168967425, 'lambda_l2': 0.6305557239130131, 'learning_rate': 0.2024204883842394, 'max_depth': 80, 'min_data_in_leaf': 10, 'num_leaves': 1246} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9354184589393547, 'lambda_l2': 0.983265052123307, 'learning_rate': 0.40026412287507407, 'max_depth': 95, 'min_data_in_leaf': 16, 'num_leaves': 1616} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6005347201578682, 'lambda_l2': 0.3221982274137199, 'learning_rate': 0.0023345097101816945, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 617} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8728359583388476, 'lambda_l2': 0.21610308344230308, 'learning_rate': 0.1361461218767917, 'max_depth': 88, 'min_data_in_leaf': 5, 'num_leaves': 1859} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8213675027016833, 'lambda_l2': 0.8372243770312444, 'learning_rate': 0.48343239140205024, 'max_depth': 83, 'min_data_in_leaf': 8, 'num_leaves': 722} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.10806040535355527, 'lambda_l2': 0.7116565485353565, 'learning_rate': 0.9931786935475673, 'max_depth': 77, 'min_data_in_leaf': 18, 'num_leaves': 2134} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6457143737988671, 'lambda_l2': 0.0022442307343631673, 'learning_rate': 0.34410010113786094, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 1334} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.581793226653258, 'lambda_l2': 1.61712962346368, 'learning_rate': 0.26088172115433894, 'max_depth': 97, 'min_data_in_leaf': 15, 'num_leaves': 2453} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9974424912158222, 'lambda_l2': 1.1269818596172336, 'learning_rate': 0.21138927909730865, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2310} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8955224058269268, 'lambda_l2': 0.518703264542279, 'learning_rate': 0.0045268555835925785, 'max_depth': 74, 'min_data_in_leaf': 7, 'num_leaves': 1713} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4878434637295007, 'lambda_l2': 2.262760554516053, 'learning_rate': 0.5646364386814254, 'max_depth': 71, 'min_data_in_leaf': 20, 'num_leaves': 1078} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6253758221013607, 'lambda_l2': 1.4286284996638852, 'learning_rate': 0.2938442385331068, 'max_depth': 93, 'min_data_in_leaf': 2, 'num_leaves': 2158} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6846217014359322, 'lambda_l2': 0.38711239802424213, 'learning_rate': 0.781842115106254, 'max_depth': 87, 'min_data_in_leaf': 42, 'num_leaves': 1960} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.46636072949951407, 'lambda_l2': 0.6112223171185838, 'learning_rate': 0.15322218117517428, 'max_depth': 81, 'min_data_in_leaf': 24, 'num_leaves': 1567} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.531317071473427, 'lambda_l2': 1.2278192782087283, 'learning_rate': 0.18234458609787163, 'max_depth': 84, 'min_data_in_leaf': 9, 'num_leaves': 2232} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5675117117234318, 'lambda_l2': 0.9227373533743404, 'learning_rate': 0.018715977769139348, 'max_depth': 89, 'min_data_in_leaf': 5, 'num_leaves': 1813} : acc= 58.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6644790880818281, 'lambda_l2': 0.2878883685177926, 'learning_rate': 0.2426199167794545, 'max_depth': 95, 'min_data_in_leaf': 37, 'num_leaves': 2070} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5070939264094123, 'lambda_l2': 0.1972545898053857, 'learning_rate': 0.40443924995920755, 'max_depth': 92, 'min_data_in_leaf': 16, 'num_leaves': 2557} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5524588785757498, 'lambda_l2': 1.9789900284088286, 'learning_rate': 0.1257272911167929, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 653} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.738226654952504, 'lambda_l2': 0.46675403684095024, 'learning_rate': 0.9978930901391128, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 366} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5959970468181228, 'lambda_l2': 0.8011769959219406, 'learning_rate': 0.6566163563906523, 'max_depth': 79, 'min_data_in_leaf': 18, 'num_leaves': 2706} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.21402258850780942, 'lambda_l2': 0.11662451150939568, 'learning_rate': 0.33099083316554473, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 855} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.13539592180371385, 'lambda_l2': 0.7259256920099577, 'learning_rate': 0.46357762526835, 'max_depth': 82, 'min_data_in_leaf': 22, 'num_leaves': 1899} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7939385151051837, 'lambda_l2': 0.3267709145030079, 'learning_rate': 0.2770693047142779, 'max_depth': 75, 'min_data_in_leaf': 3, 'num_leaves': 2433} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.47385437215079035, 'lambda_l2': 1.8056275134467468, 'learning_rate': 0.22356414956897003, 'max_depth': 84, 'min_data_in_leaf': 6, 'num_leaves': 1420} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7115587844372286, 'lambda_l2': 0.9974643444029212, 'learning_rate': 0.5073228285539405, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 2311} : acc= 73.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7773243608604921, 'lambda_l2': 1.225544956316963, 'learning_rate': 0.7914941244230066, 'max_depth': 76, 'min_data_in_leaf': 8, 'num_leaves': 2623} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7621860476587672, 'lambda_l2': 1.05562707223157, 'learning_rate': 0.890290911651786, 'max_depth': 79, 'min_data_in_leaf': 14, 'num_leaves': 2529} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7351858823373719, 'lambda_l2': 1.43708049462248, 'learning_rate': 0.7765357723221673, 'max_depth': 94, 'min_data_in_leaf': 28, 'num_leaves': 2508} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8209305648267393, 'lambda_l2': 1.326504628412128, 'learning_rate': 0.5935383001143912, 'max_depth': 96, 'min_data_in_leaf': 19, 'num_leaves': 2655} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8363157853807789, 'lambda_l2': 1.3336719271303015, 'learning_rate': 0.6273352611069434, 'max_depth': 91, 'min_data_in_leaf': 25, 'num_leaves': 2374} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7434065195591681, 'lambda_l2': 1.1238741037819322, 'learning_rate': 0.904302559707582, 'max_depth': 73, 'min_data_in_leaf': 11, 'num_leaves': 2356} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7144702248131336, 'lambda_l2': 1.285987842970418, 'learning_rate': 0.7172878590590596, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 2427} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8045716123706456, 'lambda_l2': 1.1124957393346926, 'learning_rate': 0.6749080428467334, 'max_depth': 92, 'min_data_in_leaf': 17, 'num_leaves': 2610} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8624656548037578, 'lambda_l2': 1.0224409308365299, 'learning_rate': 0.44076081073610895, 'max_depth': 98, 'min_data_in_leaf': 16, 'num_leaves': 2747} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7957428669136446, 'lambda_l2': 0.5567660607150704, 'learning_rate': 0.5315959240094932, 'max_depth': 95, 'min_data_in_leaf': 49, 'num_leaves': 2529} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7642509454136494, 'lambda_l2': 1.1981567454012838, 'learning_rate': 0.5091937587132402, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 2682} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7482689180969183, 'lambda_l2': 1.4622584868992317, 'learning_rate': 0.5322861261692327, 'max_depth': 89, 'min_data_in_leaf': 23, 'num_leaves': 2452} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.722757712730646, 'lambda_l2': 1.009692510478149, 'learning_rate': 0.9168813206733377, 'max_depth': 81, 'min_data_in_leaf': 9, 'num_leaves': 2268} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8377534928094961, 'lambda_l2': 1.5988462339783598, 'learning_rate': 0.37042723328933486, 'max_depth': 100, 'min_data_in_leaf': 58, 'num_leaves': 745} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9216048406585533, 'lambda_l2': 0.6529140307413436, 'learning_rate': 0.7588955907408935, 'max_depth': 93, 'min_data_in_leaf': 6, 'num_leaves': 2303} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8909365885431901, 'lambda_l2': 0.8459922243949592, 'learning_rate': 0.6736558183446205, 'max_depth': 95, 'min_data_in_leaf': 11, 'num_leaves': 2459} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7847309166954692, 'lambda_l2': 0.4472380418044468, 'learning_rate': 0.46112574979551707, 'max_depth': 91, 'min_data_in_leaf': 4, 'num_leaves': 2335} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8771506313360103, 'lambda_l2': 0.7321309758023717, 'learning_rate': 0.5633968017513638, 'max_depth': 98, 'min_data_in_leaf': 9, 'num_leaves': 2724} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6695711079497582, 'lambda_l2': 1.18711006027215, 'learning_rate': 0.9763849909918682, 'max_depth': 79, 'min_data_in_leaf': 63, 'num_leaves': 2203} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.857183258947687, 'lambda_l2': 0.6252045986406142, 'learning_rate': 0.6143891753433145, 'max_depth': 100, 'min_data_in_leaf': 1, 'num_leaves': 55} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7308051499606786, 'lambda_l2': 0.9378429174336864, 'learning_rate': 0.7845318900845306, 'max_depth': 77, 'min_data_in_leaf': 14, 'num_leaves': 2186} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7238930311287716, 'lambda_l2': 1.2487742612802113, 'learning_rate': 0.5042209977811968, 'max_depth': 85, 'min_data_in_leaf': 27, 'num_leaves': 2544} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.771763634533438, 'lambda_l2': 1.0883295934074249, 'learning_rate': 0.8548124419603483, 'max_depth': 82, 'min_data_in_leaf': 7, 'num_leaves': 2110} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.808644976396287, 'lambda_l2': 1.5157127002626387, 'learning_rate': 0.11169047558856884, 'max_depth': 89, 'min_data_in_leaf': 21, 'num_leaves': 490} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7014918877974445, 'lambda_l2': 1.3023854715262653, 'learning_rate': 0.6276463912831807, 'max_depth': 85, 'min_data_in_leaf': 25, 'num_leaves': 2285} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.765689412793436, 'lambda_l2': 1.5666676352121978, 'learning_rate': 0.1728718352540714, 'max_depth': 87, 'min_data_in_leaf': 30, 'num_leaves': 1288} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5124904349656507, 'lambda_l2': 0.5213625015105019, 'learning_rate': 0.4110316417177324, 'max_depth': 98, 'min_data_in_leaf': 12, 'num_leaves': 2394} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.815712743036442, 'lambda_l2': 1.3489740165963657, 'learning_rate': 0.14621686881559873, 'max_depth': 90, 'min_data_in_leaf': 17, 'num_leaves': 814} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7125773793733623, 'lambda_l2': 1.149122215310799, 'learning_rate': 0.011606032974159498, 'max_depth': 84, 'min_data_in_leaf': 21, 'num_leaves': 2563} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.673758336133814, 'lambda_l2': 1.0224886598324596, 'learning_rate': 0.5986760627190715, 'max_depth': 75, 'min_data_in_leaf': 15, 'num_leaves': 2215} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7663378482199582, 'lambda_l2': 0.9184686070007316, 'learning_rate': 0.31493552558598226, 'max_depth': 93, 'min_data_in_leaf': 19, 'num_leaves': 1094} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6986413891941503, 'lambda_l2': 1.202809669047748, 'learning_rate': 0.7318719149730343, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2322} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7063201499766238, 'lambda_l2': 1.453484000184896, 'learning_rate': 0.4919802845050512, 'max_depth': 89, 'min_data_in_leaf': 24, 'num_leaves': 2387} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6484329885184219, 'lambda_l2': 1.0526914697419723, 'learning_rate': 0.9987785070561788, 'max_depth': 82, 'min_data_in_leaf': 26, 'num_leaves': 2512} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.45955512981948987, 'lambda_l2': 0.3785673058245679, 'learning_rate': 0.06573758555747317, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 353} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6970492549117975, 'lambda_l2': 0.9397345729366494, 'learning_rate': 0.3961535043876209, 'max_depth': 91, 'min_data_in_leaf': 18, 'num_leaves': 2251} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8292978507241324, 'lambda_l2': 0.9101734241098638, 'learning_rate': 0.2721990555657995, 'max_depth': 70, 'min_data_in_leaf': 11, 'num_leaves': 907} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.527313307142553, 'lambda_l2': 0.783323471017891, 'learning_rate': 0.3891955002811791, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 449} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7939467225662069, 'lambda_l2': 1.6615140165233795, 'learning_rate': 0.19745689110231965, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 1165} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9093604790246111, 'lambda_l2': 1.4477630227038136, 'learning_rate': 0.34237413916738263, 'max_depth': 86, 'min_data_in_leaf': 9, 'num_leaves': 975} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6826966267347883, 'lambda_l2': 1.268426989368489, 'learning_rate': 0.5311479191907793, 'max_depth': 88, 'min_data_in_leaf': 22, 'num_leaves': 2656} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4812265290333658, 'lambda_l2': 0.5929141833690174, 'learning_rate': 0.43968784815719697, 'max_depth': 98, 'min_data_in_leaf': 1, 'num_leaves': 2818} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7508678496717641, 'lambda_l2': 1.3372871284154586, 'learning_rate': 0.6633019872916542, 'max_depth': 93, 'min_data_in_leaf': 16, 'num_leaves': 2120} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6840942328791145, 'lambda_l2': 1.092394690672454, 'learning_rate': 0.45327743103225365, 'max_depth': 84, 'min_data_in_leaf': 23, 'num_leaves': 2470} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8418196316927364, 'lambda_l2': 0.9748443896338403, 'learning_rate': 0.24250792639888047, 'max_depth': 72, 'min_data_in_leaf': 10, 'num_leaves': 610} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8870186570364526, 'lambda_l2': 1.079529568740226, 'learning_rate': 0.055302494108278824, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 606} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9497064893933488, 'lambda_l2': 0.8378015419710341, 'learning_rate': 0.3019196047322202, 'max_depth': 78, 'min_data_in_leaf': 4, 'num_leaves': 688} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6487518842648112, 'lambda_l2': 4.998891731054398, 'learning_rate': 0.3759468442681232, 'max_depth': 81, 'min_data_in_leaf': 20, 'num_leaves': 2332} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6843459254393837, 'lambda_l2': 1.1517581707105427, 'learning_rate': 0.546219177771791, 'max_depth': 83, 'min_data_in_leaf': 28, 'num_leaves': 2197} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.04730712976367951, 'lambda_l2': 0.23722180733960174, 'learning_rate': 0.12355896332192298, 'max_depth': 97, 'min_data_in_leaf': 12, 'num_leaves': 427} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.742964813544135, 'lambda_l2': 1.2524521002611453, 'learning_rate': 0.3442646306609326, 'max_depth': 91, 'min_data_in_leaf': 32, 'num_leaves': 2436} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6434699977974795, 'lambda_l2': 0.8997672614505849, 'learning_rate': 0.007349864273486682, 'max_depth': 74, 'min_data_in_leaf': 8, 'num_leaves': 2032} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7108949621208598, 'lambda_l2': 1.4218907964584786, 'learning_rate': 0.7791906827497139, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 2622} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6632125942767967, 'lambda_l2': 0.6894749024285426, 'learning_rate': 0.38714073810674815, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2007} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6234350034299936, 'lambda_l2': 0.8146198638561335, 'learning_rate': 0.317955737220423, 'max_depth': 88, 'min_data_in_leaf': 14, 'num_leaves': 2106} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.63403008559966, 'lambda_l2': 0.7926286308710865, 'learning_rate': 0.29006675044197217, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2241} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6639346587879126, 'lambda_l2': 0.7411447155720159, 'learning_rate': 0.34481804642785463, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2066} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6864968337006797, 'lambda_l2': 0.8125373515569141, 'learning_rate': 0.4243143530833778, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2140} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6042676102363294, 'lambda_l2': 1.002895561794447, 'learning_rate': 0.2825068083550647, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 2008} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.719145540550758, 'lambda_l2': 0.9539115355076042, 'learning_rate': 0.3639794878402702, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 1939} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6667628952629384, 'lambda_l2': 0.6358828127774458, 'learning_rate': 0.4492521500216766, 'max_depth': 82, 'min_data_in_leaf': 14, 'num_leaves': 2176} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.628748121760795, 'lambda_l2': 0.8859763624451725, 'learning_rate': 0.25009373700028936, 'max_depth': 88, 'min_data_in_leaf': 10, 'num_leaves': 2058} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7260046642900261, 'lambda_l2': 0.6982788500282202, 'learning_rate': 0.3307595002359756, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 2273} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6075124105751706, 'lambda_l2': 0.5420570661851545, 'learning_rate': 0.4844914198030629, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 2312} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6912897683979191, 'lambda_l2': 0.9963776845543625, 'learning_rate': 0.40150695212730636, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 1928} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6464921670733812, 'lambda_l2': 0.8854847566411896, 'learning_rate': 0.28525149442820286, 'max_depth': 92, 'min_data_in_leaf': 10, 'num_leaves': 2199} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.570673518943256, 'lambda_l2': 0.45792356261967093, 'learning_rate': 0.25957778994295305, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2123} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5888144721761562, 'lambda_l2': 0.7424418405619075, 'learning_rate': 0.3522233870526684, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 2238} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6267844076841375, 'lambda_l2': 1.1236804520887316, 'learning_rate': 0.21602850902430545, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 2354} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.747646809336058, 'lambda_l2': 0.5512088205964779, 'learning_rate': 0.31001436132466154, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 2009} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6641563968001833, 'lambda_l2': 0.6742598958663789, 'learning_rate': 0.39680367120103205, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 2382} : acc= 74.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.708573706209501, 'lambda_l2': 1.0430726038728546, 'learning_rate': 0.5662446237081726, 'max_depth': 79, 'min_data_in_leaf': 17, 'num_leaves': 2585} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6834845390907253, 'lambda_l2': 1.1817930136551549, 'learning_rate': 0.5856486744420242, 'max_depth': 82, 'min_data_in_leaf': 15, 'num_leaves': 2456} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5547855215907677, 'lambda_l2': 0.43643150583148943, 'learning_rate': 0.439285387120466, 'max_depth': 92, 'min_data_in_leaf': 6, 'num_leaves': 2533} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.674786515269088, 'lambda_l2': 0.9145046063454034, 'learning_rate': 0.5065067134547412, 'max_depth': 78, 'min_data_in_leaf': 8, 'num_leaves': 2405} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5864259554051452, 'lambda_l2': 0.3981614079002478, 'learning_rate': 0.4555113597662338, 'max_depth': 94, 'min_data_in_leaf': 6, 'num_leaves': 2453} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.608837286563308, 'lambda_l2': 0.6103685516495843, 'learning_rate': 0.39148374648647183, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 2654} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7861655276020678, 'lambda_l2': 0.49390010942091495, 'learning_rate': 0.24019801774120028, 'max_depth': 77, 'min_data_in_leaf': 9, 'num_leaves': 2373} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6519652246656519, 'lambda_l2': 0.8090081021191946, 'learning_rate': 0.5029037044079763, 'max_depth': 76, 'min_data_in_leaf': 10, 'num_leaves': 2288} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.542757349821801, 'lambda_l2': 0.3492329620190904, 'learning_rate': 0.416719463348687, 'max_depth': 91, 'min_data_in_leaf': 4, 'num_leaves': 2567} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6915420459978605, 'lambda_l2': 0.969791342870575, 'learning_rate': 0.6526224553696615, 'max_depth': 80, 'min_data_in_leaf': 20, 'num_leaves': 2464} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7544968225493773, 'lambda_l2': 0.24662595740811147, 'learning_rate': 0.3367678063635504, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 2745} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7545461682078929, 'lambda_l2': 0.2918747904275706, 'learning_rate': 0.2982538255249343, 'max_depth': 86, 'min_data_in_leaf': 6, 'num_leaves': 2500} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7252964340259551, 'lambda_l2': 0.15916690907544528, 'learning_rate': 0.26453682216142976, 'max_depth': 82, 'min_data_in_leaf': 12, 'num_leaves': 2741} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5828074284114542, 'lambda_l2': 0.6334278294839452, 'learning_rate': 0.3916588831346694, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 2342} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7134923825381165, 'lambda_l2': 0.7277164871333786, 'learning_rate': 0.5663302284518348, 'max_depth': 85, 'min_data_in_leaf': 11, 'num_leaves': 2387} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.701303528429516, 'lambda_l2': 1.1175980270590455, 'learning_rate': 0.4998029354379266, 'max_depth': 87, 'min_data_in_leaf': 5, 'num_leaves': 2277} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6158335712131796, 'lambda_l2': 0.3910539733623757, 'learning_rate': 0.3083849120074195, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 2644} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5702173714854101, 'lambda_l2': 0.5047396243781259, 'learning_rate': 0.22261474683009996, 'max_depth': 91, 'min_data_in_leaf': 3, 'num_leaves': 2464} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6360059030126877, 'lambda_l2': 0.9421734282930809, 'learning_rate': 0.7203061325456644, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2107} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5219959255647743, 'lambda_l2': 0.5580468681742057, 'learning_rate': 0.43059753439702175, 'max_depth': 88, 'min_data_in_leaf': 6, 'num_leaves': 2579} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7788477218829124, 'lambda_l2': 0.001077252891733299, 'learning_rate': 0.19208062340115808, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2701} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6529605195723365, 'lambda_l2': 0.7744448987094705, 'learning_rate': 0.5838763612570931, 'max_depth': 77, 'min_data_in_leaf': 8, 'num_leaves': 2171} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6074814598079619, 'lambda_l2': 0.343090446726364, 'learning_rate': 0.3656875508155985, 'max_depth': 93, 'min_data_in_leaf': 3, 'num_leaves': 2384} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7313605134610969, 'lambda_l2': 1.224493728208654, 'learning_rate': 0.493644010746479, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2409} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6614853785435, 'lambda_l2': 1.0014809455592606, 'learning_rate': 0.626711318032302, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 2286} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6606737069130664, 'lambda_l2': 0.8384903857487381, 'learning_rate': 0.6979757459824708, 'max_depth': 79, 'min_data_in_leaf': 1, 'num_leaves': 2247} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6827284032170466, 'lambda_l2': 1.3195989844377176, 'learning_rate': 0.3609250205393274, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2221} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6947588143592665, 'lambda_l2': 1.1028511097256728, 'learning_rate': 0.47143131440835384, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2564} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6394839212548051, 'lambda_l2': 0.8607686066766831, 'learning_rate': 0.579693329464605, 'max_depth': 74, 'min_data_in_leaf': 10, 'num_leaves': 2126} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7328556484888737, 'lambda_l2': 0.6797413388454568, 'learning_rate': 0.41387617629809953, 'max_depth': 75, 'min_data_in_leaf': 6, 'num_leaves': 2332} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7063098604380884, 'lambda_l2': 1.3882007841047654, 'learning_rate': 0.5329733020372925, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 2363} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7940721724761585, 'lambda_l2': 0.15693096331971312, 'learning_rate': 0.25676223491405015, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 2791} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.652693233461296, 'lambda_l2': 0.828597504994797, 'learning_rate': 0.8763350725989928, 'max_depth': 77, 'min_data_in_leaf': 4, 'num_leaves': 2190} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7409095260735771, 'lambda_l2': 0.10403606817799232, 'learning_rate': 0.22680359110831402, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2482} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.668221803522592, 'lambda_l2': 1.0272154881357223, 'learning_rate': 0.3398838535863962, 'max_depth': 81, 'min_data_in_leaf': 16, 'num_leaves': 2513} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7641182583934972, 'lambda_l2': 0.29990023737919413, 'learning_rate': 0.2746382585121202, 'max_depth': 90, 'min_data_in_leaf': 11, 'num_leaves': 2417} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.719573234965627, 'lambda_l2': 1.198792552078905, 'learning_rate': 0.4301752113597318, 'max_depth': 88, 'min_data_in_leaf': 9, 'num_leaves': 2252} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6318263473397281, 'lambda_l2': 0.7054810927899187, 'learning_rate': 0.6896786235255618, 'max_depth': 78, 'min_data_in_leaf': 5, 'num_leaves': 2053} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7999129739813291, 'lambda_l2': 0.4542511487203309, 'learning_rate': 0.19903343252593078, 'max_depth': 84, 'min_data_in_leaf': 1, 'num_leaves': 2574} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4959608032637577, 'lambda_l2': 0.5137597560857159, 'learning_rate': 0.2818478580207745, 'max_depth': 96, 'min_data_in_leaf': 7, 'num_leaves': 2605} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7771281588685893, 'lambda_l2': 0.24536659498295108, 'learning_rate': 0.22521026222563825, 'max_depth': 90, 'min_data_in_leaf': 13, 'num_leaves': 2329} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.688971017345098, 'lambda_l2': 0.9667413394445561, 'learning_rate': 0.37771692059488077, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 2686} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7089187077992688, 'lambda_l2': 0.7440006483337294, 'learning_rate': 0.47637838688076195, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 2207} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6907581084759267, 'lambda_l2': 1.099864062412794, 'learning_rate': 0.3361012504147739, 'max_depth': 81, 'min_data_in_leaf': 16, 'num_leaves': 2309} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7722834597995198, 'lambda_l2': 0.6307901526370874, 'learning_rate': 0.17850037072035327, 'max_depth': 94, 'min_data_in_leaf': 10, 'num_leaves': 510} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6674315429377163, 'lambda_l2': 0.8900246166734301, 'learning_rate': 0.5361005964869461, 'max_depth': 80, 'min_data_in_leaf': 21, 'num_leaves': 2475} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6728429159297566, 'lambda_l2': 1.269705992403355, 'learning_rate': 0.399598900050691, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 2159} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5479934058749116, 'lambda_l2': 0.43398398540975747, 'learning_rate': 0.3025422118586782, 'max_depth': 93, 'min_data_in_leaf': 4, 'num_leaves': 2397} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8282312553612906, 'lambda_l2': 0.09670648148569866, 'learning_rate': 0.22544215236283977, 'max_depth': 72, 'min_data_in_leaf': 8, 'num_leaves': 758} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5317645451925125, 'lambda_l2': 0.5640609985965609, 'learning_rate': 0.2509507616678639, 'max_depth': 90, 'min_data_in_leaf': 3, 'num_leaves': 2864} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7179061945837538, 'lambda_l2': 1.386778020271122, 'learning_rate': 0.45324961615291987, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2083} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8590340281410558, 'lambda_l2': 0.2126821428299752, 'learning_rate': 0.190263724920504, 'max_depth': 83, 'min_data_in_leaf': 52, 'num_leaves': 562} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6099848031512365, 'lambda_l2': 0.813072881581149, 'learning_rate': 0.63685673449984, 'max_depth': 74, 'min_data_in_leaf': 12, 'num_leaves': 1940} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9847426924995435, 'lambda_l2': 0.32424137669625713, 'learning_rate': 0.30200945604604146, 'max_depth': 91, 'min_data_in_leaf': 10, 'num_leaves': 134} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9152503680856876, 'lambda_l2': 0.10602367720338968, 'learning_rate': 0.25511759911222487, 'max_depth': 95, 'min_data_in_leaf': 6, 'num_leaves': 310} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.502333902763883, 'lambda_l2': 0.4529988585361936, 'learning_rate': 0.3299756516828526, 'max_depth': 92, 'min_data_in_leaf': 2, 'num_leaves': 2680} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6306458606844811, 'lambda_l2': 0.9059271083326558, 'learning_rate': 0.8214038119664492, 'max_depth': 76, 'min_data_in_leaf': 7, 'num_leaves': 2005} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6708561974615759, 'lambda_l2': 0.6691585305591253, 'learning_rate': 0.37983623469890926, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 2253} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7491395293993752, 'lambda_l2': 0.1772759616163348, 'learning_rate': 0.16506409123423071, 'max_depth': 79, 'min_data_in_leaf': 95, 'num_leaves': 1803} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5765456180942127, 'lambda_l2': 0.34573795979783656, 'learning_rate': 0.207570079044722, 'max_depth': 97, 'min_data_in_leaf': 12, 'num_leaves': 2533} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7302489371161783, 'lambda_l2': 1.1608091264286473, 'learning_rate': 0.5211657900803633, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2333} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6948369829020352, 'lambda_l2': 1.0504813828981319, 'learning_rate': 0.44289019441581695, 'max_depth': 88, 'min_data_in_leaf': 10, 'num_leaves': 2148} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5965792695042588, 'lambda_l2': 0.7554410634999883, 'learning_rate': 0.5852416711361635, 'max_depth': 71, 'min_data_in_leaf': 8, 'num_leaves': 2075} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6315284498844027, 'lambda_l2': 0.8667908653697068, 'learning_rate': 0.36174051313988187, 'max_depth': 76, 'min_data_in_leaf': 5, 'num_leaves': 1897} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7494220792592465, 'lambda_l2': 1.5630073609879467, 'learning_rate': 0.26603224332872505, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 670} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7997840630981283, 'lambda_l2': 0.5980501674792547, 'learning_rate': 0.1589467405870664, 'max_depth': 89, 'min_data_in_leaf': 1, 'num_leaves': 2773} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.659985543876401, 'lambda_l2': 0.9975221145662341, 'learning_rate': 0.7193655994111362, 'max_depth': 84, 'min_data_in_leaf': 22, 'num_leaves': 2181} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7300378678290635, 'lambda_l2': 0.6660321645916825, 'learning_rate': 0.495680311003297, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 2277} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6412727001410098, 'lambda_l2': 1.271800772700658, 'learning_rate': 0.3276193017587431, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 2481} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7001502723294002, 'lambda_l2': 0.7264341056939126, 'learning_rate': 0.03779558756607031, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 2329} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6449747592929718, 'lambda_l2': 1.088824697297832, 'learning_rate': 0.41022704954427275, 'max_depth': 79, 'min_data_in_leaf': 18, 'num_leaves': 2625} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6144772586052868, 'lambda_l2': 0.8594774778029245, 'learning_rate': 0.9793977460742407, 'max_depth': 73, 'min_data_in_leaf': 9, 'num_leaves': 2055} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.44629119773819415, 'lambda_l2': 0.9514460217199701, 'learning_rate': 0.5209948270289354, 'max_depth': 78, 'min_data_in_leaf': 5, 'num_leaves': 2137} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6720932557209897, 'lambda_l2': 0.5751878817815981, 'learning_rate': 0.36514205560669705, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 2200} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8466740709293088, 'lambda_l2': 0.2575641766376526, 'learning_rate': 0.2328943035686027, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 1001} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7129295954281211, 'lambda_l2': 1.3281753317324232, 'learning_rate': 0.6079908486917993, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 2240} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6255037001093519, 'lambda_l2': 1.1358475873364715, 'learning_rate': 0.313603357463748, 'max_depth': 80, 'min_data_in_leaf': 17, 'num_leaves': 2450} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6881953603318861, 'lambda_l2': 0.7888646927019279, 'learning_rate': 0.4750766574254652, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2392} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8226999198628444, 'lambda_l2': 0.10686557914955125, 'learning_rate': 0.19650185516737373, 'max_depth': 88, 'min_data_in_leaf': 12, 'num_leaves': 377} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.47952235783768377, 'lambda_l2': 0.695417123500798, 'learning_rate': 0.7700553107153305, 'max_depth': 76, 'min_data_in_leaf': 3, 'num_leaves': 2003} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6531895282408715, 'lambda_l2': 1.415648861948878, 'learning_rate': 0.38770941740687853, 'max_depth': 81, 'min_data_in_leaf': 23, 'num_leaves': 2406} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.46576042313743643, 'lambda_l2': 0.9858758284075825, 'learning_rate': 0.8437578814448454, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 1893} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7627305999381991, 'lambda_l2': 0.4005907412122517, 'learning_rate': 0.28983479148526, 'max_depth': 94, 'min_data_in_leaf': 11, 'num_leaves': 1208} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.17815659847445997, 'lambda_l2': 0.488200108677459, 'learning_rate': 0.249317892114925, 'max_depth': 91, 'min_data_in_leaf': 7, 'num_leaves': 785} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5903876177409517, 'lambda_l2': 1.2084253413487425, 'learning_rate': 0.4304114583092478, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 2561} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5586190280169102, 'lambda_l2': 0.82395132847086, 'learning_rate': 0.7096675585676043, 'max_depth': 70, 'min_data_in_leaf': 1, 'num_leaves': 1964} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6474686482274501, 'lambda_l2': 0.012217264106985926, 'learning_rate': 0.3390570356666042, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2121} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7269594642520358, 'lambda_l2': 1.7023100567428857, 'learning_rate': 0.6481166979632584, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 2376} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6790500267948802, 'lambda_l2': 1.0243331187271352, 'learning_rate': 0.2851407496934096, 'max_depth': 85, 'min_data_in_leaf': 22, 'num_leaves': 2507} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7072354054670285, 'lambda_l2': 1.4905814731218603, 'learning_rate': 0.023126177143881405, 'max_depth': 93, 'min_data_in_leaf': 13, 'num_leaves': 2308} : acc= 58.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45589332960651774, 'lambda_l2': 0.7343511471869434, 'learning_rate': 0.5619597458227534, 'max_depth': 75, 'min_data_in_leaf': 6, 'num_leaves': 1996} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5338771954095061, 'lambda_l2': 0.4021171302737053, 'learning_rate': 0.21832167484320897, 'max_depth': 97, 'min_data_in_leaf': 4, 'num_leaves': 54} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6228316240932121, 'lambda_l2': 3.2556858708610497, 'learning_rate': 0.45225012885547033, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 2850} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8023815422590804, 'lambda_l2': 0.005288884870561564, 'learning_rate': 0.17292975318240197, 'max_depth': 100, 'min_data_in_leaf': 9, 'num_leaves': 484} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7839459423006887, 'lambda_l2': 0.23062520150735, 'learning_rate': 0.13809293461120106, 'max_depth': 67, 'min_data_in_leaf': 45, 'num_leaves': 605} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6096542653140802, 'lambda_l2': 0.6348163449451688, 'learning_rate': 0.3691911079622122, 'max_depth': 81, 'min_data_in_leaf': 16, 'num_leaves': 2240} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5104050670992332, 'lambda_l2': 0.5351883548939146, 'learning_rate': 0.29974526602546603, 'max_depth': 97, 'min_data_in_leaf': 10, 'num_leaves': 884} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6602867734835516, 'lambda_l2': 0.9107240699233716, 'learning_rate': 0.42812799173973975, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 2116} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5544805257607375, 'lambda_l2': 0.3244861198262731, 'learning_rate': 0.20417117851696295, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 223} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5000050685598653, 'lambda_l2': 0.44608644464723385, 'learning_rate': 0.2582941933462823, 'max_depth': 94, 'min_data_in_leaf': 1, 'num_leaves': 1357} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.43729606215891903, 'lambda_l2': 0.7699305442971669, 'learning_rate': 0.5103772313188325, 'max_depth': 73, 'min_data_in_leaf': 12, 'num_leaves': 1869} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5904993101255073, 'lambda_l2': 0.6583319600690655, 'learning_rate': 0.995595243026035, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2061} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5710323421692434, 'lambda_l2': 0.8865856070053144, 'learning_rate': 0.5858463489136674, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 1970} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.681026225468113, 'lambda_l2': 1.1612332155130303, 'learning_rate': 0.33226741034827134, 'max_depth': 88, 'min_data_in_leaf': 16, 'num_leaves': 2668} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5260827508693318, 'lambda_l2': 0.5298457544663062, 'learning_rate': 0.1826406068040512, 'max_depth': 100, 'min_data_in_leaf': 8, 'num_leaves': 338} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6407964035764323, 'lambda_l2': 1.0406960540868024, 'learning_rate': 0.38751421887907583, 'max_depth': 83, 'min_data_in_leaf': 21, 'num_leaves': 2610} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4728498142465745, 'lambda_l2': 0.61589328149141, 'learning_rate': 0.8240263114990353, 'max_depth': 80, 'min_data_in_leaf': 5, 'num_leaves': 1835} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.664267266438861, 'lambda_l2': 0.1586110607526444, 'learning_rate': 0.4708039403828226, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 2310} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5046889438271602, 'lambda_l2': 0.8549386609097005, 'learning_rate': 0.6521574981610785, 'max_depth': 77, 'min_data_in_leaf': 3, 'num_leaves': 2148} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6216148863492099, 'lambda_l2': 1.3168647329821883, 'learning_rate': 0.31141802380667216, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 2768} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7315755236134335, 'lambda_l2': 1.5470966537787998, 'learning_rate': 0.3398034686481505, 'max_depth': 92, 'min_data_in_leaf': 13, 'num_leaves': 2446} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5520461155888357, 'lambda_l2': 0.3698184403787528, 'learning_rate': 0.2364511812074376, 'max_depth': 98, 'min_data_in_leaf': 9, 'num_leaves': 558} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7090335802370417, 'lambda_l2': 0.23125954219447453, 'learning_rate': 0.5332735404580129, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 2221} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8162578802333528, 'lambda_l2': 0.08199834897445968, 'learning_rate': 0.0014612818254099037, 'max_depth': 96, 'min_data_in_leaf': 6, 'num_leaves': 1678} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5939443434976739, 'lambda_l2': 0.77264011762683, 'learning_rate': 0.41073252003513916, 'max_depth': 73, 'min_data_in_leaf': 4, 'num_leaves': 2063} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.754273628842517, 'lambda_l2': 0.272845539197763, 'learning_rate': 0.2710934963521025, 'max_depth': 91, 'min_data_in_leaf': 14, 'num_leaves': 2510} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.48963519339690026, 'lambda_l2': 0.9456217718597272, 'learning_rate': 0.374754233558607, 'max_depth': 69, 'min_data_in_leaf': 8, 'num_leaves': 1954} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7704948867759397, 'lambda_l2': 0.12950433950133067, 'learning_rate': 0.15113158485054246, 'max_depth': 95, 'min_data_in_leaf': 1, 'num_leaves': 688} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.44447335169899516, 'lambda_l2': 0.6697516105327257, 'learning_rate': 0.4770150961663036, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 1794} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6970698852988841, 'lambda_l2': 0.5250104730580519, 'learning_rate': 0.27288290458752673, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2353} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.537963111804739, 'lambda_l2': 0.3756280294398979, 'learning_rate': 0.22257012902796514, 'max_depth': 93, 'min_data_in_leaf': 12, 'num_leaves': 422} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8607738530867043, 'lambda_l2': 0.20324183844921534, 'learning_rate': 0.16459836671991288, 'max_depth': 87, 'min_data_in_leaf': 5, 'num_leaves': 147} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7393452238224232, 'lambda_l2': 1.3776806571263958, 'learning_rate': 0.709861673096276, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2217} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5684465819721136, 'lambda_l2': 0.46384418476948264, 'learning_rate': 0.19948314437084091, 'max_depth': 94, 'min_data_in_leaf': 8, 'num_leaves': 1030} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.48516374083900893, 'lambda_l2': 1.1168302463982003, 'learning_rate': 0.9975153071792017, 'max_depth': 82, 'min_data_in_leaf': 10, 'num_leaves': 2058} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6161699086684543, 'lambda_l2': 1.151802337438133, 'learning_rate': 0.344011978771896, 'max_depth': 85, 'min_data_in_leaf': 22, 'num_leaves': 2427} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6752922223417243, 'lambda_l2': 1.2220698582438279, 'learning_rate': 0.3012748788070841, 'max_depth': 82, 'min_data_in_leaf': 24, 'num_leaves': 2598} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.23403211953460917, 'lambda_l2': 0.3650764830254515, 'learning_rate': 0.24503205094616165, 'max_depth': 92, 'min_data_in_leaf': 13, 'num_leaves': 813} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801129985234073, 'lambda_l2': 0.7412525077241936, 'learning_rate': 0.5863118173654374, 'max_depth': 75, 'min_data_in_leaf': 1, 'num_leaves': 1999} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6355321732358068, 'lambda_l2': 1.056089681425877, 'learning_rate': 0.42446044657399606, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 2296} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.551360218381987, 'lambda_l2': 0.5507752358874501, 'learning_rate': 0.1420678651632668, 'max_depth': 100, 'min_data_in_leaf': 7, 'num_leaves': 274} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6540830567172693, 'lambda_l2': 2.6666427296880038, 'learning_rate': 0.386829234149751, 'max_depth': 90, 'min_data_in_leaf': 17, 'num_leaves': 2190} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6119628380483013, 'lambda_l2': 1.6361805367787272, 'learning_rate': 0.49859290087452757, 'max_depth': 86, 'min_data_in_leaf': 26, 'num_leaves': 2553} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6045295843883168, 'lambda_l2': 0.0019501164055433229, 'learning_rate': 0.3100859560166735, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 2374} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6860082625985626, 'lambda_l2': 1.2644313228404627, 'learning_rate': 0.5768745048247099, 'max_depth': 84, 'min_data_in_leaf': 23, 'num_leaves': 2273} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5925194083525274, 'lambda_l2': 0.9427771648047254, 'learning_rate': 0.2708785840662783, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2693} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6293739929442704, 'lambda_l2': 4.200895281772821, 'learning_rate': 0.04432198063783128, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2520} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5287084560235558, 'lambda_l2': 0.2875670462103956, 'learning_rate': 0.17884809591382161, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 1484} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4278876356011371, 'lambda_l2': 0.8240246461904919, 'learning_rate': 0.6743995003760391, 'max_depth': 71, 'min_data_in_leaf': 3, 'num_leaves': 1797} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.699405663687031, 'lambda_l2': 1.4933766201892655, 'learning_rate': 0.4304527927482906, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 2429} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8897840162708515, 'lambda_l2': 0.07632615746519485, 'learning_rate': 0.2230902950077399, 'max_depth': 92, 'min_data_in_leaf': 5, 'num_leaves': 1145} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5164809809677262, 'lambda_l2': 0.6642138660771907, 'learning_rate': 0.8278810815844443, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 2129} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.45831648906618994, 'lambda_l2': 0.6320984470938139, 'learning_rate': 0.0034606425771376136, 'max_depth': 77, 'min_data_in_leaf': 13, 'num_leaves': 1911} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7416869958173402, 'lambda_l2': 0.17193474156380223, 'learning_rate': 0.3498278041549383, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 2171} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2673291399467997, 'lambda_l2': 2.7831755359137373, 'learning_rate': 0.19493441931674246, 'max_depth': 66, 'min_data_in_leaf': 6, 'num_leaves': 1713} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.485171053933543, 'lambda_l2': 0.7908190145703597, 'learning_rate': 0.5375809905553198, 'max_depth': 78, 'min_data_in_leaf': 11, 'num_leaves': 1906} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.657984705389326, 'lambda_l2': 0.4537638383580023, 'learning_rate': 0.36756941340835936, 'max_depth': 88, 'min_data_in_leaf': 56, 'num_leaves': 2389} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5580353044184484, 'lambda_l2': 0.40588012853900685, 'learning_rate': 0.10009594332900411, 'max_depth': 99, 'min_data_in_leaf': 60, 'num_leaves': 743} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6461628366982176, 'lambda_l2': 1.0371582493273364, 'learning_rate': 0.3120264186480802, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2250} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8333076328658446, 'lambda_l2': 0.29383096402496034, 'learning_rate': 0.2352876538512663, 'max_depth': 94, 'min_data_in_leaf': 3, 'num_leaves': 1277} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801354206752075, 'lambda_l2': 2.951504274975894, 'learning_rate': 0.46165357210024976, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 2453} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6752356054425922, 'lambda_l2': 1.3506049520474293, 'learning_rate': 0.2862440325489082, 'max_depth': 81, 'min_data_in_leaf': 25, 'num_leaves': 2340} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7321642106588006, 'lambda_l2': 0.49387718627109445, 'learning_rate': 0.6355828348856934, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 2126} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7194229045083462, 'lambda_l2': 0.0051156331518056875, 'learning_rate': 0.41765686248469164, 'max_depth': 83, 'min_data_in_leaf': 21, 'num_leaves': 2739} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.1958672548841178, 'lambda_l2': 0.00830682318825065, 'learning_rate': 0.12151835239178173, 'max_depth': 90, 'min_data_in_leaf': 8, 'num_leaves': 1422} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4761694110048137, 'lambda_l2': 0.8981752752513822, 'learning_rate': 0.0026989491691501114, 'max_depth': 75, 'min_data_in_leaf': 1, 'num_leaves': 2020} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5119343293378882, 'lambda_l2': 0.3123621146198009, 'learning_rate': 0.2020975607684372, 'max_depth': 96, 'min_data_in_leaf': 6, 'num_leaves': 868} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.2439682977113396, 'lambda_l2': 0.18720916415126887, 'learning_rate': 0.1410906492542334, 'max_depth': 91, 'min_data_in_leaf': 10, 'num_leaves': 641} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.703981348979653, 'lambda_l2': 1.7323936436592824, 'learning_rate': 0.030553662221380503, 'max_depth': 88, 'min_data_in_leaf': 14, 'num_leaves': 2284} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5333780529074768, 'lambda_l2': 0.5491003348368513, 'learning_rate': 0.15656018435552366, 'max_depth': 95, 'min_data_in_leaf': 8, 'num_leaves': 1061} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6345215831040072, 'lambda_l2': 3.1186615580858152, 'learning_rate': 0.2587896687901134, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 2914} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9662760813630543, 'lambda_l2': 0.09007248422806045, 'learning_rate': 0.7453905554944861, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 2188} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4997122079748868, 'lambda_l2': 0.8465531996590622, 'learning_rate': 0.47340783919958185, 'max_depth': 79, 'min_data_in_leaf': 4, 'num_leaves': 2071} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5426036399031756, 'lambda_l2': 0.42781506855317, 'learning_rate': 0.08504465672956774, 'max_depth': 97, 'min_data_in_leaf': 10, 'num_leaves': 540} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5928390250392996, 'lambda_l2': 1.2007412761019414, 'learning_rate': 0.3281452459934519, 'max_depth': 83, 'min_data_in_leaf': 20, 'num_leaves': 2518} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.43302021664553497, 'lambda_l2': 0.6822345382563815, 'learning_rate': 0.5740500466152431, 'max_depth': 71, 'min_data_in_leaf': 7, 'num_leaves': 1863} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.3049472450292196, 'lambda_l2': 0.25719760161140875, 'learning_rate': 0.18621065349944482, 'max_depth': 94, 'min_data_in_leaf': 13, 'num_leaves': 1578} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3213839913873311, 'lambda_l2': 0.00813471110585397, 'learning_rate': 0.2207114368141359, 'max_depth': 88, 'min_data_in_leaf': 2, 'num_leaves': 427} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.9447611898633133, 'lambda_l2': 0.16172043629034608, 'learning_rate': 0.1712378392564053, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 201} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.561118963270802, 'lambda_l2': 0.5128727614428173, 'learning_rate': 0.2592083975800182, 'max_depth': 98, 'min_data_in_leaf': 65, 'num_leaves': 278} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5200722783373457, 'lambda_l2': 0.334972599757045, 'learning_rate': 0.2768555095681479, 'max_depth': 94, 'min_data_in_leaf': 6, 'num_leaves': 114} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4608043696984634, 'lambda_l2': 0.614884033626176, 'learning_rate': 0.5062795311504227, 'max_depth': 73, 'min_data_in_leaf': 5, 'num_leaves': 1950} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7482314327775027, 'lambda_l2': 2.162312003175089, 'learning_rate': 0.3697771381553392, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2311} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8056489246107675, 'lambda_l2': 0.09376008215435494, 'learning_rate': 0.11187317770414626, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 1543} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7772692983091924, 'lambda_l2': 0.15228948637523254, 'learning_rate': 0.13117733664545844, 'max_depth': 69, 'min_data_in_leaf': 12, 'num_leaves': 1614} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4465803625602314, 'lambda_l2': 0.7220142441690655, 'learning_rate': 0.4138528824119216, 'max_depth': 77, 'min_data_in_leaf': 9, 'num_leaves': 1763} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.48518633675678846, 'lambda_l2': 0.962749300908903, 'learning_rate': 0.8466045424289372, 'max_depth': 80, 'min_data_in_leaf': 1, 'num_leaves': 2015} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.024604511837476167, 'lambda_l2': 1.5328044310336737, 'learning_rate': 0.32493148258188403, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2161} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7058322402470928, 'lambda_l2': 0.5676726350731794, 'learning_rate': 0.3834423201062942, 'max_depth': 91, 'min_data_in_leaf': 15, 'num_leaves': 2616} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.676714511466796, 'lambda_l2': 0.004956505407146542, 'learning_rate': 0.01728652422017292, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 2469} : acc= 54.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6170883858494728, 'lambda_l2': 1.0781930160321418, 'learning_rate': 0.30304189690014877, 'max_depth': 83, 'min_data_in_leaf': 21, 'num_leaves': 2662} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.40949763269373574, 'lambda_l2': 0.004986313875189219, 'learning_rate': 0.23143314066303453, 'max_depth': 85, 'min_data_in_leaf': 3, 'num_leaves': 976} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.718550369806291, 'lambda_l2': 0.2806808861583539, 'learning_rate': 0.5275104041063956, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 2256} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5645693840681286, 'lambda_l2': 0.7218516002778439, 'learning_rate': 0.6159543618048805, 'max_depth': 74, 'min_data_in_leaf': 7, 'num_leaves': 1862} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6526542539568265, 'lambda_l2': 0.396761318821721, 'learning_rate': 0.35017296047659824, 'max_depth': 89, 'min_data_in_leaf': 24, 'num_leaves': 2360} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.499482171153897, 'lambda_l2': 0.7959238507979265, 'learning_rate': 0.7126848477942188, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2084} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.791867479070885, 'lambda_l2': 0.20923056664265788, 'learning_rate': 0.15211746670417667, 'max_depth': 100, 'min_data_in_leaf': 12, 'num_leaves': 1253} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5991092305886274, 'lambda_l2': 1.4083955848354353, 'learning_rate': 0.4712679220553576, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 2809} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5762992508554396, 'lambda_l2': 0.9598143260219711, 'learning_rate': 0.9848328034423843, 'max_depth': 76, 'min_data_in_leaf': 5, 'num_leaves': 1985} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7626591660731572, 'lambda_l2': 1.8148620066570698, 'learning_rate': 0.06184898022878055, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 2194} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5424272894155387, 'lambda_l2': 0.47974678753970634, 'learning_rate': 0.1925806612807659, 'max_depth': 98, 'min_data_in_leaf': 8, 'num_leaves': 732} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.16459907789853861, 'lambda_l2': 0.5949701000883325, 'learning_rate': 0.410821418813561, 'max_depth': 93, 'min_data_in_leaf': 14, 'num_leaves': 2394} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.382464140172611, 'lambda_l2': 0.35672880638484983, 'learning_rate': 0.2504248429022027, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 498} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.2964853610958116, 'lambda_l2': 3.599338387080252, 'learning_rate': 0.2194844211102484, 'max_depth': 92, 'min_data_in_leaf': 3, 'num_leaves': 1373} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5173715861111612, 'lambda_l2': 1.0446653789034723, 'learning_rate': 0.5565343454652238, 'max_depth': 80, 'min_data_in_leaf': 5, 'num_leaves': 1868} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6206076719919783, 'lambda_l2': 1.2293523945873175, 'learning_rate': 0.001206842631483827, 'max_depth': 84, 'min_data_in_leaf': 24, 'num_leaves': 2503} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6857605989170558, 'lambda_l2': 0.6036960688051489, 'learning_rate': 0.3001382469394882, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 345} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.601013708407582, 'lambda_l2': 1.141461538713765, 'learning_rate': 0.4588425210598282, 'max_depth': 82, 'min_data_in_leaf': 27, 'num_leaves': 2285} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6641373000327964, 'lambda_l2': 0.4644163939319217, 'learning_rate': 0.3495616126514627, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 2558} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5330826764398366, 'lambda_l2': 0.29470894412656956, 'learning_rate': 0.10217689926766603, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 908} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6518407067434575, 'lambda_l2': 1.6052130327817917, 'learning_rate': 0.2774259221307142, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 2155} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6427491529161901, 'lambda_l2': 1.2877952522484917, 'learning_rate': 0.6533833126475073, 'max_depth': 83, 'min_data_in_leaf': 22, 'num_leaves': 2407} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5724743140866924, 'lambda_l2': 0.9022010978038983, 'learning_rate': 0.3928710329387247, 'max_depth': 79, 'min_data_in_leaf': 22, 'num_leaves': 2636} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6222622930375757, 'lambda_l2': 0.8431632860591678, 'learning_rate': 0.32395353539565436, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 51} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8752239273401718, 'lambda_l2': 0.186448491501642, 'learning_rate': 0.17248029094616668, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 1679} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6937380241332787, 'lambda_l2': 0.7360130161139644, 'learning_rate': 0.47318531719554924, 'max_depth': 87, 'min_data_in_leaf': 20, 'num_leaves': 2111} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7092253837984944, 'lambda_l2': 1.3896716840159964, 'learning_rate': 0.24045186162177817, 'max_depth': 76, 'min_data_in_leaf': 25, 'num_leaves': 249} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7420270799922478, 'lambda_l2': 2.386638430148072, 'learning_rate': 0.772214768149602, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 447} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5962404702928443, 'lambda_l2': 0.5570129647610174, 'learning_rate': 0.2112539258926858, 'max_depth': 93, 'min_data_in_leaf': 26, 'num_leaves': 106} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6668600986151818, 'lambda_l2': 0.977099714422363, 'learning_rate': 0.28980733490142435, 'max_depth': 84, 'min_data_in_leaf': 16, 'num_leaves': 2230} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2750144325292075, 'lambda_l2': 0.1404920195436058, 'learning_rate': 0.162079408315719, 'max_depth': 72, 'min_data_in_leaf': 11, 'num_leaves': 703} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9290712654224598, 'lambda_l2': 0.2665477237910361, 'learning_rate': 0.1355088377817563, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 817} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5465424371564984, 'lambda_l2': 0.43041674970713184, 'learning_rate': 0.2577223024377829, 'max_depth': 97, 'min_data_in_leaf': 4, 'num_leaves': 635} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.1297315873864816, 'lambda_l2': 0.007080576103553227, 'learning_rate': 0.07474881352142453, 'max_depth': 59, 'min_data_in_leaf': 7, 'num_leaves': 1122} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.35886606451876524, 'lambda_l2': 0.0013386654322714575, 'learning_rate': 0.1807675644096063, 'max_depth': 69, 'min_data_in_leaf': 9, 'num_leaves': 582} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7315697609953107, 'lambda_l2': 1.196034852857549, 'learning_rate': 0.3076961240563928, 'max_depth': 74, 'min_data_in_leaf': 24, 'num_leaves': 76} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6245225009580085, 'lambda_l2': 1.0181723738713586, 'learning_rate': 0.0038578129238263695, 'max_depth': 77, 'min_data_in_leaf': 17, 'num_leaves': 220} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6371208077250587, 'lambda_l2': 1.275996980543812, 'learning_rate': 0.4205019451558912, 'max_depth': 82, 'min_data_in_leaf': 30, 'num_leaves': 73} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6850539264152268, 'lambda_l2': 1.8935146925640058, 'learning_rate': 0.21824235183995658, 'max_depth': 79, 'min_data_in_leaf': 23, 'num_leaves': 310} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.21896042989608672, 'lambda_l2': 0.3836142000612329, 'learning_rate': 0.20455872414189824, 'max_depth': 61, 'min_data_in_leaf': 13, 'num_leaves': 1170} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801830819333388, 'lambda_l2': 0.6502242258533952, 'learning_rate': 0.020782215031909787, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 2311} : acc= 57.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6017076771320539, 'lambda_l2': 0.5942576964727061, 'learning_rate': 0.256893349859595, 'max_depth': 88, 'min_data_in_leaf': 29, 'num_leaves': 68} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48972737246817183, 'lambda_l2': 0.48597837976176056, 'learning_rate': 0.16092717934223222, 'max_depth': 99, 'min_data_in_leaf': 82, 'num_leaves': 345} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5667327222603046, 'lambda_l2': 1.1041656429542348, 'learning_rate': 0.3481014028211614, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2469} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7079712088166128, 'lambda_l2': 0.8807290803730947, 'learning_rate': 0.32002961935811397, 'max_depth': 74, 'min_data_in_leaf': 18, 'num_leaves': 161} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5869233764854316, 'lambda_l2': 0.6916727825200839, 'learning_rate': 0.1236634511205052, 'max_depth': 81, 'min_data_in_leaf': 22, 'num_leaves': 217} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6666246501507186, 'lambda_l2': 1.4507020032084454, 'learning_rate': 0.5475850102826263, 'max_depth': 80, 'min_data_in_leaf': 26, 'num_leaves': 163} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6370216453628242, 'lambda_l2': 0.7806712136398893, 'learning_rate': 0.052021069955496956, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2564} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8416136942714731, 'lambda_l2': 0.0031582682637769643, 'learning_rate': 0.18032582214429116, 'max_depth': 94, 'min_data_in_leaf': 11, 'num_leaves': 1507} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.43921923921824285, 'lambda_l2': 0.30244869686682496, 'learning_rate': 0.15176536484628145, 'max_depth': 66, 'min_data_in_leaf': 29, 'num_leaves': 125} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5170070089989598, 'lambda_l2': 0.40917041586761804, 'learning_rate': 0.10267817465152573, 'max_depth': 99, 'min_data_in_leaf': 6, 'num_leaves': 1031} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6921361239445627, 'lambda_l2': 0.9898287423364092, 'learning_rate': 0.6341155718644583, 'max_depth': 82, 'min_data_in_leaf': 33, 'num_leaves': 194} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5597338973937565, 'lambda_l2': 0.5995228743633736, 'learning_rate': 0.03628830871158723, 'max_depth': 91, 'min_data_in_leaf': 21, 'num_leaves': 94} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7688468224182861, 'lambda_l2': 0.09130624586389345, 'learning_rate': 0.38686576232998204, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 2078} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4029235373280492, 'lambda_l2': 0.2005890726925036, 'learning_rate': 0.23676338597681224, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 1742} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6582247864914911, 'lambda_l2': 0.7823598835255458, 'learning_rate': 0.5084404192635278, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 2853} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.47420097680503503, 'lambda_l2': 0.7020774570827917, 'learning_rate': 0.005702835174988243, 'max_depth': 71, 'min_data_in_leaf': 4, 'num_leaves': 1990} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.745160040329566, 'lambda_l2': 1.5557223179136124, 'learning_rate': 0.26699331706021046, 'max_depth': 80, 'min_data_in_leaf': 27, 'num_leaves': 149} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6222680289010921, 'lambda_l2': 0.4856708752500741, 'learning_rate': 0.4324301189696717, 'max_depth': 90, 'min_data_in_leaf': 23, 'num_leaves': 341} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5433022449442995, 'lambda_l2': 0.6207626182421513, 'learning_rate': 0.8355784923345412, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2618} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6073114558358431, 'lambda_l2': 1.134564885335585, 'learning_rate': 0.8709824305502621, 'max_depth': 72, 'min_data_in_leaf': 18, 'num_leaves': 2766} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.620026934297324, 'lambda_l2': 0.35398637253876936, 'learning_rate': 0.3437465978773309, 'max_depth': 89, 'min_data_in_leaf': 39, 'num_leaves': 72} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4692825462256929, 'lambda_l2': 0.6735376468408906, 'learning_rate': 0.42364358643337846, 'max_depth': 77, 'min_data_in_leaf': 8, 'num_leaves': 93} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5860843049767758, 'lambda_l2': 0.5806923320429791, 'learning_rate': 0.3051261546285189, 'max_depth': 86, 'min_data_in_leaf': 21, 'num_leaves': 259} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7194840607279017, 'lambda_l2': 0.8475059498091309, 'learning_rate': 0.7090051613982475, 'max_depth': 83, 'min_data_in_leaf': 15, 'num_leaves': 2708} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7681412996145747, 'lambda_l2': 1.4784950947216333, 'learning_rate': 0.21423857120024298, 'max_depth': 81, 'min_data_in_leaf': 31, 'num_leaves': 388} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.09359881725802133, 'lambda_l2': 0.27038783950769263, 'learning_rate': 0.19268653713459458, 'max_depth': 97, 'min_data_in_leaf': 12, 'num_leaves': 303} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5701778021382234, 'lambda_l2': 0.5247912690589098, 'learning_rate': 0.28000883000220933, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 378} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.45795630483439886, 'lambda_l2': 4.776346283445523, 'learning_rate': 0.5749918207778577, 'max_depth': 77, 'min_data_in_leaf': 3, 'num_leaves': 1803} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5483435199397947, 'lambda_l2': 0.7325410370044159, 'learning_rate': 0.3522415261940932, 'max_depth': 92, 'min_data_in_leaf': 23, 'num_leaves': 199} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6345555578223299, 'lambda_l2': 0.4717245752675394, 'learning_rate': 0.23441874910379973, 'max_depth': 95, 'min_data_in_leaf': 36, 'num_leaves': 67} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7488722743997385, 'lambda_l2': 1.6827528272176067, 'learning_rate': 0.13201100740131033, 'max_depth': 83, 'min_data_in_leaf': 18, 'num_leaves': 508} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6811647775188969, 'lambda_l2': 1.343260803250002, 'learning_rate': 0.2754518079086974, 'max_depth': 75, 'min_data_in_leaf': 23, 'num_leaves': 121} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6629405062088389, 'lambda_l2': 1.0823083423226496, 'learning_rate': 0.49705164442902455, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2368} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6451482552043037, 'lambda_l2': 0.9847506547282129, 'learning_rate': 0.5585240291720655, 'max_depth': 74, 'min_data_in_leaf': 17, 'num_leaves': 2476} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.00025587563945564384, 'lambda_l2': 2.5607053413851055, 'learning_rate': 0.38744882863367797, 'max_depth': 90, 'min_data_in_leaf': 10, 'num_leaves': 2162} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6115828216534189, 'lambda_l2': 1.2552321626283176, 'learning_rate': 0.6935447644201996, 'max_depth': 79, 'min_data_in_leaf': 73, 'num_leaves': 2251} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4202955424810254, 'lambda_l2': 3.985986617863194, 'learning_rate': 0.16456443318403402, 'max_depth': 58, 'min_data_in_leaf': 8, 'num_leaves': 1328} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6055826591390928, 'lambda_l2': 0.9105741264848941, 'learning_rate': 0.646654407329942, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2887} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5205870836222897, 'lambda_l2': 0.7852750214982731, 'learning_rate': 0.4685472569833896, 'max_depth': 79, 'min_data_in_leaf': 6, 'num_leaves': 2669} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.501197939727196, 'lambda_l2': 0.6646053944124484, 'learning_rate': 0.3193972910928676, 'max_depth': 64, 'min_data_in_leaf': 1, 'num_leaves': 163} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6437715990264558, 'lambda_l2': 0.8804354148241855, 'learning_rate': 0.8773125046968024, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 66} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5784669925235144, 'lambda_l2': 1.199336519969082, 'learning_rate': 0.3792352866068678, 'max_depth': 86, 'min_data_in_leaf': 14, 'num_leaves': 2368} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6807521463559167, 'lambda_l2': 2.030167176511424, 'learning_rate': 0.426877935873673, 'max_depth': 88, 'min_data_in_leaf': 17, 'num_leaves': 2218} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5899258161573423, 'lambda_l2': 0.3772246887144123, 'learning_rate': 0.09170067216771027, 'max_depth': 92, 'min_data_in_leaf': 43, 'num_leaves': 434} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.44812646815978463, 'lambda_l2': 0.08978664813653725, 'learning_rate': 0.20645424592514947, 'max_depth': 94, 'min_data_in_leaf': 5, 'num_leaves': 240} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5118316643262131, 'lambda_l2': 0.18732885853963804, 'learning_rate': 0.2396352077794986, 'max_depth': 97, 'min_data_in_leaf': 9, 'num_leaves': 784} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6256447120369173, 'lambda_l2': 1.0717012541101245, 'learning_rate': 0.756495637590725, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2067} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6077344492606584, 'lambda_l2': 1.049106188827215, 'learning_rate': 0.5814822252538799, 'max_depth': 73, 'min_data_in_leaf': 16, 'num_leaves': 2548} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4304472314170926, 'lambda_l2': 0.2985317477962765, 'learning_rate': 0.11654477381093957, 'max_depth': 53, 'min_data_in_leaf': 7, 'num_leaves': 516} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5342098428172631, 'lambda_l2': 0.5632309413911145, 'learning_rate': 0.44730457923642525, 'max_depth': 70, 'min_data_in_leaf': 2, 'num_leaves': 146} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7210926927581368, 'lambda_l2': 1.413178513574834, 'learning_rate': 0.26737472334962686, 'max_depth': 67, 'min_data_in_leaf': 26, 'num_leaves': 297} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6559010088901751, 'lambda_l2': 0.9417271149950599, 'learning_rate': 0.9302759194913923, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 63} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.42318806164681316, 'lambda_l2': 0.8535634810668731, 'learning_rate': 0.3239852690686489, 'max_depth': 72, 'min_data_in_leaf': 4, 'num_leaves': 1657} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5589944747826215, 'lambda_l2': 1.1709013610551324, 'learning_rate': 0.5006289470442961, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 2276} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.46970278131264764, 'lambda_l2': 0.7060894949768534, 'learning_rate': 0.4045645167231351, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 2755} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6732193017313252, 'lambda_l2': 1.3728809951555865, 'learning_rate': 0.6248699583493368, 'max_depth': 84, 'min_data_in_leaf': 25, 'num_leaves': 66} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5049306030438904, 'lambda_l2': 0.41044803262237045, 'learning_rate': 0.02607615544030344, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 887} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5648321564821134, 'lambda_l2': 0.5661988259552574, 'learning_rate': 0.2822938447028251, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 266} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5882058425014718, 'lambda_l2': 0.4576619040303383, 'learning_rate': 0.0018895835057883338, 'max_depth': 91, 'min_data_in_leaf': 20, 'num_leaves': 431} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48979308629537144, 'lambda_l2': 0.7799011511942886, 'learning_rate': 0.9862871704448702, 'max_depth': 75, 'min_data_in_leaf': 6, 'num_leaves': 1904} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5358208824789219, 'lambda_l2': 0.5186628371370896, 'learning_rate': 0.3440845057454277, 'max_depth': 90, 'min_data_in_leaf': 28, 'num_leaves': 217} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8195626954130768, 'lambda_l2': 0.09603324344950792, 'learning_rate': 0.1487381565431168, 'max_depth': 100, 'min_data_in_leaf': 11, 'num_leaves': 1598} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.42229447075602, 'lambda_l2': 0.9498409217106658, 'learning_rate': 0.35432631911813167, 'max_depth': 67, 'min_data_in_leaf': 9, 'num_leaves': 1748} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6319139457451105, 'lambda_l2': 1.1769131400351007, 'learning_rate': 0.5226003763731563, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2369} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6994537747076918, 'lambda_l2': 1.7149740949390675, 'learning_rate': 0.2510443110838979, 'max_depth': 76, 'min_data_in_leaf': 21, 'num_leaves': 62} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.37727713092525855, 'lambda_l2': 0.0029411638296107656, 'learning_rate': 0.7461940774923201, 'max_depth': 62, 'min_data_in_leaf': 1, 'num_leaves': 2754} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7064387009595099, 'lambda_l2': 1.2809183464721803, 'learning_rate': 0.4525791021629864, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2450} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8107159217012934, 'lambda_l2': 0.2074235663922564, 'learning_rate': 0.07080748379623207, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 1461} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4462849289995117, 'lambda_l2': 0.8688332237857397, 'learning_rate': 0.39396601443881013, 'max_depth': 71, 'min_data_in_leaf': 5, 'num_leaves': 2548} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.450236945220782, 'lambda_l2': 1.0630175881446506, 'learning_rate': 0.7616438274499907, 'max_depth': 68, 'min_data_in_leaf': 3, 'num_leaves': 2648} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5169301571370184, 'lambda_l2': 0.3174447712298283, 'learning_rate': 0.17826274682129656, 'max_depth': 99, 'min_data_in_leaf': 47, 'num_leaves': 1224} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5704115894549008, 'lambda_l2': 1.0538271235979442, 'learning_rate': 0.010335294903558778, 'max_depth': 78, 'min_data_in_leaf': 19, 'num_leaves': 2806} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.504846880221026, 'lambda_l2': 0.22214022789861598, 'learning_rate': 0.08059053416137055, 'max_depth': 93, 'min_data_in_leaf': 9, 'num_leaves': 626} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7236853263656444, 'lambda_l2': 1.6200071645483036, 'learning_rate': 0.6470978575779124, 'max_depth': 73, 'min_data_in_leaf': 14, 'num_leaves': 2599} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6877305140757322, 'lambda_l2': 1.5598501398047258, 'learning_rate': 0.8548452484841916, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 2978} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.784267892759917, 'lambda_l2': 1.243889543037729, 'learning_rate': 0.5454057898512575, 'max_depth': 82, 'min_data_in_leaf': 12, 'num_leaves': 445} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.3589117060399249, 'lambda_l2': 0.08583660953130706, 'learning_rate': 0.19656252070111047, 'max_depth': 90, 'min_data_in_leaf': 11, 'num_leaves': 1414} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4874838000550182, 'lambda_l2': 0.7728317147951513, 'learning_rate': 0.48589537783934816, 'max_depth': 78, 'min_data_in_leaf': 6, 'num_leaves': 2078} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.47196567390336785, 'lambda_l2': 0.8341584147266912, 'learning_rate': 0.9697103064477292, 'max_depth': 74, 'min_data_in_leaf': 4, 'num_leaves': 2728} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5502153761455466, 'lambda_l2': 0.6039192593698064, 'learning_rate': 0.3201643361696992, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 344} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3988006013452844, 'lambda_l2': 0.933395655321257, 'learning_rate': 0.6698061750002864, 'max_depth': 70, 'min_data_in_leaf': 8, 'num_leaves': 2860} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7278674743250866, 'lambda_l2': 1.2866038124218988, 'learning_rate': 0.229045605585524, 'max_depth': 83, 'min_data_in_leaf': 24, 'num_leaves': 184} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7417048961198895, 'lambda_l2': 1.8585331912920187, 'learning_rate': 0.21195959498705733, 'max_depth': 85, 'min_data_in_leaf': 28, 'num_leaves': 585} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6046098771680726, 'lambda_l2': 1.142682592327564, 'learning_rate': 0.84796600782154, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 2503} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6171058520232485, 'lambda_l2': 0.99937310894769, 'learning_rate': 0.5650149603984019, 'max_depth': 78, 'min_data_in_leaf': 16, 'num_leaves': 2441} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5838045175524854, 'lambda_l2': 0.8777149386418569, 'learning_rate': 0.7042178893887314, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2702} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6325292025352336, 'lambda_l2': 1.1274467430376212, 'learning_rate': 0.04519369117202961, 'max_depth': 82, 'min_data_in_leaf': 17, 'num_leaves': 307} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6607430336116903, 'lambda_l2': 1.4857680523194756, 'learning_rate': 0.3629819277225979, 'max_depth': 84, 'min_data_in_leaf': 21, 'num_leaves': 2296} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6354125942171349, 'lambda_l2': 1.1498947070424812, 'learning_rate': 0.5803831042442089, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 2597} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5888753870470415, 'lambda_l2': 0.9129044227016697, 'learning_rate': 0.7792619091609939, 'max_depth': 77, 'min_data_in_leaf': 14, 'num_leaves': 2441} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6890393990929017, 'lambda_l2': 1.3635136012799527, 'learning_rate': 0.5011349127081867, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 2372} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5476197253484126, 'lambda_l2': 0.7296415803149334, 'learning_rate': 0.28993147746435644, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2147} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6065750942877839, 'lambda_l2': 0.09987102392464416, 'learning_rate': 0.9045968391855488, 'max_depth': 94, 'min_data_in_leaf': 2, 'num_leaves': 2543} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.9809026514013679, 'lambda_l2': 0.01089414951932871, 'learning_rate': 0.10968888060681468, 'max_depth': 87, 'min_data_in_leaf': 33, 'num_leaves': 405} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.42693139005922115, 'lambda_l2': 3.4346870926120516, 'learning_rate': 0.5215200075060241, 'max_depth': 75, 'min_data_in_leaf': 5, 'num_leaves': 2665} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6780207967910613, 'lambda_l2': 1.50309741074254, 'learning_rate': 0.7423755258948583, 'max_depth': 81, 'min_data_in_leaf': 23, 'num_leaves': 2497} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6490027965654038, 'lambda_l2': 1.7530932592274533, 'learning_rate': 0.994385715185412, 'max_depth': 72, 'min_data_in_leaf': 13, 'num_leaves': 2352} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6271803860739179, 'lambda_l2': 0.8133808206454118, 'learning_rate': 0.4059784283739236, 'max_depth': 84, 'min_data_in_leaf': 16, 'num_leaves': 2425} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5657044749542782, 'lambda_l2': 0.6700766551155662, 'learning_rate': 0.43159562251680084, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 2386} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6639242340153165, 'lambda_l2': 1.3283968839469888, 'learning_rate': 0.4734198297398632, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2301} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6509601163539697, 'lambda_l2': 0.7940329191689084, 'learning_rate': 0.3126852714152201, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 2207} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6970702918527857, 'lambda_l2': 0.9703256767658149, 'learning_rate': 0.34826263851127964, 'max_depth': 84, 'min_data_in_leaf': 15, 'num_leaves': 521} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6690114657566449, 'lambda_l2': 0.8448334758350454, 'learning_rate': 0.29533590276704696, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 2204} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.64044825331113, 'lambda_l2': 0.6855575636650966, 'learning_rate': 0.35842115502254585, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2048} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6186475147940708, 'lambda_l2': 1.0270165282824641, 'learning_rate': 0.2719267324218056, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 2109} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5356575312665646, 'lambda_l2': 0.3944004658414207, 'learning_rate': 0.24516339974297044, 'max_depth': 89, 'min_data_in_leaf': 11, 'num_leaves': 1884} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7575803801595249, 'lambda_l2': 0.4996853700332717, 'learning_rate': 0.29628076169168716, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 546} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5265028063544711, 'lambda_l2': 0.5968280127052037, 'learning_rate': 0.3183532572957906, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 668} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.528627247464607, 'lambda_l2': 0.46852928742909755, 'learning_rate': 0.2390028325677761, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 437} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5623213735853224, 'lambda_l2': 0.7087759653892773, 'learning_rate': 0.43578382467202537, 'max_depth': 80, 'min_data_in_leaf': 9, 'num_leaves': 2333} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5155231647705166, 'lambda_l2': 0.3416698025260869, 'learning_rate': 0.367476622956594, 'max_depth': 82, 'min_data_in_leaf': 12, 'num_leaves': 253} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6732313404414095, 'lambda_l2': 1.446849321231831, 'learning_rate': 0.5153070668942603, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2265} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7132853314766093, 'lambda_l2': 0.48902516543501856, 'learning_rate': 0.250447824638923, 'max_depth': 89, 'min_data_in_leaf': 17, 'num_leaves': 178} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5485581305685315, 'lambda_l2': 0.2702769053726706, 'learning_rate': 0.40771746331252723, 'max_depth': 92, 'min_data_in_leaf': 10, 'num_leaves': 2353} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5940125147372277, 'lambda_l2': 0.9357129030052281, 'learning_rate': 0.3415938203863082, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 2140} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6480811296314247, 'lambda_l2': 1.1914060764041343, 'learning_rate': 0.6122141271656447, 'max_depth': 80, 'min_data_in_leaf': 18, 'num_leaves': 2226} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4600623553539611, 'lambda_l2': 1.3526880724321229, 'learning_rate': 0.4713339625081262, 'max_depth': 77, 'min_data_in_leaf': 7, 'num_leaves': 1995} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5922195106771276, 'lambda_l2': 0.7600890658721213, 'learning_rate': 0.41333921679619934, 'max_depth': 78, 'min_data_in_leaf': 12, 'num_leaves': 2505} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.625247623821213, 'lambda_l2': 1.2341453624785184, 'learning_rate': 0.5772310193316874, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2301} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7065384102847897, 'lambda_l2': 1.5553525635814403, 'learning_rate': 0.49942110799683037, 'max_depth': 87, 'min_data_in_leaf': 8, 'num_leaves': 2423} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6371703490902045, 'lambda_l2': 1.1569385800100715, 'learning_rate': 0.5743548008779877, 'max_depth': 75, 'min_data_in_leaf': 14, 'num_leaves': 2215} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7189468682803448, 'lambda_l2': 1.316010881775324, 'learning_rate': 0.38568071340804, 'max_depth': 82, 'min_data_in_leaf': 15, 'num_leaves': 2440} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6819770839524889, 'lambda_l2': 0.8027792530894308, 'learning_rate': 0.287037629783038, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 347} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7360043182729278, 'lambda_l2': 0.3656214694274188, 'learning_rate': 0.20855290000436533, 'max_depth': 89, 'min_data_in_leaf': 10, 'num_leaves': 652} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6896831607438038, 'lambda_l2': 0.6571248854176686, 'learning_rate': 0.32469138924484103, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 2122} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.669853428125572, 'lambda_l2': 1.131772494793411, 'learning_rate': 0.6286868292710183, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2323} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.502696198966973, 'lambda_l2': 0.5341647885341072, 'learning_rate': 0.2680492374983163, 'max_depth': 90, 'min_data_in_leaf': 10, 'num_leaves': 1936} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.623871806339113, 'lambda_l2': 1.0471748546504338, 'learning_rate': 0.45709538506972125, 'max_depth': 79, 'min_data_in_leaf': 13, 'num_leaves': 2278} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.575107862440092, 'lambda_l2': 0.8334581296419039, 'learning_rate': 0.4936907500802307, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 2461} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5301869992543815, 'lambda_l2': 0.19251107721732147, 'learning_rate': 0.28429582432043, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 1963} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6529475640850443, 'lambda_l2': 1.2709486493706015, 'learning_rate': 0.4248681057115001, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2339} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7013792256334581, 'lambda_l2': 1.14394820129377, 'learning_rate': 0.33599107145583906, 'max_depth': 81, 'min_data_in_leaf': 19, 'num_leaves': 2574} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5739398365886955, 'lambda_l2': 0.948671521532756, 'learning_rate': 0.395389174875212, 'max_depth': 86, 'min_data_in_leaf': 16, 'num_leaves': 2443} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6583111713686383, 'lambda_l2': 0.6490942907172009, 'learning_rate': 0.3662043914583103, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 2157} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4772408469202954, 'lambda_l2': 0.7476684780792634, 'learning_rate': 0.31340649438762486, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 2056} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5947338322516322, 'lambda_l2': 0.8768259732083045, 'learning_rate': 0.25767891737569704, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 2208} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5268425211485046, 'lambda_l2': 0.3980928121593943, 'learning_rate': 0.21497391671146374, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 802} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6002077690826328, 'lambda_l2': 0.6101397863769469, 'learning_rate': 0.6300783778822482, 'max_depth': 84, 'min_data_in_leaf': 15, 'num_leaves': 2530} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6162517969805287, 'lambda_l2': 0.25798044696152467, 'learning_rate': 0.3652912062197422, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 469} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4960973473840887, 'lambda_l2': 1.4658623898899763, 'learning_rate': 0.545831340615053, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2028} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6674707379887312, 'lambda_l2': 1.3571964021278262, 'learning_rate': 0.5114647160962429, 'max_depth': 81, 'min_data_in_leaf': 22, 'num_leaves': 2255} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5484306376613164, 'lambda_l2': 0.7532885076469767, 'learning_rate': 0.4587560945919198, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 2402} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4808523480003555, 'lambda_l2': 0.517316220757425, 'learning_rate': 0.1779475155222226, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 394} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6089960419753305, 'lambda_l2': 1.0185952849341602, 'learning_rate': 0.5424104031679515, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 2613} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6422657615157291, 'lambda_l2': 1.2143703161574495, 'learning_rate': 0.6834483313987807, 'max_depth': 83, 'min_data_in_leaf': 20, 'num_leaves': 2175} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6958107940313812, 'lambda_l2': 1.6520708035908995, 'learning_rate': 0.46772599839415346, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2264} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5778101517980481, 'lambda_l2': 0.6989623765953132, 'learning_rate': 0.3887062065707673, 'max_depth': 78, 'min_data_in_leaf': 6, 'num_leaves': 2329} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4652646396120287, 'lambda_l2': 1.4014208830389734, 'learning_rate': 0.32960329729499593, 'max_depth': 73, 'min_data_in_leaf': 9, 'num_leaves': 2532} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.719518392992723, 'lambda_l2': 1.234804464512113, 'learning_rate': 0.29367879177161793, 'max_depth': 75, 'min_data_in_leaf': 15, 'num_leaves': 141} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6786576280620991, 'lambda_l2': 1.186738934031663, 'learning_rate': 0.6808450578001983, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 2395} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7376876880940731, 'lambda_l2': 1.4431056777181794, 'learning_rate': 0.37187488822539033, 'max_depth': 79, 'min_data_in_leaf': 17, 'num_leaves': 2489} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.45965239141786346, 'lambda_l2': 1.0695802470819584, 'learning_rate': 0.43338667999329955, 'max_depth': 76, 'min_data_in_leaf': 11, 'num_leaves': 2385} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4931910550339928, 'lambda_l2': 1.0811456480360138, 'learning_rate': 0.3264836197402824, 'max_depth': 69, 'min_data_in_leaf': 7, 'num_leaves': 2253} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.562848040039341, 'lambda_l2': 0.813420120706028, 'learning_rate': 0.5983539649038296, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 58} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.637851077081988, 'lambda_l2': 0.4353782270496834, 'learning_rate': 0.24265279344893467, 'max_depth': 94, 'min_data_in_leaf': 24, 'num_leaves': 738} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5489317860851963, 'lambda_l2': 0.8900114960384246, 'learning_rate': 0.4337116739480569, 'max_depth': 82, 'min_data_in_leaf': 9, 'num_leaves': 2646} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6148562985962547, 'lambda_l2': 0.9267128668816674, 'learning_rate': 0.5060617683566505, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 2553} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6643345494553745, 'lambda_l2': 1.2722990620590058, 'learning_rate': 0.5531356352545866, 'max_depth': 85, 'min_data_in_leaf': 20, 'num_leaves': 2120} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5211563086411151, 'lambda_l2': 0.31591485495336286, 'learning_rate': 0.23133288813294559, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 1806} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.07793829313717912, 'lambda_l2': 0.11968105122087208, 'learning_rate': 0.2011964687445033, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 965} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.1884639083696117, 'lambda_l2': 0.42701698165109614, 'learning_rate': 0.26644098277199835, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 1926} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6040151502002649, 'lambda_l2': 0.5901174152483097, 'learning_rate': 0.29754555116470627, 'max_depth': 86, 'min_data_in_leaf': 23, 'num_leaves': 2071} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5836349850422151, 'lambda_l2': 0.6840138175850587, 'learning_rate': 0.40192496506037717, 'max_depth': 80, 'min_data_in_leaf': 6, 'num_leaves': 2382} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6309554567015171, 'lambda_l2': 1.0068685777373976, 'learning_rate': 0.00822242886711731, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2192} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.442285030247255, 'lambda_l2': 1.54136965663876, 'learning_rate': 0.36155576059387967, 'max_depth': 73, 'min_data_in_leaf': 7, 'num_leaves': 59} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5595484937592381, 'lambda_l2': 0.6193016206299606, 'learning_rate': 0.4519799995954371, 'max_depth': 77, 'min_data_in_leaf': 4, 'num_leaves': 2341} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5976137054248531, 'lambda_l2': 0.7803076786415484, 'learning_rate': 0.39673574689971913, 'max_depth': 89, 'min_data_in_leaf': 15, 'num_leaves': 2470} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7503965222767078, 'lambda_l2': 1.7420446625923565, 'learning_rate': 0.6387781263902691, 'max_depth': 88, 'min_data_in_leaf': 10, 'num_leaves': 2141} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7667507010184835, 'lambda_l2': 1.648761890581449, 'learning_rate': 0.3224154173012823, 'max_depth': 83, 'min_data_in_leaf': 15, 'num_leaves': 262} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4969066023969951, 'lambda_l2': 0.9113175646123449, 'learning_rate': 0.2962600387307638, 'max_depth': 82, 'min_data_in_leaf': 8, 'num_leaves': 2000} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7805437595205068, 'lambda_l2': 0.18367474262932235, 'learning_rate': 0.19606488763982366, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 545} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7000726771152637, 'lambda_l2': 1.3344117009758418, 'learning_rate': 0.7536403833477497, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 2243} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6315342361502749, 'lambda_l2': 0.001728091977443297, 'learning_rate': 0.5470555062411684, 'max_depth': 90, 'min_data_in_leaf': 13, 'num_leaves': 361} : acc= 53.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5094733445710036, 'lambda_l2': 0.30540010322328004, 'learning_rate': 0.23906054516365063, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 1848} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5268622499277955, 'lambda_l2': 0.5059570736501746, 'learning_rate': 0.21208520810985138, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 839} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.11596282178094924, 'lambda_l2': 0.2339074446197791, 'learning_rate': 0.25863568606565573, 'max_depth': 93, 'min_data_in_leaf': 9, 'num_leaves': 1288} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6841256781596877, 'lambda_l2': 1.8199113100054236, 'learning_rate': 0.496504786369775, 'max_depth': 87, 'min_data_in_leaf': 8, 'num_leaves': 2166} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5739989279910163, 'lambda_l2': 0.8562684009739434, 'learning_rate': 0.42540134009013014, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 2599} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4866966382101976, 'lambda_l2': 0.6799565543325591, 'learning_rate': 0.3429131880363427, 'max_depth': 78, 'min_data_in_leaf': 6, 'num_leaves': 1956} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6554749175718855, 'lambda_l2': 0.9961039492998542, 'learning_rate': 0.2831762752413938, 'max_depth': 84, 'min_data_in_leaf': 22, 'num_leaves': 197} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6245491695051381, 'lambda_l2': 1.1924068087891802, 'learning_rate': 0.6241105563626274, 'max_depth': 79, 'min_data_in_leaf': 13, 'num_leaves': 2320} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5401686468927508, 'lambda_l2': 0.7481645456851002, 'learning_rate': 0.357829410222655, 'max_depth': 77, 'min_data_in_leaf': 11, 'num_leaves': 2093} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3361353521270999, 'lambda_l2': 0.11368026771191438, 'learning_rate': 0.17129008572820129, 'max_depth': 88, 'min_data_in_leaf': 3, 'num_leaves': 722} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6482176350025897, 'lambda_l2': 1.0454017737486214, 'learning_rate': 0.6589803404036909, 'max_depth': 75, 'min_data_in_leaf': 15, 'num_leaves': 2276} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5868787877126441, 'lambda_l2': 0.5807496856850315, 'learning_rate': 0.45680944894769265, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 2698} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7567938652662447, 'lambda_l2': 1.4890084291185033, 'learning_rate': 0.14993591488108798, 'max_depth': 63, 'min_data_in_leaf': 5, 'num_leaves': 1487} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7027133459450934, 'lambda_l2': 0.8318703631446447, 'learning_rate': 0.2522693766554849, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 299} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.15930735452525308, 'lambda_l2': 0.3713141353975929, 'learning_rate': 0.30695527566939873, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 601} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6016457968574855, 'lambda_l2': 0.6233566210502663, 'learning_rate': 0.013006721171194483, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 2582} : acc= 51.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.2073943521429466, 'lambda_l2': 0.4175595640089699, 'learning_rate': 0.1941636845644975, 'max_depth': 98, 'min_data_in_leaf': 10, 'num_leaves': 520} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6491472179512656, 'lambda_l2': 1.1227697618170138, 'learning_rate': 0.7609483974310347, 'max_depth': 81, 'min_data_in_leaf': 7, 'num_leaves': 2205} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9052162802700515, 'lambda_l2': 0.006404821218523107, 'learning_rate': 0.22332064245453692, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 1696} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7271164409260715, 'lambda_l2': 0.9611184524444648, 'learning_rate': 0.28231459914742424, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 1995} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7159540149941497, 'lambda_l2': 1.366012000144936, 'learning_rate': 0.567467772743232, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2429} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.46558723445094813, 'lambda_l2': 1.1148209379265008, 'learning_rate': 0.3938163578084519, 'max_depth': 75, 'min_data_in_leaf': 8, 'num_leaves': 2076} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6154242151525213, 'lambda_l2': 0.5393719154407255, 'learning_rate': 0.5175867738725614, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 389} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5542104136576997, 'lambda_l2': 0.2698126889976996, 'learning_rate': 0.378398694417284, 'max_depth': 94, 'min_data_in_leaf': 2, 'num_leaves': 1155} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.705793779738905, 'lambda_l2': 1.280291375211645, 'learning_rate': 0.4415120116489723, 'max_depth': 83, 'min_data_in_leaf': 16, 'num_leaves': 2302} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6638756136750228, 'lambda_l2': 0.15458739018729878, 'learning_rate': 0.25072944982601186, 'max_depth': 30, 'min_data_in_leaf': 25, 'num_leaves': 493} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.48788957609137834, 'lambda_l2': 1.0673237690782307, 'learning_rate': 0.4907232450707397, 'max_depth': 71, 'min_data_in_leaf': 4, 'num_leaves': 2037} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6763354980492491, 'lambda_l2': 1.2175075715862929, 'learning_rate': 0.8509151606794827, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2357} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5145858355773854, 'lambda_l2': 0.39006460329731263, 'learning_rate': 0.17376048375598996, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 1770} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7289777523506892, 'lambda_l2': 1.427039366781088, 'learning_rate': 0.36824813826422725, 'max_depth': 74, 'min_data_in_leaf': 19, 'num_leaves': 2509} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6836008963783783, 'lambda_l2': 0.7242453438368683, 'learning_rate': 0.3215422115116647, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 64} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6321441833725926, 'lambda_l2': 0.9969821188159819, 'learning_rate': 0.7195819986536055, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 2190} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.568426270418491, 'lambda_l2': 0.8356756738547182, 'learning_rate': 0.22355056394834197, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 146} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6610520455938519, 'lambda_l2': 1.2736515920103761, 'learning_rate': 0.6031837016210465, 'max_depth': 81, 'min_data_in_leaf': 17, 'num_leaves': 2410} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.23677105858517278, 'lambda_l2': 0.29914702794859294, 'learning_rate': 0.18944315937090536, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 1844} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7567562233293775, 'lambda_l2': 1.6114351329038423, 'learning_rate': 0.3288498599570984, 'max_depth': 24, 'min_data_in_leaf': 15, 'num_leaves': 698} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5486933354909411, 'lambda_l2': 0.5043897862625683, 'learning_rate': 0.15344939763807786, 'max_depth': 48, 'min_data_in_leaf': 12, 'num_leaves': 874} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5336578063710176, 'lambda_l2': 0.4641965387613345, 'learning_rate': 0.27986903683823056, 'max_depth': 91, 'min_data_in_leaf': 5, 'num_leaves': 1013} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6816128283995231, 'lambda_l2': 1.153951206410981, 'learning_rate': 0.3498965018160294, 'max_depth': 79, 'min_data_in_leaf': 17, 'num_leaves': 2474} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6124992391118403, 'lambda_l2': 0.8831495661724191, 'learning_rate': 0.23033373792076478, 'max_depth': 85, 'min_data_in_leaf': 23, 'num_leaves': 2105} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6379979728284135, 'lambda_l2': 1.070323425962058, 'learning_rate': 0.5082252316007122, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2255} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6432350466563614, 'lambda_l2': 1.3408132648491553, 'learning_rate': 0.4259981557883311, 'max_depth': 79, 'min_data_in_leaf': 1, 'num_leaves': 2253} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5179572156684, 'lambda_l2': 0.40154109860007, 'learning_rate': 0.1862351583156986, 'max_depth': 98, 'min_data_in_leaf': 11, 'num_leaves': 655} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7389860601282529, 'lambda_l2': 0.1859852432318173, 'learning_rate': 0.2643456113154507, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 560} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5437961996645155, 'lambda_l2': 0.2514035279723693, 'learning_rate': 0.4154369452077431, 'max_depth': 96, 'min_data_in_leaf': 6, 'num_leaves': 1058} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6166104514479559, 'lambda_l2': 1.0973410669745205, 'learning_rate': 0.6785985546348999, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 2171} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.05766383295286642, 'lambda_l2': 0.5789536923583647, 'learning_rate': 0.30690083009121494, 'max_depth': 89, 'min_data_in_leaf': 89, 'num_leaves': 300} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5014651898115426, 'lambda_l2': 0.12112907414741161, 'learning_rate': 0.20522234832107192, 'max_depth': 94, 'min_data_in_leaf': 9, 'num_leaves': 1911} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.578278310871736, 'lambda_l2': 0.7498501777391239, 'learning_rate': 0.46985895292379387, 'max_depth': 82, 'min_data_in_leaf': 3, 'num_leaves': 55} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5942299311028254, 'lambda_l2': 0.6326639402736396, 'learning_rate': 0.5489151447352877, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 2490} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9274725047526091, 'lambda_l2': 0.07600308977103876, 'learning_rate': 0.1321333194840718, 'max_depth': 40, 'min_data_in_leaf': 10, 'num_leaves': 938} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5405283111504451, 'lambda_l2': 0.3490413105009142, 'learning_rate': 0.39153283326320915, 'max_depth': 91, 'min_data_in_leaf': 6, 'num_leaves': 2356} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.40172281821195266, 'lambda_l2': 0.5064087032670608, 'learning_rate': 0.16568093178424168, 'max_depth': 97, 'min_data_in_leaf': 12, 'num_leaves': 57} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4871286851984035, 'lambda_l2': 0.15013874917454134, 'learning_rate': 0.01487039546021948, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 1597} : acc= 55.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5724430832847403, 'lambda_l2': 0.7081077929555103, 'learning_rate': 0.3831551818201853, 'max_depth': 66, 'min_data_in_leaf': 5, 'num_leaves': 2579} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4326055007971407, 'lambda_l2': 1.238155540001729, 'learning_rate': 0.33326085300215313, 'max_depth': 69, 'min_data_in_leaf': 8, 'num_leaves': 2750} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6601236690000902, 'lambda_l2': 0.9620999193668518, 'learning_rate': 0.5860858961306381, 'max_depth': 74, 'min_data_in_leaf': 15, 'num_leaves': 2319} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6191614255167357, 'lambda_l2': 0.4552536761947379, 'learning_rate': 0.46399345257416513, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 428} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9649304820824002, 'lambda_l2': 1.4986232599216867, 'learning_rate': 0.7465044448394004, 'max_depth': 87, 'min_data_in_leaf': 10, 'num_leaves': 2125} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4415860520819496, 'lambda_l2': 1.4042870995035774, 'learning_rate': 0.8533333560283438, 'max_depth': 71, 'min_data_in_leaf': 2, 'num_leaves': 1959} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9972314481946503, 'lambda_l2': 0.014031712222639797, 'learning_rate': 0.2500604724498605, 'max_depth': 85, 'min_data_in_leaf': 27, 'num_leaves': 206} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.2873011364559047, 'lambda_l2': 0.20739404786937868, 'learning_rate': 0.2110193882708993, 'max_depth': 56, 'min_data_in_leaf': 16, 'num_leaves': 1281} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5915104178403404, 'lambda_l2': 0.7944767320656055, 'learning_rate': 0.5308149544507537, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 2647} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6425025795237114, 'lambda_l2': 1.1585472430072574, 'learning_rate': 0.637990649002629, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 2404} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7814749036436464, 'lambda_l2': 1.8774614980154847, 'learning_rate': 0.1433607468356349, 'max_depth': 96, 'min_data_in_leaf': 4, 'num_leaves': 1669} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5067716385869425, 'lambda_l2': 0.9006822519415613, 'learning_rate': 0.43317892683774045, 'max_depth': 60, 'min_data_in_leaf': 8, 'num_leaves': 2015} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7145667656803654, 'lambda_l2': 1.5954888357770585, 'learning_rate': 0.30648292459368504, 'max_depth': 77, 'min_data_in_leaf': 18, 'num_leaves': 251} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8624570571598335, 'lambda_l2': 0.35176042088850235, 'learning_rate': 0.17198350213156455, 'max_depth': 36, 'min_data_in_leaf': 51, 'num_leaves': 1132} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7917035948107944, 'lambda_l2': 0.08575111008914353, 'learning_rate': 0.2514065604136238, 'max_depth': 99, 'min_data_in_leaf': 25, 'num_leaves': 596} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6893495431753833, 'lambda_l2': 1.0679583882961583, 'learning_rate': 0.47251589806027794, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 2205} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.654952631843209, 'lambda_l2': 1.0165564467148722, 'learning_rate': 0.9701386286459197, 'max_depth': 82, 'min_data_in_leaf': 14, 'num_leaves': 2303} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7006927951983193, 'lambda_l2': 1.387661319186315, 'learning_rate': 0.2865125068200716, 'max_depth': 77, 'min_data_in_leaf': 21, 'num_leaves': 2802} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7272571233471234, 'lambda_l2': 1.3024290785877664, 'learning_rate': 0.3653515322161242, 'max_depth': 74, 'min_data_in_leaf': 17, 'num_leaves': 136} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6775292478720396, 'lambda_l2': 0.606280808124956, 'learning_rate': 0.2358823474870612, 'max_depth': 89, 'min_data_in_leaf': 24, 'num_leaves': 346} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4550228648131344, 'lambda_l2': 1.2391036668516717, 'learning_rate': 0.33870567159703563, 'max_depth': 70, 'min_data_in_leaf': 7, 'num_leaves': 2571} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6051558669098701, 'lambda_l2': 0.8576985698176713, 'learning_rate': 0.2825485415816684, 'max_depth': 84, 'min_data_in_leaf': 22, 'num_leaves': 1997} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6992156831587255, 'lambda_l2': 1.5571720664644737, 'learning_rate': 0.3185115178433539, 'max_depth': 73, 'min_data_in_leaf': 20, 'num_leaves': 2489} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4249217345678005, 'lambda_l2': 1.1287234870928506, 'learning_rate': 0.3529690165926358, 'max_depth': 72, 'min_data_in_leaf': 2, 'num_leaves': 2685} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5614291010210692, 'lambda_l2': 0.6646956123209499, 'learning_rate': 0.41758366495689575, 'max_depth': 83, 'min_data_in_leaf': 5, 'num_leaves': 2416} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6681089504365961, 'lambda_l2': 1.3334924867645184, 'learning_rate': 0.03321191945435569, 'max_depth': 83, 'min_data_in_leaf': 19, 'num_leaves': 2175} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5262620669540543, 'lambda_l2': 0.5157487018150613, 'learning_rate': 0.19285199407911569, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 1091} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5601152412130526, 'lambda_l2': 0.3264492354959738, 'learning_rate': 0.21851928030617604, 'max_depth': 91, 'min_data_in_leaf': 14, 'num_leaves': 52} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7133309798481572, 'lambda_l2': 1.7735096011081204, 'learning_rate': 0.5942976252783689, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 2094} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6605014251828228, 'lambda_l2': 1.0073842187530253, 'learning_rate': 0.5215519645783097, 'max_depth': 78, 'min_data_in_leaf': 1, 'num_leaves': 2257} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.47357069915063943, 'lambda_l2': 0.7384770472373258, 'learning_rate': 0.29587176313994484, 'max_depth': 45, 'min_data_in_leaf': 9, 'num_leaves': 1807} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5789075622792534, 'lambda_l2': 1.467095844052597, 'learning_rate': 0.7028852033914047, 'max_depth': 85, 'min_data_in_leaf': 14, 'num_leaves': 2328} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5091242006419101, 'lambda_l2': 0.6003086111664261, 'learning_rate': 0.4696033217443105, 'max_depth': 81, 'min_data_in_leaf': 6, 'num_leaves': 2447} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4708721614187456, 'lambda_l2': 0.6722527159207511, 'learning_rate': 0.36596702125291847, 'max_depth': 80, 'min_data_in_leaf': 10, 'num_leaves': 1754} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5473331681728313, 'lambda_l2': 0.8427709344467122, 'learning_rate': 0.38214404285878395, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 2541} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7692202844364879, 'lambda_l2': 1.2170975240665047, 'learning_rate': 0.1275201682345645, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 700} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8047700151693494, 'lambda_l2': 0.002371763016355849, 'learning_rate': 0.16452143666983154, 'max_depth': 65, 'min_data_in_leaf': 4, 'num_leaves': 1367} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5971831048017849, 'lambda_l2': 0.5664336083153474, 'learning_rate': 0.06001358453888979, 'max_depth': 89, 'min_data_in_leaf': 22, 'num_leaves': 2038} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.39031409944505147, 'lambda_l2': 2.870152755780114, 'learning_rate': 0.22674259249694925, 'max_depth': 94, 'min_data_in_leaf': 17, 'num_leaves': 801} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.49851541200581917, 'lambda_l2': 0.2528161323732625, 'learning_rate': 0.24431748828946287, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 1903} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6272473407667951, 'lambda_l2': 1.0990889988751797, 'learning_rate': 0.8543576053195581, 'max_depth': 82, 'min_data_in_leaf': 9, 'num_leaves': 2256} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.38027235247432306, 'lambda_l2': 0.20562170395899204, 'learning_rate': 0.2011312651486569, 'max_depth': 50, 'min_data_in_leaf': 16, 'num_leaves': 1211} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7592283967960436, 'lambda_l2': 2.4568406377663368, 'learning_rate': 0.27431208076399155, 'max_depth': 95, 'min_data_in_leaf': 12, 'num_leaves': 1450} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5704218201696195, 'lambda_l2': 0.7840418809349629, 'learning_rate': 0.5577230619366776, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 2921} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.529183665441498, 'lambda_l2': 0.37375119547539914, 'learning_rate': 0.1154592704412654, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 2388} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7319574470153262, 'lambda_l2': 2.229204089354976, 'learning_rate': 0.42569685211341635, 'max_depth': 89, 'min_data_in_leaf': 10, 'num_leaves': 2140} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.47488994332689566, 'lambda_l2': 0.9196459172873045, 'learning_rate': 0.30008050306242506, 'max_depth': 77, 'min_data_in_leaf': 4, 'num_leaves': 1879} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4417097068026434, 'lambda_l2': 0.6409421730986609, 'learning_rate': 0.3339832087632238, 'max_depth': 80, 'min_data_in_leaf': 8, 'num_leaves': 1951} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7315078276720803, 'lambda_l2': 1.9822222911434737, 'learning_rate': 0.0944184479315288, 'max_depth': 84, 'min_data_in_leaf': 40, 'num_leaves': 522} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.33032487900047025, 'lambda_l2': 0.07152223165156602, 'learning_rate': 0.143228645101494, 'max_depth': 54, 'min_data_in_leaf': 7, 'num_leaves': 914} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6956014410400475, 'lambda_l2': 1.1729475993531568, 'learning_rate': 0.040369081028398056, 'max_depth': 76, 'min_data_in_leaf': 19, 'num_leaves': 282} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5203998603325257, 'lambda_l2': 0.43095726346652213, 'learning_rate': 0.2639696369894821, 'max_depth': 100, 'min_data_in_leaf': 6, 'num_leaves': 844} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.818384100513724, 'lambda_l2': 0.2969112759113646, 'learning_rate': 0.17342205009891073, 'max_depth': 91, 'min_data_in_leaf': 26, 'num_leaves': 435} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6090709360802717, 'lambda_l2': 0.9090852954850589, 'learning_rate': 0.251969738183888, 'max_depth': 86, 'min_data_in_leaf': 23, 'num_leaves': 141} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6372612910591365, 'lambda_l2': 1.0163082422597685, 'learning_rate': 0.6371935551947884, 'max_depth': 79, 'min_data_in_leaf': 14, 'num_leaves': 2342} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.2587241454295641, 'lambda_l2': 0.4247757667613088, 'learning_rate': 0.19304931476159057, 'max_depth': 94, 'min_data_in_leaf': 13, 'num_leaves': 757} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.68347935761871, 'lambda_l2': 1.3096655534873411, 'learning_rate': 0.32620947231981695, 'max_depth': 80, 'min_data_in_leaf': 19, 'num_leaves': 2671} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8857408884696514, 'lambda_l2': 0.18497453482849047, 'learning_rate': 0.15667181219089166, 'max_depth': 90, 'min_data_in_leaf': 11, 'num_leaves': 658} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5846229386024249, 'lambda_l2': 0.5435706336813521, 'learning_rate': 0.27775604241299373, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 2066} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7526992550190574, 'lambda_l2': 0.10789450136672692, 'learning_rate': 0.37073895733815004, 'max_depth': 91, 'min_data_in_leaf': 16, 'num_leaves': 497} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6244212808027099, 'lambda_l2': 0.971104984687885, 'learning_rate': 0.5014633046952554, 'max_depth': 81, 'min_data_in_leaf': 3, 'num_leaves': 2235} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4066162820382315, 'lambda_l2': 0.17744832796264692, 'learning_rate': 0.1374442617404695, 'max_depth': 68, 'min_data_in_leaf': 9, 'num_leaves': 1332} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4897237589815643, 'lambda_l2': 0.28594330722556216, 'learning_rate': 0.21932793791089536, 'max_depth': 93, 'min_data_in_leaf': 12, 'num_leaves': 1723} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.844438904277837, 'lambda_l2': 0.43979814321773447, 'learning_rate': 0.1864454843683675, 'max_depth': 96, 'min_data_in_leaf': 15, 'num_leaves': 1513} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5551528227404665, 'lambda_l2': 2.7396774783224807, 'learning_rate': 0.3060835372424059, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 352} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.94159760187045, 'lambda_l2': 0.5118093652576614, 'learning_rate': 0.22113119968387082, 'max_depth': 98, 'min_data_in_leaf': 5, 'num_leaves': 591} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6680540078223952, 'lambda_l2': 4.376474569233865, 'learning_rate': 0.791960725232372, 'max_depth': 88, 'min_data_in_leaf': 11, 'num_leaves': 2144} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4651155743264995, 'lambda_l2': 0.755860977020243, 'learning_rate': 0.3618605635388397, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 1821} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4184252039186309, 'lambda_l2': 0.9727776827690399, 'learning_rate': 0.45745331059123856, 'max_depth': 72, 'min_data_in_leaf': 7, 'num_leaves': 53} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5125116332094479, 'lambda_l2': 0.004511626316125811, 'learning_rate': 0.40764572017404804, 'max_depth': 91, 'min_data_in_leaf': 3, 'num_leaves': 2486} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5843160315126062, 'lambda_l2': 0.7086346893503986, 'learning_rate': 0.5838627398054695, 'max_depth': 86, 'min_data_in_leaf': 14, 'num_leaves': 2561} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7012261206670484, 'lambda_l2': 1.6432909517088496, 'learning_rate': 0.05284612185584763, 'max_depth': 78, 'min_data_in_leaf': 24, 'num_leaves': 220} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5327820223924941, 'lambda_l2': 0.3493152943582257, 'learning_rate': 0.2527724980944307, 'max_depth': 94, 'min_data_in_leaf': 13, 'num_leaves': 944} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4877163794456056, 'lambda_l2': 0.7899012060474064, 'learning_rate': 0.31974096883505176, 'max_depth': 38, 'min_data_in_leaf': 10, 'num_leaves': 1928} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5400166783013315, 'lambda_l2': 0.6784825455397312, 'learning_rate': 0.5239984756599908, 'max_depth': 82, 'min_data_in_leaf': 8, 'num_leaves': 2416} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6520990994033005, 'lambda_l2': 0.007805430792857837, 'learning_rate': 0.6878698509149669, 'max_depth': 89, 'min_data_in_leaf': 49, 'num_leaves': 2236} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6914058513290123, 'lambda_l2': 1.4958345273724492, 'learning_rate': 0.46223737126512604, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2116} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6438765245531385, 'lambda_l2': 1.4082975493171541, 'learning_rate': 0.5255562322107243, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2307} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6810200493420158, 'lambda_l2': 1.1328407108620853, 'learning_rate': 0.6513169423515062, 'max_depth': 85, 'min_data_in_leaf': 29, 'num_leaves': 2185} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5977942262199574, 'lambda_l2': 0.5745397899081928, 'learning_rate': 0.2506124536091822, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 172} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.9083658516540778, 'lambda_l2': 0.2584167908638466, 'learning_rate': 0.2072093033618208, 'max_depth': 100, 'min_data_in_leaf': 5, 'num_leaves': 1701} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.04489117513384752, 'lambda_l2': 0.1132226196146981, 'learning_rate': 0.268047500873368, 'max_depth': 90, 'min_data_in_leaf': 26, 'num_leaves': 461} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.2571138142546666, 'lambda_l2': 0.46801642495923135, 'learning_rate': 0.10398170488711515, 'max_depth': 62, 'min_data_in_leaf': 12, 'num_leaves': 994} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6042279641206557, 'lambda_l2': 0.8906814752077798, 'learning_rate': 0.2841196252383459, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 2050} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.577085038881711, 'lambda_l2': 0.764861848450283, 'learning_rate': 0.4070513936513257, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2631} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.22330583970916024, 'lambda_l2': 0.5307019215629927, 'learning_rate': 0.33753073600915917, 'max_depth': 92, 'min_data_in_leaf': 44, 'num_leaves': 351} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.12513172933074745, 'lambda_l2': 0.32739883725525964, 'learning_rate': 0.15534931964703888, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 1609} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7365692218469515, 'lambda_l2': 2.121285658997025, 'learning_rate': 0.3905514838150261, 'max_depth': 75, 'min_data_in_leaf': 16, 'num_leaves': 2850} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7188144508770751, 'lambda_l2': 1.7237472200662922, 'learning_rate': 0.7848541976815765, 'max_depth': 32, 'min_data_in_leaf': 61, 'num_leaves': 2330} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5377463386125031, 'lambda_l2': 0.40054160619431384, 'learning_rate': 0.08192674838722575, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 1196} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6229865191914509, 'lambda_l2': 0.012803963113929695, 'learning_rate': 0.4385318342186766, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 2486} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5113565964471242, 'lambda_l2': 0.4730871715841973, 'learning_rate': 0.1804796555519297, 'max_depth': 100, 'min_data_in_leaf': 11, 'num_leaves': 1381} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6649481979829799, 'lambda_l2': 1.295339009005328, 'learning_rate': 0.5757749704393069, 'max_depth': 83, 'min_data_in_leaf': 20, 'num_leaves': 2184} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.48536046478316675, 'lambda_l2': 0.23186439338370265, 'learning_rate': 0.12806650205347275, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 1820} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.14216765671101053, 'lambda_l2': 0.1082849700217313, 'learning_rate': 0.22117303411405662, 'max_depth': 92, 'min_data_in_leaf': 15, 'num_leaves': 1583} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7099578041215171, 'lambda_l2': 1.580514579312433, 'learning_rate': 0.35574249680264725, 'max_depth': 80, 'min_data_in_leaf': 14, 'num_leaves': 249} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.459793391831861, 'lambda_l2': 0.29610888160116366, 'learning_rate': 0.2369566428409559, 'max_depth': 98, 'min_data_in_leaf': 10, 'num_leaves': 1861} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4355470138976264, 'lambda_l2': 0.6649677277773524, 'learning_rate': 0.30115934207111655, 'max_depth': 79, 'min_data_in_leaf': 8, 'num_leaves': 2068} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.41585151244637686, 'lambda_l2': 1.2401143038409645, 'learning_rate': 0.38147215489059083, 'max_depth': 68, 'min_data_in_leaf': 6, 'num_leaves': 2741} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6270517931090926, 'lambda_l2': 1.0355054834720527, 'learning_rate': 0.974529878056797, 'max_depth': 75, 'min_data_in_leaf': 13, 'num_leaves': 2389} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5577717384555847, 'lambda_l2': 0.8542050798937, 'learning_rate': 0.4855119900586975, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 2506} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6075574106018407, 'lambda_l2': 0.6130472208262185, 'learning_rate': 0.2811078669631578, 'max_depth': 84, 'min_data_in_leaf': 24, 'num_leaves': 2023} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7800182255228721, 'lambda_l2': 0.21320302585935974, 'learning_rate': 0.17729160881670142, 'max_depth': 60, 'min_data_in_leaf': 16, 'num_leaves': 760} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6455303431673581, 'lambda_l2': 1.0783391114848755, 'learning_rate': 0.6589142211516684, 'max_depth': 82, 'min_data_in_leaf': 17, 'num_leaves': 2296} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6812502729148167, 'lambda_l2': 1.1870854816113336, 'learning_rate': 0.7568371073493748, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 2124} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5488259088280479, 'lambda_l2': 0.43902974233278547, 'learning_rate': 0.1936339374568329, 'max_depth': 95, 'min_data_in_leaf': 3, 'num_leaves': 589} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8314199128951151, 'lambda_l2': 0.16604033622970335, 'learning_rate': 0.21549508227664083, 'max_depth': 90, 'min_data_in_leaf': 35, 'num_leaves': 454} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6648824898886553, 'lambda_l2': 1.1928518627582574, 'learning_rate': 0.5207680825589128, 'max_depth': 81, 'min_data_in_leaf': 22, 'num_leaves': 2368} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6066645225368353, 'lambda_l2': 0.8797665488836851, 'learning_rate': 0.06807138779808136, 'max_depth': 86, 'min_data_in_leaf': 27, 'num_leaves': 303} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5209981762614218, 'lambda_l2': 0.36569906089347415, 'learning_rate': 0.025909935107951202, 'max_depth': 92, 'min_data_in_leaf': 1, 'num_leaves': 1014} : acc= 62.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5585656787554859, 'lambda_l2': 0.5159949885902255, 'learning_rate': 0.44104114139180406, 'max_depth': 90, 'min_data_in_leaf': 3, 'num_leaves': 1278} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5807651718986142, 'lambda_l2': 0.7810213964720825, 'learning_rate': 0.3262416311625632, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 2012} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7571138160827177, 'lambda_l2': 0.5863992308201708, 'learning_rate': 0.2519754159520911, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 408} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6380061560734422, 'lambda_l2': 1.4916939523718555, 'learning_rate': 0.6393978596572084, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2241} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.29665112036605606, 'lambda_l2': 0.08388271440545125, 'learning_rate': 0.1740881421980607, 'max_depth': 99, 'min_data_in_leaf': 11, 'num_leaves': 1111} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5878222416253815, 'lambda_l2': 0.6828216150479185, 'learning_rate': 0.31979745515702374, 'max_depth': 83, 'min_data_in_leaf': 24, 'num_leaves': 2089} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4516129004763833, 'lambda_l2': 0.010436868017670575, 'learning_rate': 0.14379773874728982, 'max_depth': 51, 'min_data_in_leaf': 9, 'num_leaves': 1701} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6275463888874339, 'lambda_l2': 0.9743969507845867, 'learning_rate': 0.5910345783712984, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2214} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45159979992956956, 'lambda_l2': 0.9510864008136175, 'learning_rate': 0.8944754593161498, 'max_depth': 71, 'min_data_in_leaf': 6, 'num_leaves': 2138} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6790140942671663, 'lambda_l2': 1.1318907896886574, 'learning_rate': 0.5429696977023483, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 2428} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.39621770788649613, 'lambda_l2': 1.4088183599231732, 'learning_rate': 0.4227633806892179, 'max_depth': 73, 'min_data_in_leaf': 10, 'num_leaves': 2795} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6500809003089013, 'lambda_l2': 0.31757483727896824, 'learning_rate': 0.27744091794411335, 'max_depth': 90, 'min_data_in_leaf': 15, 'num_leaves': 538} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5644365014802913, 'lambda_l2': 0.8050531323311568, 'learning_rate': 0.37407917743140856, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 272} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5921924024789174, 'lambda_l2': 0.6504053488398441, 'learning_rate': 0.47490533804615886, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2569} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.721076024509679, 'lambda_l2': 0.11173286822484581, 'learning_rate': 0.6997595562716611, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 2320} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.47748690713531655, 'lambda_l2': 0.7464210693388944, 'learning_rate': 0.4098809553512459, 'max_depth': 76, 'min_data_in_leaf': 4, 'num_leaves': 2621} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8069832100311376, 'lambda_l2': 0.2276950352816801, 'learning_rate': 0.1298168696782319, 'max_depth': 98, 'min_data_in_leaf': 7, 'num_leaves': 892} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4963333012795683, 'lambda_l2': 0.4192778404462558, 'learning_rate': 0.15279992566012368, 'max_depth': 57, 'min_data_in_leaf': 12, 'num_leaves': 635} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7517027928382003, 'lambda_l2': 1.3414963923044625, 'learning_rate': 0.3479652322915351, 'max_depth': 80, 'min_data_in_leaf': 55, 'num_leaves': 149} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.022335289883705756, 'lambda_l2': 0.5338063692360215, 'learning_rate': 0.4673525559277865, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 369} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5090066005257989, 'lambda_l2': 0.6822837539732125, 'learning_rate': 0.3229724305700018, 'max_depth': 77, 'min_data_in_leaf': 5, 'num_leaves': 1993} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6169963445791645, 'lambda_l2': 0.8733886234042707, 'learning_rate': 0.240338898330778, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 133} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7099484919568076, 'lambda_l2': 1.0975825064514542, 'learning_rate': 0.11772757839654845, 'max_depth': 75, 'min_data_in_leaf': 17, 'num_leaves': 2714} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.779312828648262, 'lambda_l2': 3.181190996980641, 'learning_rate': 0.277065499621911, 'max_depth': 94, 'min_data_in_leaf': 25, 'num_leaves': 787} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45824354091544467, 'lambda_l2': 1.026619000677933, 'learning_rate': 0.3812835810380234, 'max_depth': 72, 'min_data_in_leaf': 1, 'num_leaves': 2495} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6901996554595896, 'lambda_l2': 0.7827906461811922, 'learning_rate': 0.2211391725076724, 'max_depth': 85, 'min_data_in_leaf': 20, 'num_leaves': 2054} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7321046413914938, 'lambda_l2': 1.5772721672846488, 'learning_rate': 0.3536683245289117, 'max_depth': 34, 'min_data_in_leaf': 38, 'num_leaves': 660} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6418235477627657, 'lambda_l2': 0.9857911935716235, 'learning_rate': 0.7715207897371867, 'max_depth': 77, 'min_data_in_leaf': 13, 'num_leaves': 2401} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.17614667164350103, 'lambda_l2': 0.00399846171115481, 'learning_rate': 0.23568766659734644, 'max_depth': 97, 'min_data_in_leaf': 9, 'num_leaves': 1792} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5583057290943743, 'lambda_l2': 0.6360805335764433, 'learning_rate': 0.3219726571897982, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 267} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.474033179759854, 'lambda_l2': 0.9537846231267435, 'learning_rate': 0.5838495538327081, 'max_depth': 79, 'min_data_in_leaf': 98, 'num_leaves': 1970} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.3481429904712726, 'lambda_l2': 1.9247625799569823, 'learning_rate': 0.04763160093359794, 'max_depth': 65, 'min_data_in_leaf': 3, 'num_leaves': 1415} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.500983513168307, 'lambda_l2': 0.3335868300889546, 'learning_rate': 0.1983972173524894, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 1526} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5938103035721368, 'lambda_l2': 0.007999591087401383, 'learning_rate': 0.4290241422097126, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 434} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7065967077902139, 'lambda_l2': 4.673334091360488, 'learning_rate': 0.09328304137341521, 'max_depth': 77, 'min_data_in_leaf': 30, 'num_leaves': 2653} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5294708119421958, 'lambda_l2': 0.47589170613389475, 'learning_rate': 0.17199528249829676, 'max_depth': 95, 'min_data_in_leaf': 8, 'num_leaves': 894} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6734156265805713, 'lambda_l2': 0.003661698144136083, 'learning_rate': 0.25340466345813645, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 513} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9670576902254105, 'lambda_l2': 0.17036844546708935, 'learning_rate': 0.2837391963949956, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 1790} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6539170554487983, 'lambda_l2': 1.2861844463355743, 'learning_rate': 0.9962060134350869, 'max_depth': 80, 'min_data_in_leaf': 6, 'num_leaves': 2252} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6645524456217514, 'lambda_l2': 1.4273263409075825, 'learning_rate': 0.5102750539994242, 'max_depth': 83, 'min_data_in_leaf': 18, 'num_leaves': 2328} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5642979267410614, 'lambda_l2': 0.8525177620424279, 'learning_rate': 0.42803181359167797, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 2568} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.37709507684399246, 'lambda_l2': 0.2605545922783331, 'learning_rate': 0.1103886777810632, 'max_depth': 41, 'min_data_in_leaf': 4, 'num_leaves': 57} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.19298469441130997, 'lambda_l2': 0.43830621208796605, 'learning_rate': 0.20448001503323981, 'max_depth': 97, 'min_data_in_leaf': 9, 'num_leaves': 1196} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6323362932388509, 'lambda_l2': 1.2194788561369954, 'learning_rate': 0.6214578427775977, 'max_depth': 83, 'min_data_in_leaf': 27, 'num_leaves': 2422} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.15210136305338834, 'lambda_l2': 0.3640936567819829, 'learning_rate': 0.28931822543562147, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 1919} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6105738359192127, 'lambda_l2': 1.0691640194059078, 'learning_rate': 0.8227978353800223, 'max_depth': 75, 'min_data_in_leaf': 14, 'num_leaves': 2182} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.2786342177999521, 'lambda_l2': 0.1519081039482993, 'learning_rate': 0.1576890998407081, 'max_depth': 54, 'min_data_in_leaf': 16, 'num_leaves': 834} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6184853868817108, 'lambda_l2': 1.0817727460806315, 'learning_rate': 0.5200211670909941, 'max_depth': 73, 'min_data_in_leaf': 71, 'num_leaves': 2260} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5382584545514876, 'lambda_l2': 0.5435508148928109, 'learning_rate': 0.30917536177875865, 'max_depth': 87, 'min_data_in_leaf': 23, 'num_leaves': 186} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7386882171431541, 'lambda_l2': 1.464942317335162, 'learning_rate': 0.3862556564640046, 'max_depth': 82, 'min_data_in_leaf': 12, 'num_leaves': 727} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.44343145636494863, 'lambda_l2': 0.9176582572398978, 'learning_rate': 0.5181805338422028, 'max_depth': 79, 'min_data_in_leaf': 2, 'num_leaves': 1924} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.08053512927897036, 'lambda_l2': 0.08919303993891405, 'learning_rate': 0.6681667499587056, 'max_depth': 89, 'min_data_in_leaf': 8, 'num_leaves': 2124} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5025640426145664, 'lambda_l2': 0.2605553904161936, 'learning_rate': 0.23290758526063848, 'max_depth': 94, 'min_data_in_leaf': 6, 'num_leaves': 1671} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6766254774004784, 'lambda_l2': 1.6793825093881376, 'learning_rate': 0.4764961481811617, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 2468} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6951996042435866, 'lambda_l2': 1.373916580114926, 'learning_rate': 0.34734163587428557, 'max_depth': 73, 'min_data_in_leaf': 22, 'num_leaves': 2638} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5216884565049233, 'lambda_l2': 0.36722770479588945, 'learning_rate': 0.08472580845462982, 'max_depth': 93, 'min_data_in_leaf': 1, 'num_leaves': 2371} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7913403315630455, 'lambda_l2': 1.2798575504242657, 'learning_rate': 0.3862455759954621, 'max_depth': 80, 'min_data_in_leaf': 77, 'num_leaves': 370} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6455805252688535, 'lambda_l2': 1.1841240182332895, 'learning_rate': 0.5871962451026569, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2317} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.36278488476848264, 'lambda_l2': 0.5610287832669205, 'learning_rate': 0.18616084124766716, 'max_depth': 63, 'min_data_in_leaf': 10, 'num_leaves': 1127} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7203143066391718, 'lambda_l2': 1.2089334759900652, 'learning_rate': 0.300260950339908, 'max_depth': 70, 'min_data_in_leaf': 20, 'num_leaves': 2521} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5853473494974112, 'lambda_l2': 0.7155138672582722, 'learning_rate': 0.2784289764426154, 'max_depth': 87, 'min_data_in_leaf': 23, 'num_leaves': 2050} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.41778804410996895, 'lambda_l2': 0.004420805296579983, 'learning_rate': 0.21249159510580887, 'max_depth': 100, 'min_data_in_leaf': 15, 'num_leaves': 1316} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5708177259036257, 'lambda_l2': 0.629046496958916, 'learning_rate': 0.4367534062548807, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 2561} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7081397102770665, 'lambda_l2': 1.711327764333527, 'learning_rate': 0.7217284446882725, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 2285} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6241213020217787, 'lambda_l2': 0.9957027879163609, 'learning_rate': 0.5395559519723669, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2206} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4770927978162293, 'lambda_l2': 0.8987024384288933, 'learning_rate': 0.4554732343962268, 'max_depth': 68, 'min_data_in_leaf': 4, 'num_leaves': 1992} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6955949555871931, 'lambda_l2': 3.0107220733953497, 'learning_rate': 0.028563875648802584, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 2141} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.57748914867166, 'lambda_l2': 4.070500136663355, 'learning_rate': 0.3755983602688264, 'max_depth': 91, 'min_data_in_leaf': 19, 'num_leaves': 2808} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8868643528206679, 'lambda_l2': 3.348548182859316, 'learning_rate': 0.584955319344244, 'max_depth': 100, 'min_data_in_leaf': 10, 'num_leaves': 2218} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6782830543826499, 'lambda_l2': 1.1423114655564963, 'learning_rate': 0.7567463222174996, 'max_depth': 82, 'min_data_in_leaf': 25, 'num_leaves': 2423} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5977376021777473, 'lambda_l2': 3.7208475894024566, 'learning_rate': 0.06854763782599617, 'max_depth': 95, 'min_data_in_leaf': 13, 'num_leaves': 452} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.543217135272915, 'lambda_l2': 0.7859192627874518, 'learning_rate': 0.2601340014413764, 'max_depth': 85, 'min_data_in_leaf': 20, 'num_leaves': 207} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.42743784870572266, 'lambda_l2': 1.0284756497743834, 'learning_rate': 0.3410700133891661, 'max_depth': 70, 'min_data_in_leaf': 8, 'num_leaves': 2478} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.49283958187742466, 'lambda_l2': 0.9343668434628571, 'learning_rate': 0.41294773624296466, 'max_depth': 47, 'min_data_in_leaf': 5, 'num_leaves': 1921} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5558573851841454, 'lambda_l2': 0.5829270329862977, 'learning_rate': 0.5056801849146005, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2609} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.46283103346979104, 'lambda_l2': 0.7213905340175807, 'learning_rate': 0.31015545447189946, 'max_depth': 77, 'min_data_in_leaf': 10, 'num_leaves': 1849} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5232648147661639, 'lambda_l2': 0.4618617909241409, 'learning_rate': 0.14663892752653576, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 1083} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6147123398201167, 'lambda_l2': 0.24928998956651172, 'learning_rate': 0.4101533896681542, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 584} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8691351680007702, 'lambda_l2': 0.09297227933807971, 'learning_rate': 0.19011208410109376, 'max_depth': 66, 'min_data_in_leaf': 14, 'num_leaves': 1475} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.39986118172978974, 'lambda_l2': 0.3523126132161039, 'learning_rate': 0.13729219502073228, 'max_depth': 93, 'min_data_in_leaf': 3, 'num_leaves': 954} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7915111496317183, 'lambda_l2': 0.15821081907669754, 'learning_rate': 0.22932979734341954, 'max_depth': 58, 'min_data_in_leaf': 15, 'num_leaves': 58} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.10791611257276754, 'lambda_l2': 0.005120888261159749, 'learning_rate': 0.05915841708876163, 'max_depth': 21, 'min_data_in_leaf': 7, 'num_leaves': 2152} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7714693131206478, 'lambda_l2': 0.24925536904910758, 'learning_rate': 0.19944527932107745, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 1557} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6475703765598178, 'lambda_l2': 1.131787092564185, 'learning_rate': 0.9763613424814179, 'max_depth': 81, 'min_data_in_leaf': 9, 'num_leaves': 2335} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6662280350374236, 'lambda_l2': 1.3891521910494355, 'learning_rate': 0.8513820207135254, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 2382} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7434141509913457, 'lambda_l2': 2.619536382548916, 'learning_rate': 0.26086089399437623, 'max_depth': 87, 'min_data_in_leaf': 31, 'num_leaves': 628} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8437954037519868, 'lambda_l2': 1.5385137294791709, 'learning_rate': 0.6386911633713986, 'max_depth': 90, 'min_data_in_leaf': 6, 'num_leaves': 2239} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7438048515894473, 'lambda_l2': 0.5058673864929799, 'learning_rate': 0.33482498906134084, 'max_depth': 88, 'min_data_in_leaf': 29, 'num_leaves': 712} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6427705087686467, 'lambda_l2': 1.301012560281995, 'learning_rate': 0.5817865337253599, 'max_depth': 80, 'min_data_in_leaf': 21, 'num_leaves': 2296} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.915239422843678, 'lambda_l2': 2.3307508281786022, 'learning_rate': 0.4786207787119909, 'max_depth': 29, 'min_data_in_leaf': 8, 'num_leaves': 2068} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6123902584028788, 'lambda_l2': 4.908237966476801, 'learning_rate': 0.10084537694129664, 'max_depth': 91, 'min_data_in_leaf': 13, 'num_leaves': 475} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.480077414310646, 'lambda_l2': 0.8213452052950468, 'learning_rate': 0.297643136240894, 'max_depth': 74, 'min_data_in_leaf': 4, 'num_leaves': 1873} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5828377738086502, 'lambda_l2': 0.5377817947541559, 'learning_rate': 0.43868642435565325, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 580} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5745519584017721, 'lambda_l2': 0.6707672940223248, 'learning_rate': 0.3799256597336473, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 2528} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5580971280163347, 'lambda_l2': 0.8158908374440559, 'learning_rate': 0.6865910829586406, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 2664} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6351224230975053, 'lambda_l2': 1.0410254221824737, 'learning_rate': 0.559155002289918, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 2446} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5288323075594719, 'lambda_l2': 0.400045294375605, 'learning_rate': 0.22696812926989407, 'max_depth': 44, 'min_data_in_leaf': 2, 'num_leaves': 851} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.662312762714493, 'lambda_l2': 1.5260102734488625, 'learning_rate': 0.45923701628046876, 'max_depth': 83, 'min_data_in_leaf': 15, 'num_leaves': 2166} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6027619998006994, 'lambda_l2': 1.032925773353652, 'learning_rate': 0.8486626760290772, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2380} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6918868886930705, 'lambda_l2': 2.076471575019779, 'learning_rate': 0.36273991655423926, 'max_depth': 78, 'min_data_in_leaf': 22, 'num_leaves': 278} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5137582938277903, 'lambda_l2': 0.6936976202394323, 'learning_rate': 0.9962851030396306, 'max_depth': 78, 'min_data_in_leaf': 5, 'num_leaves': 2489} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6124831703075525, 'lambda_l2': 0.9612403864973862, 'learning_rate': 0.5189176410953307, 'max_depth': 74, 'min_data_in_leaf': 14, 'num_leaves': 2096} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5958443044906032, 'lambda_l2': 0.0036639241034815435, 'learning_rate': 0.11515618725575003, 'max_depth': 92, 'min_data_in_leaf': 10, 'num_leaves': 748} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4343436386821054, 'lambda_l2': 0.8647953747943105, 'learning_rate': 0.403324949369322, 'max_depth': 71, 'min_data_in_leaf': 7, 'num_leaves': 1987} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.20956124820839722, 'lambda_l2': 0.17581865108699318, 'learning_rate': 0.6785991074892909, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 2221} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.9991359635326503, 'lambda_l2': 0.43361822953144646, 'learning_rate': 0.25290740248267635, 'max_depth': 95, 'min_data_in_leaf': 26, 'num_leaves': 50} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5464755417719683, 'lambda_l2': 0.555732678495582, 'learning_rate': 0.01703437529565025, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 2619} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5063314518326518, 'lambda_l2': 0.3408766269224677, 'learning_rate': 0.1745086835906019, 'max_depth': 98, 'min_data_in_leaf': 57, 'num_leaves': 52} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6974063917217335, 'lambda_l2': 4.5250014999518715, 'learning_rate': 0.33597857433719525, 'max_depth': 76, 'min_data_in_leaf': 18, 'num_leaves': 2730} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.462612628857599, 'lambda_l2': 0.6439382126668021, 'learning_rate': 0.33222902325829645, 'max_depth': 82, 'min_data_in_leaf': 80, 'num_leaves': 1736} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5075649320832587, 'lambda_l2': 0.37668076869646283, 'learning_rate': 0.17236687978809564, 'max_depth': 93, 'min_data_in_leaf': 68, 'num_leaves': 1027} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6603878221880272, 'lambda_l2': 1.1450429572206833, 'learning_rate': 0.488507553711604, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2103} : acc= 73.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5411482709019811, 'lambda_l2': 0.302754708981539, 'learning_rate': 0.12128092933159715, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 1787} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7269161422200868, 'lambda_l2': 1.1067091608515167, 'learning_rate': 0.28792085728277583, 'max_depth': 84, 'min_data_in_leaf': 23, 'num_leaves': 135} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7114787932893589, 'lambda_l2': 1.2505329096117341, 'learning_rate': 0.02272002752742613, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 2023} : acc= 57.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5220995311343651, 'lambda_l2': 0.494445543396454, 'learning_rate': 0.25989466830315744, 'max_depth': 94, 'min_data_in_leaf': 6, 'num_leaves': 1906} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6328968078635819, 'lambda_l2': 0.7622910363862297, 'learning_rate': 0.385733340596839, 'max_depth': 90, 'min_data_in_leaf': 18, 'num_leaves': 333} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5708335148524423, 'lambda_l2': 0.6267920385345745, 'learning_rate': 0.4352462910666802, 'max_depth': 88, 'min_data_in_leaf': 16, 'num_leaves': 215} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.658832873046023, 'lambda_l2': 0.1950871671922558, 'learning_rate': 0.3216453252495977, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 400} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6877537204033851, 'lambda_l2': 1.3284768526694264, 'learning_rate': 0.4897163823445589, 'max_depth': 86, 'min_data_in_leaf': 24, 'num_leaves': 2078} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6723929773194863, 'lambda_l2': 0.9780165769651956, 'learning_rate': 0.41772024877194835, 'max_depth': 80, 'min_data_in_leaf': 9, 'num_leaves': 1994} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6573176000821288, 'lambda_l2': 1.5052087011180266, 'learning_rate': 0.8066971530841065, 'max_depth': 79, 'min_data_in_leaf': 13, 'num_leaves': 2169} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7553071702666848, 'lambda_l2': 1.6981673913627962, 'learning_rate': 0.7731602297358168, 'max_depth': 83, 'min_data_in_leaf': 5, 'num_leaves': 2105} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5728408295949038, 'lambda_l2': 0.929523897700113, 'learning_rate': 0.6730300829930378, 'max_depth': 88, 'min_data_in_leaf': 12, 'num_leaves': 2288} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7174530272632937, 'lambda_l2': 1.8595054114687282, 'learning_rate': 0.9055740775812018, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 2977} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6504112793886583, 'lambda_l2': 0.8891229730032679, 'learning_rate': 0.5763619752111623, 'max_depth': 81, 'min_data_in_leaf': 15, 'num_leaves': 1994} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6816587575404938, 'lambda_l2': 1.1960694610009837, 'learning_rate': 0.47211386419205265, 'max_depth': 86, 'min_data_in_leaf': 26, 'num_leaves': 2073} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7279019600304683, 'lambda_l2': 1.8062014069721104, 'learning_rate': 0.3605715647496462, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 1923} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6692214860010901, 'lambda_l2': 0.863539070385015, 'learning_rate': 0.36388704376613995, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2150} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.691922964183688, 'lambda_l2': 1.4169865689608705, 'learning_rate': 0.5278626723794355, 'max_depth': 82, 'min_data_in_leaf': 12, 'num_leaves': 2282} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6376514821749155, 'lambda_l2': 1.1974229487102872, 'learning_rate': 0.4825712768999653, 'max_depth': 79, 'min_data_in_leaf': 14, 'num_leaves': 2205} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5360694884157845, 'lambda_l2': 0.4882985764236982, 'learning_rate': 0.6019403414746506, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 2329} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6793428159105189, 'lambda_l2': 1.2532178607853577, 'learning_rate': 0.41348553465591886, 'max_depth': 80, 'min_data_in_leaf': 17, 'num_leaves': 2369} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7647774763061392, 'lambda_l2': 1.4828661687648104, 'learning_rate': 0.27844435070207674, 'max_depth': 83, 'min_data_in_leaf': 10, 'num_leaves': 2213} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5482994657821493, 'lambda_l2': 0.5569028548588448, 'learning_rate': 0.5305601898950557, 'max_depth': 88, 'min_data_in_leaf': 10, 'num_leaves': 2283} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7134111262912425, 'lambda_l2': 0.2700297888527884, 'learning_rate': 0.29260986702429675, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 1596} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6021701537754112, 'lambda_l2': 0.4930414023564152, 'learning_rate': 0.5938085322154311, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 2367} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7412404239825617, 'lambda_l2': 1.3571845843256325, 'learning_rate': 0.3582589663202186, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2029} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6292988308187806, 'lambda_l2': 0.8271397972807597, 'learning_rate': 0.32837976930701074, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 1945} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.49161548391382603, 'lambda_l2': 0.8061087068105082, 'learning_rate': 0.36650175031633947, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 2083} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6249144165730348, 'lambda_l2': 0.74296740611753, 'learning_rate': 0.45814856026769624, 'max_depth': 85, 'min_data_in_leaf': 14, 'num_leaves': 2433} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7458358968716832, 'lambda_l2': 1.2955255728441024, 'learning_rate': 0.2994108809475245, 'max_depth': 84, 'min_data_in_leaf': 8, 'num_leaves': 2221} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6489062916030791, 'lambda_l2': 0.604786953289399, 'learning_rate': 0.2502684965789152, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 1288} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.659243029376724, 'lambda_l2': 1.0342327965637768, 'learning_rate': 0.3909255923178329, 'max_depth': 85, 'min_data_in_leaf': 16, 'num_leaves': 2166} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6159005369770216, 'lambda_l2': 0.9091734881167861, 'learning_rate': 0.5263913519518967, 'max_depth': 83, 'min_data_in_leaf': 18, 'num_leaves': 2386} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7775282443075612, 'lambda_l2': 1.4144403271725372, 'learning_rate': 0.46757526759547746, 'max_depth': 88, 'min_data_in_leaf': 8, 'num_leaves': 2119} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6906082383071965, 'lambda_l2': 1.1505315119378907, 'learning_rate': 0.576363531947294, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2239} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7122217316322126, 'lambda_l2': 1.077045348698811, 'learning_rate': 0.4403423766901096, 'max_depth': 76, 'min_data_in_leaf': 10, 'num_leaves': 2165} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5605010459854987, 'lambda_l2': 0.40639062434748163, 'learning_rate': 0.4083909345189605, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 2306} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5868156192396221, 'lambda_l2': 0.6562757263420926, 'learning_rate': 0.3019739660992063, 'max_depth': 91, 'min_data_in_leaf': 14, 'num_leaves': 1475} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5389204044557143, 'lambda_l2': 0.3183609756124778, 'learning_rate': 0.6864433133499871, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 2430} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5199643837373703, 'lambda_l2': 0.5657745995279493, 'learning_rate': 0.23632979582793986, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 1419} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6380055607470263, 'lambda_l2': 1.1417138245877343, 'learning_rate': 0.00679269441571916, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 2105} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6748386114400927, 'lambda_l2': 1.339994854096875, 'learning_rate': 0.5267937573362766, 'max_depth': 87, 'min_data_in_leaf': 12, 'num_leaves': 2051} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.48848424311029737, 'lambda_l2': 0.09277744517134628, 'learning_rate': 0.2831068474391843, 'max_depth': 84, 'min_data_in_leaf': 7, 'num_leaves': 1067} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.620154136447494, 'lambda_l2': 0.9435653752602082, 'learning_rate': 0.46153427790782975, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 2321} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4475232856262837, 'lambda_l2': 1.220655869991396, 'learning_rate': 0.4063663046973527, 'max_depth': 81, 'min_data_in_leaf': 10, 'num_leaves': 1959} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5031494767221132, 'lambda_l2': 0.42095941001739223, 'learning_rate': 0.3249967308857778, 'max_depth': 90, 'min_data_in_leaf': 12, 'num_leaves': 1875} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6548857778287261, 'lambda_l2': 1.1357410031543043, 'learning_rate': 0.6109980658291599, 'max_depth': 78, 'min_data_in_leaf': 14, 'num_leaves': 2207} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.690905537893335, 'lambda_l2': 1.3319340654570302, 'learning_rate': 0.35717446386200336, 'max_depth': 77, 'min_data_in_leaf': 16, 'num_leaves': 2480} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.23338974238192498, 'lambda_l2': 0.2059682251282282, 'learning_rate': 0.2743376252560878, 'max_depth': 89, 'min_data_in_leaf': 7, 'num_leaves': 1714} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.590897890086903, 'lambda_l2': 0.7883541957205199, 'learning_rate': 0.49538412151088895, 'max_depth': 81, 'min_data_in_leaf': 8, 'num_leaves': 2284} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5658120072801568, 'lambda_l2': 0.26698317815289757, 'learning_rate': 0.43734075370943115, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 2391} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5468409848189756, 'lambda_l2': 0.6088159032066918, 'learning_rate': 0.2389136690855675, 'max_depth': 94, 'min_data_in_leaf': 17, 'num_leaves': 1605} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7173724722157552, 'lambda_l2': 1.2014760584216473, 'learning_rate': 0.5485560289337483, 'max_depth': 84, 'min_data_in_leaf': 15, 'num_leaves': 2152} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.696501582875388, 'lambda_l2': 1.279881434097462, 'learning_rate': 0.35559348065589597, 'max_depth': 80, 'min_data_in_leaf': 20, 'num_leaves': 2504} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6724393275339243, 'lambda_l2': 1.4890438330479057, 'learning_rate': 0.4017176882784125, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 2254} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7010528957744574, 'lambda_l2': 0.9753384632321711, 'learning_rate': 0.2945358828263235, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 2160} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6592328288204198, 'lambda_l2': 0.8637391425439639, 'learning_rate': 0.3232061221247192, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 2054} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7543114320240006, 'lambda_l2': 0.11189494750050999, 'learning_rate': 0.2113212999347928, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 1819} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6327441935753845, 'lambda_l2': 1.0729960216211323, 'learning_rate': 0.6627363218678732, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 2186} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.47531241811230257, 'lambda_l2': 0.7272626186202782, 'learning_rate': 0.25809471946063145, 'max_depth': 26, 'min_data_in_leaf': 6, 'num_leaves': 52} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.60822358690443, 'lambda_l2': 0.736996572201816, 'learning_rate': 0.4514357100877802, 'max_depth': 82, 'min_data_in_leaf': 9, 'num_leaves': 2335} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7313197519819086, 'lambda_l2': 1.5549574868817544, 'learning_rate': 0.36249901859215616, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 2427} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6635380642693783, 'lambda_l2': 1.358304684671714, 'learning_rate': 0.5547785063313596, 'max_depth': 87, 'min_data_in_leaf': 12, 'num_leaves': 2033} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6781026068168301, 'lambda_l2': 0.9650214157076632, 'learning_rate': 0.3354506925260307, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 1971} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7089584178368606, 'lambda_l2': 1.5923648443949427, 'learning_rate': 0.39134583063455963, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 2400} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6079796020405938, 'lambda_l2': 0.8491185650919852, 'learning_rate': 0.6413799907989479, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 2327} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7316730962269159, 'lambda_l2': 1.1801048511578078, 'learning_rate': 0.4743467806657515, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 2538} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6455210800670492, 'lambda_l2': 1.0568496757298362, 'learning_rate': 0.6118309013868469, 'max_depth': 78, 'min_data_in_leaf': 10, 'num_leaves': 2114} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9384713619791812, 'lambda_l2': 3.5350995503055587, 'learning_rate': 0.22050297484976727, 'max_depth': 90, 'min_data_in_leaf': 5, 'num_leaves': 711} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7168391872355532, 'lambda_l2': 1.280512816952376, 'learning_rate': 0.40931406369671375, 'max_depth': 76, 'min_data_in_leaf': 19, 'num_leaves': 2242} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.46625067102164475, 'lambda_l2': 1.0893428377493275, 'learning_rate': 0.7022934712483543, 'max_depth': 79, 'min_data_in_leaf': 8, 'num_leaves': 1977} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7524750712662032, 'lambda_l2': 0.18534072674220953, 'learning_rate': 0.2104004485975646, 'max_depth': 92, 'min_data_in_leaf': 16, 'num_leaves': 1723} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6407124013646514, 'lambda_l2': 1.156300363492333, 'learning_rate': 0.7829882954327944, 'max_depth': 83, 'min_data_in_leaf': 21, 'num_leaves': 2249} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4331079896934771, 'lambda_l2': 1.4326839100800628, 'learning_rate': 0.3311352389230055, 'max_depth': 75, 'min_data_in_leaf': 7, 'num_leaves': 1914} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6741026470887916, 'lambda_l2': 1.0707079182606702, 'learning_rate': 0.5078864517675231, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2159} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6488592950977495, 'lambda_l2': 1.2688752726749384, 'learning_rate': 0.5950771354711774, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 2277} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5681446666311936, 'lambda_l2': 0.440458371918477, 'learning_rate': 0.4196429475483521, 'max_depth': 92, 'min_data_in_leaf': 5, 'num_leaves': 2362} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.41198119056500304, 'lambda_l2': 0.9780622602747006, 'learning_rate': 0.35866354891164803, 'max_depth': 73, 'min_data_in_leaf': 10, 'num_leaves': 2446} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7018120214381306, 'lambda_l2': 1.3531389608535727, 'learning_rate': 0.517369304451449, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 2108} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7012551392421008, 'lambda_l2': 1.5770508884965395, 'learning_rate': 0.7695355590666313, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2099} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.717666869854907, 'lambda_l2': 1.3972460898404266, 'learning_rate': 0.5116784079160134, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 1996} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.44135727189119334, 'lambda_l2': 1.0939534170486462, 'learning_rate': 0.46901310862551887, 'max_depth': 77, 'min_data_in_leaf': 7, 'num_leaves': 1833} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7826871977250643, 'lambda_l2': 1.6335606874389985, 'learning_rate': 0.697395443025463, 'max_depth': 81, 'min_data_in_leaf': 4, 'num_leaves': 2520} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6632033726112514, 'lambda_l2': 1.2195586166449264, 'learning_rate': 0.5941953906460138, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 2224} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5285580944196185, 'lambda_l2': 0.5634161498303601, 'learning_rate': 0.2620042263673967, 'max_depth': 95, 'min_data_in_leaf': 11, 'num_leaves': 784} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6544311453770402, 'lambda_l2': 1.0155995252635566, 'learning_rate': 0.4157987386546465, 'max_depth': 81, 'min_data_in_leaf': 12, 'num_leaves': 2213} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4932071847608493, 'lambda_l2': 0.264303382756954, 'learning_rate': 0.23968691781109894, 'max_depth': 96, 'min_data_in_leaf': 9, 'num_leaves': 1189} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6360021340792714, 'lambda_l2': 1.2206104228706607, 'learning_rate': 0.6174029696462658, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2052} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6301666504381294, 'lambda_l2': 0.9539710715233811, 'learning_rate': 0.46156633900334976, 'max_depth': 80, 'min_data_in_leaf': 12, 'num_leaves': 2290} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5913066436384395, 'lambda_l2': 0.8270919149477004, 'learning_rate': 0.3009495861903079, 'max_depth': 86, 'min_data_in_leaf': 21, 'num_leaves': 3993} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7340052980270025, 'lambda_l2': 1.464618398222784, 'learning_rate': 0.8491584644877634, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 2100} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6924508836243961, 'lambda_l2': 1.5603911011092122, 'learning_rate': 0.6804346692419859, 'max_depth': 84, 'min_data_in_leaf': 7, 'num_leaves': 2032} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7452888293793968, 'lambda_l2': 1.5059724371391998, 'learning_rate': 0.6769612614591439, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 2109} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6825351589082234, 'lambda_l2': 1.1688491792261952, 'learning_rate': 0.3829901097255196, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 313} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.858903680165864, 'lambda_l2': 1.3443035768596294, 'learning_rate': 0.30144205727838724, 'max_depth': 93, 'min_data_in_leaf': 9, 'num_leaves': 1844} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6203066072523203, 'lambda_l2': 1.0408530656520913, 'learning_rate': 0.5259575619571232, 'max_depth': 18, 'min_data_in_leaf': 10, 'num_leaves': 2306} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6146717803269238, 'lambda_l2': 0.003044325891415317, 'learning_rate': 0.4063694886636678, 'max_depth': 89, 'min_data_in_leaf': 6, 'num_leaves': 2409} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7002920588516918, 'lambda_l2': 1.7722144172257503, 'learning_rate': 0.8526164035735474, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 2118} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6741865053277878, 'lambda_l2': 1.113167844583601, 'learning_rate': 0.555564195754289, 'max_depth': 85, 'min_data_in_leaf': 22, 'num_leaves': 2250} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7743644128015018, 'lambda_l2': 1.6642904527229347, 'learning_rate': 0.7231969919343667, 'max_depth': 91, 'min_data_in_leaf': 3, 'num_leaves': 1945} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8008125455097526, 'lambda_l2': 1.6517703229404004, 'learning_rate': 0.2733627689447529, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 1877} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5498941293136653, 'lambda_l2': 0.6711984293930744, 'learning_rate': 0.25023687277542184, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 1361} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.724957313770419, 'lambda_l2': 1.7586626150703042, 'learning_rate': 0.8525217753086995, 'max_depth': 82, 'min_data_in_leaf': 14, 'num_leaves': 2037} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.46047789812379114, 'lambda_l2': 0.8159382817592232, 'learning_rate': 0.3322805736086954, 'max_depth': 86, 'min_data_in_leaf': 4, 'num_leaves': 1876} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7187930687240013, 'lambda_l2': 1.4090698912322652, 'learning_rate': 0.7312826722269942, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 2175} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7719263008184692, 'lambda_l2': 1.5629134917410352, 'learning_rate': 0.9344315736659593, 'max_depth': 91, 'min_data_in_leaf': 84, 'num_leaves': 2382} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6729265374622667, 'lambda_l2': 1.2324389091628567, 'learning_rate': 0.3510058049072203, 'max_depth': 77, 'min_data_in_leaf': 18, 'num_leaves': 2559} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6536341734256716, 'lambda_l2': 1.1004457887578827, 'learning_rate': 0.4900023116462016, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 2334} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6867716269474481, 'lambda_l2': 1.8785088500883778, 'learning_rate': 0.6233961021473496, 'max_depth': 89, 'min_data_in_leaf': 17, 'num_leaves': 2506} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7514734500980264, 'lambda_l2': 0.09988473073968254, 'learning_rate': 0.40013690849789263, 'max_depth': 93, 'min_data_in_leaf': 6, 'num_leaves': 548} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4831824472681816, 'lambda_l2': 0.9212405877651482, 'learning_rate': 0.449687631190645, 'max_depth': 74, 'min_data_in_leaf': 9, 'num_leaves': 1772} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6296692629073387, 'lambda_l2': 1.4374494162058045, 'learning_rate': 0.9087194784601347, 'max_depth': 86, 'min_data_in_leaf': 6, 'num_leaves': 2191} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7685932373232929, 'lambda_l2': 1.7382102749684865, 'learning_rate': 0.49436678557213687, 'max_depth': 90, 'min_data_in_leaf': 11, 'num_leaves': 2087} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7364796487753265, 'lambda_l2': 0.7143988727813336, 'learning_rate': 0.3195790817189172, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 55} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8237599112164234, 'lambda_l2': 0.0024033184174303557, 'learning_rate': 0.21908104559477806, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 143} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6988714969283574, 'lambda_l2': 2.0126239241267183, 'learning_rate': 0.4393322868415949, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2074} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.17271329080053976, 'lambda_l2': 0.43715811336408716, 'learning_rate': 0.23479882737487354, 'max_depth': 95, 'min_data_in_leaf': 16, 'num_leaves': 985} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.80944170406829, 'lambda_l2': 1.3713928941045597, 'learning_rate': 0.9881747771959896, 'max_depth': 88, 'min_data_in_leaf': 8, 'num_leaves': 1993} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7378138700355635, 'lambda_l2': 1.3222676034391716, 'learning_rate': 0.5588346485182211, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 2596} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5103339058456419, 'lambda_l2': 0.5064008401780342, 'learning_rate': 0.19700259487869703, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 51} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7130556924372222, 'lambda_l2': 0.7081213770012227, 'learning_rate': 0.38619430686582007, 'max_depth': 90, 'min_data_in_leaf': 19, 'num_leaves': 2163} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.25764196955363794, 'lambda_l2': 0.0019243890436992928, 'learning_rate': 0.26588046243684366, 'max_depth': 91, 'min_data_in_leaf': 22, 'num_leaves': 1212} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.586267904421276, 'lambda_l2': 0.8730799859466241, 'learning_rate': 0.31392522838218057, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 2522} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7864018676551577, 'lambda_l2': 1.5322736183792502, 'learning_rate': 0.6737619120881956, 'max_depth': 94, 'min_data_in_leaf': 1, 'num_leaves': 2246} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7664546484018022, 'lambda_l2': 0.15997872753960907, 'learning_rate': 0.16388158142252973, 'max_depth': 96, 'min_data_in_leaf': 10, 'num_leaves': 253} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8320090650969036, 'lambda_l2': 0.10167548463270548, 'learning_rate': 0.2757762297839943, 'max_depth': 64, 'min_data_in_leaf': 5, 'num_leaves': 1588} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7959941558771192, 'lambda_l2': 0.29968776265098784, 'learning_rate': 0.36800661272196616, 'max_depth': 91, 'min_data_in_leaf': 12, 'num_leaves': 640} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7073649574331362, 'lambda_l2': 1.399169373165826, 'learning_rate': 0.7634530846586258, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2454} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.649103358531517, 'lambda_l2': 1.0421992743937423, 'learning_rate': 0.787997447696669, 'max_depth': 82, 'min_data_in_leaf': 14, 'num_leaves': 2323} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.416460933631042, 'lambda_l2': 1.1869056842089716, 'learning_rate': 0.5505043711395081, 'max_depth': 81, 'min_data_in_leaf': 93, 'num_leaves': 2428} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.70518924074369, 'lambda_l2': 1.9484419130348218, 'learning_rate': 0.30667632896374336, 'max_depth': 87, 'min_data_in_leaf': 20, 'num_leaves': 1922} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.44573814816892143, 'lambda_l2': 1.299689000462526, 'learning_rate': 0.5964489009696263, 'max_depth': 78, 'min_data_in_leaf': 7, 'num_leaves': 2357} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.8975549643491388, 'lambda_l2': 0.003726389765060012, 'learning_rate': 0.40939239063549054, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 460} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6991199232758648, 'lambda_l2': 1.6961749644620578, 'learning_rate': 0.7215580520119191, 'max_depth': 87, 'min_data_in_leaf': 15, 'num_leaves': 2003} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5988051916099247, 'lambda_l2': 0.8340854015641406, 'learning_rate': 0.4581313730831127, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 2439} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7594603956984542, 'lambda_l2': 1.8374688396788872, 'learning_rate': 0.6361414456083253, 'max_depth': 98, 'min_data_in_leaf': 6, 'num_leaves': 961} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9598049082261568, 'lambda_l2': 0.3809030483526639, 'learning_rate': 0.1949454109007981, 'max_depth': 43, 'min_data_in_leaf': 2, 'num_leaves': 136} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3474865247268465, 'lambda_l2': 0.5755261565447632, 'learning_rate': 0.18581732832759773, 'max_depth': 52, 'min_data_in_leaf': 10, 'num_leaves': 378} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6263038051392146, 'lambda_l2': 0.9948385077310061, 'learning_rate': 0.5198975896553529, 'max_depth': 84, 'min_data_in_leaf': 4, 'num_leaves': 2188} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7317124460782543, 'lambda_l2': 1.4681062510882854, 'learning_rate': 0.3905704254503358, 'max_depth': 89, 'min_data_in_leaf': 12, 'num_leaves': 1996} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6933638006872669, 'lambda_l2': 1.6458775094651, 'learning_rate': 0.7732457067702062, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2125} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6641779477879399, 'lambda_l2': 1.1536326902678136, 'learning_rate': 0.9909814696998084, 'max_depth': 85, 'min_data_in_leaf': 8, 'num_leaves': 2258} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7182218678924757, 'lambda_l2': 1.301453907970999, 'learning_rate': 0.5180014691000442, 'max_depth': 74, 'min_data_in_leaf': 14, 'num_leaves': 2333} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7553210998066351, 'lambda_l2': 1.4063919776346405, 'learning_rate': 0.3618807982881865, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2123} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7121051770809321, 'lambda_l2': 1.504725707722886, 'learning_rate': 0.5811624726527104, 'max_depth': 82, 'min_data_in_leaf': 23, 'num_leaves': 2291} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6245163791962713, 'lambda_l2': 0.9567174262866224, 'learning_rate': 0.45554042528007577, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2363} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.31437891805544166, 'lambda_l2': 0.09484948863856346, 'learning_rate': 0.6361623448871917, 'max_depth': 94, 'min_data_in_leaf': 63, 'num_leaves': 1739} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.48147408680886394, 'lambda_l2': 0.9306436153759257, 'learning_rate': 0.35850775209297225, 'max_depth': 78, 'min_data_in_leaf': 8, 'num_leaves': 1895} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.60494032856876, 'lambda_l2': 1.0180737666226172, 'learning_rate': 0.44282069723023476, 'max_depth': 81, 'min_data_in_leaf': 10, 'num_leaves': 2230} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6456727963865444, 'lambda_l2': 1.1064373793751006, 'learning_rate': 0.034981019969335225, 'max_depth': 77, 'min_data_in_leaf': 18, 'num_leaves': 2602} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5053503883198244, 'lambda_l2': 0.7264619855726759, 'learning_rate': 0.3012305839249877, 'max_depth': 78, 'min_data_in_leaf': 11, 'num_leaves': 1815} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5710738737359919, 'lambda_l2': 0.48384151249203383, 'learning_rate': 0.2687041025719851, 'max_depth': 91, 'min_data_in_leaf': 6, 'num_leaves': 878} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.47792072262326984, 'lambda_l2': 0.6606964034376255, 'learning_rate': 0.33615498791674825, 'max_depth': 86, 'min_data_in_leaf': 4, 'num_leaves': 1889} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.822397628772247, 'lambda_l2': 0.2259102540600174, 'learning_rate': 0.5060059407938414, 'max_depth': 96, 'min_data_in_leaf': 1, 'num_leaves': 1638} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5315743264005597, 'lambda_l2': 0.3763540028498954, 'learning_rate': 0.15610564646483904, 'max_depth': 98, 'min_data_in_leaf': 8, 'num_leaves': 793} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5863008000143436, 'lambda_l2': 0.7896331764677023, 'learning_rate': 0.25536405120750566, 'max_depth': 83, 'min_data_in_leaf': 22, 'num_leaves': 1965} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5107353583216755, 'lambda_l2': 0.2742265273520481, 'learning_rate': 0.20760994879099917, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 1662} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6835564794837518, 'lambda_l2': 1.2986874968629798, 'learning_rate': 0.5916988178788829, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2034} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6370313544061235, 'lambda_l2': 1.1692674771859688, 'learning_rate': 0.7585469563961144, 'max_depth': 84, 'min_data_in_leaf': 9, 'num_leaves': 2460} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7384775257548184, 'lambda_l2': 1.3900198710928429, 'learning_rate': 0.5057917604592128, 'max_depth': 88, 'min_data_in_leaf': 2, 'num_leaves': 243} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.4018915500584313, 'lambda_l2': 0.9664682096659218, 'learning_rate': 0.31506806995246645, 'max_depth': 72, 'min_data_in_leaf': 7, 'num_leaves': 2542} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5196771548497887, 'lambda_l2': 0.32812352294715097, 'learning_rate': 0.22787849473843613, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 1761} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.47053165643431594, 'lambda_l2': 0.7669319112094873, 'learning_rate': 0.4003080357042704, 'max_depth': 75, 'min_data_in_leaf': 5, 'num_leaves': 2025} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6633178094343293, 'lambda_l2': 1.250324883622571, 'learning_rate': 0.9747261290060661, 'max_depth': 84, 'min_data_in_leaf': 8, 'num_leaves': 2214} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5449436551834286, 'lambda_l2': 0.432034914317507, 'learning_rate': 0.27550447702000597, 'max_depth': 92, 'min_data_in_leaf': 10, 'num_leaves': 1340} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7104742089675118, 'lambda_l2': 1.6200375551068709, 'learning_rate': 0.6425321499451897, 'max_depth': 77, 'min_data_in_leaf': 15, 'num_leaves': 2173} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6906323946050169, 'lambda_l2': 2.443088322229808, 'learning_rate': 0.7377941503812739, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 2366} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6011601247072678, 'lambda_l2': 0.9153652615365966, 'learning_rate': 0.42468268544551535, 'max_depth': 78, 'min_data_in_leaf': 15, 'num_leaves': 2279} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7278097986767075, 'lambda_l2': 1.6639736657122894, 'learning_rate': 0.38640633080930165, 'max_depth': 90, 'min_data_in_leaf': 41, 'num_leaves': 1938} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6082520472476073, 'lambda_l2': 1.032849379617056, 'learning_rate': 0.4688462130660652, 'max_depth': 74, 'min_data_in_leaf': 16, 'num_leaves': 3721} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6242603453000656, 'lambda_l2': 1.181136912158647, 'learning_rate': 0.3507271662872277, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 669} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.570234900259441, 'lambda_l2': 0.636410498933241, 'learning_rate': 0.30196591875623724, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 325} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6798307091652316, 'lambda_l2': 1.4789229321569288, 'learning_rate': 0.34785834850180236, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 514} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7567237691478861, 'lambda_l2': 1.5576638413579578, 'learning_rate': 0.5664456016306784, 'max_depth': 81, 'min_data_in_leaf': 3, 'num_leaves': 2133} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4512336022812062, 'lambda_l2': 1.060374840891421, 'learning_rate': 0.29057099366153644, 'max_depth': 75, 'min_data_in_leaf': 21, 'num_leaves': 518} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4852518850315746, 'lambda_l2': 1.0626941945787471, 'learning_rate': 0.26459282152115365, 'max_depth': 79, 'min_data_in_leaf': 53, 'num_leaves': 190} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.2824772093945045, 'lambda_l2': 0.1765806818109927, 'learning_rate': 0.21846964468182736, 'max_depth': 95, 'min_data_in_leaf': 12, 'num_leaves': 1664} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6882518141988486, 'lambda_l2': 1.3891392015318211, 'learning_rate': 0.989955530276953, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2103} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4997278681543694, 'lambda_l2': 1.781261575420101, 'learning_rate': 0.41930694736514773, 'max_depth': 86, 'min_data_in_leaf': 6, 'num_leaves': 1763} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7623925336305629, 'lambda_l2': 1.3800734915315316, 'learning_rate': 0.041500992253555344, 'max_depth': 90, 'min_data_in_leaf': 24, 'num_leaves': 591} : acc= 61.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.44509187583264537, 'lambda_l2': 0.6027992439234631, 'learning_rate': 0.34494751114780925, 'max_depth': 85, 'min_data_in_leaf': 9, 'num_leaves': 1849} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5561611241797858, 'lambda_l2': 0.7638094599144135, 'learning_rate': 0.005151881953391788, 'max_depth': 83, 'min_data_in_leaf': 11, 'num_leaves': 1863} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5801215935166775, 'lambda_l2': 0.8983797019738342, 'learning_rate': 0.2938936315604104, 'max_depth': 82, 'min_data_in_leaf': 10, 'num_leaves': 1700} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6505920064430419, 'lambda_l2': 1.2934620557368803, 'learning_rate': 0.5071143619157696, 'max_depth': 80, 'min_data_in_leaf': 1, 'num_leaves': 2264} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5984589277815471, 'lambda_l2': 0.526690923396255, 'learning_rate': 0.44194200593937916, 'max_depth': 88, 'min_data_in_leaf': 48, 'num_leaves': 2688} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.678978221764356, 'lambda_l2': 1.4946354172697451, 'learning_rate': 0.4589985845073349, 'max_depth': 84, 'min_data_in_leaf': 15, 'num_leaves': 2036} : acc= 73.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7581170851968544, 'lambda_l2': 1.8742867880114442, 'learning_rate': 0.6054014161365256, 'max_depth': 86, 'min_data_in_leaf': 12, 'num_leaves': 1930} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6597976359390375, 'lambda_l2': 2.046392313383932, 'learning_rate': 0.5737855258593852, 'max_depth': 84, 'min_data_in_leaf': 21, 'num_leaves': 2424} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7390157214830659, 'lambda_l2': 1.7251612159014909, 'learning_rate': 0.8773445028760105, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 2033} : acc= 62.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6728909591494857, 'lambda_l2': 1.765557929992128, 'learning_rate': 0.35899811787499847, 'max_depth': 80, 'min_data_in_leaf': 87, 'num_leaves': 427} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6985855335930237, 'lambda_l2': 1.61170940851189, 'learning_rate': 0.8427121655871272, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 2043} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6169690769006727, 'lambda_l2': 2.2275699309554793, 'learning_rate': 0.07446421829265798, 'max_depth': 89, 'min_data_in_leaf': 18, 'num_leaves': 158} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6726400998686112, 'lambda_l2': 1.5674245930433446, 'learning_rate': 0.5005177209097856, 'max_depth': 76, 'min_data_in_leaf': 23, 'num_leaves': 2163} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6743231513585562, 'lambda_l2': 1.6930013593422273, 'learning_rate': 0.41164197676163505, 'max_depth': 87, 'min_data_in_leaf': 25, 'num_leaves': 1931} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7026970745888046, 'lambda_l2': 1.6217642435612885, 'learning_rate': 0.6352034920718085, 'max_depth': 91, 'min_data_in_leaf': 20, 'num_leaves': 2325} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7468812481131779, 'lambda_l2': 3.8774059290524896, 'learning_rate': 0.48917035282444976, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 1950} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7206042234200929, 'lambda_l2': 2.3101953031039373, 'learning_rate': 0.3935803205483549, 'max_depth': 88, 'min_data_in_leaf': 17, 'num_leaves': 1990} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.720259307198556, 'lambda_l2': 1.8579668636314053, 'learning_rate': 0.5612254620070082, 'max_depth': 91, 'min_data_in_leaf': 19, 'num_leaves': 2094} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6403188849217387, 'lambda_l2': 1.9088860184955094, 'learning_rate': 0.3377020206624449, 'max_depth': 86, 'min_data_in_leaf': 24, 'num_leaves': 601} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7260077764878673, 'lambda_l2': 1.7903147421888148, 'learning_rate': 0.48628844948742417, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 2032} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6955338495542787, 'lambda_l2': 1.9572177207316788, 'learning_rate': 0.7859719765414921, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2215} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6931464622341657, 'lambda_l2': 1.541570932177418, 'learning_rate': 0.7117500892860062, 'max_depth': 82, 'min_data_in_leaf': 16, 'num_leaves': 2106} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6598421898115981, 'lambda_l2': 1.4553595033862952, 'learning_rate': 0.55401533387529, 'max_depth': 77, 'min_data_in_leaf': 14, 'num_leaves': 2180} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6501344171683314, 'lambda_l2': 1.5216097572664138, 'learning_rate': 0.38049632702950653, 'max_depth': 82, 'min_data_in_leaf': 17, 'num_leaves': 1997} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8394053718084683, 'lambda_l2': 1.9914532408399785, 'learning_rate': 0.18011429806122034, 'max_depth': 94, 'min_data_in_leaf': 5, 'num_leaves': 1812} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7617901407570958, 'lambda_l2': 1.7812658136223036, 'learning_rate': 0.44366699862111614, 'max_depth': 94, 'min_data_in_leaf': 22, 'num_leaves': 715} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7178377564791445, 'lambda_l2': 1.6351640759619304, 'learning_rate': 0.48106247970464044, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 201} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6751648816983895, 'lambda_l2': 1.8445932060567307, 'learning_rate': 0.3081781999237212, 'max_depth': 89, 'min_data_in_leaf': 15, 'num_leaves': 1840} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6666481650361255, 'lambda_l2': 1.490597948216923, 'learning_rate': 0.3388877513578873, 'max_depth': 80, 'min_data_in_leaf': 18, 'num_leaves': 498} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.01339644117893965, 'lambda_l2': 0.07402714647926717, 'learning_rate': 0.23913188759383086, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 248} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7411161916413119, 'lambda_l2': 1.7745347937590121, 'learning_rate': 0.6256161715237002, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 2453} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6319360980958713, 'lambda_l2': 1.4514378528552514, 'learning_rate': 0.054145171849195387, 'max_depth': 85, 'min_data_in_leaf': 25, 'num_leaves': 592} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6820310057148004, 'lambda_l2': 1.311714356600808, 'learning_rate': 0.4411941341015015, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 2341} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.749336669516761, 'lambda_l2': 1.660838048067023, 'learning_rate': 0.680447147761509, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 1962} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7261424478725639, 'lambda_l2': 1.3414526232007642, 'learning_rate': 0.9969339780736772, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2132} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7873702811436964, 'lambda_l2': 1.5559197555401187, 'learning_rate': 0.8696308643321079, 'max_depth': 23, 'min_data_in_leaf': 7, 'num_leaves': 2507} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6499715921918142, 'lambda_l2': 1.1995159362908892, 'learning_rate': 0.44327728676818867, 'max_depth': 80, 'min_data_in_leaf': 10, 'num_leaves': 2377} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7805287720378407, 'lambda_l2': 1.7159575827955773, 'learning_rate': 0.3765835195415926, 'max_depth': 87, 'min_data_in_leaf': 1, 'num_leaves': 1682} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7318456535449509, 'lambda_l2': 1.6210612807477978, 'learning_rate': 0.5226718054077274, 'max_depth': 89, 'min_data_in_leaf': 23, 'num_leaves': 556} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6282284786959449, 'lambda_l2': 1.465380934026894, 'learning_rate': 0.5673069371210648, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 684} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7139357144825443, 'lambda_l2': 1.4751761563567838, 'learning_rate': 0.7185686168124373, 'max_depth': 82, 'min_data_in_leaf': 16, 'num_leaves': 2063} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.700949063902486, 'lambda_l2': 2.073691010361485, 'learning_rate': 0.4698580588189273, 'max_depth': 83, 'min_data_in_leaf': 14, 'num_leaves': 1901} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3975697292449536, 'lambda_l2': 0.8490696941298183, 'learning_rate': 0.33747762061406694, 'max_depth': 73, 'min_data_in_leaf': 4, 'num_leaves': 2679} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6147922436968014, 'lambda_l2': 2.0903333733015548, 'learning_rate': 0.2419674683396075, 'max_depth': 90, 'min_data_in_leaf': 30, 'num_leaves': 678} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6273313481180167, 'lambda_l2': 1.2287943780689958, 'learning_rate': 0.0028090089151504623, 'max_depth': 76, 'min_data_in_leaf': 18, 'num_leaves': 3598} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6953833559487217, 'lambda_l2': 1.5547250346412904, 'learning_rate': 0.6298304937927213, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 1975} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6609925112772214, 'lambda_l2': 1.3850012439211787, 'learning_rate': 0.21898387739772654, 'max_depth': 87, 'min_data_in_leaf': 26, 'num_leaves': 771} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6478322707123751, 'lambda_l2': 1.265781223563911, 'learning_rate': 0.4287121739487846, 'max_depth': 77, 'min_data_in_leaf': 20, 'num_leaves': 2268} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6180783913086338, 'lambda_l2': 1.0505348603814535, 'learning_rate': 0.5288705993444894, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 2488} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6832711377277152, 'lambda_l2': 1.7318359966335575, 'learning_rate': 0.5561012101567738, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2091} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6436533729457058, 'lambda_l2': 0.9622735766763502, 'learning_rate': 0.3563257494244512, 'max_depth': 81, 'min_data_in_leaf': 11, 'num_leaves': 1985} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.801372041705049, 'lambda_l2': 1.3598194642089672, 'learning_rate': 0.256244942865735, 'max_depth': 92, 'min_data_in_leaf': 27, 'num_leaves': 836} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5868426417179199, 'lambda_l2': 0.06790572530590314, 'learning_rate': 0.0010380492701443967, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 2242} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6987128942288764, 'lambda_l2': 1.9042119440585712, 'learning_rate': 0.8346651099803863, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2584} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7658461411966303, 'lambda_l2': 2.156512520141722, 'learning_rate': 0.27891219618002755, 'max_depth': 97, 'min_data_in_leaf': 20, 'num_leaves': 578} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6739997069406145, 'lambda_l2': 1.18993741148875, 'learning_rate': 0.3962519932928698, 'max_depth': 72, 'min_data_in_leaf': 14, 'num_leaves': 2389} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7264051948389293, 'lambda_l2': 1.6294756645331951, 'learning_rate': 0.019801103173651177, 'max_depth': 83, 'min_data_in_leaf': 15, 'num_leaves': 2172} : acc= 54.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.9818034287562074, 'lambda_l2': 0.15298661638857583, 'learning_rate': 0.2977425201519488, 'max_depth': 100, 'min_data_in_leaf': 9, 'num_leaves': 1878} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7395174673353718, 'lambda_l2': 1.9254268813972661, 'learning_rate': 0.5881895562352114, 'max_depth': 91, 'min_data_in_leaf': 15, 'num_leaves': 2096} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6669684646203783, 'lambda_l2': 1.2044852423412433, 'learning_rate': 0.3991695661795034, 'max_depth': 79, 'min_data_in_leaf': 6, 'num_leaves': 2280} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6618693698062273, 'lambda_l2': 1.2977395465235078, 'learning_rate': 0.4723864163885406, 'max_depth': 76, 'min_data_in_leaf': 23, 'num_leaves': 2332} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6355585107392848, 'lambda_l2': 1.4382415328524023, 'learning_rate': 0.35864365354125816, 'max_depth': 83, 'min_data_in_leaf': 11, 'num_leaves': 1922} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.710200408791624, 'lambda_l2': 1.6510748330594107, 'learning_rate': 0.7052778601524069, 'max_depth': 88, 'min_data_in_leaf': 12, 'num_leaves': 2140} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6916224672227077, 'lambda_l2': 1.7329033861951668, 'learning_rate': 0.5437754512265084, 'max_depth': 91, 'min_data_in_leaf': 13, 'num_leaves': 2284} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5580786615431319, 'lambda_l2': 0.6388540092573882, 'learning_rate': 0.210244984439274, 'max_depth': 90, 'min_data_in_leaf': 20, 'num_leaves': 122} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6523516296016806, 'lambda_l2': 1.433523592904511, 'learning_rate': 0.4795685753092436, 'max_depth': 84, 'min_data_in_leaf': 18, 'num_leaves': 2187} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3107933154291074, 'lambda_l2': 1.5983026849098654, 'learning_rate': 0.16441502123552798, 'max_depth': 95, 'min_data_in_leaf': 33, 'num_leaves': 786} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7113714501317597, 'lambda_l2': 1.4064158773182427, 'learning_rate': 0.8566006923833325, 'max_depth': 81, 'min_data_in_leaf': 14, 'num_leaves': 2205} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6801950005332116, 'lambda_l2': 1.544985324455418, 'learning_rate': 0.6462308377006362, 'max_depth': 89, 'min_data_in_leaf': 19, 'num_leaves': 2071} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7847800748810788, 'lambda_l2': 1.528472934450759, 'learning_rate': 0.8049351702212351, 'max_depth': 86, 'min_data_in_leaf': 4, 'num_leaves': 2217} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6234930086183831, 'lambda_l2': 0.7991098907769594, 'learning_rate': 0.32863562012100156, 'max_depth': 83, 'min_data_in_leaf': 9, 'num_leaves': 1845} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6171967676739857, 'lambda_l2': 0.9312528240986877, 'learning_rate': 0.6664452136258533, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 2442} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5995920855067027, 'lambda_l2': 0.9462950531362133, 'learning_rate': 0.40913783062862874, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2618} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.681154515506666, 'lambda_l2': 1.0856120293757652, 'learning_rate': 0.41910918571798317, 'max_depth': 71, 'min_data_in_leaf': 16, 'num_leaves': 2721} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7900209610172025, 'lambda_l2': 1.627267888651255, 'learning_rate': 0.3125709940803851, 'max_depth': 62, 'min_data_in_leaf': 7, 'num_leaves': 1728} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5863397493384549, 'lambda_l2': 1.1503784611105177, 'learning_rate': 0.5202309028319456, 'max_depth': 81, 'min_data_in_leaf': 13, 'num_leaves': 2549} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7251227255201796, 'lambda_l2': 2.00107558533281, 'learning_rate': 0.09982505920347554, 'max_depth': 97, 'min_data_in_leaf': 1, 'num_leaves': 897} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8317720076741936, 'lambda_l2': 1.7207927162583365, 'learning_rate': 0.2516504873937261, 'max_depth': 93, 'min_data_in_leaf': 6, 'num_leaves': 1831} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3894060647467673, 'lambda_l2': 0.0023314860774634183, 'learning_rate': 0.136030598289297, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 1111} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4609911723878821, 'lambda_l2': 0.7560105866314959, 'learning_rate': 0.29072225275850044, 'max_depth': 74, 'min_data_in_leaf': 9, 'num_leaves': 369} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7475885996304683, 'lambda_l2': 1.3887324847589362, 'learning_rate': 0.4795141577593274, 'max_depth': 87, 'min_data_in_leaf': 8, 'num_leaves': 1975} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.8780470903970025, 'lambda_l2': 0.2117601166489066, 'learning_rate': 0.19746232179625947, 'max_depth': 99, 'min_data_in_leaf': 5, 'num_leaves': 699} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6605702958495626, 'lambda_l2': 1.2004893384528657, 'learning_rate': 0.6075115047901573, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2058} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.14106313131746911, 'lambda_l2': 1.2386656983414523, 'learning_rate': 0.23962099489736807, 'max_depth': 89, 'min_data_in_leaf': 27, 'num_leaves': 579} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7428254150782037, 'lambda_l2': 1.5265316741835382, 'learning_rate': 0.4552483856502027, 'max_depth': 90, 'min_data_in_leaf': 25, 'num_leaves': 489} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6625520483300955, 'lambda_l2': 1.135755186992902, 'learning_rate': 0.046879597435590704, 'max_depth': 81, 'min_data_in_leaf': 22, 'num_leaves': 2404} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.09675600896399641, 'lambda_l2': 0.3374312705759136, 'learning_rate': 0.18873808208000808, 'max_depth': 99, 'min_data_in_leaf': 46, 'num_leaves': 1576} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4326222102231613, 'lambda_l2': 1.3180853024068677, 'learning_rate': 0.3636394444589314, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 338} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.768640801956278, 'lambda_l2': 1.478228234556647, 'learning_rate': 0.3748659211957374, 'max_depth': 31, 'min_data_in_leaf': 10, 'num_leaves': 1936} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5313045680133884, 'lambda_l2': 0.5823759118337416, 'learning_rate': 0.9983775982913884, 'max_depth': 84, 'min_data_in_leaf': 7, 'num_leaves': 1786} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6492242712781263, 'lambda_l2': 1.3325555639175026, 'learning_rate': 0.6919829799566481, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 2161} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.519649971361846, 'lambda_l2': 0.09165288285689556, 'learning_rate': 0.277845826806153, 'max_depth': 94, 'min_data_in_leaf': 16, 'num_leaves': 1889} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.061692118915183336, 'lambda_l2': 0.1888942467643535, 'learning_rate': 0.1666220920102453, 'max_depth': 58, 'min_data_in_leaf': 2, 'num_leaves': 680} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4406130107544645, 'lambda_l2': 1.9028130613188001, 'learning_rate': 0.3481568618569966, 'max_depth': 55, 'min_data_in_leaf': 5, 'num_leaves': 1788} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7389344583580597, 'lambda_l2': 2.0337981142490067, 'learning_rate': 0.145166600688698, 'max_depth': 92, 'min_data_in_leaf': 17, 'num_leaves': 229} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7079800111650912, 'lambda_l2': 1.3107994322352037, 'learning_rate': 0.428046557244901, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 2024} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5688990696280174, 'lambda_l2': 0.6783946284877214, 'learning_rate': 0.23089929963818634, 'max_depth': 93, 'min_data_in_leaf': 19, 'num_leaves': 347} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5973653876796251, 'lambda_l2': 0.8629757931749688, 'learning_rate': 0.20971217611379303, 'max_depth': 90, 'min_data_in_leaf': 24, 'num_leaves': 684} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8050847042823113, 'lambda_l2': 0.30981537411565824, 'learning_rate': 0.07588069604951604, 'max_depth': 94, 'min_data_in_leaf': 11, 'num_leaves': 2092} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.689096474474046, 'lambda_l2': 1.5767546238535388, 'learning_rate': 0.5452933264851986, 'max_depth': 88, 'min_data_in_leaf': 66, 'num_leaves': 584} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.636521318409523, 'lambda_l2': 1.1426011565326877, 'learning_rate': 0.33205112806375037, 'max_depth': 86, 'min_data_in_leaf': 24, 'num_leaves': 833} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4817220044604175, 'lambda_l2': 0.682342910038465, 'learning_rate': 0.2928661598886137, 'max_depth': 48, 'min_data_in_leaf': 8, 'num_leaves': 1761} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6759351563996043, 'lambda_l2': 1.123696228469339, 'learning_rate': 0.3164552780558957, 'max_depth': 81, 'min_data_in_leaf': 19, 'num_leaves': 303} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6913632249435242, 'lambda_l2': 2.248598137622169, 'learning_rate': 0.25110642448683684, 'max_depth': 84, 'min_data_in_leaf': 17, 'num_leaves': 108} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6182927028991586, 'lambda_l2': 1.089616797263473, 'learning_rate': 0.38168471384632996, 'max_depth': 79, 'min_data_in_leaf': 19, 'num_leaves': 2146} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6457309142664102, 'lambda_l2': 1.412949425272826, 'learning_rate': 0.39696289459278594, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 618} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.46008904037334786, 'lambda_l2': 0.5274506141839488, 'learning_rate': 0.3107105754144275, 'max_depth': 61, 'min_data_in_leaf': 10, 'num_leaves': 53} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7399557694219541, 'lambda_l2': 0.08166518023688629, 'learning_rate': 0.4925470375962099, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 2034} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.3671681101682561, 'lambda_l2': 0.9737190553728483, 'learning_rate': 0.12282191926350396, 'max_depth': 68, 'min_data_in_leaf': 15, 'num_leaves': 2580} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7576461161435618, 'lambda_l2': 1.4525460848645513, 'learning_rate': 0.4539041291068746, 'max_depth': 84, 'min_data_in_leaf': 11, 'num_leaves': 1942} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7790027612866443, 'lambda_l2': 1.8349238692357517, 'learning_rate': 0.03046853918086962, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 429} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5950038121267369, 'lambda_l2': 0.010376685366898192, 'learning_rate': 0.06322685091075829, 'max_depth': 100, 'min_data_in_leaf': 27, 'num_leaves': 769} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5840813788243511, 'lambda_l2': 0.853614765373028, 'learning_rate': 0.32315656285612826, 'max_depth': 78, 'min_data_in_leaf': 17, 'num_leaves': 160} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4976320245139996, 'lambda_l2': 0.4921956285127811, 'learning_rate': 0.30037376112486497, 'max_depth': 49, 'min_data_in_leaf': 6, 'num_leaves': 2006} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6933528263723361, 'lambda_l2': 1.3396489538984062, 'learning_rate': 0.745689154290215, 'max_depth': 89, 'min_data_in_leaf': 17, 'num_leaves': 628} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7126938688819029, 'lambda_l2': 1.2574241101212436, 'learning_rate': 0.53495162078073, 'max_depth': 82, 'min_data_in_leaf': 20, 'num_leaves': 2077} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7223899417966554, 'lambda_l2': 1.7320403544062857, 'learning_rate': 0.394414851222454, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 397} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5536167830358801, 'lambda_l2': 0.40277178214077725, 'learning_rate': 0.2421792800085599, 'max_depth': 92, 'min_data_in_leaf': 29, 'num_leaves': 742} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5339690085134782, 'lambda_l2': 1.7962248428282679, 'learning_rate': 0.6245669635107173, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2226} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7191684799172544, 'lambda_l2': 1.5438044211447663, 'learning_rate': 0.5436780079913908, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 653} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.21958363790291321, 'lambda_l2': 0.19910021798465613, 'learning_rate': 0.21158670229113857, 'max_depth': 38, 'min_data_in_leaf': 24, 'num_leaves': 533} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8495924745108341, 'lambda_l2': 2.5216299597585397, 'learning_rate': 0.15581888332986196, 'max_depth': 97, 'min_data_in_leaf': 15, 'num_leaves': 249} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4896700283272597, 'lambda_l2': 1.627135652886201, 'learning_rate': 0.7572979631177141, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2337} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.42316324022767837, 'lambda_l2': 1.239332421769732, 'learning_rate': 0.8174045578432829, 'max_depth': 75, 'min_data_in_leaf': 13, 'num_leaves': 2511} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6829864604928033, 'lambda_l2': 1.3087468176268526, 'learning_rate': 0.4402983050941005, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 57} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.20153868506604744, 'lambda_l2': 2.9353773047441236, 'learning_rate': 0.26916178935035695, 'max_depth': 90, 'min_data_in_leaf': 15, 'num_leaves': 1848} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.33870726775524396, 'lambda_l2': 1.1928362451328125, 'learning_rate': 0.137600798800859, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 699} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5655820900579426, 'lambda_l2': 0.3121932027748765, 'learning_rate': 0.6649368660734402, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 2409} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8065668184720161, 'lambda_l2': 1.456181863471184, 'learning_rate': 0.08902293533432644, 'max_depth': 100, 'min_data_in_leaf': 7, 'num_leaves': 2298} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5864657718495063, 'lambda_l2': 1.078262451816443, 'learning_rate': 0.4843098540146318, 'max_depth': 35, 'min_data_in_leaf': 1, 'num_leaves': 2347} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5529745949131102, 'lambda_l2': 0.010355873007438676, 'learning_rate': 0.2665602904308159, 'max_depth': 94, 'min_data_in_leaf': 22, 'num_leaves': 911} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8206112559025642, 'lambda_l2': 2.171545865342166, 'learning_rate': 0.3679314769965686, 'max_depth': 97, 'min_data_in_leaf': 9, 'num_leaves': 1921} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6152857194666098, 'lambda_l2': 0.8390849580610588, 'learning_rate': 0.6130219701901569, 'max_depth': 80, 'min_data_in_leaf': 3, 'num_leaves': 2283} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.9288224879541266, 'lambda_l2': 0.40713278191175206, 'learning_rate': 0.18270054846450415, 'max_depth': 96, 'min_data_in_leaf': 6, 'num_leaves': 1565} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7334744803451124, 'lambda_l2': 1.658860130805743, 'learning_rate': 0.7523707689145804, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2498} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.707828633992895, 'lambda_l2': 1.3855706641678383, 'learning_rate': 0.9056818658435626, 'max_depth': 77, 'min_data_in_leaf': 11, 'num_leaves': 2805} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6751432887825892, 'lambda_l2': 1.4825253965501166, 'learning_rate': 0.7174749607901081, 'max_depth': 90, 'min_data_in_leaf': 19, 'num_leaves': 515} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6176114172034116, 'lambda_l2': 0.8588359550703335, 'learning_rate': 0.3640100388649248, 'max_depth': 79, 'min_data_in_leaf': 9, 'num_leaves': 2145} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7014358915381077, 'lambda_l2': 1.3493029588923817, 'learning_rate': 0.6345209280247409, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 2220} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6590802032120096, 'lambda_l2': 1.0595065386154117, 'learning_rate': 0.41925803515426824, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 2422} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6308559843673093, 'lambda_l2': 1.2477908967617235, 'learning_rate': 0.6970471647555784, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2245} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6439060629863911, 'lambda_l2': 0.7386836772494411, 'learning_rate': 0.3156808271050517, 'max_depth': 81, 'min_data_in_leaf': 4, 'num_leaves': 2015} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.2682723378990681, 'lambda_l2': 0.23123794574839956, 'learning_rate': 0.18801379198136378, 'max_depth': 33, 'min_data_in_leaf': 51, 'num_leaves': 2576} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.638414339509917, 'lambda_l2': 1.1063348624402352, 'learning_rate': 0.3423088193492758, 'max_depth': 79, 'min_data_in_leaf': 19, 'num_leaves': 2059} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7199104524257481, 'lambda_l2': 1.8511744152532348, 'learning_rate': 0.5697537174060276, 'max_depth': 92, 'min_data_in_leaf': 14, 'num_leaves': 2110} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5179163743336636, 'lambda_l2': 1.3148175735155536, 'learning_rate': 0.008992501802180529, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2175} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.580340388832147, 'lambda_l2': 1.0389614162012395, 'learning_rate': 0.3781291963899513, 'max_depth': 74, 'min_data_in_leaf': 15, 'num_leaves': 1912} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5326141780528781, 'lambda_l2': 1.5021992989595254, 'learning_rate': 0.6173465371002281, 'max_depth': 86, 'min_data_in_leaf': 11, 'num_leaves': 2311} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.8793078142712958, 'lambda_l2': 0.08508788998899641, 'learning_rate': 0.24333971431414933, 'max_depth': 89, 'min_data_in_leaf': 28, 'num_leaves': 882} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7505718672396237, 'lambda_l2': 1.2589889368222844, 'learning_rate': 0.4562565973608537, 'max_depth': 84, 'min_data_in_leaf': 1, 'num_leaves': 443} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8646986199242512, 'lambda_l2': 0.008625312892849069, 'learning_rate': 0.169265478900285, 'max_depth': 95, 'min_data_in_leaf': 5, 'num_leaves': 1740} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6807187450952479, 'lambda_l2': 1.7912478106076186, 'learning_rate': 0.9975231424409444, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 2225} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6066399391650029, 'lambda_l2': 1.2563950059711722, 'learning_rate': 0.5220258842474284, 'max_depth': 86, 'min_data_in_leaf': 22, 'num_leaves': 769} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6739011786439577, 'lambda_l2': 1.1587123213382458, 'learning_rate': 0.42933870808371194, 'max_depth': 75, 'min_data_in_leaf': 8, 'num_leaves': 2460} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6057208597704414, 'lambda_l2': 1.1478023570146871, 'learning_rate': 0.5534812035936229, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 517} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6637201689736333, 'lambda_l2': 0.9818243773738738, 'learning_rate': 0.004165670334097416, 'max_depth': 83, 'min_data_in_leaf': 16, 'num_leaves': 2126} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6968304090905637, 'lambda_l2': 0.8456306572773934, 'learning_rate': 0.4748534225902635, 'max_depth': 93, 'min_data_in_leaf': 37, 'num_leaves': 2147} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7884797471815325, 'lambda_l2': 1.6415139147565827, 'learning_rate': 0.8000096120190066, 'max_depth': 28, 'min_data_in_leaf': 5, 'num_leaves': 2624} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.542932616442968, 'lambda_l2': 0.5772793457361034, 'learning_rate': 0.5213844509792324, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 2346} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6441491472715382, 'lambda_l2': 1.3829288555380783, 'learning_rate': 0.8652643093477607, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2282} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5644219052712611, 'lambda_l2': 0.9807321305395237, 'learning_rate': 0.4571866035135172, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 2907} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4113147076717121, 'lambda_l2': 1.5511690192060965, 'learning_rate': 0.41552368716510046, 'max_depth': 86, 'min_data_in_leaf': 7, 'num_leaves': 2003} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6309168423427508, 'lambda_l2': 0.1433329270382528, 'learning_rate': 0.1125683944267086, 'max_depth': 100, 'min_data_in_leaf': 4, 'num_leaves': 839} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.8998017858467705, 'lambda_l2': 0.3527573241303985, 'learning_rate': 0.210525710134274, 'max_depth': 95, 'min_data_in_leaf': 8, 'num_leaves': 1446} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6098195552412604, 'lambda_l2': 1.1312789801351315, 'learning_rate': 0.3626363119193224, 'max_depth': 81, 'min_data_in_leaf': 10, 'num_leaves': 1984} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6577287397831107, 'lambda_l2': 1.4518836032108227, 'learning_rate': 0.6343930218441236, 'max_depth': 85, 'min_data_in_leaf': 7, 'num_leaves': 2370} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6300435575705511, 'lambda_l2': 1.012176518866938, 'learning_rate': 0.6991750334564986, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2204} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6610397265191755, 'lambda_l2': 1.2170157274557605, 'learning_rate': 0.2817356933142793, 'max_depth': 78, 'min_data_in_leaf': 16, 'num_leaves': 200} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.8001975329763681, 'lambda_l2': 1.319982786016029, 'learning_rate': 0.9249416704386532, 'max_depth': 84, 'min_data_in_leaf': 6, 'num_leaves': 2438} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6512037052733637, 'lambda_l2': 1.2018090376167478, 'learning_rate': 0.33830490357922177, 'max_depth': 88, 'min_data_in_leaf': 24, 'num_leaves': 663} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5742238368789256, 'lambda_l2': 2.805418977193751, 'learning_rate': 0.2367334962370948, 'max_depth': 90, 'min_data_in_leaf': 30, 'num_leaves': 420} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.3265602203887289, 'lambda_l2': 0.002042381316244235, 'learning_rate': 0.19386765926820582, 'max_depth': 88, 'min_data_in_leaf': 26, 'num_leaves': 652} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.3342803266734625, 'lambda_l2': 1.7666647009013676, 'learning_rate': 0.27866029481454085, 'max_depth': 92, 'min_data_in_leaf': 13, 'num_leaves': 1842} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7317747963854334, 'lambda_l2': 1.4294320394228224, 'learning_rate': 0.0016662528146412295, 'max_depth': 77, 'min_data_in_leaf': 16, 'num_leaves': 1928} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.3822072502574301, 'lambda_l2': 1.4043073394956684, 'learning_rate': 0.5826754091106292, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 2493} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7394150566606299, 'lambda_l2': 4.261170720772682, 'learning_rate': 0.9893112871970704, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 2701} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.4233318809937854, 'lambda_l2': 1.5842617316816427, 'learning_rate': 0.30934210578726484, 'max_depth': 64, 'min_data_in_leaf': 3, 'num_leaves': 1675} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4668611146215778, 'lambda_l2': 0.6498656744158126, 'learning_rate': 0.2789628530056377, 'max_depth': 75, 'min_data_in_leaf': 9, 'num_leaves': 2764} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7131575901222994, 'lambda_l2': 1.8767811563070107, 'learning_rate': 0.7718997796179783, 'max_depth': 90, 'min_data_in_leaf': 75, 'num_leaves': 2540} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.4994780556358316, 'lambda_l2': 1.2478920912770235, 'learning_rate': 0.2520312646131346, 'max_depth': 87, 'min_data_in_leaf': 20, 'num_leaves': 780} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.952343787932308, 'lambda_l2': 0.2217256518979967, 'learning_rate': 0.03981817134779844, 'max_depth': 94, 'min_data_in_leaf': 9, 'num_leaves': 2063} : acc= 63.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.710737708765641, 'lambda_l2': 1.652684515407437, 'learning_rate': 0.3855737290993487, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2057} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45942261978145027, 'lambda_l2': 0.5904871147030397, 'learning_rate': 0.47892892136483917, 'max_depth': 67, 'min_data_in_leaf': 5, 'num_leaves': 2398} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6769726294363326, 'lambda_l2': 1.0713173294236316, 'learning_rate': 0.6716529089355234, 'max_depth': 82, 'min_data_in_leaf': 11, 'num_leaves': 2281} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.49645761090432305, 'lambda_l2': 2.3856270875000307, 'learning_rate': 0.9073424625548314, 'max_depth': 85, 'min_data_in_leaf': 11, 'num_leaves': 2218} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4681329006549144, 'lambda_l2': 0.5117945377109793, 'learning_rate': 0.33025073057073523, 'max_depth': 80, 'min_data_in_leaf': 7, 'num_leaves': 1659} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6898286636285736, 'lambda_l2': 1.4860885293109316, 'learning_rate': 0.5568999060830554, 'max_depth': 88, 'min_data_in_leaf': 35, 'num_leaves': 3798} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5236178000556018, 'lambda_l2': 0.7617057371550994, 'learning_rate': 0.4171022070575422, 'max_depth': 86, 'min_data_in_leaf': 13, 'num_leaves': 2132} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8523999627389847, 'lambda_l2': 0.2514402596240141, 'learning_rate': 0.13873684056277502, 'max_depth': 98, 'min_data_in_leaf': 3, 'num_leaves': 1593} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7694565594617686, 'lambda_l2': 2.0152631260377674, 'learning_rate': 0.6168302106394722, 'max_depth': 93, 'min_data_in_leaf': 12, 'num_leaves': 2371} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7744806571951232, 'lambda_l2': 1.3540038709228543, 'learning_rate': 0.5266505709665902, 'max_depth': 25, 'min_data_in_leaf': 8, 'num_leaves': 2447} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7313216881441141, 'lambda_l2': 1.665995605513298, 'learning_rate': 0.41952902840120426, 'max_depth': 90, 'min_data_in_leaf': 21, 'num_leaves': 2007} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.16778349575689266, 'lambda_l2': 0.2974138427209859, 'learning_rate': 0.21750454204092315, 'max_depth': 19, 'min_data_in_leaf': 42, 'num_leaves': 294} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6371934180922887, 'lambda_l2': 0.9660376377949855, 'learning_rate': 0.32804857615632743, 'max_depth': 77, 'min_data_in_leaf': 17, 'num_leaves': 146} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.8014819571580059, 'lambda_l2': 1.7142642782525097, 'learning_rate': 0.7429855299447232, 'max_depth': 96, 'min_data_in_leaf': 5, 'num_leaves': 2631} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6881916292180863, 'lambda_l2': 1.5383118913506766, 'learning_rate': 0.511508197929504, 'max_depth': 89, 'min_data_in_leaf': 19, 'num_leaves': 673} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.43316078639948924, 'lambda_l2': 1.1043044275257807, 'learning_rate': 0.002247500680585435, 'max_depth': 70, 'min_data_in_leaf': 11, 'num_leaves': 2318} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.8055132207280552, 'lambda_l2': 0.12486391514822731, 'learning_rate': 0.9943810148849734, 'max_depth': 94, 'min_data_in_leaf': 2, 'num_leaves': 2504} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5868185682403099, 'lambda_l2': 0.9053153949522562, 'learning_rate': 0.2912031508941334, 'max_depth': 81, 'min_data_in_leaf': 18, 'num_leaves': 105} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6129168026491733, 'lambda_l2': 1.0362377476390987, 'learning_rate': 0.3634665624836526, 'max_depth': 79, 'min_data_in_leaf': 24, 'num_leaves': 2152} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.1217133062952061, 'lambda_l2': 0.13607141981347975, 'learning_rate': 0.1486397629279083, 'max_depth': 91, 'min_data_in_leaf': 9, 'num_leaves': 53} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6390786598935447, 'lambda_l2': 0.9279314869224891, 'learning_rate': 0.48773103409585145, 'max_depth': 80, 'min_data_in_leaf': 9, 'num_leaves': 2225} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5107325025301944, 'lambda_l2': 0.6588762871272889, 'learning_rate': 0.43910036678008124, 'max_depth': 59, 'min_data_in_leaf': 7, 'num_leaves': 1759} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.26136488305651495, 'lambda_l2': 0.421479594765216, 'learning_rate': 0.1826081495584762, 'max_depth': 100, 'min_data_in_leaf': 10, 'num_leaves': 1470} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7014835224362238, 'lambda_l2': 3.0534235916167325, 'learning_rate': 0.114146203661705, 'max_depth': 69, 'min_data_in_leaf': 16, 'num_leaves': 2689} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.45246025710296794, 'lambda_l2': 1.3090893238374317, 'learning_rate': 0.012085958624995934, 'max_depth': 73, 'min_data_in_leaf': 14, 'num_leaves': 3528} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5976488029867816, 'lambda_l2': 1.1623897907692438, 'learning_rate': 0.4131747375154275, 'max_depth': 83, 'min_data_in_leaf': 7, 'num_leaves': 2370} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6557976529740682, 'lambda_l2': 1.321655297466339, 'learning_rate': 0.586806989897246, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 2431} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.660720066445201, 'lambda_l2': 0.8181991923536475, 'learning_rate': 0.26281609752139506, 'max_depth': 86, 'min_data_in_leaf': 22, 'num_leaves': 1938} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6061588511904172, 'lambda_l2': 1.1720725215026686, 'learning_rate': 0.4590489382164106, 'max_depth': 79, 'min_data_in_leaf': 5, 'num_leaves': 2268} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.285825889195031, 'lambda_l2': 0.2760723942352794, 'learning_rate': 0.22039820439973454, 'max_depth': 98, 'min_data_in_leaf': 10, 'num_leaves': 1865} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7560063404621322, 'lambda_l2': 1.8380053355404429, 'learning_rate': 0.07928922261025068, 'max_depth': 93, 'min_data_in_leaf': 58, 'num_leaves': 517} : acc= 64.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5707184434739394, 'lambda_l2': 0.7228130698389464, 'learning_rate': 0.2916448137642587, 'max_depth': 77, 'min_data_in_leaf': 15, 'num_leaves': 2058} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5930969976931336, 'lambda_l2': 0.47652949527718247, 'learning_rate': 0.22951588459547906, 'max_depth': 96, 'min_data_in_leaf': 2, 'num_leaves': 299} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.673116649409931, 'lambda_l2': 1.2315895269256516, 'learning_rate': 0.365264930677837, 'max_depth': 78, 'min_data_in_leaf': 4, 'num_leaves': 2524} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.48432304851130276, 'lambda_l2': 0.524342098486031, 'learning_rate': 0.30629797682880594, 'max_depth': 40, 'min_data_in_leaf': 8, 'num_leaves': 1797} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.76134352680801, 'lambda_l2': 1.9539655902376158, 'learning_rate': 0.16149323982983055, 'max_depth': 95, 'min_data_in_leaf': 6, 'num_leaves': 912} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4117241680762809, 'lambda_l2': 0.6329596908578449, 'learning_rate': 0.26805069406123944, 'max_depth': 67, 'min_data_in_leaf': 9, 'num_leaves': 2610} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6135610094772647, 'lambda_l2': 0.8610388577259307, 'learning_rate': 0.3265444525645204, 'max_depth': 83, 'min_data_in_leaf': 17, 'num_leaves': 391} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5392878859714358, 'lambda_l2': 1.0940496445821961, 'learning_rate': 0.09709071635340885, 'max_depth': 88, 'min_data_in_leaf': 21, 'num_leaves': 810} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5547268216421067, 'lambda_l2': 0.754309367373048, 'learning_rate': 0.34557491882042557, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 160} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7330780994906627, 'lambda_l2': 1.5109474952383637, 'learning_rate': 0.0666702245147296, 'max_depth': 91, 'min_data_in_leaf': 23, 'num_leaves': 762} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6314738051285258, 'lambda_l2': 0.9047773469647049, 'learning_rate': 0.5542284318879279, 'max_depth': 81, 'min_data_in_leaf': 17, 'num_leaves': 2376} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7770371810946846, 'lambda_l2': 1.4242059548391877, 'learning_rate': 0.6545744611267587, 'max_depth': 84, 'min_data_in_leaf': 3, 'num_leaves': 2171} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6994021180932962, 'lambda_l2': 1.3507102848479193, 'learning_rate': 0.7494303749795624, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2303} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7067561330351947, 'lambda_l2': 1.018918961900102, 'learning_rate': 0.8821438127103689, 'max_depth': 74, 'min_data_in_leaf': 14, 'num_leaves': 2611} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5430970939514052, 'lambda_l2': 0.40973816769292326, 'learning_rate': 0.056914532555335656, 'max_depth': 89, 'min_data_in_leaf': 12, 'num_leaves': 2443} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6765421181685681, 'lambda_l2': 1.2602692411533023, 'learning_rate': 0.23557332960698166, 'max_depth': 84, 'min_data_in_leaf': 25, 'num_leaves': 345} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5749549414457923, 'lambda_l2': 1.0122960188503511, 'learning_rate': 0.49531913298554364, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2672} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.749651399541183, 'lambda_l2': 1.6756994646158867, 'learning_rate': 0.6729498328761433, 'max_depth': 93, 'min_data_in_leaf': 11, 'num_leaves': 2513} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.38889128275794405, 'lambda_l2': 1.229271649619758, 'learning_rate': 0.1979406075791049, 'max_depth': 72, 'min_data_in_leaf': 14, 'num_leaves': 2270} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5744237294245815, 'lambda_l2': 0.970939737661946, 'learning_rate': 0.4341523264511071, 'max_depth': 80, 'min_data_in_leaf': 12, 'num_leaves': 2740} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6733407105905046, 'lambda_l2': 1.098459742470111, 'learning_rate': 0.015482279200837895, 'max_depth': 80, 'min_data_in_leaf': 19, 'num_leaves': 52} : acc= 52.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6235427459704588, 'lambda_l2': 0.9689622542884936, 'learning_rate': 0.3777235408804658, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 2054} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6910676061713245, 'lambda_l2': 1.4513256523629754, 'learning_rate': 0.5026115404768562, 'max_depth': 91, 'min_data_in_leaf': 28, 'num_leaves': 537} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6426486978883478, 'lambda_l2': 1.1408726037330963, 'learning_rate': 0.4026796678783013, 'max_depth': 79, 'min_data_in_leaf': 6, 'num_leaves': 2235} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6946387875777779, 'lambda_l2': 1.4207076063579813, 'learning_rate': 0.34417037322334576, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 460} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5059745565905389, 'lambda_l2': 0.5677255598889811, 'learning_rate': 0.39995578915452934, 'max_depth': 46, 'min_data_in_leaf': 10, 'num_leaves': 1883} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7040900373336972, 'lambda_l2': 1.3363845860532333, 'learning_rate': 0.3023239183405917, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 566} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5257478260177527, 'lambda_l2': 0.7230169729094974, 'learning_rate': 0.3814032851491553, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 2124} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6617160427694954, 'lambda_l2': 0.8692056113378941, 'learning_rate': 0.4398144646891437, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 1984} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6269659315943507, 'lambda_l2': 0.4869524910771408, 'learning_rate': 0.27404294813542973, 'max_depth': 85, 'min_data_in_leaf': 22, 'num_leaves': 599} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6308487321914229, 'lambda_l2': 0.29356102602441114, 'learning_rate': 0.3906057222897483, 'max_depth': 86, 'min_data_in_leaf': 15, 'num_leaves': 975} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7203139933853325, 'lambda_l2': 1.2361775271609898, 'learning_rate': 0.3377976868461984, 'max_depth': 82, 'min_data_in_leaf': 16, 'num_leaves': 2110} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6532290357710254, 'lambda_l2': 1.2195705752095007, 'learning_rate': 0.3380915137631248, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 426} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4793808827543963, 'lambda_l2': 0.5940167312336768, 'learning_rate': 0.3971606422852174, 'max_depth': 85, 'min_data_in_leaf': 10, 'num_leaves': 1831} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.24103793833520307, 'lambda_l2': 0.426650951260729, 'learning_rate': 0.25760107048364295, 'max_depth': 84, 'min_data_in_leaf': 12, 'num_leaves': 1205} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6608715145535925, 'lambda_l2': 0.3974976392388789, 'learning_rate': 0.28268039113708193, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2058} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6547285519503334, 'lambda_l2': 0.12194179718415243, 'learning_rate': 0.3188931789055443, 'max_depth': 86, 'min_data_in_leaf': 17, 'num_leaves': 712} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6393084318322556, 'lambda_l2': 1.2634286000219754, 'learning_rate': 0.3678342799694133, 'max_depth': 82, 'min_data_in_leaf': 13, 'num_leaves': 819} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6216208384875519, 'lambda_l2': 1.1096340719085527, 'learning_rate': 0.3718245928866726, 'max_depth': 76, 'min_data_in_leaf': 15, 'num_leaves': 2341} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.717872351784056, 'lambda_l2': 1.4586243674121353, 'learning_rate': 0.3037640215133767, 'max_depth': 90, 'min_data_in_leaf': 15, 'num_leaves': 1995} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6832724159915908, 'lambda_l2': 0.19023566437088751, 'learning_rate': 0.23857871636124567, 'max_depth': 88, 'min_data_in_leaf': 20, 'num_leaves': 631} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6796537760650656, 'lambda_l2': 1.3097062857045207, 'learning_rate': 0.5439724444093629, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2207} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6713629373766921, 'lambda_l2': 1.3763810502950338, 'learning_rate': 0.503917313746218, 'max_depth': 79, 'min_data_in_leaf': 10, 'num_leaves': 2186} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6992803971803874, 'lambda_l2': 1.5602438744455067, 'learning_rate': 0.5147452278864013, 'max_depth': 78, 'min_data_in_leaf': 13, 'num_leaves': 2263} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6637211341023707, 'lambda_l2': 1.0154662425183585, 'learning_rate': 0.2616896726733006, 'max_depth': 82, 'min_data_in_leaf': 23, 'num_leaves': 452} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6048944845650094, 'lambda_l2': 0.9114121044549705, 'learning_rate': 0.43944837248916185, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 3439} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6375684151216231, 'lambda_l2': 1.0476581354799797, 'learning_rate': 0.5964370861248675, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2284} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4983461658511016, 'lambda_l2': 0.7000694018493135, 'learning_rate': 0.48143828487341844, 'max_depth': 84, 'min_data_in_leaf': 8, 'num_leaves': 2164} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5531725395002649, 'lambda_l2': 0.7713925701246844, 'learning_rate': 0.31660176106303806, 'max_depth': 83, 'min_data_in_leaf': 11, 'num_leaves': 1652} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6931875388167856, 'lambda_l2': 1.3825185023741409, 'learning_rate': 0.32580086959648635, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 2069} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5165639985734591, 'lambda_l2': 0.34864524296896754, 'learning_rate': 0.22405871901955643, 'max_depth': 89, 'min_data_in_leaf': 9, 'num_leaves': 1495} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.647957122751516, 'lambda_l2': 1.1513346785946421, 'learning_rate': 0.46024962536643527, 'max_depth': 87, 'min_data_in_leaf': 18, 'num_leaves': 588} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5585096333284523, 'lambda_l2': 0.6716590451248767, 'learning_rate': 0.40199268044920217, 'max_depth': 81, 'min_data_in_leaf': 9, 'num_leaves': 2430} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7392172006623534, 'lambda_l2': 1.4209974248716224, 'learning_rate': 0.5468172964539699, 'max_depth': 80, 'min_data_in_leaf': 10, 'num_leaves': 2101} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.643923376885208, 'lambda_l2': 1.2518815592820804, 'learning_rate': 0.5516542390252815, 'max_depth': 88, 'min_data_in_leaf': 14, 'num_leaves': 2188} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6654746155672604, 'lambda_l2': 1.199539603247345, 'learning_rate': 0.4459648740252265, 'max_depth': 85, 'min_data_in_leaf': 17, 'num_leaves': 2277} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.46596085866393583, 'lambda_l2': 0.7608876143426304, 'learning_rate': 0.366480498019094, 'max_depth': 86, 'min_data_in_leaf': 11, 'num_leaves': 1881} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6842093823592529, 'lambda_l2': 1.3313496167067338, 'learning_rate': 0.46640589767005136, 'max_depth': 80, 'min_data_in_leaf': 12, 'num_leaves': 2202} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7160194956822519, 'lambda_l2': 0.8791776984800375, 'learning_rate': 0.4097309353585287, 'max_depth': 85, 'min_data_in_leaf': 8, 'num_leaves': 1994} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6136050320724317, 'lambda_l2': 1.1751066681790918, 'learning_rate': 0.597529841480881, 'max_depth': 83, 'min_data_in_leaf': 16, 'num_leaves': 2317} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6610965924636172, 'lambda_l2': 1.1337626841544177, 'learning_rate': 0.28231918441046405, 'max_depth': 78, 'min_data_in_leaf': 16, 'num_leaves': 717} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.49765456580508705, 'lambda_l2': 0.46328515059977493, 'learning_rate': 0.2564950277902424, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 1769} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6733245495607219, 'lambda_l2': 0.8614984739533817, 'learning_rate': 0.37162913173085904, 'max_depth': 84, 'min_data_in_leaf': 91, 'num_leaves': 1958} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6175721981596376, 'lambda_l2': 0.06698724939974741, 'learning_rate': 0.3524222639985004, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 865} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7162851194425671, 'lambda_l2': 1.4841556382126095, 'learning_rate': 0.5952402012675306, 'max_depth': 89, 'min_data_in_leaf': 14, 'num_leaves': 701} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.726568836813786, 'lambda_l2': 1.5799185694893656, 'learning_rate': 0.4750488301211094, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 2123} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7034965755412641, 'lambda_l2': 0.8651455071909353, 'learning_rate': 0.5105999582734058, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 2373} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6898072901899667, 'lambda_l2': 0.9877981598872088, 'learning_rate': 0.3973647273003136, 'max_depth': 86, 'min_data_in_leaf': 18, 'num_leaves': 2053} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8217021183432479, 'lambda_l2': 0.24749965074123415, 'learning_rate': 0.20659433090693385, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 1816} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5952788586411464, 'lambda_l2': 0.15141577718030472, 'learning_rate': 0.2970661096161691, 'max_depth': 86, 'min_data_in_leaf': 20, 'num_leaves': 874} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6298413544187754, 'lambda_l2': 0.9211638710742712, 'learning_rate': 0.4496897115498996, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2198} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.04762591348484316, 'lambda_l2': 0.020254147064966237, 'learning_rate': 0.4079832209183164, 'max_depth': 91, 'min_data_in_leaf': 10, 'num_leaves': 795} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5956587300314938, 'lambda_l2': 0.8062174728395806, 'learning_rate': 0.32281248944656155, 'max_depth': 77, 'min_data_in_leaf': 14, 'num_leaves': 2344} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6857275318930441, 'lambda_l2': 0.5403396258383313, 'learning_rate': 0.4383442995509456, 'max_depth': 90, 'min_data_in_leaf': 17, 'num_leaves': 722} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7302714705435541, 'lambda_l2': 1.593215149035159, 'learning_rate': 0.6475169526840696, 'max_depth': 88, 'min_data_in_leaf': 13, 'num_leaves': 652} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5332559071190974, 'lambda_l2': 0.33032960247437143, 'learning_rate': 0.2554943057200871, 'max_depth': 93, 'min_data_in_leaf': 7, 'num_leaves': 1030} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.71235706260188, 'lambda_l2': 0.3452356555143525, 'learning_rate': 0.35770922099400637, 'max_depth': 89, 'min_data_in_leaf': 15, 'num_leaves': 1964} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5927988598888451, 'lambda_l2': 0.5672264706423036, 'learning_rate': 0.25531659954259084, 'max_depth': 85, 'min_data_in_leaf': 23, 'num_leaves': 613} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5034120092787748, 'lambda_l2': 0.38656571615545443, 'learning_rate': 0.2024701337962074, 'max_depth': 94, 'min_data_in_leaf': 7, 'num_leaves': 1374} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6089395316852011, 'lambda_l2': 0.782802297391291, 'learning_rate': 0.33551156096866697, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 52} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6241388047737468, 'lambda_l2': 0.07569855181341428, 'learning_rate': 0.29486174768021045, 'max_depth': 82, 'min_data_in_leaf': 21, 'num_leaves': 492} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.47256597254482013, 'lambda_l2': 1.3604590132639773, 'learning_rate': 0.30760422827319595, 'max_depth': 82, 'min_data_in_leaf': 9, 'num_leaves': 1711} : acc= 72.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5720266922115147, 'lambda_l2': 0.931050133716836, 'learning_rate': 0.5196047195193119, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 2258} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6831982850240872, 'lambda_l2': 1.0578959507278798, 'learning_rate': 0.22358973189218886, 'max_depth': 81, 'min_data_in_leaf': 20, 'num_leaves': 490} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6634501676289922, 'lambda_l2': 1.0142022339513685, 'learning_rate': 0.2677088738407472, 'max_depth': 75, 'min_data_in_leaf': 17, 'num_leaves': 2455} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6366164128546146, 'lambda_l2': 0.9990456523052912, 'learning_rate': 0.34493049476556076, 'max_depth': 73, 'min_data_in_leaf': 15, 'num_leaves': 2418} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6476168809515338, 'lambda_l2': 1.1210919319531578, 'learning_rate': 0.4492459724727067, 'max_depth': 81, 'min_data_in_leaf': 17, 'num_leaves': 2297} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6482482794499504, 'lambda_l2': 1.2889590576439232, 'learning_rate': 0.5272601824731794, 'max_depth': 81, 'min_data_in_leaf': 7, 'num_leaves': 2445} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.581756015453293, 'lambda_l2': 0.6014813141509585, 'learning_rate': 0.40848972034252307, 'max_depth': 85, 'min_data_in_leaf': 13, 'num_leaves': 2193} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5950877417035773, 'lambda_l2': 0.6596155290475276, 'learning_rate': 0.2362549899398929, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 520} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7525648317318837, 'lambda_l2': 0.4711130938167001, 'learning_rate': 0.2937120639752012, 'max_depth': 92, 'min_data_in_leaf': 11, 'num_leaves': 2080} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7290637824778086, 'lambda_l2': 0.16535941092735895, 'learning_rate': 0.4651868596085005, 'max_depth': 89, 'min_data_in_leaf': 13, 'num_leaves': 1944} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4558690632528349, 'lambda_l2': 0.5936323112670732, 'learning_rate': 0.2856672567648319, 'max_depth': 78, 'min_data_in_leaf': 9, 'num_leaves': 1879} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6766228280717222, 'lambda_l2': 0.8287891516438173, 'learning_rate': 0.3988875934355916, 'max_depth': 84, 'min_data_in_leaf': 15, 'num_leaves': 2116} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7014935465459431, 'lambda_l2': 0.017577154198944234, 'learning_rate': 0.5808580241924512, 'max_depth': 88, 'min_data_in_leaf': 8, 'num_leaves': 2302} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5731982717514653, 'lambda_l2': 0.9037439177811304, 'learning_rate': 0.3852965467344816, 'max_depth': 78, 'min_data_in_leaf': 18, 'num_leaves': 2560} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5388381757331668, 'lambda_l2': 2.709721046232352, 'learning_rate': 0.33083671735603914, 'max_depth': 86, 'min_data_in_leaf': 19, 'num_leaves': 654} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6579362098926129, 'lambda_l2': 1.4055432914953516, 'learning_rate': 0.6868709638860215, 'max_depth': 87, 'min_data_in_leaf': 16, 'num_leaves': 2341} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.9153611308946633, 'lambda_l2': 0.27716112963429257, 'learning_rate': 0.17490926747000762, 'max_depth': 92, 'min_data_in_leaf': 6, 'num_leaves': 1558} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6047604149113693, 'lambda_l2': 0.24628425639393786, 'learning_rate': 0.2633535716109522, 'max_depth': 85, 'min_data_in_leaf': 19, 'num_leaves': 574} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7079671386332426, 'lambda_l2': 0.1624575406562303, 'learning_rate': 0.4701122185519868, 'max_depth': 90, 'min_data_in_leaf': 11, 'num_leaves': 2000} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5480987900116341, 'lambda_l2': 0.7146502013548821, 'learning_rate': 0.3551450409274673, 'max_depth': 78, 'min_data_in_leaf': 5, 'num_leaves': 2387} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.726480488971057, 'lambda_l2': 1.2011537319440233, 'learning_rate': 0.5960315349727947, 'max_depth': 76, 'min_data_in_leaf': 13, 'num_leaves': 2183} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6186793340679251, 'lambda_l2': 1.0656018337423159, 'learning_rate': 0.43089873729149625, 'max_depth': 83, 'min_data_in_leaf': 24, 'num_leaves': 390} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6792010657332039, 'lambda_l2': 1.5248289912556223, 'learning_rate': 0.4980016387377703, 'max_depth': 82, 'min_data_in_leaf': 15, 'num_leaves': 2043} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6983361177049531, 'lambda_l2': 1.3760161818860082, 'learning_rate': 0.671880666754489, 'max_depth': 87, 'min_data_in_leaf': 17, 'num_leaves': 2236} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6257420745055062, 'lambda_l2': 1.113545190437799, 'learning_rate': 0.4160149443368194, 'max_depth': 78, 'min_data_in_leaf': 18, 'num_leaves': 2150} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6746307502969039, 'lambda_l2': 0.7897673825625249, 'learning_rate': 0.3431464949939121, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2073} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6504028676270632, 'lambda_l2': 1.26570888893747, 'learning_rate': 0.5363855171828946, 'max_depth': 81, 'min_data_in_leaf': 14, 'num_leaves': 2162} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6607450876625881, 'lambda_l2': 1.556369140000255, 'learning_rate': 0.39132348352279656, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 2103} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.4426030315008826, 'lambda_l2': 1.2756570479443565, 'learning_rate': 0.4624503569331052, 'max_depth': 83, 'min_data_in_leaf': 12, 'num_leaves': 1994} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6340637267642633, 'lambda_l2': 0.9733028226194523, 'learning_rate': 0.31337689024697624, 'max_depth': 85, 'min_data_in_leaf': 26, 'num_leaves': 338} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5728064808338023, 'lambda_l2': 3.2613571003627326, 'learning_rate': 0.18512208327811688, 'max_depth': 80, 'min_data_in_leaf': 20, 'num_leaves': 437} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6092190353246251, 'lambda_l2': 1.1228323547883576, 'learning_rate': 0.4541694479100876, 'max_depth': 80, 'min_data_in_leaf': 16, 'num_leaves': 2238} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7674276970302067, 'lambda_l2': 0.2570344383151413, 'learning_rate': 0.6088834275505131, 'max_depth': 95, 'min_data_in_leaf': 7, 'num_leaves': 1667} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7843113464659601, 'lambda_l2': 0.15908802396435778, 'learning_rate': 0.6823858190054979, 'max_depth': 93, 'min_data_in_leaf': 5, 'num_leaves': 1297} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5192519407422318, 'lambda_l2': 0.5441226588466462, 'learning_rate': 0.3556859033474568, 'max_depth': 86, 'min_data_in_leaf': 9, 'num_leaves': 1893} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7478658144146879, 'lambda_l2': 1.2494832242980403, 'learning_rate': 0.3154977860502433, 'max_depth': 82, 'min_data_in_leaf': 11, 'num_leaves': 1935} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.562185934111926, 'lambda_l2': 1.1436820560159398, 'learning_rate': 0.50325038697557, 'max_depth': 76, 'min_data_in_leaf': 14, 'num_leaves': 2290} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4393674809143364, 'lambda_l2': 1.4728072140989599, 'learning_rate': 0.2666970673491219, 'max_depth': 83, 'min_data_in_leaf': 8, 'num_leaves': 1817} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5049062773109892, 'lambda_l2': 0.5127086057615082, 'learning_rate': 0.4053993511939588, 'max_depth': 87, 'min_data_in_leaf': 10, 'num_leaves': 1760} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6905386291004064, 'lambda_l2': 1.7118514704202539, 'learning_rate': 0.6069813435996619, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2364} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6304051989835487, 'lambda_l2': 1.1824792751542241, 'learning_rate': 0.7635929383074319, 'max_depth': 82, 'min_data_in_leaf': 15, 'num_leaves': 2237} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5311024237347176, 'lambda_l2': 0.7887050205732393, 'learning_rate': 0.38253060656401133, 'max_depth': 85, 'min_data_in_leaf': 18, 'num_leaves': 2135} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.03244769504988529, 'lambda_l2': 0.3281251040321106, 'learning_rate': 0.5488189277551395, 'max_depth': 90, 'min_data_in_leaf': 7, 'num_leaves': 2360} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6855696196108017, 'lambda_l2': 1.4392101553836425, 'learning_rate': 0.3539516641548149, 'max_depth': 85, 'min_data_in_leaf': 11, 'num_leaves': 1907} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6122608057984597, 'lambda_l2': 1.0629798348879533, 'learning_rate': 0.4524886955502902, 'max_depth': 73, 'min_data_in_leaf': 13, 'num_leaves': 2484} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.638129964872437, 'lambda_l2': 1.3547012970350194, 'learning_rate': 0.5496030838789895, 'max_depth': 86, 'min_data_in_leaf': 5, 'num_leaves': 2313} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.4778831535002905, 'lambda_l2': 0.8675150624602155, 'learning_rate': 0.2793537401117277, 'max_depth': 75, 'min_data_in_leaf': 11, 'num_leaves': 285} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5140784889599894, 'lambda_l2': 0.48103211627123565, 'learning_rate': 0.1972888322305519, 'max_depth': 97, 'min_data_in_leaf': 22, 'num_leaves': 875} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5497941403247562, 'lambda_l2': 0.2240147583855275, 'learning_rate': 0.19916202427416968, 'max_depth': 92, 'min_data_in_leaf': 8, 'num_leaves': 1086} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5800302587995377, 'lambda_l2': 0.4240563116780095, 'learning_rate': 0.22601520644181658, 'max_depth': 88, 'min_data_in_leaf': 24, 'num_leaves': 608} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.4869776543664258, 'lambda_l2': 0.6780334932570414, 'learning_rate': 0.31030848663952937, 'max_depth': 53, 'min_data_in_leaf': 4, 'num_leaves': 2493} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.587643262128116, 'lambda_l2': 0.9134010873720085, 'learning_rate': 0.38278075247121396, 'max_depth': 71, 'min_data_in_leaf': 13, 'num_leaves': 2225} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6654491502841452, 'lambda_l2': 1.5896737077304421, 'learning_rate': 0.7075582514467824, 'max_depth': 83, 'min_data_in_leaf': 9, 'num_leaves': 2110} : acc= 65.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6436983263127697, 'lambda_l2': 1.2685055327430959, 'learning_rate': 0.5210934461651282, 'max_depth': 79, 'min_data_in_leaf': 6, 'num_leaves': 130} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7452806507807248, 'lambda_l2': 1.465978666589365, 'learning_rate': 0.6274539354864412, 'max_depth': 80, 'min_data_in_leaf': 9, 'num_leaves': 2147} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7529365873403819, 'lambda_l2': 1.6775252520280426, 'learning_rate': 0.7665398692631125, 'max_depth': 91, 'min_data_in_leaf': 11, 'num_leaves': 2037} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5995588566602096, 'lambda_l2': 0.8230701589077478, 'learning_rate': 0.3003026529161236, 'max_depth': 77, 'min_data_in_leaf': 19, 'num_leaves': 218} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.3114364177808008, 'lambda_l2': 1.1739164197978227, 'learning_rate': 0.23118776254527887, 'max_depth': 81, 'min_data_in_leaf': 15, 'num_leaves': 764} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4874326695288813, 'lambda_l2': 0.6400284076276183, 'learning_rate': 0.273065320638047, 'max_depth': 79, 'min_data_in_leaf': 12, 'num_leaves': 1785} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5310232729029307, 'lambda_l2': 0.37376556370541736, 'learning_rate': 0.1643847076443874, 'max_depth': 94, 'min_data_in_leaf': 22, 'num_leaves': 787} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.9694361330103884, 'lambda_l2': 0.44402541530247314, 'learning_rate': 0.20913131928549852, 'max_depth': 94, 'min_data_in_leaf': 4, 'num_leaves': 1230} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6250651901083285, 'lambda_l2': 1.0784502185185318, 'learning_rate': 0.42076063246014145, 'max_depth': 78, 'min_data_in_leaf': 17, 'num_leaves': 2348} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.350506229389428, 'lambda_l2': 0.09950483927377628, 'learning_rate': 0.1278936984855986, 'max_depth': 98, 'min_data_in_leaf': 8, 'num_leaves': 1378} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6495162282758752, 'lambda_l2': 0.19024241544671022, 'learning_rate': 0.24249041660077025, 'max_depth': 17, 'min_data_in_leaf': 15, 'num_leaves': 2462} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.1467129560455907, 'lambda_l2': 0.3813933860079045, 'learning_rate': 0.22552067888064486, 'max_depth': 96, 'min_data_in_leaf': 27, 'num_leaves': 955} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6660943390087567, 'lambda_l2': 1.0294344167322218, 'learning_rate': 0.5408486473611985, 'max_depth': 80, 'min_data_in_leaf': 14, 'num_leaves': 2182} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4932430226743851, 'lambda_l2': 0.7360054066421396, 'learning_rate': 0.294890516953876, 'max_depth': 72, 'min_data_in_leaf': 6, 'num_leaves': 268} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6448540505816538, 'lambda_l2': 1.2108903744968824, 'learning_rate': 0.468018971623485, 'max_depth': 83, 'min_data_in_leaf': 20, 'num_leaves': 2257} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5921120489078018, 'lambda_l2': 0.8494362231133588, 'learning_rate': 0.3488423426170045, 'max_depth': 76, 'min_data_in_leaf': 15, 'num_leaves': 2599} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6925945521529957, 'lambda_l2': 1.3300639517133233, 'learning_rate': 0.6638230470529487, 'max_depth': 89, 'min_data_in_leaf': 12, 'num_leaves': 2077} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5452030104563722, 'lambda_l2': 0.9715509828132234, 'learning_rate': 0.2511200694142751, 'max_depth': 82, 'min_data_in_leaf': 21, 'num_leaves': 456} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5667173957469119, 'lambda_l2': 0.01049049055967144, 'learning_rate': 0.43187973393041845, 'max_depth': 87, 'min_data_in_leaf': 13, 'num_leaves': 2366} : acc= 64.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7065402996695435, 'lambda_l2': 0.11285131874014898, 'learning_rate': 0.7712164686242857, 'max_depth': 90, 'min_data_in_leaf': 9, 'num_leaves': 2228} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7195549006339402, 'lambda_l2': 1.3565921197147957, 'learning_rate': 0.5789603101669911, 'max_depth': 79, 'min_data_in_leaf': 7, 'num_leaves': 2394} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.41081451900157007, 'lambda_l2': 0.6448031689789235, 'learning_rate': 0.31720075158329436, 'max_depth': 55, 'min_data_in_leaf': 2, 'num_leaves': 1538} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.729954928907173, 'lambda_l2': 1.5955477107506233, 'learning_rate': 0.3543991043741407, 'max_depth': 88, 'min_data_in_leaf': 25, 'num_leaves': 383} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.2450656748201599, 'lambda_l2': 0.009166309623514224, 'learning_rate': 0.23425507806725512, 'max_depth': 91, 'min_data_in_leaf': 17, 'num_leaves': 1919} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.5479645087743747, 'lambda_l2': 0.7068935665674789, 'learning_rate': 0.2726403482435748, 'max_depth': 60, 'min_data_in_leaf': 10, 'num_leaves': 55} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6727050906320708, 'lambda_l2': 0.9312468664834794, 'learning_rate': 0.18569082733639197, 'max_depth': 84, 'min_data_in_leaf': 21, 'num_leaves': 506} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5313017688132239, 'lambda_l2': 0.49039942607546966, 'learning_rate': 0.17575952827488917, 'max_depth': 98, 'min_data_in_leaf': 19, 'num_leaves': 1141} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7048280801679558, 'lambda_l2': 1.2954811643743258, 'learning_rate': 0.6292342265031032, 'max_depth': 85, 'min_data_in_leaf': 12, 'num_leaves': 2126} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6780743416777332, 'lambda_l2': 1.1560862978536035, 'learning_rate': 0.5170717602712016, 'max_depth': 81, 'min_data_in_leaf': 14, 'num_leaves': 2048} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7716634121906891, 'lambda_l2': 1.480483298216639, 'learning_rate': 0.5861956578944463, 'max_depth': 92, 'min_data_in_leaf': 2, 'num_leaves': 690} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.08428420171737527, 'lambda_l2': 0.2535411891438365, 'learning_rate': 0.21359771015003617, 'max_depth': 89, 'min_data_in_leaf': 17, 'num_leaves': 1161} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5548482554025185, 'lambda_l2': 0.00203392491279919, 'learning_rate': 0.27811292789781966, 'max_depth': 87, 'min_data_in_leaf': 19, 'num_leaves': 715} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6609841390766021, 'lambda_l2': 1.5294586432432202, 'learning_rate': 0.3997984563465487, 'max_depth': 85, 'min_data_in_leaf': 10, 'num_leaves': 1978} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6052427930934324, 'lambda_l2': 0.9194327998188867, 'learning_rate': 0.38290042440203603, 'max_depth': 81, 'min_data_in_leaf': 100, 'num_leaves': 2292} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.1860278847729108, 'lambda_l2': 0.2994850576275757, 'learning_rate': 0.4618838383023073, 'max_depth': 91, 'min_data_in_leaf': 4, 'num_leaves': 906} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6227348045267688, 'lambda_l2': 1.0970203799828449, 'learning_rate': 0.465769122505617, 'max_depth': 81, 'min_data_in_leaf': 6, 'num_leaves': 2232} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.4539335013239435, 'lambda_l2': 1.046102084956063, 'learning_rate': 0.33794585302026664, 'max_depth': 70, 'min_data_in_leaf': 18, 'num_leaves': 2524} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.42841530896052155, 'lambda_l2': 0.616706453406483, 'learning_rate': 0.322401404685389, 'max_depth': 87, 'min_data_in_leaf': 8, 'num_leaves': 1871} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6922590169400441, 'lambda_l2': 1.7656951178895968, 'learning_rate': 0.6623598951504246, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 2146} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5168622461642511, 'lambda_l2': 0.5750194148145303, 'learning_rate': 0.36440521812740584, 'max_depth': 66, 'min_data_in_leaf': 6, 'num_leaves': 2467} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.29854949763662286, 'lambda_l2': 0.010833310491408338, 'learning_rate': 0.17031665596699314, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 942} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.9444620771185507, 'lambda_l2': 0.5257915370063074, 'learning_rate': 0.26411008085119414, 'max_depth': 89, 'min_data_in_leaf': 16, 'num_leaves': 2033} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5147446677870309, 'lambda_l2': 0.38549769322603483, 'learning_rate': 0.7833094076382554, 'max_depth': 92, 'min_data_in_leaf': 12, 'num_leaves': 2375} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4689906671125474, 'lambda_l2': 0.688153733822746, 'learning_rate': 0.39969772837533174, 'max_depth': 83, 'min_data_in_leaf': 8, 'num_leaves': 2436} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.20821118063911934, 'lambda_l2': 0.010681320143760331, 'learning_rate': 0.24330749817457545, 'max_depth': 21, 'min_data_in_leaf': 20, 'num_leaves': 801} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.4366944808689509, 'lambda_l2': 0.7679974045191431, 'learning_rate': 0.3009369603013989, 'max_depth': 83, 'min_data_in_leaf': 4, 'num_leaves': 112} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4775833783724332, 'lambda_l2': 0.7162750311651002, 'learning_rate': 0.29798507123931456, 'max_depth': 74, 'min_data_in_leaf': 11, 'num_leaves': 1849} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7205231471562151, 'lambda_l2': 1.3183191335777007, 'learning_rate': 0.3499173846595184, 'max_depth': 87, 'min_data_in_leaf': 22, 'num_leaves': 466} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7389146411247771, 'lambda_l2': 1.369865063395579, 'learning_rate': 0.33788123558786515, 'max_depth': 87, 'min_data_in_leaf': 23, 'num_leaves': 332} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6065846755572746, 'lambda_l2': 0.19965439732822393, 'learning_rate': 0.19958803005147724, 'max_depth': 85, 'min_data_in_leaf': 27, 'num_leaves': 999} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.8629675902240201, 'lambda_l2': 0.3129255129428326, 'learning_rate': 0.1611029143919381, 'max_depth': 95, 'min_data_in_leaf': 10, 'num_leaves': 1796} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5645950524671479, 'lambda_l2': 0.48067351525082, 'learning_rate': 0.49651191851550547, 'max_depth': 93, 'min_data_in_leaf': 15, 'num_leaves': 845} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.4635952182254171, 'lambda_l2': 0.6163670841528546, 'learning_rate': 0.2798439985235381, 'max_depth': 77, 'min_data_in_leaf': 1, 'num_leaves': 1750} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.4454823626578857, 'lambda_l2': 0.7774737405924856, 'learning_rate': 0.3031994198636569, 'max_depth': 69, 'min_data_in_leaf': 7, 'num_leaves': 1949} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7090294939356488, 'lambda_l2': 1.4595921680181603, 'learning_rate': 0.5569666601954488, 'max_depth': 74, 'min_data_in_leaf': 13, 'num_leaves': 2300} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6424740311475288, 'lambda_l2': 1.2006348984761688, 'learning_rate': 0.5175980089523289, 'max_depth': 85, 'min_data_in_leaf': 9, 'num_leaves': 2190} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.43586505212277504, 'lambda_l2': 1.407287975584245, 'learning_rate': 0.8489504653962017, 'max_depth': 83, 'min_data_in_leaf': 6, 'num_leaves': 2516} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6035630166757168, 'lambda_l2': 0.19146612815466343, 'learning_rate': 0.025477750935383743, 'max_depth': 88, 'min_data_in_leaf': 12, 'num_leaves': 661} : acc= 60.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6608277219051352, 'lambda_l2': 1.1520025988966363, 'learning_rate': 0.5037771970152264, 'max_depth': 79, 'min_data_in_leaf': 16, 'num_leaves': 2596} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5263965493868531, 'lambda_l2': 0.42677780788405717, 'learning_rate': 0.13779965845709152, 'max_depth': 92, 'min_data_in_leaf': 9, 'num_leaves': 1067} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5832732285140018, 'lambda_l2': 0.9631170964451843, 'learning_rate': 0.4166548305907498, 'max_depth': 87, 'min_data_in_leaf': 14, 'num_leaves': 2290} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7116626899021881, 'lambda_l2': 1.2766686000516942, 'learning_rate': 0.6269662209082764, 'max_depth': 89, 'min_data_in_leaf': 15, 'num_leaves': 2182} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.738235894874509, 'lambda_l2': 1.6136711054452788, 'learning_rate': 0.7103017599996955, 'max_depth': 90, 'min_data_in_leaf': 18, 'num_leaves': 602} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5342216739809381, 'lambda_l2': 0.6265919703679853, 'learning_rate': 0.22760816472742965, 'max_depth': 94, 'min_data_in_leaf': 17, 'num_leaves': 2106} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7456163807914783, 'lambda_l2': 1.8308082306897904, 'learning_rate': 0.24829530887169504, 'max_depth': 91, 'min_data_in_leaf': 19, 'num_leaves': 740} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6357248291627414, 'lambda_l2': 1.03666417558138, 'learning_rate': 0.42740440628164555, 'max_depth': 78, 'min_data_in_leaf': 17, 'num_leaves': 2391} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.459247834059273, 'lambda_l2': 0.8550414999677454, 'learning_rate': 0.5098909563746843, 'max_depth': 63, 'min_data_in_leaf': 4, 'num_leaves': 2434} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6821741497627132, 'lambda_l2': 0.9481060303970493, 'learning_rate': 0.2005456063915742, 'max_depth': 81, 'min_data_in_leaf': 21, 'num_leaves': 554} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.5749194853408628, 'lambda_l2': 0.8150587033685287, 'learning_rate': 0.3899669635193774, 'max_depth': 77, 'min_data_in_leaf': 13, 'num_leaves': 2303} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6486893912406754, 'lambda_l2': 1.1762263110470403, 'learning_rate': 0.3350631163105232, 'max_depth': 80, 'min_data_in_leaf': 21, 'num_leaves': 365} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.625500132895252, 'lambda_l2': 1.0852665719044803, 'learning_rate': 0.5723360369172497, 'max_depth': 83, 'min_data_in_leaf': 14, 'num_leaves': 2357} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6692882654655233, 'lambda_l2': 0.9353516240858729, 'learning_rate': 0.23530271143471876, 'max_depth': 79, 'min_data_in_leaf': 24, 'num_leaves': 226} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6750180746107491, 'lambda_l2': 1.0094200997988132, 'learning_rate': 0.18673507712450438, 'max_depth': 75, 'min_data_in_leaf': 16, 'num_leaves': 2570} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.49324550968765973, 'lambda_l2': 0.27359545062200374, 'learning_rate': 0.21722913515793424, 'max_depth': 98, 'min_data_in_leaf': 11, 'num_leaves': 1526} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7687068831701509, 'lambda_l2': 0.13589961809115167, 'learning_rate': 0.7233544710316973, 'max_depth': 96, 'min_data_in_leaf': 11, 'num_leaves': 205} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6929031261413937, 'lambda_l2': 1.1708017693346047, 'learning_rate': 0.08925320476316954, 'max_depth': 76, 'min_data_in_leaf': 18, 'num_leaves': 528} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.804979138251454, 'lambda_l2': 0.08683838509475354, 'learning_rate': 0.04941536332024701, 'max_depth': 51, 'min_data_in_leaf': 6, 'num_leaves': 1416} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5509747222338426, 'lambda_l2': 0.5540596184069595, 'learning_rate': 0.1770235843852085, 'max_depth': 95, 'min_data_in_leaf': 8, 'num_leaves': 1278} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7253919240856178, 'lambda_l2': 1.2486029333734905, 'learning_rate': 0.3816146886812638, 'max_depth': 86, 'min_data_in_leaf': 26, 'num_leaves': 412} : acc= 72.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6340033301481223, 'lambda_l2': 1.290030209936442, 'learning_rate': 0.4792855946075239, 'max_depth': 82, 'min_data_in_leaf': 1, 'num_leaves': 2454} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.758002984971081, 'lambda_l2': 1.6929593302112151, 'learning_rate': 0.43661249388780715, 'max_depth': 86, 'min_data_in_leaf': 39, 'num_leaves': 1935} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6573504009389078, 'lambda_l2': 1.0417943258537274, 'learning_rate': 0.4337961780212041, 'max_depth': 83, 'min_data_in_leaf': 18, 'num_leaves': 1979} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.6280717843761006, 'lambda_l2': 0.9240416183304794, 'learning_rate': 0.3645184250469589, 'max_depth': 89, 'min_data_in_leaf': 96, 'num_leaves': 358} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.3939975540552979, 'lambda_l2': 0.7404323519059104, 'learning_rate': 0.2656619458485781, 'max_depth': 70, 'min_data_in_leaf': 45, 'num_leaves': 1677} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6070327566741154, 'lambda_l2': 1.0149340854994855, 'learning_rate': 0.4701406391586414, 'max_depth': 89, 'min_data_in_leaf': 32, 'num_leaves': 466} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6960003318759258, 'lambda_l2': 1.1233931658506202, 'learning_rate': 0.5730914813005777, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2519} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7727649692224843, 'lambda_l2': 0.006109814642474543, 'learning_rate': 0.03379018164871489, 'max_depth': 93, 'min_data_in_leaf': 5, 'num_leaves': 2213} : acc= 63.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.49562919163901886, 'lambda_l2': 0.8126420655097607, 'learning_rate': 0.3000814923659334, 'max_depth': 72, 'min_data_in_leaf': 1, 'num_leaves': 225} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7253139741964337, 'lambda_l2': 0.47022330665366147, 'learning_rate': 0.35784997224266507, 'max_depth': 92, 'min_data_in_leaf': 14, 'num_leaves': 2067} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5632085708175905, 'lambda_l2': 1.5250204111018248, 'learning_rate': 0.6413378114956728, 'max_depth': 84, 'min_data_in_leaf': 12, 'num_leaves': 2243} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.6958060331222294, 'lambda_l2': 1.2710918045327975, 'learning_rate': 0.8832309329769606, 'max_depth': 73, 'min_data_in_leaf': 12, 'num_leaves': 2101} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6687572223318669, 'lambda_l2': 1.42763352645886, 'learning_rate': 0.4354474577971206, 'max_depth': 82, 'min_data_in_leaf': 18, 'num_leaves': 1997} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6597691983167967, 'lambda_l2': 1.1838614051904717, 'learning_rate': 0.3313051628680746, 'max_depth': 78, 'min_data_in_leaf': 24, 'num_leaves': 316} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7005876867526746, 'lambda_l2': 0.78340028419348, 'learning_rate': 0.4127052560635846, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 2051} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.11630625348910234, 'lambda_l2': 0.3173491068141204, 'learning_rate': 0.14774049119544228, 'max_depth': 96, 'min_data_in_leaf': 4, 'num_leaves': 914} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.7390244571900684, 'lambda_l2': 1.0075897771181632, 'learning_rate': 0.28141314661601824, 'max_depth': 90, 'min_data_in_leaf': 23, 'num_leaves': 294} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.7156786964141719, 'lambda_l2': 1.2509567105920785, 'learning_rate': 0.36889887756137446, 'max_depth': 79, 'min_data_in_leaf': 33, 'num_leaves': 159} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.445892367413987, 'lambda_l2': 1.1248877580212218, 'learning_rate': 0.317030379834724, 'max_depth': 74, 'min_data_in_leaf': 9, 'num_leaves': 1543} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6436337648659815, 'lambda_l2': 1.1842150277771732, 'learning_rate': 0.33314837358309357, 'max_depth': 80, 'min_data_in_leaf': 22, 'num_leaves': 457} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7975146186254939, 'lambda_l2': 1.5229809817693483, 'learning_rate': 0.5800725208732752, 'max_depth': 85, 'min_data_in_leaf': 60, 'num_leaves': 393} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8282619184902522, 'lambda_l2': 1.2953801321251222, 'learning_rate': 0.3100323201684594, 'max_depth': 82, 'min_data_in_leaf': 30, 'num_leaves': 455} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.7036773978680847, 'lambda_l2': 1.649770306747605, 'learning_rate': 0.5263391291331079, 'max_depth': 75, 'min_data_in_leaf': 12, 'num_leaves': 2290} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7248210179237947, 'lambda_l2': 0.41980685930727984, 'learning_rate': 0.4936515551642457, 'max_depth': 90, 'min_data_in_leaf': 14, 'num_leaves': 2017} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.6223358591772588, 'lambda_l2': 1.1097722159013665, 'learning_rate': 0.38272667161035584, 'max_depth': 81, 'min_data_in_leaf': 70, 'num_leaves': 2150} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6790877739896524, 'lambda_l2': 1.3480694245044476, 'learning_rate': 0.7024711434393676, 'max_depth': 78, 'min_data_in_leaf': 16, 'num_leaves': 2185} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5988028072917657, 'lambda_l2': 1.2352232547044426, 'learning_rate': 0.4252395808313718, 'max_depth': 85, 'min_data_in_leaf': 7, 'num_leaves': 400} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7652024517561885, 'lambda_l2': 1.2666008917803435, 'learning_rate': 0.3636081570630492, 'max_depth': 86, 'min_data_in_leaf': 35, 'num_leaves': 485} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.721316672597059, 'lambda_l2': 1.218912067609886, 'learning_rate': 0.46971253754108155, 'max_depth': 79, 'min_data_in_leaf': 22, 'num_leaves': 276} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7354332295271226, 'lambda_l2': 1.378135579649939, 'learning_rate': 0.5503692787072546, 'max_depth': 88, 'min_data_in_leaf': 19, 'num_leaves': 2281} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7421303133310961, 'lambda_l2': 1.7026011510236303, 'learning_rate': 0.7827250177034675, 'max_depth': 91, 'min_data_in_leaf': 54, 'num_leaves': 469} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.35287792736217627, 'lambda_l2': 0.19655841009057684, 'learning_rate': 0.22920980675608588, 'max_depth': 100, 'min_data_in_leaf': 3, 'num_leaves': 1021} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7081403885195776, 'lambda_l2': 0.33367623490254195, 'learning_rate': 0.1250214529915875, 'max_depth': 88, 'min_data_in_leaf': 15, 'num_leaves': 1926} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6653919202247786, 'lambda_l2': 1.3816367612683687, 'learning_rate': 0.4726462764393519, 'max_depth': 83, 'min_data_in_leaf': 20, 'num_leaves': 2381} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.49963307443991456, 'lambda_l2': 0.6577811843078131, 'learning_rate': 0.2718015169798918, 'max_depth': 66, 'min_data_in_leaf': 10, 'num_leaves': 1625} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.4166815258710919, 'lambda_l2': 1.5227347275963186, 'learning_rate': 0.2987947684809266, 'max_depth': 77, 'min_data_in_leaf': 36, 'num_leaves': 2558} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.5917464597277934, 'lambda_l2': 0.97484988576767, 'learning_rate': 0.3267966397499735, 'max_depth': 75, 'min_data_in_leaf': 17, 'num_leaves': 2728} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.16215372200962175, 'lambda_l2': 0.5402508686960245, 'learning_rate': 0.25208327438681155, 'max_depth': 87, 'min_data_in_leaf': 11, 'num_leaves': 144} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.5243063373679161, 'lambda_l2': 0.49930323807077337, 'learning_rate': 0.2346408659637876, 'max_depth': 91, 'min_data_in_leaf': 29, 'num_leaves': 518} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.5883007392738754, 'lambda_l2': 0.898033964313934, 'learning_rate': 0.3613283055269216, 'max_depth': 85, 'min_data_in_leaf': 15, 'num_leaves': 57} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.46999301535525595, 'lambda_l2': 0.6327621980206865, 'learning_rate': 0.2882894855047583, 'max_depth': 42, 'min_data_in_leaf': 8, 'num_leaves': 1890} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.8802610063237079, 'lambda_l2': 0.09138017970883183, 'learning_rate': 0.15839773719164293, 'max_depth': 56, 'min_data_in_leaf': 29, 'num_leaves': 620} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7475035982694818, 'lambda_l2': 1.09053156290442, 'learning_rate': 0.2208479269191593, 'max_depth': 86, 'min_data_in_leaf': 26, 'num_leaves': 290} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.5841389921019199, 'lambda_l2': 0.893585342907473, 'learning_rate': 0.10227308448420251, 'max_depth': 81, 'min_data_in_leaf': 20, 'num_leaves': 639} : acc= 65.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.776893330293135, 'lambda_l2': 1.6738909611372321, 'learning_rate': 0.6320803732810496, 'max_depth': 86, 'min_data_in_leaf': 5, 'num_leaves': 2340} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6514598002063543, 'lambda_l2': 1.05750342895216, 'learning_rate': 0.41708549712651716, 'max_depth': 82, 'min_data_in_leaf': 17, 'num_leaves': 2039} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.734041508934515, 'lambda_l2': 1.5631071022953056, 'learning_rate': 0.7090054298286724, 'max_depth': 89, 'min_data_in_leaf': 32, 'num_leaves': 196} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6294772733759373, 'lambda_l2': 1.012842152383127, 'learning_rate': 0.47089859423755154, 'max_depth': 82, 'min_data_in_leaf': 19, 'num_leaves': 2211} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.6127389216853477, 'lambda_l2': 1.0911324863832186, 'learning_rate': 0.868131414965861, 'max_depth': 83, 'min_data_in_leaf': 13, 'num_leaves': 2413} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6874598862983923, 'lambda_l2': 0.7790819889061968, 'learning_rate': 0.43032676844088547, 'max_depth': 84, 'min_data_in_leaf': 13, 'num_leaves': 2002} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.50932223968088, 'lambda_l2': 0.36175077868063676, 'learning_rate': 0.5282504277328143, 'max_depth': 94, 'min_data_in_leaf': 43, 'num_leaves': 331} : acc= 66.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.5447553673436157, 'lambda_l2': 0.7128307781696004, 'learning_rate': 0.20832709655698692, 'max_depth': 77, 'min_data_in_leaf': 23, 'num_leaves': 780} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6105174974198219, 'lambda_l2': 0.8662651145092513, 'learning_rate': 0.3227136604224724, 'max_depth': 84, 'min_data_in_leaf': 28, 'num_leaves': 289} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.773161210591282, 'lambda_l2': 1.6078787782736919, 'learning_rate': 0.3962029303310123, 'max_depth': 92, 'min_data_in_leaf': 50, 'num_leaves': 393} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.9979641866909925, 'lambda_l2': 0.7483394506686986, 'learning_rate': 0.39071402066447664, 'max_depth': 27, 'min_data_in_leaf': 7, 'num_leaves': 67} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6877188289154432, 'lambda_l2': 1.7996221085309616, 'learning_rate': 0.14990894604596638, 'max_depth': 97, 'min_data_in_leaf': 20, 'num_leaves': 568} : acc= 67.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.6443814238994682, 'lambda_l2': 2.6395445264782027, 'learning_rate': 0.5939354030199452, 'max_depth': 88, 'min_data_in_leaf': 16, 'num_leaves': 2323} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.7475476336976874, 'lambda_l2': 1.2466942599797448, 'learning_rate': 0.24353786854398374, 'max_depth': 87, 'min_data_in_leaf': 21, 'num_leaves': 560} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6211482295974261, 'lambda_l2': 1.3993357364631536, 'learning_rate': 0.6372675907923168, 'max_depth': 37, 'min_data_in_leaf': 9, 'num_leaves': 2239} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.794230240970942, 'lambda_l2': 0.07714185159100022, 'learning_rate': 0.18444348038488523, 'max_depth': 94, 'min_data_in_leaf': 26, 'num_leaves': 410} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.6687941918532169, 'lambda_l2': 1.4680386553862204, 'learning_rate': 0.793508747634707, 'max_depth': 80, 'min_data_in_leaf': 13, 'num_leaves': 2120} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7651721602709463, 'lambda_l2': 1.9259613055405, 'learning_rate': 0.48002614055465664, 'max_depth': 93, 'min_data_in_leaf': 15, 'num_leaves': 2143} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.22301121008742586, 'lambda_l2': 0.4239052802546488, 'learning_rate': 0.2567416731480632, 'max_depth': 89, 'min_data_in_leaf': 10, 'num_leaves': 1968} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8422996725868777, 'lambda_l2': 2.1567047514054254, 'learning_rate': 0.5759761049940418, 'max_depth': 88, 'min_data_in_leaf': 4, 'num_leaves': 2616} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7422421500026889, 'lambda_l2': 1.4579101731667807, 'learning_rate': 0.4954371032973548, 'max_depth': 86, 'min_data_in_leaf': 11, 'num_leaves': 2068} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7167920675565789, 'lambda_l2': 1.3564166876198274, 'learning_rate': 0.2658877051647473, 'max_depth': 90, 'min_data_in_leaf': 23, 'num_leaves': 559} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.9027215573104003, 'lambda_l2': 0.26421466866129417, 'learning_rate': 0.16053621179669542, 'max_depth': 45, 'min_data_in_leaf': 1, 'num_leaves': 988} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.6033162700061219, 'lambda_l2': 0.9209470090800236, 'learning_rate': 0.06062559798781178, 'max_depth': 84, 'min_data_in_leaf': 20, 'num_leaves': 2500} : acc= 65.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3929948759098117, 'lambda_l2': 1.5275718786333294, 'learning_rate': 0.8874493423813316, 'max_depth': 59, 'min_data_in_leaf': 6, 'num_leaves': 2433} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7588419079709239, 'lambda_l2': 1.4345397054493323, 'learning_rate': 0.6119085736839595, 'max_depth': 86, 'min_data_in_leaf': 7, 'num_leaves': 102} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.6847488049913191, 'lambda_l2': 1.656066110612852, 'learning_rate': 0.44607797785316267, 'max_depth': 90, 'min_data_in_leaf': 18, 'num_leaves': 2094} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.4860340916604477, 'lambda_l2': 1.3529926210818388, 'learning_rate': 0.3715146328588978, 'max_depth': 84, 'min_data_in_leaf': 14, 'num_leaves': 2046} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.933656391536303, 'lambda_l2': 0.1452888064781901, 'learning_rate': 0.7680804782757299, 'max_depth': 96, 'min_data_in_leaf': 3, 'num_leaves': 2542} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5613054801958575, 'lambda_l2': 0.8576109192166529, 'learning_rate': 0.20149571648622414, 'max_depth': 72, 'min_data_in_leaf': 17, 'num_leaves': 2679} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.7278368318835643, 'lambda_l2': 1.080846170000871, 'learning_rate': 0.3263520186247571, 'max_depth': 74, 'min_data_in_leaf': 12, 'num_leaves': 126} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.6808545236639945, 'lambda_l2': 1.5924033412943956, 'learning_rate': 0.528092093939622, 'max_depth': 88, 'min_data_in_leaf': 18, 'num_leaves': 2126} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.6703980425618474, 'lambda_l2': 1.1832585514039546, 'learning_rate': 0.3599368395007735, 'max_depth': 84, 'min_data_in_leaf': 10, 'num_leaves': 494} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.7965191870089438, 'lambda_l2': 0.20141148549262217, 'learning_rate': 0.08113376391660142, 'max_depth': 93, 'min_data_in_leaf': 8, 'num_leaves': 2175} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.818882081701208, 'lambda_l2': 0.09749765990953552, 'learning_rate': 0.2566482218911327, 'max_depth': 91, 'min_data_in_leaf': 24, 'num_leaves': 364} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.07349961560860171, 'lambda_l2': 1.978133494091494, 'learning_rate': 0.6573881316214304, 'max_depth': 95, 'min_data_in_leaf': 13, 'num_leaves': 806} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7122931377542455, 'lambda_l2': 2.112643946158147, 'learning_rate': 0.41098011710318216, 'max_depth': 88, 'min_data_in_leaf': 16, 'num_leaves': 1957} : acc= 68.33%\n",
            "[HPO] metrics with {'lambda_l1': 0.5905996426270101, 'lambda_l2': 0.7986983608420082, 'learning_rate': 0.04299806032375619, 'max_depth': 82, 'min_data_in_leaf': 22, 'num_leaves': 2533} : acc= 62.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.41061339603745883, 'lambda_l2': 0.520012246514247, 'learning_rate': 0.29248910494021013, 'max_depth': 63, 'min_data_in_leaf': 10, 'num_leaves': 1810} : acc= 71.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.47685197519456574, 'lambda_l2': 1.802409575271228, 'learning_rate': 0.6961798625179806, 'max_depth': 78, 'min_data_in_leaf': 12, 'num_leaves': 3343} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.5380618197990105, 'lambda_l2': 0.001670009050211348, 'learning_rate': 0.02250207412224715, 'max_depth': 86, 'min_data_in_leaf': 14, 'num_leaves': 2276} : acc= 56.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.8183887770186533, 'lambda_l2': 0.33600896490925114, 'learning_rate': 0.4173348619746645, 'max_depth': 93, 'min_data_in_leaf': 64, 'num_leaves': 426} : acc= 66.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.5666287206806921, 'lambda_l2': 0.6885636842912785, 'learning_rate': 0.23507161083309366, 'max_depth': 90, 'min_data_in_leaf': 16, 'num_leaves': 1883} : acc= 67.50%\n",
            "[HPO] metrics with {'lambda_l1': 0.7591898691483396, 'lambda_l2': 1.4777165140913398, 'learning_rate': 0.3624632157711629, 'max_depth': 86, 'min_data_in_leaf': 8, 'num_leaves': 588} : acc= 70.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.5078716803665172, 'lambda_l2': 0.3683346590007732, 'learning_rate': 0.11097617208018569, 'max_depth': 100, 'min_data_in_leaf': 6, 'num_leaves': 1521} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.5423086801325654, 'lambda_l2': 0.5787593861610973, 'learning_rate': 0.2115163936977778, 'max_depth': 91, 'min_data_in_leaf': 24, 'num_leaves': 238} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.7859479964840785, 'lambda_l2': 0.2233325030873322, 'learning_rate': 0.1290225542735094, 'max_depth': 98, 'min_data_in_leaf': 20, 'num_leaves': 144} : acc= 70.42%\n",
            "[HPO] metrics with {'lambda_l1': 0.8559111108097847, 'lambda_l2': 0.2031033397974457, 'learning_rate': 0.1812211878358464, 'max_depth': 93, 'min_data_in_leaf': 20, 'num_leaves': 648} : acc= 69.58%\n",
            "[HPO] metrics with {'lambda_l1': 0.7231564132430249, 'lambda_l2': 1.3151466582313422, 'learning_rate': 0.5944410427303809, 'max_depth': 80, 'min_data_in_leaf': 15, 'num_leaves': 2318} : acc= 72.08%\n",
            "[HPO] metrics with {'lambda_l1': 0.002129582241401695, 'lambda_l2': 0.9485949557260885, 'learning_rate': 0.31295755151924876, 'max_depth': 88, 'min_data_in_leaf': 28, 'num_leaves': 344} : acc= 71.67%\n",
            "[HPO] metrics with {'lambda_l1': 0.7105391583222872, 'lambda_l2': 1.2780934191130457, 'learning_rate': 0.40042718129166055, 'max_depth': 82, 'min_data_in_leaf': 26, 'num_leaves': 191} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6098645708032525, 'lambda_l2': 0.9419617829712502, 'learning_rate': 0.49757545301193595, 'max_depth': 84, 'min_data_in_leaf': 19, 'num_leaves': 2473} : acc= 67.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.46240936086277795, 'lambda_l2': 1.0707455841258484, 'learning_rate': 0.4588736679864861, 'max_depth': 80, 'min_data_in_leaf': 11, 'num_leaves': 2380} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.3629981139449664, 'lambda_l2': 0.0015365582768201436, 'learning_rate': 0.1914145529724199, 'max_depth': 97, 'min_data_in_leaf': 24, 'num_leaves': 266} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.7608104395644828, 'lambda_l2': 0.4606443196223471, 'learning_rate': 0.5270969402945603, 'max_depth': 91, 'min_data_in_leaf': 16, 'num_leaves': 2143} : acc= 69.17%\n",
            "[HPO] metrics with {'lambda_l1': 0.704047026605392, 'lambda_l2': 0.09089411689442124, 'learning_rate': 0.8259806394015055, 'max_depth': 89, 'min_data_in_leaf': 12, 'num_leaves': 2411} : acc= 60.83%\n",
            "[HPO] metrics with {'lambda_l1': 0.7408795149302893, 'lambda_l2': 1.4566659988093886, 'learning_rate': 0.6398068835818838, 'max_depth': 87, 'min_data_in_leaf': 30, 'num_leaves': 558} : acc= 68.75%\n",
            "[HPO] metrics with {'lambda_l1': 0.6441860714771044, 'lambda_l2': 1.1951746599188589, 'learning_rate': 0.028394742791210976, 'max_depth': 85, 'min_data_in_leaf': 27, 'num_leaves': 473} : acc= 61.25%\n",
            "[HPO] metrics with {'lambda_l1': 0.8155816198079495, 'lambda_l2': 0.5891785462093193, 'learning_rate': 0.26735931432693544, 'max_depth': 95, 'min_data_in_leaf': 27, 'num_leaves': 300} : acc= 70.00%\n",
            "[HPO] metrics with {'lambda_l1': 0.3680930774855164, 'lambda_l2': 1.7566086985442528, 'learning_rate': 0.009985966090905025, 'max_depth': 94, 'min_data_in_leaf': 5, 'num_leaves': 863} : acc= 47.92%\n",
            "[HPO] metrics with {'lambda_l1': 0.6487490634802843, 'lambda_l2': 0.8661917814168765, 'learning_rate': 0.3380750128077565, 'max_depth': 88, 'min_data_in_leaf': 26, 'num_leaves': 391} : acc= 70.00%\n",
            "100%|██████████| 3000/3000 [19:53<00:00,  2.51trial/s, best loss: -0.7458333333333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 학습된 모델을 이용하여 New dataset 에 대한 성능 도출\n",
        "\n",
        "new_dataset_accuracy = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    preds_new = model.predict(X_test_new)\n",
        "    accuracy_new = accuracy_score(preds_new, y_test_new)\n",
        "    acc = f'{(100 * accuracy_new):6.2f}'\n",
        "\n",
        "    new_dataset_accuracy.append(100 * accuracy_new)\n",
        "    print(f'[NEW data] metrics for {i + 1}-th model : acc={acc}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTmpL3TO3VGn",
        "outputId": "71b82b09-c4db-48ea-f742-9ef49594b2a2"
      },
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NEW data] metrics for 1-th model : acc= 58.67%\n",
            "[NEW data] metrics for 2-th model : acc= 66.33%\n",
            "[NEW data] metrics for 3-th model : acc= 47.67%\n",
            "[NEW data] metrics for 4-th model : acc= 47.67%\n",
            "[NEW data] metrics for 5-th model : acc= 47.67%\n",
            "[NEW data] metrics for 6-th model : acc= 66.00%\n",
            "[NEW data] metrics for 7-th model : acc= 65.33%\n",
            "[NEW data] metrics for 8-th model : acc= 69.33%\n",
            "[NEW data] metrics for 9-th model : acc= 60.67%\n",
            "[NEW data] metrics for 10-th model : acc= 66.33%\n",
            "[NEW data] metrics for 11-th model : acc= 67.33%\n",
            "[NEW data] metrics for 12-th model : acc= 66.67%\n",
            "[NEW data] metrics for 13-th model : acc= 51.33%\n",
            "[NEW data] metrics for 14-th model : acc= 67.67%\n",
            "[NEW data] metrics for 15-th model : acc= 47.67%\n",
            "[NEW data] metrics for 16-th model : acc= 58.33%\n",
            "[NEW data] metrics for 17-th model : acc= 47.67%\n",
            "[NEW data] metrics for 18-th model : acc= 62.00%\n",
            "[NEW data] metrics for 19-th model : acc= 67.67%\n",
            "[NEW data] metrics for 20-th model : acc= 64.33%\n",
            "[NEW data] metrics for 21-th model : acc= 67.67%\n",
            "[NEW data] metrics for 22-th model : acc= 67.67%\n",
            "[NEW data] metrics for 23-th model : acc= 67.00%\n",
            "[NEW data] metrics for 24-th model : acc= 66.33%\n",
            "[NEW data] metrics for 25-th model : acc= 66.67%\n",
            "[NEW data] metrics for 26-th model : acc= 62.33%\n",
            "[NEW data] metrics for 27-th model : acc= 47.67%\n",
            "[NEW data] metrics for 28-th model : acc= 67.00%\n",
            "[NEW data] metrics for 29-th model : acc= 63.67%\n",
            "[NEW data] metrics for 30-th model : acc= 67.33%\n",
            "[NEW data] metrics for 31-th model : acc= 63.00%\n",
            "[NEW data] metrics for 32-th model : acc= 67.00%\n",
            "[NEW data] metrics for 33-th model : acc= 50.67%\n",
            "[NEW data] metrics for 34-th model : acc= 69.00%\n",
            "[NEW data] metrics for 35-th model : acc= 47.67%\n",
            "[NEW data] metrics for 36-th model : acc= 65.33%\n",
            "[NEW data] metrics for 37-th model : acc= 68.00%\n",
            "[NEW data] metrics for 38-th model : acc= 64.33%\n",
            "[NEW data] metrics for 39-th model : acc= 65.67%\n",
            "[NEW data] metrics for 40-th model : acc= 60.00%\n",
            "[NEW data] metrics for 41-th model : acc= 68.33%\n",
            "[NEW data] metrics for 42-th model : acc= 55.67%\n",
            "[NEW data] metrics for 43-th model : acc= 68.67%\n",
            "[NEW data] metrics for 44-th model : acc= 71.00%\n",
            "[NEW data] metrics for 45-th model : acc= 64.67%\n",
            "[NEW data] metrics for 46-th model : acc= 66.67%\n",
            "[NEW data] metrics for 47-th model : acc= 68.00%\n",
            "[NEW data] metrics for 48-th model : acc= 47.67%\n",
            "[NEW data] metrics for 49-th model : acc= 63.00%\n",
            "[NEW data] metrics for 50-th model : acc= 53.33%\n",
            "[NEW data] metrics for 51-th model : acc= 47.67%\n",
            "[NEW data] metrics for 52-th model : acc= 47.67%\n",
            "[NEW data] metrics for 53-th model : acc= 66.67%\n",
            "[NEW data] metrics for 54-th model : acc= 69.00%\n",
            "[NEW data] metrics for 55-th model : acc= 68.00%\n",
            "[NEW data] metrics for 56-th model : acc= 62.67%\n",
            "[NEW data] metrics for 57-th model : acc= 47.67%\n",
            "[NEW data] metrics for 58-th model : acc= 67.67%\n",
            "[NEW data] metrics for 59-th model : acc= 67.00%\n",
            "[NEW data] metrics for 60-th model : acc= 64.00%\n",
            "[NEW data] metrics for 61-th model : acc= 68.00%\n",
            "[NEW data] metrics for 62-th model : acc= 60.33%\n",
            "[NEW data] metrics for 63-th model : acc= 59.67%\n",
            "[NEW data] metrics for 64-th model : acc= 47.67%\n",
            "[NEW data] metrics for 65-th model : acc= 67.33%\n",
            "[NEW data] metrics for 66-th model : acc= 68.67%\n",
            "[NEW data] metrics for 67-th model : acc= 70.00%\n",
            "[NEW data] metrics for 68-th model : acc= 67.67%\n",
            "[NEW data] metrics for 69-th model : acc= 66.33%\n",
            "[NEW data] metrics for 70-th model : acc= 64.33%\n",
            "[NEW data] metrics for 71-th model : acc= 68.67%\n",
            "[NEW data] metrics for 72-th model : acc= 68.00%\n",
            "[NEW data] metrics for 73-th model : acc= 68.00%\n",
            "[NEW data] metrics for 74-th model : acc= 68.33%\n",
            "[NEW data] metrics for 75-th model : acc= 64.00%\n",
            "[NEW data] metrics for 76-th model : acc= 67.67%\n",
            "[NEW data] metrics for 77-th model : acc= 66.67%\n",
            "[NEW data] metrics for 78-th model : acc= 69.00%\n",
            "[NEW data] metrics for 79-th model : acc= 66.67%\n",
            "[NEW data] metrics for 80-th model : acc= 63.33%\n",
            "[NEW data] metrics for 81-th model : acc= 62.33%\n",
            "[NEW data] metrics for 82-th model : acc= 65.67%\n",
            "[NEW data] metrics for 83-th model : acc= 67.33%\n",
            "[NEW data] metrics for 84-th model : acc= 63.33%\n",
            "[NEW data] metrics for 85-th model : acc= 67.00%\n",
            "[NEW data] metrics for 86-th model : acc= 61.33%\n",
            "[NEW data] metrics for 87-th model : acc= 70.00%\n",
            "[NEW data] metrics for 88-th model : acc= 67.00%\n",
            "[NEW data] metrics for 89-th model : acc= 62.00%\n",
            "[NEW data] metrics for 90-th model : acc= 66.67%\n",
            "[NEW data] metrics for 91-th model : acc= 67.67%\n",
            "[NEW data] metrics for 92-th model : acc= 67.00%\n",
            "[NEW data] metrics for 93-th model : acc= 65.67%\n",
            "[NEW data] metrics for 94-th model : acc= 64.00%\n",
            "[NEW data] metrics for 95-th model : acc= 67.00%\n",
            "[NEW data] metrics for 96-th model : acc= 66.33%\n",
            "[NEW data] metrics for 97-th model : acc= 47.67%\n",
            "[NEW data] metrics for 98-th model : acc= 65.67%\n",
            "[NEW data] metrics for 99-th model : acc= 62.00%\n",
            "[NEW data] metrics for 100-th model : acc= 47.67%\n",
            "[NEW data] metrics for 101-th model : acc= 53.67%\n",
            "[NEW data] metrics for 102-th model : acc= 47.67%\n",
            "[NEW data] metrics for 103-th model : acc= 47.67%\n",
            "[NEW data] metrics for 104-th model : acc= 54.33%\n",
            "[NEW data] metrics for 105-th model : acc= 58.33%\n",
            "[NEW data] metrics for 106-th model : acc= 63.00%\n",
            "[NEW data] metrics for 107-th model : acc= 68.33%\n",
            "[NEW data] metrics for 108-th model : acc= 67.00%\n",
            "[NEW data] metrics for 109-th model : acc= 64.00%\n",
            "[NEW data] metrics for 110-th model : acc= 65.33%\n",
            "[NEW data] metrics for 111-th model : acc= 65.67%\n",
            "[NEW data] metrics for 112-th model : acc= 47.67%\n",
            "[NEW data] metrics for 113-th model : acc= 65.33%\n",
            "[NEW data] metrics for 114-th model : acc= 69.67%\n",
            "[NEW data] metrics for 115-th model : acc= 65.33%\n",
            "[NEW data] metrics for 116-th model : acc= 67.00%\n",
            "[NEW data] metrics for 117-th model : acc= 69.33%\n",
            "[NEW data] metrics for 118-th model : acc= 66.67%\n",
            "[NEW data] metrics for 119-th model : acc= 63.33%\n",
            "[NEW data] metrics for 120-th model : acc= 68.00%\n",
            "[NEW data] metrics for 121-th model : acc= 66.00%\n",
            "[NEW data] metrics for 122-th model : acc= 67.33%\n",
            "[NEW data] metrics for 123-th model : acc= 64.67%\n",
            "[NEW data] metrics for 124-th model : acc= 47.67%\n",
            "[NEW data] metrics for 125-th model : acc= 65.33%\n",
            "[NEW data] metrics for 126-th model : acc= 47.67%\n",
            "[NEW data] metrics for 127-th model : acc= 61.67%\n",
            "[NEW data] metrics for 128-th model : acc= 64.33%\n",
            "[NEW data] metrics for 129-th model : acc= 63.67%\n",
            "[NEW data] metrics for 130-th model : acc= 65.00%\n",
            "[NEW data] metrics for 131-th model : acc= 67.00%\n",
            "[NEW data] metrics for 132-th model : acc= 62.33%\n",
            "[NEW data] metrics for 133-th model : acc= 68.00%\n",
            "[NEW data] metrics for 134-th model : acc= 66.67%\n",
            "[NEW data] metrics for 135-th model : acc= 47.67%\n",
            "[NEW data] metrics for 136-th model : acc= 67.67%\n",
            "[NEW data] metrics for 137-th model : acc= 65.33%\n",
            "[NEW data] metrics for 138-th model : acc= 65.00%\n",
            "[NEW data] metrics for 139-th model : acc= 68.67%\n",
            "[NEW data] metrics for 140-th model : acc= 67.33%\n",
            "[NEW data] metrics for 141-th model : acc= 69.67%\n",
            "[NEW data] metrics for 142-th model : acc= 62.00%\n",
            "[NEW data] metrics for 143-th model : acc= 66.00%\n",
            "[NEW data] metrics for 144-th model : acc= 59.67%\n",
            "[NEW data] metrics for 145-th model : acc= 62.00%\n",
            "[NEW data] metrics for 146-th model : acc= 69.33%\n",
            "[NEW data] metrics for 147-th model : acc= 66.67%\n",
            "[NEW data] metrics for 148-th model : acc= 65.33%\n",
            "[NEW data] metrics for 149-th model : acc= 65.33%\n",
            "[NEW data] metrics for 150-th model : acc= 63.67%\n",
            "[NEW data] metrics for 151-th model : acc= 65.00%\n",
            "[NEW data] metrics for 152-th model : acc= 68.33%\n",
            "[NEW data] metrics for 153-th model : acc= 66.00%\n",
            "[NEW data] metrics for 154-th model : acc= 63.33%\n",
            "[NEW data] metrics for 155-th model : acc= 66.33%\n",
            "[NEW data] metrics for 156-th model : acc= 66.33%\n",
            "[NEW data] metrics for 157-th model : acc= 64.00%\n",
            "[NEW data] metrics for 158-th model : acc= 65.33%\n",
            "[NEW data] metrics for 159-th model : acc= 67.00%\n",
            "[NEW data] metrics for 160-th model : acc= 68.00%\n",
            "[NEW data] metrics for 161-th model : acc= 68.33%\n",
            "[NEW data] metrics for 162-th model : acc= 67.67%\n",
            "[NEW data] metrics for 163-th model : acc= 64.33%\n",
            "[NEW data] metrics for 164-th model : acc= 65.67%\n",
            "[NEW data] metrics for 165-th model : acc= 61.33%\n",
            "[NEW data] metrics for 166-th model : acc= 67.67%\n",
            "[NEW data] metrics for 167-th model : acc= 67.33%\n",
            "[NEW data] metrics for 168-th model : acc= 57.33%\n",
            "[NEW data] metrics for 169-th model : acc= 64.67%\n",
            "[NEW data] metrics for 170-th model : acc= 47.67%\n",
            "[NEW data] metrics for 171-th model : acc= 63.33%\n",
            "[NEW data] metrics for 172-th model : acc= 68.00%\n",
            "[NEW data] metrics for 173-th model : acc= 67.33%\n",
            "[NEW data] metrics for 174-th model : acc= 67.67%\n",
            "[NEW data] metrics for 175-th model : acc= 68.33%\n",
            "[NEW data] metrics for 176-th model : acc= 66.67%\n",
            "[NEW data] metrics for 177-th model : acc= 62.67%\n",
            "[NEW data] metrics for 178-th model : acc= 69.00%\n",
            "[NEW data] metrics for 179-th model : acc= 66.33%\n",
            "[NEW data] metrics for 180-th model : acc= 69.00%\n",
            "[NEW data] metrics for 181-th model : acc= 65.67%\n",
            "[NEW data] metrics for 182-th model : acc= 65.00%\n",
            "[NEW data] metrics for 183-th model : acc= 66.00%\n",
            "[NEW data] metrics for 184-th model : acc= 64.33%\n",
            "[NEW data] metrics for 185-th model : acc= 63.33%\n",
            "[NEW data] metrics for 186-th model : acc= 67.00%\n",
            "[NEW data] metrics for 187-th model : acc= 54.67%\n",
            "[NEW data] metrics for 188-th model : acc= 67.00%\n",
            "[NEW data] metrics for 189-th model : acc= 67.33%\n",
            "[NEW data] metrics for 190-th model : acc= 47.67%\n",
            "[NEW data] metrics for 191-th model : acc= 70.00%\n",
            "[NEW data] metrics for 192-th model : acc= 64.67%\n",
            "[NEW data] metrics for 193-th model : acc= 69.00%\n",
            "[NEW data] metrics for 194-th model : acc= 47.67%\n",
            "[NEW data] metrics for 195-th model : acc= 65.00%\n",
            "[NEW data] metrics for 196-th model : acc= 63.00%\n",
            "[NEW data] metrics for 197-th model : acc= 67.33%\n",
            "[NEW data] metrics for 198-th model : acc= 64.33%\n",
            "[NEW data] metrics for 199-th model : acc= 68.00%\n",
            "[NEW data] metrics for 200-th model : acc= 64.33%\n",
            "[NEW data] metrics for 201-th model : acc= 58.00%\n",
            "[NEW data] metrics for 202-th model : acc= 68.00%\n",
            "[NEW data] metrics for 203-th model : acc= 66.00%\n",
            "[NEW data] metrics for 204-th model : acc= 60.00%\n",
            "[NEW data] metrics for 205-th model : acc= 67.33%\n",
            "[NEW data] metrics for 206-th model : acc= 65.33%\n",
            "[NEW data] metrics for 207-th model : acc= 67.67%\n",
            "[NEW data] metrics for 208-th model : acc= 65.33%\n",
            "[NEW data] metrics for 209-th model : acc= 68.33%\n",
            "[NEW data] metrics for 210-th model : acc= 66.00%\n",
            "[NEW data] metrics for 211-th model : acc= 65.67%\n",
            "[NEW data] metrics for 212-th model : acc= 47.67%\n",
            "[NEW data] metrics for 213-th model : acc= 60.67%\n",
            "[NEW data] metrics for 214-th model : acc= 66.00%\n",
            "[NEW data] metrics for 215-th model : acc= 68.67%\n",
            "[NEW data] metrics for 216-th model : acc= 68.00%\n",
            "[NEW data] metrics for 217-th model : acc= 66.67%\n",
            "[NEW data] metrics for 218-th model : acc= 66.00%\n",
            "[NEW data] metrics for 219-th model : acc= 67.67%\n",
            "[NEW data] metrics for 220-th model : acc= 68.00%\n",
            "[NEW data] metrics for 221-th model : acc= 64.67%\n",
            "[NEW data] metrics for 222-th model : acc= 66.33%\n",
            "[NEW data] metrics for 223-th model : acc= 64.33%\n",
            "[NEW data] metrics for 224-th model : acc= 47.67%\n",
            "[NEW data] metrics for 225-th model : acc= 67.00%\n",
            "[NEW data] metrics for 226-th model : acc= 66.67%\n",
            "[NEW data] metrics for 227-th model : acc= 68.00%\n",
            "[NEW data] metrics for 228-th model : acc= 63.67%\n",
            "[NEW data] metrics for 229-th model : acc= 67.33%\n",
            "[NEW data] metrics for 230-th model : acc= 67.33%\n",
            "[NEW data] metrics for 231-th model : acc= 66.33%\n",
            "[NEW data] metrics for 232-th model : acc= 65.67%\n",
            "[NEW data] metrics for 233-th model : acc= 66.67%\n",
            "[NEW data] metrics for 234-th model : acc= 68.00%\n",
            "[NEW data] metrics for 235-th model : acc= 67.33%\n",
            "[NEW data] metrics for 236-th model : acc= 62.67%\n",
            "[NEW data] metrics for 237-th model : acc= 65.33%\n",
            "[NEW data] metrics for 238-th model : acc= 66.33%\n",
            "[NEW data] metrics for 239-th model : acc= 64.33%\n",
            "[NEW data] metrics for 240-th model : acc= 67.00%\n",
            "[NEW data] metrics for 241-th model : acc= 64.33%\n",
            "[NEW data] metrics for 242-th model : acc= 64.67%\n",
            "[NEW data] metrics for 243-th model : acc= 68.00%\n",
            "[NEW data] metrics for 244-th model : acc= 65.00%\n",
            "[NEW data] metrics for 245-th model : acc= 67.00%\n",
            "[NEW data] metrics for 246-th model : acc= 53.67%\n",
            "[NEW data] metrics for 247-th model : acc= 65.00%\n",
            "[NEW data] metrics for 248-th model : acc= 47.67%\n",
            "[NEW data] metrics for 249-th model : acc= 47.67%\n",
            "[NEW data] metrics for 250-th model : acc= 67.67%\n",
            "[NEW data] metrics for 251-th model : acc= 62.33%\n",
            "[NEW data] metrics for 252-th model : acc= 52.33%\n",
            "[NEW data] metrics for 253-th model : acc= 66.33%\n",
            "[NEW data] metrics for 254-th model : acc= 68.00%\n",
            "[NEW data] metrics for 255-th model : acc= 67.67%\n",
            "[NEW data] metrics for 256-th model : acc= 47.67%\n",
            "[NEW data] metrics for 257-th model : acc= 67.33%\n",
            "[NEW data] metrics for 258-th model : acc= 66.00%\n",
            "[NEW data] metrics for 259-th model : acc= 67.00%\n",
            "[NEW data] metrics for 260-th model : acc= 63.67%\n",
            "[NEW data] metrics for 261-th model : acc= 64.67%\n",
            "[NEW data] metrics for 262-th model : acc= 67.67%\n",
            "[NEW data] metrics for 263-th model : acc= 68.33%\n",
            "[NEW data] metrics for 264-th model : acc= 64.33%\n",
            "[NEW data] metrics for 265-th model : acc= 47.67%\n",
            "[NEW data] metrics for 266-th model : acc= 64.67%\n",
            "[NEW data] metrics for 267-th model : acc= 65.67%\n",
            "[NEW data] metrics for 268-th model : acc= 62.33%\n",
            "[NEW data] metrics for 269-th model : acc= 68.00%\n",
            "[NEW data] metrics for 270-th model : acc= 67.00%\n",
            "[NEW data] metrics for 271-th model : acc= 64.33%\n",
            "[NEW data] metrics for 272-th model : acc= 64.33%\n",
            "[NEW data] metrics for 273-th model : acc= 68.33%\n",
            "[NEW data] metrics for 274-th model : acc= 56.33%\n",
            "[NEW data] metrics for 275-th model : acc= 67.67%\n",
            "[NEW data] metrics for 276-th model : acc= 59.67%\n",
            "[NEW data] metrics for 277-th model : acc= 69.00%\n",
            "[NEW data] metrics for 278-th model : acc= 65.33%\n",
            "[NEW data] metrics for 279-th model : acc= 68.33%\n",
            "[NEW data] metrics for 280-th model : acc= 67.33%\n",
            "[NEW data] metrics for 281-th model : acc= 68.67%\n",
            "[NEW data] metrics for 282-th model : acc= 66.00%\n",
            "[NEW data] metrics for 283-th model : acc= 64.00%\n",
            "[NEW data] metrics for 284-th model : acc= 67.67%\n",
            "[NEW data] metrics for 285-th model : acc= 67.67%\n",
            "[NEW data] metrics for 286-th model : acc= 66.67%\n",
            "[NEW data] metrics for 287-th model : acc= 66.67%\n",
            "[NEW data] metrics for 288-th model : acc= 67.67%\n",
            "[NEW data] metrics for 289-th model : acc= 67.33%\n",
            "[NEW data] metrics for 290-th model : acc= 69.00%\n",
            "[NEW data] metrics for 291-th model : acc= 65.00%\n",
            "[NEW data] metrics for 292-th model : acc= 67.67%\n",
            "[NEW data] metrics for 293-th model : acc= 67.33%\n",
            "[NEW data] metrics for 294-th model : acc= 69.00%\n",
            "[NEW data] metrics for 295-th model : acc= 65.33%\n",
            "[NEW data] metrics for 296-th model : acc= 68.67%\n",
            "[NEW data] metrics for 297-th model : acc= 63.33%\n",
            "[NEW data] metrics for 298-th model : acc= 67.67%\n",
            "[NEW data] metrics for 299-th model : acc= 68.00%\n",
            "[NEW data] metrics for 300-th model : acc= 62.00%\n",
            "[NEW data] metrics for 301-th model : acc= 65.33%\n",
            "[NEW data] metrics for 302-th model : acc= 69.67%\n",
            "[NEW data] metrics for 303-th model : acc= 67.67%\n",
            "[NEW data] metrics for 304-th model : acc= 47.67%\n",
            "[NEW data] metrics for 305-th model : acc= 68.00%\n",
            "[NEW data] metrics for 306-th model : acc= 47.67%\n",
            "[NEW data] metrics for 307-th model : acc= 66.67%\n",
            "[NEW data] metrics for 308-th model : acc= 68.33%\n",
            "[NEW data] metrics for 309-th model : acc= 68.33%\n",
            "[NEW data] metrics for 310-th model : acc= 66.33%\n",
            "[NEW data] metrics for 311-th model : acc= 62.00%\n",
            "[NEW data] metrics for 312-th model : acc= 67.67%\n",
            "[NEW data] metrics for 313-th model : acc= 64.67%\n",
            "[NEW data] metrics for 314-th model : acc= 68.33%\n",
            "[NEW data] metrics for 315-th model : acc= 54.33%\n",
            "[NEW data] metrics for 316-th model : acc= 67.00%\n",
            "[NEW data] metrics for 317-th model : acc= 63.67%\n",
            "[NEW data] metrics for 318-th model : acc= 66.33%\n",
            "[NEW data] metrics for 319-th model : acc= 69.33%\n",
            "[NEW data] metrics for 320-th model : acc= 69.67%\n",
            "[NEW data] metrics for 321-th model : acc= 65.67%\n",
            "[NEW data] metrics for 322-th model : acc= 65.33%\n",
            "[NEW data] metrics for 323-th model : acc= 65.67%\n",
            "[NEW data] metrics for 324-th model : acc= 68.67%\n",
            "[NEW data] metrics for 325-th model : acc= 66.67%\n",
            "[NEW data] metrics for 326-th model : acc= 64.67%\n",
            "[NEW data] metrics for 327-th model : acc= 66.67%\n",
            "[NEW data] metrics for 328-th model : acc= 61.67%\n",
            "[NEW data] metrics for 329-th model : acc= 67.33%\n",
            "[NEW data] metrics for 330-th model : acc= 62.33%\n",
            "[NEW data] metrics for 331-th model : acc= 65.33%\n",
            "[NEW data] metrics for 332-th model : acc= 65.33%\n",
            "[NEW data] metrics for 333-th model : acc= 65.67%\n",
            "[NEW data] metrics for 334-th model : acc= 65.00%\n",
            "[NEW data] metrics for 335-th model : acc= 67.00%\n",
            "[NEW data] metrics for 336-th model : acc= 66.00%\n",
            "[NEW data] metrics for 337-th model : acc= 63.33%\n",
            "[NEW data] metrics for 338-th model : acc= 66.33%\n",
            "[NEW data] metrics for 339-th model : acc= 68.00%\n",
            "[NEW data] metrics for 340-th model : acc= 65.00%\n",
            "[NEW data] metrics for 341-th model : acc= 66.33%\n",
            "[NEW data] metrics for 342-th model : acc= 68.33%\n",
            "[NEW data] metrics for 343-th model : acc= 66.33%\n",
            "[NEW data] metrics for 344-th model : acc= 63.33%\n",
            "[NEW data] metrics for 345-th model : acc= 67.00%\n",
            "[NEW data] metrics for 346-th model : acc= 64.33%\n",
            "[NEW data] metrics for 347-th model : acc= 67.00%\n",
            "[NEW data] metrics for 348-th model : acc= 68.33%\n",
            "[NEW data] metrics for 349-th model : acc= 66.00%\n",
            "[NEW data] metrics for 350-th model : acc= 65.33%\n",
            "[NEW data] metrics for 351-th model : acc= 67.00%\n",
            "[NEW data] metrics for 352-th model : acc= 69.00%\n",
            "[NEW data] metrics for 353-th model : acc= 65.67%\n",
            "[NEW data] metrics for 354-th model : acc= 67.67%\n",
            "[NEW data] metrics for 355-th model : acc= 67.67%\n",
            "[NEW data] metrics for 356-th model : acc= 68.00%\n",
            "[NEW data] metrics for 357-th model : acc= 64.33%\n",
            "[NEW data] metrics for 358-th model : acc= 67.00%\n",
            "[NEW data] metrics for 359-th model : acc= 47.67%\n",
            "[NEW data] metrics for 360-th model : acc= 68.00%\n",
            "[NEW data] metrics for 361-th model : acc= 65.67%\n",
            "[NEW data] metrics for 362-th model : acc= 66.67%\n",
            "[NEW data] metrics for 363-th model : acc= 47.67%\n",
            "[NEW data] metrics for 364-th model : acc= 53.00%\n",
            "[NEW data] metrics for 365-th model : acc= 67.33%\n",
            "[NEW data] metrics for 366-th model : acc= 66.00%\n",
            "[NEW data] metrics for 367-th model : acc= 64.33%\n",
            "[NEW data] metrics for 368-th model : acc= 66.33%\n",
            "[NEW data] metrics for 369-th model : acc= 64.00%\n",
            "[NEW data] metrics for 370-th model : acc= 64.33%\n",
            "[NEW data] metrics for 371-th model : acc= 67.67%\n",
            "[NEW data] metrics for 372-th model : acc= 59.33%\n",
            "[NEW data] metrics for 373-th model : acc= 65.00%\n",
            "[NEW data] metrics for 374-th model : acc= 69.00%\n",
            "[NEW data] metrics for 375-th model : acc= 68.67%\n",
            "[NEW data] metrics for 376-th model : acc= 66.33%\n",
            "[NEW data] metrics for 377-th model : acc= 65.33%\n",
            "[NEW data] metrics for 378-th model : acc= 65.67%\n",
            "[NEW data] metrics for 379-th model : acc= 56.33%\n",
            "[NEW data] metrics for 380-th model : acc= 67.33%\n",
            "[NEW data] metrics for 381-th model : acc= 67.67%\n",
            "[NEW data] metrics for 382-th model : acc= 68.33%\n",
            "[NEW data] metrics for 383-th model : acc= 59.33%\n",
            "[NEW data] metrics for 384-th model : acc= 65.33%\n",
            "[NEW data] metrics for 385-th model : acc= 66.33%\n",
            "[NEW data] metrics for 386-th model : acc= 68.00%\n",
            "[NEW data] metrics for 387-th model : acc= 67.00%\n",
            "[NEW data] metrics for 388-th model : acc= 65.00%\n",
            "[NEW data] metrics for 389-th model : acc= 68.00%\n",
            "[NEW data] metrics for 390-th model : acc= 68.33%\n",
            "[NEW data] metrics for 391-th model : acc= 65.00%\n",
            "[NEW data] metrics for 392-th model : acc= 66.00%\n",
            "[NEW data] metrics for 393-th model : acc= 67.00%\n",
            "[NEW data] metrics for 394-th model : acc= 65.00%\n",
            "[NEW data] metrics for 395-th model : acc= 47.67%\n",
            "[NEW data] metrics for 396-th model : acc= 67.67%\n",
            "[NEW data] metrics for 397-th model : acc= 47.67%\n",
            "[NEW data] metrics for 398-th model : acc= 67.00%\n",
            "[NEW data] metrics for 399-th model : acc= 68.00%\n",
            "[NEW data] metrics for 400-th model : acc= 62.67%\n",
            "[NEW data] metrics for 401-th model : acc= 62.67%\n",
            "[NEW data] metrics for 402-th model : acc= 67.33%\n",
            "[NEW data] metrics for 403-th model : acc= 68.67%\n",
            "[NEW data] metrics for 404-th model : acc= 64.33%\n",
            "[NEW data] metrics for 405-th model : acc= 65.67%\n",
            "[NEW data] metrics for 406-th model : acc= 64.67%\n",
            "[NEW data] metrics for 407-th model : acc= 63.00%\n",
            "[NEW data] metrics for 408-th model : acc= 65.33%\n",
            "[NEW data] metrics for 409-th model : acc= 67.00%\n",
            "[NEW data] metrics for 410-th model : acc= 66.67%\n",
            "[NEW data] metrics for 411-th model : acc= 65.67%\n",
            "[NEW data] metrics for 412-th model : acc= 66.00%\n",
            "[NEW data] metrics for 413-th model : acc= 66.67%\n",
            "[NEW data] metrics for 414-th model : acc= 64.67%\n",
            "[NEW data] metrics for 415-th model : acc= 66.67%\n",
            "[NEW data] metrics for 416-th model : acc= 64.67%\n",
            "[NEW data] metrics for 417-th model : acc= 67.67%\n",
            "[NEW data] metrics for 418-th model : acc= 65.00%\n",
            "[NEW data] metrics for 419-th model : acc= 67.67%\n",
            "[NEW data] metrics for 420-th model : acc= 67.33%\n",
            "[NEW data] metrics for 421-th model : acc= 68.33%\n",
            "[NEW data] metrics for 422-th model : acc= 67.00%\n",
            "[NEW data] metrics for 423-th model : acc= 66.33%\n",
            "[NEW data] metrics for 424-th model : acc= 66.33%\n",
            "[NEW data] metrics for 425-th model : acc= 61.67%\n",
            "[NEW data] metrics for 426-th model : acc= 65.67%\n",
            "[NEW data] metrics for 427-th model : acc= 70.33%\n",
            "[NEW data] metrics for 428-th model : acc= 68.00%\n",
            "[NEW data] metrics for 429-th model : acc= 67.67%\n",
            "[NEW data] metrics for 430-th model : acc= 66.00%\n",
            "[NEW data] metrics for 431-th model : acc= 67.00%\n",
            "[NEW data] metrics for 432-th model : acc= 66.67%\n",
            "[NEW data] metrics for 433-th model : acc= 42.67%\n",
            "[NEW data] metrics for 434-th model : acc= 65.00%\n",
            "[NEW data] metrics for 435-th model : acc= 67.67%\n",
            "[NEW data] metrics for 436-th model : acc= 68.00%\n",
            "[NEW data] metrics for 437-th model : acc= 69.33%\n",
            "[NEW data] metrics for 438-th model : acc= 69.00%\n",
            "[NEW data] metrics for 439-th model : acc= 47.67%\n",
            "[NEW data] metrics for 440-th model : acc= 67.00%\n",
            "[NEW data] metrics for 441-th model : acc= 66.33%\n",
            "[NEW data] metrics for 442-th model : acc= 67.67%\n",
            "[NEW data] metrics for 443-th model : acc= 67.00%\n",
            "[NEW data] metrics for 444-th model : acc= 65.67%\n",
            "[NEW data] metrics for 445-th model : acc= 64.67%\n",
            "[NEW data] metrics for 446-th model : acc= 64.67%\n",
            "[NEW data] metrics for 447-th model : acc= 64.33%\n",
            "[NEW data] metrics for 448-th model : acc= 66.67%\n",
            "[NEW data] metrics for 449-th model : acc= 67.33%\n",
            "[NEW data] metrics for 450-th model : acc= 66.33%\n",
            "[NEW data] metrics for 451-th model : acc= 69.33%\n",
            "[NEW data] metrics for 452-th model : acc= 65.33%\n",
            "[NEW data] metrics for 453-th model : acc= 65.67%\n",
            "[NEW data] metrics for 454-th model : acc= 67.33%\n",
            "[NEW data] metrics for 455-th model : acc= 66.67%\n",
            "[NEW data] metrics for 456-th model : acc= 65.00%\n",
            "[NEW data] metrics for 457-th model : acc= 68.00%\n",
            "[NEW data] metrics for 458-th model : acc= 69.67%\n",
            "[NEW data] metrics for 459-th model : acc= 68.00%\n",
            "[NEW data] metrics for 460-th model : acc= 67.33%\n",
            "[NEW data] metrics for 461-th model : acc= 67.67%\n",
            "[NEW data] metrics for 462-th model : acc= 65.00%\n",
            "[NEW data] metrics for 463-th model : acc= 65.67%\n",
            "[NEW data] metrics for 464-th model : acc= 64.00%\n",
            "[NEW data] metrics for 465-th model : acc= 47.67%\n",
            "[NEW data] metrics for 466-th model : acc= 70.67%\n",
            "[NEW data] metrics for 467-th model : acc= 69.00%\n",
            "[NEW data] metrics for 468-th model : acc= 67.00%\n",
            "[NEW data] metrics for 469-th model : acc= 66.00%\n",
            "[NEW data] metrics for 470-th model : acc= 63.67%\n",
            "[NEW data] metrics for 471-th model : acc= 66.00%\n",
            "[NEW data] metrics for 472-th model : acc= 68.00%\n",
            "[NEW data] metrics for 473-th model : acc= 66.00%\n",
            "[NEW data] metrics for 474-th model : acc= 64.33%\n",
            "[NEW data] metrics for 475-th model : acc= 47.67%\n",
            "[NEW data] metrics for 476-th model : acc= 70.00%\n",
            "[NEW data] metrics for 477-th model : acc= 68.33%\n",
            "[NEW data] metrics for 478-th model : acc= 68.33%\n",
            "[NEW data] metrics for 479-th model : acc= 47.00%\n",
            "[NEW data] metrics for 480-th model : acc= 68.00%\n",
            "[NEW data] metrics for 481-th model : acc= 65.67%\n",
            "[NEW data] metrics for 482-th model : acc= 65.67%\n",
            "[NEW data] metrics for 483-th model : acc= 65.67%\n",
            "[NEW data] metrics for 484-th model : acc= 65.67%\n",
            "[NEW data] metrics for 485-th model : acc= 67.33%\n",
            "[NEW data] metrics for 486-th model : acc= 64.67%\n",
            "[NEW data] metrics for 487-th model : acc= 67.00%\n",
            "[NEW data] metrics for 488-th model : acc= 64.33%\n",
            "[NEW data] metrics for 489-th model : acc= 65.67%\n",
            "[NEW data] metrics for 490-th model : acc= 63.33%\n",
            "[NEW data] metrics for 491-th model : acc= 67.00%\n",
            "[NEW data] metrics for 492-th model : acc= 66.00%\n",
            "[NEW data] metrics for 493-th model : acc= 67.67%\n",
            "[NEW data] metrics for 494-th model : acc= 66.67%\n",
            "[NEW data] metrics for 495-th model : acc= 69.67%\n",
            "[NEW data] metrics for 496-th model : acc= 68.33%\n",
            "[NEW data] metrics for 497-th model : acc= 67.00%\n",
            "[NEW data] metrics for 498-th model : acc= 67.33%\n",
            "[NEW data] metrics for 499-th model : acc= 66.00%\n",
            "[NEW data] metrics for 500-th model : acc= 66.67%\n",
            "[NEW data] metrics for 501-th model : acc= 67.33%\n",
            "[NEW data] metrics for 502-th model : acc= 67.00%\n",
            "[NEW data] metrics for 503-th model : acc= 47.67%\n",
            "[NEW data] metrics for 504-th model : acc= 65.33%\n",
            "[NEW data] metrics for 505-th model : acc= 64.67%\n",
            "[NEW data] metrics for 506-th model : acc= 68.33%\n",
            "[NEW data] metrics for 507-th model : acc= 51.33%\n",
            "[NEW data] metrics for 508-th model : acc= 60.67%\n",
            "[NEW data] metrics for 509-th model : acc= 65.00%\n",
            "[NEW data] metrics for 510-th model : acc= 66.67%\n",
            "[NEW data] metrics for 511-th model : acc= 66.00%\n",
            "[NEW data] metrics for 512-th model : acc= 67.33%\n",
            "[NEW data] metrics for 513-th model : acc= 65.33%\n",
            "[NEW data] metrics for 514-th model : acc= 65.33%\n",
            "[NEW data] metrics for 515-th model : acc= 66.67%\n",
            "[NEW data] metrics for 516-th model : acc= 67.67%\n",
            "[NEW data] metrics for 517-th model : acc= 60.00%\n",
            "[NEW data] metrics for 518-th model : acc= 67.00%\n",
            "[NEW data] metrics for 519-th model : acc= 66.33%\n",
            "[NEW data] metrics for 520-th model : acc= 65.67%\n",
            "[NEW data] metrics for 521-th model : acc= 67.33%\n",
            "[NEW data] metrics for 522-th model : acc= 47.67%\n",
            "[NEW data] metrics for 523-th model : acc= 67.67%\n",
            "[NEW data] metrics for 524-th model : acc= 56.00%\n",
            "[NEW data] metrics for 525-th model : acc= 65.00%\n",
            "[NEW data] metrics for 526-th model : acc= 65.00%\n",
            "[NEW data] metrics for 527-th model : acc= 65.00%\n",
            "[NEW data] metrics for 528-th model : acc= 68.33%\n",
            "[NEW data] metrics for 529-th model : acc= 68.67%\n",
            "[NEW data] metrics for 530-th model : acc= 47.67%\n",
            "[NEW data] metrics for 531-th model : acc= 67.67%\n",
            "[NEW data] metrics for 532-th model : acc= 68.67%\n",
            "[NEW data] metrics for 533-th model : acc= 67.67%\n",
            "[NEW data] metrics for 534-th model : acc= 66.67%\n",
            "[NEW data] metrics for 535-th model : acc= 67.33%\n",
            "[NEW data] metrics for 536-th model : acc= 68.00%\n",
            "[NEW data] metrics for 537-th model : acc= 66.33%\n",
            "[NEW data] metrics for 538-th model : acc= 47.67%\n",
            "[NEW data] metrics for 539-th model : acc= 68.00%\n",
            "[NEW data] metrics for 540-th model : acc= 66.33%\n",
            "[NEW data] metrics for 541-th model : acc= 51.33%\n",
            "[NEW data] metrics for 542-th model : acc= 65.00%\n",
            "[NEW data] metrics for 543-th model : acc= 65.67%\n",
            "[NEW data] metrics for 544-th model : acc= 67.33%\n",
            "[NEW data] metrics for 545-th model : acc= 67.00%\n",
            "[NEW data] metrics for 546-th model : acc= 63.33%\n",
            "[NEW data] metrics for 547-th model : acc= 64.67%\n",
            "[NEW data] metrics for 548-th model : acc= 69.33%\n",
            "[NEW data] metrics for 549-th model : acc= 67.00%\n",
            "[NEW data] metrics for 550-th model : acc= 65.00%\n",
            "[NEW data] metrics for 551-th model : acc= 68.67%\n",
            "[NEW data] metrics for 552-th model : acc= 66.00%\n",
            "[NEW data] metrics for 553-th model : acc= 68.00%\n",
            "[NEW data] metrics for 554-th model : acc= 64.67%\n",
            "[NEW data] metrics for 555-th model : acc= 67.00%\n",
            "[NEW data] metrics for 556-th model : acc= 47.67%\n",
            "[NEW data] metrics for 557-th model : acc= 67.33%\n",
            "[NEW data] metrics for 558-th model : acc= 66.33%\n",
            "[NEW data] metrics for 559-th model : acc= 64.00%\n",
            "[NEW data] metrics for 560-th model : acc= 68.67%\n",
            "[NEW data] metrics for 561-th model : acc= 71.33%\n",
            "[NEW data] metrics for 562-th model : acc= 67.67%\n",
            "[NEW data] metrics for 563-th model : acc= 67.33%\n",
            "[NEW data] metrics for 564-th model : acc= 68.00%\n",
            "[NEW data] metrics for 565-th model : acc= 66.67%\n",
            "[NEW data] metrics for 566-th model : acc= 67.33%\n",
            "[NEW data] metrics for 567-th model : acc= 68.67%\n",
            "[NEW data] metrics for 568-th model : acc= 47.67%\n",
            "[NEW data] metrics for 569-th model : acc= 67.33%\n",
            "[NEW data] metrics for 570-th model : acc= 67.00%\n",
            "[NEW data] metrics for 571-th model : acc= 65.00%\n",
            "[NEW data] metrics for 572-th model : acc= 61.00%\n",
            "[NEW data] metrics for 573-th model : acc= 65.67%\n",
            "[NEW data] metrics for 574-th model : acc= 68.33%\n",
            "[NEW data] metrics for 575-th model : acc= 65.67%\n",
            "[NEW data] metrics for 576-th model : acc= 66.67%\n",
            "[NEW data] metrics for 577-th model : acc= 65.67%\n",
            "[NEW data] metrics for 578-th model : acc= 66.67%\n",
            "[NEW data] metrics for 579-th model : acc= 68.00%\n",
            "[NEW data] metrics for 580-th model : acc= 65.33%\n",
            "[NEW data] metrics for 581-th model : acc= 65.67%\n",
            "[NEW data] metrics for 582-th model : acc= 69.00%\n",
            "[NEW data] metrics for 583-th model : acc= 68.33%\n",
            "[NEW data] metrics for 584-th model : acc= 66.33%\n",
            "[NEW data] metrics for 585-th model : acc= 67.67%\n",
            "[NEW data] metrics for 586-th model : acc= 68.00%\n",
            "[NEW data] metrics for 587-th model : acc= 67.33%\n",
            "[NEW data] metrics for 588-th model : acc= 66.33%\n",
            "[NEW data] metrics for 589-th model : acc= 68.00%\n",
            "[NEW data] metrics for 590-th model : acc= 67.67%\n",
            "[NEW data] metrics for 591-th model : acc= 66.67%\n",
            "[NEW data] metrics for 592-th model : acc= 67.33%\n",
            "[NEW data] metrics for 593-th model : acc= 67.33%\n",
            "[NEW data] metrics for 594-th model : acc= 65.67%\n",
            "[NEW data] metrics for 595-th model : acc= 65.00%\n",
            "[NEW data] metrics for 596-th model : acc= 67.33%\n",
            "[NEW data] metrics for 597-th model : acc= 68.33%\n",
            "[NEW data] metrics for 598-th model : acc= 65.00%\n",
            "[NEW data] metrics for 599-th model : acc= 68.33%\n",
            "[NEW data] metrics for 600-th model : acc= 67.33%\n",
            "[NEW data] metrics for 601-th model : acc= 69.00%\n",
            "[NEW data] metrics for 602-th model : acc= 66.33%\n",
            "[NEW data] metrics for 603-th model : acc= 64.00%\n",
            "[NEW data] metrics for 604-th model : acc= 67.33%\n",
            "[NEW data] metrics for 605-th model : acc= 65.33%\n",
            "[NEW data] metrics for 606-th model : acc= 68.67%\n",
            "[NEW data] metrics for 607-th model : acc= 67.00%\n",
            "[NEW data] metrics for 608-th model : acc= 68.33%\n",
            "[NEW data] metrics for 609-th model : acc= 67.33%\n",
            "[NEW data] metrics for 610-th model : acc= 67.00%\n",
            "[NEW data] metrics for 611-th model : acc= 65.67%\n",
            "[NEW data] metrics for 612-th model : acc= 67.33%\n",
            "[NEW data] metrics for 613-th model : acc= 68.00%\n",
            "[NEW data] metrics for 614-th model : acc= 64.67%\n",
            "[NEW data] metrics for 615-th model : acc= 62.67%\n",
            "[NEW data] metrics for 616-th model : acc= 61.00%\n",
            "[NEW data] metrics for 617-th model : acc= 63.67%\n",
            "[NEW data] metrics for 618-th model : acc= 62.67%\n",
            "[NEW data] metrics for 619-th model : acc= 65.33%\n",
            "[NEW data] metrics for 620-th model : acc= 67.33%\n",
            "[NEW data] metrics for 621-th model : acc= 65.33%\n",
            "[NEW data] metrics for 622-th model : acc= 66.67%\n",
            "[NEW data] metrics for 623-th model : acc= 64.00%\n",
            "[NEW data] metrics for 624-th model : acc= 66.67%\n",
            "[NEW data] metrics for 625-th model : acc= 69.00%\n",
            "[NEW data] metrics for 626-th model : acc= 66.33%\n",
            "[NEW data] metrics for 627-th model : acc= 64.00%\n",
            "[NEW data] metrics for 628-th model : acc= 67.00%\n",
            "[NEW data] metrics for 629-th model : acc= 64.33%\n",
            "[NEW data] metrics for 630-th model : acc= 63.00%\n",
            "[NEW data] metrics for 631-th model : acc= 65.33%\n",
            "[NEW data] metrics for 632-th model : acc= 68.33%\n",
            "[NEW data] metrics for 633-th model : acc= 60.33%\n",
            "[NEW data] metrics for 634-th model : acc= 66.67%\n",
            "[NEW data] metrics for 635-th model : acc= 64.00%\n",
            "[NEW data] metrics for 636-th model : acc= 68.67%\n",
            "[NEW data] metrics for 637-th model : acc= 66.00%\n",
            "[NEW data] metrics for 638-th model : acc= 66.67%\n",
            "[NEW data] metrics for 639-th model : acc= 65.67%\n",
            "[NEW data] metrics for 640-th model : acc= 65.33%\n",
            "[NEW data] metrics for 641-th model : acc= 66.67%\n",
            "[NEW data] metrics for 642-th model : acc= 64.67%\n",
            "[NEW data] metrics for 643-th model : acc= 65.67%\n",
            "[NEW data] metrics for 644-th model : acc= 64.33%\n",
            "[NEW data] metrics for 645-th model : acc= 70.33%\n",
            "[NEW data] metrics for 646-th model : acc= 69.33%\n",
            "[NEW data] metrics for 647-th model : acc= 65.00%\n",
            "[NEW data] metrics for 648-th model : acc= 64.00%\n",
            "[NEW data] metrics for 649-th model : acc= 67.67%\n",
            "[NEW data] metrics for 650-th model : acc= 69.00%\n",
            "[NEW data] metrics for 651-th model : acc= 69.33%\n",
            "[NEW data] metrics for 652-th model : acc= 67.33%\n",
            "[NEW data] metrics for 653-th model : acc= 62.67%\n",
            "[NEW data] metrics for 654-th model : acc= 68.67%\n",
            "[NEW data] metrics for 655-th model : acc= 66.00%\n",
            "[NEW data] metrics for 656-th model : acc= 67.00%\n",
            "[NEW data] metrics for 657-th model : acc= 65.67%\n",
            "[NEW data] metrics for 658-th model : acc= 67.00%\n",
            "[NEW data] metrics for 659-th model : acc= 48.00%\n",
            "[NEW data] metrics for 660-th model : acc= 69.00%\n",
            "[NEW data] metrics for 661-th model : acc= 68.33%\n",
            "[NEW data] metrics for 662-th model : acc= 70.00%\n",
            "[NEW data] metrics for 663-th model : acc= 65.33%\n",
            "[NEW data] metrics for 664-th model : acc= 66.67%\n",
            "[NEW data] metrics for 665-th model : acc= 68.00%\n",
            "[NEW data] metrics for 666-th model : acc= 66.67%\n",
            "[NEW data] metrics for 667-th model : acc= 67.33%\n",
            "[NEW data] metrics for 668-th model : acc= 64.67%\n",
            "[NEW data] metrics for 669-th model : acc= 61.67%\n",
            "[NEW data] metrics for 670-th model : acc= 67.33%\n",
            "[NEW data] metrics for 671-th model : acc= 66.67%\n",
            "[NEW data] metrics for 672-th model : acc= 64.67%\n",
            "[NEW data] metrics for 673-th model : acc= 65.67%\n",
            "[NEW data] metrics for 674-th model : acc= 67.67%\n",
            "[NEW data] metrics for 675-th model : acc= 64.67%\n",
            "[NEW data] metrics for 676-th model : acc= 67.33%\n",
            "[NEW data] metrics for 677-th model : acc= 63.67%\n",
            "[NEW data] metrics for 678-th model : acc= 67.67%\n",
            "[NEW data] metrics for 679-th model : acc= 66.00%\n",
            "[NEW data] metrics for 680-th model : acc= 66.33%\n",
            "[NEW data] metrics for 681-th model : acc= 67.00%\n",
            "[NEW data] metrics for 682-th model : acc= 68.33%\n",
            "[NEW data] metrics for 683-th model : acc= 67.00%\n",
            "[NEW data] metrics for 684-th model : acc= 64.00%\n",
            "[NEW data] metrics for 685-th model : acc= 61.67%\n",
            "[NEW data] metrics for 686-th model : acc= 67.67%\n",
            "[NEW data] metrics for 687-th model : acc= 66.67%\n",
            "[NEW data] metrics for 688-th model : acc= 66.67%\n",
            "[NEW data] metrics for 689-th model : acc= 67.67%\n",
            "[NEW data] metrics for 690-th model : acc= 65.33%\n",
            "[NEW data] metrics for 691-th model : acc= 67.33%\n",
            "[NEW data] metrics for 692-th model : acc= 67.67%\n",
            "[NEW data] metrics for 693-th model : acc= 67.67%\n",
            "[NEW data] metrics for 694-th model : acc= 64.33%\n",
            "[NEW data] metrics for 695-th model : acc= 68.00%\n",
            "[NEW data] metrics for 696-th model : acc= 69.67%\n",
            "[NEW data] metrics for 697-th model : acc= 67.33%\n",
            "[NEW data] metrics for 698-th model : acc= 59.33%\n",
            "[NEW data] metrics for 699-th model : acc= 65.67%\n",
            "[NEW data] metrics for 700-th model : acc= 68.00%\n",
            "[NEW data] metrics for 701-th model : acc= 67.00%\n",
            "[NEW data] metrics for 702-th model : acc= 65.67%\n",
            "[NEW data] metrics for 703-th model : acc= 69.00%\n",
            "[NEW data] metrics for 704-th model : acc= 67.00%\n",
            "[NEW data] metrics for 705-th model : acc= 69.33%\n",
            "[NEW data] metrics for 706-th model : acc= 65.00%\n",
            "[NEW data] metrics for 707-th model : acc= 67.00%\n",
            "[NEW data] metrics for 708-th model : acc= 69.67%\n",
            "[NEW data] metrics for 709-th model : acc= 66.00%\n",
            "[NEW data] metrics for 710-th model : acc= 66.67%\n",
            "[NEW data] metrics for 711-th model : acc= 67.33%\n",
            "[NEW data] metrics for 712-th model : acc= 51.67%\n",
            "[NEW data] metrics for 713-th model : acc= 67.00%\n",
            "[NEW data] metrics for 714-th model : acc= 65.00%\n",
            "[NEW data] metrics for 715-th model : acc= 60.33%\n",
            "[NEW data] metrics for 716-th model : acc= 65.67%\n",
            "[NEW data] metrics for 717-th model : acc= 68.33%\n",
            "[NEW data] metrics for 718-th model : acc= 65.00%\n",
            "[NEW data] metrics for 719-th model : acc= 68.33%\n",
            "[NEW data] metrics for 720-th model : acc= 65.67%\n",
            "[NEW data] metrics for 721-th model : acc= 69.00%\n",
            "[NEW data] metrics for 722-th model : acc= 67.00%\n",
            "[NEW data] metrics for 723-th model : acc= 65.00%\n",
            "[NEW data] metrics for 724-th model : acc= 65.00%\n",
            "[NEW data] metrics for 725-th model : acc= 69.00%\n",
            "[NEW data] metrics for 726-th model : acc= 66.33%\n",
            "[NEW data] metrics for 727-th model : acc= 63.00%\n",
            "[NEW data] metrics for 728-th model : acc= 67.33%\n",
            "[NEW data] metrics for 729-th model : acc= 66.33%\n",
            "[NEW data] metrics for 730-th model : acc= 66.33%\n",
            "[NEW data] metrics for 731-th model : acc= 67.00%\n",
            "[NEW data] metrics for 732-th model : acc= 65.67%\n",
            "[NEW data] metrics for 733-th model : acc= 66.00%\n",
            "[NEW data] metrics for 734-th model : acc= 66.00%\n",
            "[NEW data] metrics for 735-th model : acc= 66.33%\n",
            "[NEW data] metrics for 736-th model : acc= 66.67%\n",
            "[NEW data] metrics for 737-th model : acc= 67.33%\n",
            "[NEW data] metrics for 738-th model : acc= 67.33%\n",
            "[NEW data] metrics for 739-th model : acc= 68.00%\n",
            "[NEW data] metrics for 740-th model : acc= 68.00%\n",
            "[NEW data] metrics for 741-th model : acc= 61.33%\n",
            "[NEW data] metrics for 742-th model : acc= 64.00%\n",
            "[NEW data] metrics for 743-th model : acc= 64.00%\n",
            "[NEW data] metrics for 744-th model : acc= 67.67%\n",
            "[NEW data] metrics for 745-th model : acc= 66.00%\n",
            "[NEW data] metrics for 746-th model : acc= 69.33%\n",
            "[NEW data] metrics for 747-th model : acc= 68.67%\n",
            "[NEW data] metrics for 748-th model : acc= 65.00%\n",
            "[NEW data] metrics for 749-th model : acc= 64.67%\n",
            "[NEW data] metrics for 750-th model : acc= 65.00%\n",
            "[NEW data] metrics for 751-th model : acc= 47.67%\n",
            "[NEW data] metrics for 752-th model : acc= 58.00%\n",
            "[NEW data] metrics for 753-th model : acc= 65.33%\n",
            "[NEW data] metrics for 754-th model : acc= 65.00%\n",
            "[NEW data] metrics for 755-th model : acc= 47.67%\n",
            "[NEW data] metrics for 756-th model : acc= 64.67%\n",
            "[NEW data] metrics for 757-th model : acc= 66.00%\n",
            "[NEW data] metrics for 758-th model : acc= 67.67%\n",
            "[NEW data] metrics for 759-th model : acc= 69.33%\n",
            "[NEW data] metrics for 760-th model : acc= 68.00%\n",
            "[NEW data] metrics for 761-th model : acc= 67.67%\n",
            "[NEW data] metrics for 762-th model : acc= 64.00%\n",
            "[NEW data] metrics for 763-th model : acc= 68.33%\n",
            "[NEW data] metrics for 764-th model : acc= 67.00%\n",
            "[NEW data] metrics for 765-th model : acc= 65.33%\n",
            "[NEW data] metrics for 766-th model : acc= 69.00%\n",
            "[NEW data] metrics for 767-th model : acc= 52.67%\n",
            "[NEW data] metrics for 768-th model : acc= 65.33%\n",
            "[NEW data] metrics for 769-th model : acc= 67.00%\n",
            "[NEW data] metrics for 770-th model : acc= 43.33%\n",
            "[NEW data] metrics for 771-th model : acc= 67.00%\n",
            "[NEW data] metrics for 772-th model : acc= 66.67%\n",
            "[NEW data] metrics for 773-th model : acc= 66.33%\n",
            "[NEW data] metrics for 774-th model : acc= 64.33%\n",
            "[NEW data] metrics for 775-th model : acc= 67.00%\n",
            "[NEW data] metrics for 776-th model : acc= 65.67%\n",
            "[NEW data] metrics for 777-th model : acc= 63.33%\n",
            "[NEW data] metrics for 778-th model : acc= 63.67%\n",
            "[NEW data] metrics for 779-th model : acc= 67.33%\n",
            "[NEW data] metrics for 780-th model : acc= 65.00%\n",
            "[NEW data] metrics for 781-th model : acc= 64.00%\n",
            "[NEW data] metrics for 782-th model : acc= 65.00%\n",
            "[NEW data] metrics for 783-th model : acc= 66.67%\n",
            "[NEW data] metrics for 784-th model : acc= 60.33%\n",
            "[NEW data] metrics for 785-th model : acc= 68.00%\n",
            "[NEW data] metrics for 786-th model : acc= 68.67%\n",
            "[NEW data] metrics for 787-th model : acc= 69.00%\n",
            "[NEW data] metrics for 788-th model : acc= 66.33%\n",
            "[NEW data] metrics for 789-th model : acc= 67.00%\n",
            "[NEW data] metrics for 790-th model : acc= 67.33%\n",
            "[NEW data] metrics for 791-th model : acc= 66.33%\n",
            "[NEW data] metrics for 792-th model : acc= 66.67%\n",
            "[NEW data] metrics for 793-th model : acc= 66.33%\n",
            "[NEW data] metrics for 794-th model : acc= 67.33%\n",
            "[NEW data] metrics for 795-th model : acc= 65.67%\n",
            "[NEW data] metrics for 796-th model : acc= 68.67%\n",
            "[NEW data] metrics for 797-th model : acc= 66.67%\n",
            "[NEW data] metrics for 798-th model : acc= 65.67%\n",
            "[NEW data] metrics for 799-th model : acc= 67.33%\n",
            "[NEW data] metrics for 800-th model : acc= 69.00%\n",
            "[NEW data] metrics for 801-th model : acc= 67.00%\n",
            "[NEW data] metrics for 802-th model : acc= 68.33%\n",
            "[NEW data] metrics for 803-th model : acc= 65.67%\n",
            "[NEW data] metrics for 804-th model : acc= 66.67%\n",
            "[NEW data] metrics for 805-th model : acc= 65.67%\n",
            "[NEW data] metrics for 806-th model : acc= 66.00%\n",
            "[NEW data] metrics for 807-th model : acc= 67.00%\n",
            "[NEW data] metrics for 808-th model : acc= 66.33%\n",
            "[NEW data] metrics for 809-th model : acc= 68.33%\n",
            "[NEW data] metrics for 810-th model : acc= 66.67%\n",
            "[NEW data] metrics for 811-th model : acc= 68.33%\n",
            "[NEW data] metrics for 812-th model : acc= 67.67%\n",
            "[NEW data] metrics for 813-th model : acc= 65.67%\n",
            "[NEW data] metrics for 814-th model : acc= 65.00%\n",
            "[NEW data] metrics for 815-th model : acc= 66.00%\n",
            "[NEW data] metrics for 816-th model : acc= 67.33%\n",
            "[NEW data] metrics for 817-th model : acc= 65.33%\n",
            "[NEW data] metrics for 818-th model : acc= 66.67%\n",
            "[NEW data] metrics for 819-th model : acc= 66.67%\n",
            "[NEW data] metrics for 820-th model : acc= 67.00%\n",
            "[NEW data] metrics for 821-th model : acc= 65.00%\n",
            "[NEW data] metrics for 822-th model : acc= 66.00%\n",
            "[NEW data] metrics for 823-th model : acc= 64.33%\n",
            "[NEW data] metrics for 824-th model : acc= 65.67%\n",
            "[NEW data] metrics for 825-th model : acc= 66.33%\n",
            "[NEW data] metrics for 826-th model : acc= 65.67%\n",
            "[NEW data] metrics for 827-th model : acc= 63.33%\n",
            "[NEW data] metrics for 828-th model : acc= 65.00%\n",
            "[NEW data] metrics for 829-th model : acc= 68.33%\n",
            "[NEW data] metrics for 830-th model : acc= 65.67%\n",
            "[NEW data] metrics for 831-th model : acc= 64.67%\n",
            "[NEW data] metrics for 832-th model : acc= 66.67%\n",
            "[NEW data] metrics for 833-th model : acc= 64.33%\n",
            "[NEW data] metrics for 834-th model : acc= 67.00%\n",
            "[NEW data] metrics for 835-th model : acc= 67.67%\n",
            "[NEW data] metrics for 836-th model : acc= 68.67%\n",
            "[NEW data] metrics for 837-th model : acc= 66.67%\n",
            "[NEW data] metrics for 838-th model : acc= 67.33%\n",
            "[NEW data] metrics for 839-th model : acc= 65.33%\n",
            "[NEW data] metrics for 840-th model : acc= 62.33%\n",
            "[NEW data] metrics for 841-th model : acc= 67.67%\n",
            "[NEW data] metrics for 842-th model : acc= 65.67%\n",
            "[NEW data] metrics for 843-th model : acc= 64.67%\n",
            "[NEW data] metrics for 844-th model : acc= 68.33%\n",
            "[NEW data] metrics for 845-th model : acc= 63.67%\n",
            "[NEW data] metrics for 846-th model : acc= 67.33%\n",
            "[NEW data] metrics for 847-th model : acc= 64.33%\n",
            "[NEW data] metrics for 848-th model : acc= 68.00%\n",
            "[NEW data] metrics for 849-th model : acc= 68.67%\n",
            "[NEW data] metrics for 850-th model : acc= 62.67%\n",
            "[NEW data] metrics for 851-th model : acc= 66.33%\n",
            "[NEW data] metrics for 852-th model : acc= 69.33%\n",
            "[NEW data] metrics for 853-th model : acc= 67.33%\n",
            "[NEW data] metrics for 854-th model : acc= 56.67%\n",
            "[NEW data] metrics for 855-th model : acc= 67.00%\n",
            "[NEW data] metrics for 856-th model : acc= 65.67%\n",
            "[NEW data] metrics for 857-th model : acc= 68.33%\n",
            "[NEW data] metrics for 858-th model : acc= 65.67%\n",
            "[NEW data] metrics for 859-th model : acc= 69.33%\n",
            "[NEW data] metrics for 860-th model : acc= 65.67%\n",
            "[NEW data] metrics for 861-th model : acc= 68.67%\n",
            "[NEW data] metrics for 862-th model : acc= 65.33%\n",
            "[NEW data] metrics for 863-th model : acc= 66.67%\n",
            "[NEW data] metrics for 864-th model : acc= 65.00%\n",
            "[NEW data] metrics for 865-th model : acc= 66.67%\n",
            "[NEW data] metrics for 866-th model : acc= 66.00%\n",
            "[NEW data] metrics for 867-th model : acc= 64.00%\n",
            "[NEW data] metrics for 868-th model : acc= 66.67%\n",
            "[NEW data] metrics for 869-th model : acc= 68.33%\n",
            "[NEW data] metrics for 870-th model : acc= 68.00%\n",
            "[NEW data] metrics for 871-th model : acc= 67.67%\n",
            "[NEW data] metrics for 872-th model : acc= 68.00%\n",
            "[NEW data] metrics for 873-th model : acc= 65.33%\n",
            "[NEW data] metrics for 874-th model : acc= 67.00%\n",
            "[NEW data] metrics for 875-th model : acc= 68.67%\n",
            "[NEW data] metrics for 876-th model : acc= 67.00%\n",
            "[NEW data] metrics for 877-th model : acc= 67.33%\n",
            "[NEW data] metrics for 878-th model : acc= 68.00%\n",
            "[NEW data] metrics for 879-th model : acc= 60.00%\n",
            "[NEW data] metrics for 880-th model : acc= 67.00%\n",
            "[NEW data] metrics for 881-th model : acc= 65.67%\n",
            "[NEW data] metrics for 882-th model : acc= 66.00%\n",
            "[NEW data] metrics for 883-th model : acc= 68.67%\n",
            "[NEW data] metrics for 884-th model : acc= 63.67%\n",
            "[NEW data] metrics for 885-th model : acc= 68.00%\n",
            "[NEW data] metrics for 886-th model : acc= 65.67%\n",
            "[NEW data] metrics for 887-th model : acc= 63.00%\n",
            "[NEW data] metrics for 888-th model : acc= 65.33%\n",
            "[NEW data] metrics for 889-th model : acc= 67.33%\n",
            "[NEW data] metrics for 890-th model : acc= 66.00%\n",
            "[NEW data] metrics for 891-th model : acc= 63.67%\n",
            "[NEW data] metrics for 892-th model : acc= 69.00%\n",
            "[NEW data] metrics for 893-th model : acc= 68.00%\n",
            "[NEW data] metrics for 894-th model : acc= 67.67%\n",
            "[NEW data] metrics for 895-th model : acc= 64.00%\n",
            "[NEW data] metrics for 896-th model : acc= 67.00%\n",
            "[NEW data] metrics for 897-th model : acc= 66.67%\n",
            "[NEW data] metrics for 898-th model : acc= 65.00%\n",
            "[NEW data] metrics for 899-th model : acc= 59.33%\n",
            "[NEW data] metrics for 900-th model : acc= 66.33%\n",
            "[NEW data] metrics for 901-th model : acc= 67.33%\n",
            "[NEW data] metrics for 902-th model : acc= 64.00%\n",
            "[NEW data] metrics for 903-th model : acc= 65.33%\n",
            "[NEW data] metrics for 904-th model : acc= 68.00%\n",
            "[NEW data] metrics for 905-th model : acc= 66.67%\n",
            "[NEW data] metrics for 906-th model : acc= 58.67%\n",
            "[NEW data] metrics for 907-th model : acc= 65.67%\n",
            "[NEW data] metrics for 908-th model : acc= 63.33%\n",
            "[NEW data] metrics for 909-th model : acc= 68.67%\n",
            "[NEW data] metrics for 910-th model : acc= 63.00%\n",
            "[NEW data] metrics for 911-th model : acc= 68.00%\n",
            "[NEW data] metrics for 912-th model : acc= 67.00%\n",
            "[NEW data] metrics for 913-th model : acc= 66.33%\n",
            "[NEW data] metrics for 914-th model : acc= 56.33%\n",
            "[NEW data] metrics for 915-th model : acc= 65.00%\n",
            "[NEW data] metrics for 916-th model : acc= 66.00%\n",
            "[NEW data] metrics for 917-th model : acc= 62.33%\n",
            "[NEW data] metrics for 918-th model : acc= 68.67%\n",
            "[NEW data] metrics for 919-th model : acc= 66.67%\n",
            "[NEW data] metrics for 920-th model : acc= 65.67%\n",
            "[NEW data] metrics for 921-th model : acc= 61.00%\n",
            "[NEW data] metrics for 922-th model : acc= 67.67%\n",
            "[NEW data] metrics for 923-th model : acc= 65.00%\n",
            "[NEW data] metrics for 924-th model : acc= 66.33%\n",
            "[NEW data] metrics for 925-th model : acc= 69.33%\n",
            "[NEW data] metrics for 926-th model : acc= 66.00%\n",
            "[NEW data] metrics for 927-th model : acc= 66.67%\n",
            "[NEW data] metrics for 928-th model : acc= 68.33%\n",
            "[NEW data] metrics for 929-th model : acc= 66.33%\n",
            "[NEW data] metrics for 930-th model : acc= 68.00%\n",
            "[NEW data] metrics for 931-th model : acc= 66.33%\n",
            "[NEW data] metrics for 932-th model : acc= 69.33%\n",
            "[NEW data] metrics for 933-th model : acc= 69.00%\n",
            "[NEW data] metrics for 934-th model : acc= 64.33%\n",
            "[NEW data] metrics for 935-th model : acc= 68.00%\n",
            "[NEW data] metrics for 936-th model : acc= 67.00%\n",
            "[NEW data] metrics for 937-th model : acc= 65.33%\n",
            "[NEW data] metrics for 938-th model : acc= 61.67%\n",
            "[NEW data] metrics for 939-th model : acc= 64.67%\n",
            "[NEW data] metrics for 940-th model : acc= 69.33%\n",
            "[NEW data] metrics for 941-th model : acc= 69.33%\n",
            "[NEW data] metrics for 942-th model : acc= 65.33%\n",
            "[NEW data] metrics for 943-th model : acc= 67.00%\n",
            "[NEW data] metrics for 944-th model : acc= 68.00%\n",
            "[NEW data] metrics for 945-th model : acc= 66.33%\n",
            "[NEW data] metrics for 946-th model : acc= 67.33%\n",
            "[NEW data] metrics for 947-th model : acc= 68.33%\n",
            "[NEW data] metrics for 948-th model : acc= 63.33%\n",
            "[NEW data] metrics for 949-th model : acc= 67.67%\n",
            "[NEW data] metrics for 950-th model : acc= 66.67%\n",
            "[NEW data] metrics for 951-th model : acc= 66.00%\n",
            "[NEW data] metrics for 952-th model : acc= 56.67%\n",
            "[NEW data] metrics for 953-th model : acc= 67.00%\n",
            "[NEW data] metrics for 954-th model : acc= 67.00%\n",
            "[NEW data] metrics for 955-th model : acc= 67.33%\n",
            "[NEW data] metrics for 956-th model : acc= 68.00%\n",
            "[NEW data] metrics for 957-th model : acc= 68.67%\n",
            "[NEW data] metrics for 958-th model : acc= 65.33%\n",
            "[NEW data] metrics for 959-th model : acc= 65.67%\n",
            "[NEW data] metrics for 960-th model : acc= 65.67%\n",
            "[NEW data] metrics for 961-th model : acc= 69.00%\n",
            "[NEW data] metrics for 962-th model : acc= 65.67%\n",
            "[NEW data] metrics for 963-th model : acc= 66.00%\n",
            "[NEW data] metrics for 964-th model : acc= 66.33%\n",
            "[NEW data] metrics for 965-th model : acc= 66.67%\n",
            "[NEW data] metrics for 966-th model : acc= 68.67%\n",
            "[NEW data] metrics for 967-th model : acc= 64.67%\n",
            "[NEW data] metrics for 968-th model : acc= 67.67%\n",
            "[NEW data] metrics for 969-th model : acc= 68.33%\n",
            "[NEW data] metrics for 970-th model : acc= 66.00%\n",
            "[NEW data] metrics for 971-th model : acc= 62.33%\n",
            "[NEW data] metrics for 972-th model : acc= 66.00%\n",
            "[NEW data] metrics for 973-th model : acc= 68.00%\n",
            "[NEW data] metrics for 974-th model : acc= 67.00%\n",
            "[NEW data] metrics for 975-th model : acc= 52.67%\n",
            "[NEW data] metrics for 976-th model : acc= 66.67%\n",
            "[NEW data] metrics for 977-th model : acc= 69.67%\n",
            "[NEW data] metrics for 978-th model : acc= 67.00%\n",
            "[NEW data] metrics for 979-th model : acc= 64.33%\n",
            "[NEW data] metrics for 980-th model : acc= 67.00%\n",
            "[NEW data] metrics for 981-th model : acc= 60.33%\n",
            "[NEW data] metrics for 982-th model : acc= 67.00%\n",
            "[NEW data] metrics for 983-th model : acc= 66.00%\n",
            "[NEW data] metrics for 984-th model : acc= 66.00%\n",
            "[NEW data] metrics for 985-th model : acc= 68.00%\n",
            "[NEW data] metrics for 986-th model : acc= 65.00%\n",
            "[NEW data] metrics for 987-th model : acc= 67.00%\n",
            "[NEW data] metrics for 988-th model : acc= 66.33%\n",
            "[NEW data] metrics for 989-th model : acc= 68.00%\n",
            "[NEW data] metrics for 990-th model : acc= 64.33%\n",
            "[NEW data] metrics for 991-th model : acc= 67.00%\n",
            "[NEW data] metrics for 992-th model : acc= 69.67%\n",
            "[NEW data] metrics for 993-th model : acc= 65.33%\n",
            "[NEW data] metrics for 994-th model : acc= 67.67%\n",
            "[NEW data] metrics for 995-th model : acc= 67.00%\n",
            "[NEW data] metrics for 996-th model : acc= 67.00%\n",
            "[NEW data] metrics for 997-th model : acc= 67.67%\n",
            "[NEW data] metrics for 998-th model : acc= 67.33%\n",
            "[NEW data] metrics for 999-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1000-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1001-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1002-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1003-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1004-th model : acc= 50.33%\n",
            "[NEW data] metrics for 1005-th model : acc= 72.00%\n",
            "[NEW data] metrics for 1006-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1007-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1008-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1009-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1010-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1011-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1012-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1013-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1014-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1015-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1016-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1017-th model : acc= 58.33%\n",
            "[NEW data] metrics for 1018-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1019-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1020-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1021-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1022-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1023-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1024-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1025-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1026-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1027-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1028-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1029-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1030-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1031-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1032-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1033-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1034-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1035-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1036-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1037-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1038-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1039-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1040-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1041-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1042-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1043-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1044-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1045-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1046-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1047-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1048-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1049-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1050-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1051-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1052-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1053-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1054-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1055-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1056-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1057-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1058-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1059-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1060-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1061-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1062-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1063-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1064-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1065-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1066-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1067-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1068-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1069-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1070-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1071-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1072-th model : acc= 55.67%\n",
            "[NEW data] metrics for 1073-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1074-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1075-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1076-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1077-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1078-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1079-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1080-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1081-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1082-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1083-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1084-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1085-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1086-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1087-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1088-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1089-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1090-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1091-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1092-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1093-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1094-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1095-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1096-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1097-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1098-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1099-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1100-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1101-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1102-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1103-th model : acc= 60.33%\n",
            "[NEW data] metrics for 1104-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1105-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1106-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1107-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1108-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1109-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1110-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1111-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1112-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1113-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1114-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1115-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1116-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1117-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1118-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1119-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1120-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1121-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1122-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1123-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1124-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1125-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1126-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1127-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1128-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1129-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1130-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1131-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1132-th model : acc= 62.67%\n",
            "[NEW data] metrics for 1133-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1134-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1135-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1136-th model : acc= 59.33%\n",
            "[NEW data] metrics for 1137-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1138-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1139-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1140-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1141-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1142-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1143-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1144-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1145-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1146-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1147-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1148-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1149-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1150-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1151-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1152-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1153-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1154-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1155-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1156-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1157-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1158-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1159-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1160-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1161-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1162-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1163-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1164-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1165-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1166-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1167-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1168-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1169-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1170-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1171-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1172-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1173-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1174-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1175-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1176-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1177-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1178-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1179-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1180-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1181-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1182-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1183-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1184-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1185-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1186-th model : acc= 57.00%\n",
            "[NEW data] metrics for 1187-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1188-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1189-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1190-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1191-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1192-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1193-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1194-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1195-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1196-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1197-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1198-th model : acc= 61.33%\n",
            "[NEW data] metrics for 1199-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1200-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1201-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1202-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1203-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1204-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1205-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1206-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1207-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1208-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1209-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1210-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1211-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1212-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1213-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1214-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1215-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1216-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1217-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1218-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1219-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1220-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1221-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1222-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1223-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1224-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1225-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1226-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1227-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1228-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1229-th model : acc= 61.00%\n",
            "[NEW data] metrics for 1230-th model : acc= 49.00%\n",
            "[NEW data] metrics for 1231-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1232-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1233-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1234-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1235-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1236-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1237-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1238-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1239-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1240-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1241-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1242-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1243-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1244-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1245-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1246-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1247-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1248-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1249-th model : acc= 61.33%\n",
            "[NEW data] metrics for 1250-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1251-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1252-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1253-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1254-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1255-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1256-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1257-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1258-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1259-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1260-th model : acc= 61.00%\n",
            "[NEW data] metrics for 1261-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1262-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1263-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1264-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1265-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1266-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1267-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1268-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1269-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1270-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1271-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1272-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1273-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1274-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1275-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1276-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1277-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1278-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1279-th model : acc= 48.00%\n",
            "[NEW data] metrics for 1280-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1281-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1282-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1283-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1284-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1285-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1286-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1287-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1288-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1289-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1290-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1291-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1292-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1293-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1294-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1295-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1296-th model : acc= 49.00%\n",
            "[NEW data] metrics for 1297-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1298-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1299-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1300-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1301-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1302-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1303-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1304-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1305-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1306-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1307-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1308-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1309-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1310-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1311-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1312-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1313-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1314-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1315-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1316-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1317-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1318-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1319-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1320-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1321-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1322-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1323-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1324-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1325-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1326-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1327-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1328-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1329-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1330-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1331-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1332-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1333-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1334-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1335-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1336-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1337-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1338-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1339-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1340-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1341-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1342-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1343-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1344-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1345-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1346-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1347-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1348-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1349-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1350-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1351-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1352-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1353-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1354-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1355-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1356-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1357-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1358-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1359-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1360-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1361-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1362-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1363-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1364-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1365-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1366-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1367-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1368-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1369-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1370-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1371-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1372-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1373-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1374-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1375-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1376-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1377-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1378-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1379-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1380-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1381-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1382-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1383-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1384-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1385-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1386-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1387-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1388-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1389-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1390-th model : acc= 71.67%\n",
            "[NEW data] metrics for 1391-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1392-th model : acc= 57.00%\n",
            "[NEW data] metrics for 1393-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1394-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1395-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1396-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1397-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1398-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1399-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1400-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1401-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1402-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1403-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1404-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1405-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1406-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1407-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1408-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1409-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1410-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1411-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1412-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1413-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1414-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1415-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1416-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1417-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1418-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1419-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1420-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1421-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1422-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1423-th model : acc= 51.67%\n",
            "[NEW data] metrics for 1424-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1425-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1426-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1427-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1428-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1429-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1430-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1431-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1432-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1433-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1434-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1435-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1436-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1437-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1438-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1439-th model : acc= 60.00%\n",
            "[NEW data] metrics for 1440-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1441-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1442-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1443-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1444-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1445-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1446-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1447-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1448-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1449-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1450-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1451-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1452-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1453-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1454-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1455-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1456-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1457-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1458-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1459-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1460-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1461-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1462-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1463-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1464-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1465-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1466-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1467-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1468-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1469-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1470-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1471-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1472-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1473-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1474-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1475-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1476-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1477-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1478-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1479-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1480-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1481-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1482-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1483-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1484-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1485-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1486-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1487-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1488-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1489-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1490-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1491-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1492-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1493-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1494-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1495-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1496-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1497-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1498-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1499-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1500-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1501-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1502-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1503-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1504-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1505-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1506-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1507-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1508-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1509-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1510-th model : acc= 59.67%\n",
            "[NEW data] metrics for 1511-th model : acc= 61.33%\n",
            "[NEW data] metrics for 1512-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1513-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1514-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1515-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1516-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1517-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1518-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1519-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1520-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1521-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1522-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1523-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1524-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1525-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1526-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1527-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1528-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1529-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1530-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1531-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1532-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1533-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1534-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1535-th model : acc= 62.67%\n",
            "[NEW data] metrics for 1536-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1537-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1538-th model : acc= 56.67%\n",
            "[NEW data] metrics for 1539-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1540-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1541-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1542-th model : acc= 61.67%\n",
            "[NEW data] metrics for 1543-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1544-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1545-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1546-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1547-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1548-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1549-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1550-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1551-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1552-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1553-th model : acc= 71.00%\n",
            "[NEW data] metrics for 1554-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1555-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1556-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1557-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1558-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1559-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1560-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1561-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1562-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1563-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1564-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1565-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1566-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1567-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1568-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1569-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1570-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1571-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1572-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1573-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1574-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1575-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1576-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1577-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1578-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1579-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1580-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1581-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1582-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1583-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1584-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1585-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1586-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1587-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1588-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1589-th model : acc= 71.00%\n",
            "[NEW data] metrics for 1590-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1591-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1592-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1593-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1594-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1595-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1596-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1597-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1598-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1599-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1600-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1601-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1602-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1603-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1604-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1605-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1606-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1607-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1608-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1609-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1610-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1611-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1612-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1613-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1614-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1615-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1616-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1617-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1618-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1619-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1620-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1621-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1622-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1623-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1624-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1625-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1626-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1627-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1628-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1629-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1630-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1631-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1632-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1633-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1634-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1635-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1636-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1637-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1638-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1639-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1640-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1641-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1642-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1643-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1644-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1645-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1646-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1647-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1648-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1649-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1650-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1651-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1652-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1653-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1654-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1655-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1656-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1657-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1658-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1659-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1660-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1661-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1662-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1663-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1664-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1665-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1666-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1667-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1668-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1669-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1670-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1671-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1672-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1673-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1674-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1675-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1676-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1677-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1678-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1679-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1680-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1681-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1682-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1683-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1684-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1685-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1686-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1687-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1688-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1689-th model : acc= 60.67%\n",
            "[NEW data] metrics for 1690-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1691-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1692-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1693-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1694-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1695-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1696-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1697-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1698-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1699-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1700-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1701-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1702-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1703-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1704-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1705-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1706-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1707-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1708-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1709-th model : acc= 56.00%\n",
            "[NEW data] metrics for 1710-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1711-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1712-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1713-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1714-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1715-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1716-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1717-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1718-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1719-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1720-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1721-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1722-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1723-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1724-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1725-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1726-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1727-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1728-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1729-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1730-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1731-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1732-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1733-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1734-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1735-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1736-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1737-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1738-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1739-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1740-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1741-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1742-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1743-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1744-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1745-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1746-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1747-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1748-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1749-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1750-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1751-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1752-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1753-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1754-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1755-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1756-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1757-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1758-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1759-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1760-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1761-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1762-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1763-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1764-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1765-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1766-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1767-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1768-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1769-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1770-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1771-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1772-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1773-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1774-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1775-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1776-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1777-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1778-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1779-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1780-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1781-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1782-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1783-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1784-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1785-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1786-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1787-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1788-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1789-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1790-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1791-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1792-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1793-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1794-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1795-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1796-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1797-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1798-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1799-th model : acc= 54.00%\n",
            "[NEW data] metrics for 1800-th model : acc= 71.33%\n",
            "[NEW data] metrics for 1801-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1802-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1803-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1804-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1805-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1806-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1807-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1808-th model : acc= 62.67%\n",
            "[NEW data] metrics for 1809-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1810-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1811-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1812-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1813-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1814-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1815-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1816-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1817-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1818-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1819-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1820-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1821-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1822-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1823-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1824-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1825-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1826-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1827-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1828-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1829-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1830-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1831-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1832-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1833-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1834-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1835-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1836-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1837-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1838-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1839-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1840-th model : acc= 55.00%\n",
            "[NEW data] metrics for 1841-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1842-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1843-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1844-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1845-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1846-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1847-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1848-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1849-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1850-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1851-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1852-th model : acc= 60.67%\n",
            "[NEW data] metrics for 1853-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1854-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1855-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1856-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1857-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1858-th model : acc= 71.67%\n",
            "[NEW data] metrics for 1859-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1860-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1861-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1862-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1863-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1864-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1865-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1866-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1867-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1868-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1869-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1870-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1871-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1872-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1873-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1874-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1875-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1876-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1877-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1878-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1879-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1880-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1881-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1882-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1883-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1884-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1885-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1886-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1887-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1888-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1889-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1890-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1891-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1892-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1893-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1894-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1895-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1896-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1897-th model : acc= 61.33%\n",
            "[NEW data] metrics for 1898-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1899-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1900-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1901-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1902-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1903-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1904-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1905-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1906-th model : acc= 57.67%\n",
            "[NEW data] metrics for 1907-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1908-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1909-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1910-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1911-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1912-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1913-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1914-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1915-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1916-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1917-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1918-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1919-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1920-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1921-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1922-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1923-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1924-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1925-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1926-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1927-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1928-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1929-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1930-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1931-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1932-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1933-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1934-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1935-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1936-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1937-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1938-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1939-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1940-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1941-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1942-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1943-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1944-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1945-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1946-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1947-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1948-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1949-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1950-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1951-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1952-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1953-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1954-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1955-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1956-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1957-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1958-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1959-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1960-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1961-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1962-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1963-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1964-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1965-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1966-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1967-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1968-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1969-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1970-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1971-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1972-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1973-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1974-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1975-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1976-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1977-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1978-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1979-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1980-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1981-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1982-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1983-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1984-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1985-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1986-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1987-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1988-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1989-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1990-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1991-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1992-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1993-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1994-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1995-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1996-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1997-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1998-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1999-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2000-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2001-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2002-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2003-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2004-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2005-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2006-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2007-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2008-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2009-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2010-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2011-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2012-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2013-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2014-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2015-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2016-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2017-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2018-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2019-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2020-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2021-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2022-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2023-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2024-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2025-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2026-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2027-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2028-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2029-th model : acc= 51.33%\n",
            "[NEW data] metrics for 2030-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2031-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2032-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2033-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2034-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2035-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2036-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2037-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2038-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2039-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2040-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2041-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2042-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2043-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2044-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2045-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2046-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2047-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2048-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2049-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2050-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2051-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2052-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2053-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2054-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2055-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2056-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2057-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2058-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2059-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2060-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2061-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2062-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2063-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2064-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2065-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2066-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2067-th model : acc= 56.33%\n",
            "[NEW data] metrics for 2068-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2069-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2070-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2071-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2072-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2073-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2074-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2075-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2076-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2077-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2078-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2079-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2080-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2081-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2082-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2083-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2084-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2085-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2086-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2087-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2088-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2089-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2090-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2091-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2092-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2093-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2094-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2095-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2096-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2097-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2098-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2099-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2100-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2101-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2102-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2103-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2104-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2105-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2106-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2107-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2108-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2109-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2110-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2111-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2112-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2113-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2114-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2115-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2116-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2117-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2118-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2119-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2120-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2121-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2122-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2123-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2124-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2125-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2126-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2127-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2128-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2129-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2130-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2131-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2132-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2133-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2134-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2135-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2136-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2137-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2138-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2139-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2140-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2141-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2142-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2143-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2144-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2145-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2146-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2147-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2148-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2149-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2150-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2151-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2152-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2153-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2154-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2155-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2156-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2157-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2158-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2159-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2160-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2161-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2162-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2163-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2164-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2165-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2166-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2167-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2168-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2169-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2170-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2171-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2172-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2173-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2174-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2175-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2176-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2177-th model : acc= 61.00%\n",
            "[NEW data] metrics for 2178-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2179-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2180-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2181-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2182-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2183-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2184-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2185-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2186-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2187-th model : acc= 72.33%\n",
            "[NEW data] metrics for 2188-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2189-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2190-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2191-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2192-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2193-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2194-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2195-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2196-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2197-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2198-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2199-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2200-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2201-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2202-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2203-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2204-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2205-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2206-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2207-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2208-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2209-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2210-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2211-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2212-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2213-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2214-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2215-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2216-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2217-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2218-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2219-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2220-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2221-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2222-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2223-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2224-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2225-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2226-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2227-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2228-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2229-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2230-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2231-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2232-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2233-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2234-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2235-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2236-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2237-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2238-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2239-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2240-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2241-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2242-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2243-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2244-th model : acc= 59.33%\n",
            "[NEW data] metrics for 2245-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2246-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2247-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2248-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2249-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2250-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2251-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2252-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2253-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2254-th model : acc= 62.33%\n",
            "[NEW data] metrics for 2255-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2256-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2257-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2258-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2259-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2260-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2261-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2262-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2263-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2264-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2265-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2266-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2267-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2268-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2269-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2270-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2271-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2272-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2273-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2274-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2275-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2276-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2277-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2278-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2279-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2280-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2281-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2282-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2283-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2284-th model : acc= 53.00%\n",
            "[NEW data] metrics for 2285-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2286-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2287-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2288-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2289-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2290-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2291-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2292-th model : acc= 55.67%\n",
            "[NEW data] metrics for 2293-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2294-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2295-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2296-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2297-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2298-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2299-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2300-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2301-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2302-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2303-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2304-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2305-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2306-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2307-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2308-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2309-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2310-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2311-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2312-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2313-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2314-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2315-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2316-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2317-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2318-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2319-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2320-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2321-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2322-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2323-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2324-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2325-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2326-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2327-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2328-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2329-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2330-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2331-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2332-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2333-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2334-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2335-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2336-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2337-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2338-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2339-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2340-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2341-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2342-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2343-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2344-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2345-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2346-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2347-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2348-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2349-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2350-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2351-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2352-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2353-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2354-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2355-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2356-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2357-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2358-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2359-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2360-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2361-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2362-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2363-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2364-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2365-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2366-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2367-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2368-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2369-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2370-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2371-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2372-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2373-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2374-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2375-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2376-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2377-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2378-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2379-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2380-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2381-th model : acc= 62.00%\n",
            "[NEW data] metrics for 2382-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2383-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2384-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2385-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2386-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2387-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2388-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2389-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2390-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2391-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2392-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2393-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2394-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2395-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2396-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2397-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2398-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2399-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2400-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2401-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2402-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2403-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2404-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2405-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2406-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2407-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2408-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2409-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2410-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2411-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2412-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2413-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2414-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2415-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2416-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2417-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2418-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2419-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2420-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2421-th model : acc= 61.33%\n",
            "[NEW data] metrics for 2422-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2423-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2424-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2425-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2426-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2427-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2428-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2429-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2430-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2431-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2432-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2433-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2434-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2435-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2436-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2437-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2438-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2439-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2440-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2441-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2442-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2443-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2444-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2445-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2446-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2447-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2448-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2449-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2450-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2451-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2452-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2453-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2454-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2455-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2456-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2457-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2458-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2459-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2460-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2461-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2462-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2463-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2464-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2465-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2466-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2467-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2468-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2469-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2470-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2471-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2472-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2473-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2474-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2475-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2476-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2477-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2478-th model : acc= 60.67%\n",
            "[NEW data] metrics for 2479-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2480-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2481-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2482-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2483-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2484-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2485-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2486-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2487-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2488-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2489-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2490-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2491-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2492-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2493-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2494-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2495-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2496-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2497-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2498-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2499-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2500-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2501-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2502-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2503-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2504-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2505-th model : acc= 59.67%\n",
            "[NEW data] metrics for 2506-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2507-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2508-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2509-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2510-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2511-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2512-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2513-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2514-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2515-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2516-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2517-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2518-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2519-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2520-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2521-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2522-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2523-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2524-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2525-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2526-th model : acc= 54.00%\n",
            "[NEW data] metrics for 2527-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2528-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2529-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2530-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2531-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2532-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2533-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2534-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2535-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2536-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2537-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2538-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2539-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2540-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2541-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2542-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2543-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2544-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2545-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2546-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2547-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2548-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2549-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2550-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2551-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2552-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2553-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2554-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2555-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2556-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2557-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2558-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2559-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2560-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2561-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2562-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2563-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2564-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2565-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2566-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2567-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2568-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2569-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2570-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2571-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2572-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2573-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2574-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2575-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2576-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2577-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2578-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2579-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2580-th model : acc= 58.67%\n",
            "[NEW data] metrics for 2581-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2582-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2583-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2584-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2585-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2586-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2587-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2588-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2589-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2590-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2591-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2592-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2593-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2594-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2595-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2596-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2597-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2598-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2599-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2600-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2601-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2602-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2603-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2604-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2605-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2606-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2607-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2608-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2609-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2610-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2611-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2612-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2613-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2614-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2615-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2616-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2617-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2618-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2619-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2620-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2621-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2622-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2623-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2624-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2625-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2626-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2627-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2628-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2629-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2630-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2631-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2632-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2633-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2634-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2635-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2636-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2637-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2638-th model : acc= 62.33%\n",
            "[NEW data] metrics for 2639-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2640-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2641-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2642-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2643-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2644-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2645-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2646-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2647-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2648-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2649-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2650-th model : acc= 61.33%\n",
            "[NEW data] metrics for 2651-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2652-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2653-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2654-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2655-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2656-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2657-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2658-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2659-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2660-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2661-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2662-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2663-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2664-th model : acc= 61.33%\n",
            "[NEW data] metrics for 2665-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2666-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2667-th model : acc= 62.00%\n",
            "[NEW data] metrics for 2668-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2669-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2670-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2671-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2672-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2673-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2674-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2675-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2676-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2677-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2678-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2679-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2680-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2681-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2682-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2683-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2684-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2685-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2686-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2687-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2688-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2689-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2690-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2691-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2692-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2693-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2694-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2695-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2696-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2697-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2698-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2699-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2700-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2701-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2702-th model : acc= 52.67%\n",
            "[NEW data] metrics for 2703-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2704-th model : acc= 72.00%\n",
            "[NEW data] metrics for 2705-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2706-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2707-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2708-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2709-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2710-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2711-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2712-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2713-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2714-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2715-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2716-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2717-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2718-th model : acc= 71.67%\n",
            "[NEW data] metrics for 2719-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2720-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2721-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2722-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2723-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2724-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2725-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2726-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2727-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2728-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2729-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2730-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2731-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2732-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2733-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2734-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2735-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2736-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2737-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2738-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2739-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2740-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2741-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2742-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2743-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2744-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2745-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2746-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2747-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2748-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2749-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2750-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2751-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2752-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2753-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2754-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2755-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2756-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2757-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2758-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2759-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2760-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2761-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2762-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2763-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2764-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2765-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2766-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2767-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2768-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2769-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2770-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2771-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2772-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2773-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2774-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2775-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2776-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2777-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2778-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2779-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2780-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2781-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2782-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2783-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2784-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2785-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2786-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2787-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2788-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2789-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2790-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2791-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2792-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2793-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2794-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2795-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2796-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2797-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2798-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2799-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2800-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2801-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2802-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2803-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2804-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2805-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2806-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2807-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2808-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2809-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2810-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2811-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2812-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2813-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2814-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2815-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2816-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2817-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2818-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2819-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2820-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2821-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2822-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2823-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2824-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2825-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2826-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2827-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2828-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2829-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2830-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2831-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2832-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2833-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2834-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2835-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2836-th model : acc= 61.00%\n",
            "[NEW data] metrics for 2837-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2838-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2839-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2840-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2841-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2842-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2843-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2844-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2845-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2846-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2847-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2848-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2849-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2850-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2851-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2852-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2853-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2854-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2855-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2856-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2857-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2858-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2859-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2860-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2861-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2862-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2863-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2864-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2865-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2866-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2867-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2868-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2869-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2870-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2871-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2872-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2873-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2874-th model : acc= 59.67%\n",
            "[NEW data] metrics for 2875-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2876-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2877-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2878-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2879-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2880-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2881-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2882-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2883-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2884-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2885-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2886-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2887-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2888-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2889-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2890-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2891-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2892-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2893-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2894-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2895-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2896-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2897-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2898-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2899-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2900-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2901-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2902-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2903-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2904-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2905-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2906-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2907-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2908-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2909-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2910-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2911-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2912-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2913-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2914-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2915-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2916-th model : acc= 72.00%\n",
            "[NEW data] metrics for 2917-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2918-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2919-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2920-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2921-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2922-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2923-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2924-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2925-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2926-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2927-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2928-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2929-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2930-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2931-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2932-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2933-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2934-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2935-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2936-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2937-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2938-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2939-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2940-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2941-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2942-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2943-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2944-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2945-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2946-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2947-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2948-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2949-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2950-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2951-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2952-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2953-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2954-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2955-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2956-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2957-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2958-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2959-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2960-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2961-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2962-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2963-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2964-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2965-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2966-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2967-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2968-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2969-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2970-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2971-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2972-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2973-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2974-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2975-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2976-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2977-th model : acc= 62.00%\n",
            "[NEW data] metrics for 2978-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2979-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2980-th model : acc= 57.00%\n",
            "[NEW data] metrics for 2981-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2982-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2983-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2984-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2985-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2986-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2987-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2988-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2989-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2990-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2991-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2992-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2993-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2994-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2995-th model : acc= 58.67%\n",
            "[NEW data] metrics for 2996-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2997-th model : acc= 60.00%\n",
            "[NEW data] metrics for 2998-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2999-th model : acc= 47.67%\n",
            "[NEW data] metrics for 3000-th model : acc= 68.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotly 를 이용하여 성능 비교\n",
        "\n",
        "WINDOW_SIZE = 30\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "trial_nos = np.array(range(TRIAL_COUNT))\n",
        "hpo_losses = np.array([trial['result']['loss'] for trial in trials.trials])\n",
        "hpo_accuracy = (-1) * 100.0 * hpo_losses\n",
        "\n",
        "# 성능 추이 표시\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=hpo_accuracy,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 4, 'color': '#F70'},\n",
        "                         name='HPO test dataset accuracy'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=new_dataset_accuracy,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 4, 'color': '#07F'},\n",
        "                         name='NEW test dataset accuracy'))\n",
        "\n",
        "# 성능 추이의 이동평균 표시\n",
        "hpo_accuracy_ma = np.convolve(hpo_accuracy,\n",
        "                              np.ones(WINDOW_SIZE) / WINDOW_SIZE,\n",
        "                              mode='valid')\n",
        "\n",
        "new_dataset_accuracy_ma = np.convolve(new_dataset_accuracy,\n",
        "                                      np.ones(WINDOW_SIZE) / WINDOW_SIZE,\n",
        "                                      mode='valid')\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=hpo_accuracy_ma,\n",
        "                         mode='lines',\n",
        "                         line={'color': '#FA0'},\n",
        "                         name='HPO test dataset accuracy (Moving Average)'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=new_dataset_accuracy_ma,\n",
        "                         mode='lines',\n",
        "                         line={'color': '#0AF'},\n",
        "                         name='NEW test dataset accuracy (Moving Average)'))\n",
        "\n",
        "# 차트 표시\n",
        "fig.update_layout(width=1200,\n",
        "                  height=600,\n",
        "                  xaxis_title='trial No.',\n",
        "                  yaxis_title='Accuracy (%)')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "B6GeeVkq3-T2",
        "outputId": "b01e744c-4f53-403b-e5d1-704e7ff34bae"
      },
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7292d1eb-16f2-4baf-8b57-9fccb21dc1d7\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7292d1eb-16f2-4baf-8b57-9fccb21dc1d7\")) {                    Plotly.newPlot(                        \"7292d1eb-16f2-4baf-8b57-9fccb21dc1d7\",                        [{\"marker\":{\"color\":\"#F70\",\"size\":4},\"mode\":\"markers\",\"name\":\"HPO test dataset accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[58.333333333333336,64.16666666666667,47.91666666666667,47.91666666666667,47.91666666666667,66.25,67.08333333333333,70.0,60.83333333333333,63.74999999999999,67.08333333333333,68.33333333333333,52.5,67.91666666666667,47.91666666666667,61.66666666666667,47.91666666666667,61.25000000000001,67.91666666666667,62.916666666666664,68.75,67.91666666666667,67.5,64.16666666666667,66.25,61.25000000000001,47.91666666666667,70.0,65.0,67.91666666666667,61.25000000000001,67.91666666666667,51.66666666666667,68.75,47.91666666666667,70.0,68.75,65.41666666666667,67.5,61.66666666666667,68.33333333333333,57.08333333333333,68.75,67.08333333333333,65.83333333333333,67.5,68.33333333333333,47.91666666666667,62.5,55.833333333333336,47.91666666666667,47.91666666666667,64.58333333333334,68.33333333333333,70.0,65.0,47.91666666666667,68.33333333333333,69.16666666666667,67.91666666666667,67.5,62.916666666666664,58.333333333333336,47.91666666666667,67.91666666666667,67.91666666666667,69.16666666666667,68.33333333333333,65.83333333333333,67.91666666666667,68.75,68.33333333333333,68.75,69.16666666666667,64.58333333333334,67.91666666666667,63.74999999999999,65.41666666666667,64.58333333333334,65.41666666666667,61.66666666666667,65.41666666666667,67.08333333333333,63.33333333333333,69.58333333333333,60.0,69.58333333333333,65.41666666666667,61.25000000000001,65.0,69.58333333333333,68.75,67.91666666666667,65.41666666666667,68.75,67.91666666666667,47.91666666666667,66.25,62.916666666666664,47.91666666666667,54.58333333333333,47.91666666666667,47.91666666666667,56.25,58.75,62.5,67.91666666666667,70.41666666666667,67.08333333333333,69.58333333333333,69.16666666666667,47.91666666666667,64.16666666666667,70.0,67.5,72.5,70.41666666666667,70.41666666666667,68.33333333333333,69.58333333333333,67.91666666666667,69.58333333333333,66.66666666666666,47.91666666666667,68.75,47.91666666666667,63.33333333333333,67.5,65.0,67.5,67.91666666666667,62.916666666666664,69.16666666666667,70.0,47.91666666666667,70.0,67.91666666666667,68.75,69.16666666666667,69.58333333333333,68.75,62.083333333333336,67.08333333333333,58.333333333333336,67.5,67.5,69.16666666666667,68.33333333333333,69.58333333333333,68.75,68.75,71.25,69.16666666666667,67.5,68.33333333333333,69.16666666666667,66.66666666666666,68.75,71.25,70.41666666666667,68.33333333333333,69.58333333333333,71.25,70.0,62.5,68.75,67.91666666666667,56.25,69.16666666666667,47.91666666666667,66.66666666666666,69.16666666666667,67.91666666666667,69.16666666666667,70.83333333333334,69.16666666666667,67.08333333333333,69.58333333333333,68.75,69.58333333333333,70.0,69.16666666666667,67.91666666666667,65.0,67.91666666666667,70.0,56.666666666666664,66.66666666666666,65.0,47.91666666666667,69.16666666666667,68.33333333333333,72.91666666666666,47.91666666666667,68.75,68.33333333333333,68.75,65.41666666666667,69.58333333333333,70.41666666666667,58.333333333333336,68.33333333333333,67.5,62.083333333333336,69.16666666666667,66.66666666666666,70.0,66.25,68.75,71.25,70.0,47.91666666666667,58.333333333333336,67.5,68.33333333333333,71.66666666666667,68.33333333333333,66.66666666666666,70.41666666666667,68.75,67.5,64.58333333333334,67.08333333333333,47.91666666666667,68.75,68.33333333333333,70.83333333333334,69.58333333333333,66.25,71.66666666666667,69.16666666666667,69.58333333333333,65.83333333333333,67.5,67.5,62.916666666666664,68.75,67.5,64.16666666666667,69.58333333333333,62.083333333333336,69.16666666666667,66.66666666666666,67.91666666666667,67.5,55.41666666666667,69.58333333333333,47.91666666666667,47.91666666666667,67.5,61.66666666666667,57.08333333333333,68.75,66.25,66.66666666666666,47.91666666666667,67.91666666666667,67.91666666666667,70.83333333333334,61.25000000000001,69.58333333333333,67.5,68.33333333333333,69.16666666666667,47.91666666666667,67.08333333333333,67.08333333333333,64.58333333333334,70.0,69.16666666666667,69.58333333333333,65.0,69.16666666666667,59.583333333333336,68.33333333333333,65.83333333333333,70.0,70.0,65.41666666666667,67.91666666666667,68.75,70.41666666666667,68.75,71.25,68.33333333333333,69.16666666666667,71.25,69.58333333333333,69.58333333333333,68.33333333333333,67.08333333333333,66.66666666666666,67.91666666666667,71.25,66.66666666666666,70.0,69.16666666666667,69.16666666666667,70.83333333333334,65.41666666666667,67.5,68.33333333333333,67.5,47.91666666666667,67.91666666666667,47.91666666666667,71.25,70.41666666666667,66.66666666666666,70.83333333333334,66.25,70.0,65.83333333333333,67.91666666666667,53.75,69.16666666666667,66.25,70.41666666666667,67.08333333333333,67.91666666666667,65.0,66.25,70.83333333333334,68.75,69.58333333333333,70.41666666666667,67.91666666666667,62.916666666666664,66.66666666666666,62.916666666666664,70.0,67.08333333333333,68.33333333333333,67.08333333333333,64.58333333333334,69.58333333333333,66.25,65.83333333333333,70.0,66.66666666666666,68.33333333333333,65.41666666666667,69.16666666666667,62.083333333333336,70.0,71.25,70.41666666666667,67.91666666666667,69.16666666666667,67.08333333333333,68.75,67.5,68.33333333333333,67.08333333333333,68.75,67.5,67.08333333333333,68.75,47.91666666666667,70.0,69.16666666666667,69.58333333333333,47.91666666666667,55.833333333333336,70.0,68.75,64.16666666666667,70.83333333333334,65.0,64.58333333333334,70.83333333333334,60.83333333333333,66.25,66.25,66.66666666666666,66.66666666666666,69.16666666666667,68.75,58.333333333333336,70.83333333333334,70.0,70.41666666666667,60.83333333333333,68.33333333333333,65.0,67.5,72.5,68.75,66.66666666666666,68.75,70.0,69.16666666666667,68.75,68.75,47.91666666666667,68.75,47.91666666666667,70.0,66.66666666666666,60.83333333333333,66.25,69.58333333333333,70.0,69.58333333333333,67.5,70.0,66.66666666666666,70.83333333333334,70.0,68.75,70.0,67.08333333333333,71.25,65.83333333333333,70.0,70.0,70.41666666666667,66.66666666666666,68.33333333333333,69.58333333333333,68.33333333333333,70.41666666666667,70.0,70.41666666666667,67.08333333333333,69.16666666666667,68.75,67.91666666666667,67.91666666666667,67.5,68.33333333333333,65.41666666666667,43.75,71.25,69.16666666666667,69.16666666666667,67.91666666666667,69.16666666666667,47.91666666666667,67.08333333333333,67.5,70.0,70.83333333333334,68.75,69.16666666666667,69.16666666666667,70.41666666666667,70.83333333333334,67.08333333333333,70.41666666666667,68.75,68.33333333333333,63.33333333333333,70.83333333333334,66.66666666666666,67.91666666666667,69.16666666666667,68.33333333333333,66.25,67.5,67.5,67.91666666666667,64.58333333333334,64.58333333333334,47.91666666666667,70.83333333333334,65.83333333333333,64.58333333333334,67.91666666666667,63.74999999999999,70.41666666666667,67.5,69.16666666666667,67.5,47.91666666666667,70.83333333333334,70.0,70.41666666666667,52.083333333333336,69.58333333333333,71.66666666666667,69.16666666666667,70.0,68.75,70.41666666666667,70.83333333333334,69.58333333333333,64.16666666666667,69.58333333333333,66.66666666666666,67.08333333333333,68.33333333333333,66.66666666666666,68.33333333333333,67.91666666666667,70.0,71.66666666666667,68.33333333333333,69.58333333333333,67.08333333333333,67.5,67.08333333333333,47.91666666666667,63.74999999999999,69.16666666666667,65.41666666666667,52.916666666666664,62.916666666666664,67.5,70.83333333333334,68.75,67.5,68.75,65.0,67.08333333333333,68.75,61.25000000000001,68.75,68.33333333333333,65.0,67.08333333333333,47.91666666666667,70.41666666666667,58.75,69.16666666666667,68.75,67.91666666666667,69.16666666666667,71.25,47.91666666666667,66.25,69.16666666666667,70.0,70.0,69.58333333333333,69.58333333333333,65.83333333333333,47.91666666666667,67.5,68.33333333333333,52.916666666666664,65.41666666666667,64.16666666666667,70.83333333333334,70.0,64.58333333333334,69.58333333333333,64.58333333333334,70.0,68.75,70.0,70.0,66.25,70.41666666666667,67.91666666666667,47.91666666666667,65.41666666666667,70.83333333333334,70.83333333333334,69.58333333333333,69.16666666666667,68.33333333333333,65.0,66.25,68.33333333333333,68.33333333333333,68.33333333333333,47.91666666666667,68.75,65.0,68.75,60.416666666666664,69.16666666666667,69.16666666666667,64.16666666666667,67.91666666666667,69.16666666666667,70.83333333333334,68.75,71.66666666666667,70.41666666666667,69.58333333333333,68.75,66.25,68.75,70.0,72.08333333333333,68.33333333333333,67.91666666666667,70.41666666666667,66.25,67.91666666666667,68.33333333333333,70.0,68.33333333333333,67.5,70.41666666666667,69.16666666666667,69.16666666666667,69.16666666666667,67.91666666666667,69.58333333333333,66.25,71.25,71.25,70.41666666666667,71.66666666666667,68.33333333333333,67.08333333333333,67.08333333333333,70.41666666666667,70.41666666666667,70.41666666666667,70.83333333333334,67.08333333333333,58.75,63.74999999999999,68.33333333333333,69.58333333333333,70.0,68.75,68.33333333333333,68.75,65.83333333333333,67.91666666666667,67.91666666666667,67.5,69.58333333333333,67.5,63.74999999999999,71.66666666666667,67.5,65.83333333333333,67.91666666666667,67.91666666666667,68.33333333333333,69.16666666666667,67.91666666666667,66.66666666666666,71.25,68.75,68.33333333333333,72.5,67.08333333333333,69.58333333333333,67.08333333333333,70.0,64.16666666666667,72.5,68.33333333333333,70.83333333333334,68.75,65.83333333333333,70.0,68.33333333333333,70.0,67.91666666666667,67.91666666666667,49.583333333333336,67.91666666666667,67.5,67.5,70.83333333333334,73.33333333333333,71.25,70.0,72.08333333333333,69.58333333333333,61.25000000000001,68.33333333333333,68.75,68.75,65.41666666666667,67.5,70.83333333333334,70.41666666666667,66.66666666666666,71.66666666666667,69.58333333333333,69.58333333333333,71.25,74.16666666666667,70.41666666666667,64.16666666666667,63.74999999999999,70.83333333333334,69.16666666666667,69.16666666666667,69.58333333333333,69.16666666666667,67.91666666666667,69.16666666666667,69.58333333333333,68.75,71.66666666666667,69.16666666666667,69.58333333333333,57.49999999999999,70.0,66.25,69.58333333333333,69.58333333333333,68.75,68.33333333333333,71.25,67.91666666666667,68.33333333333333,67.5,70.0,70.0,70.41666666666667,52.5,66.66666666666666,69.58333333333333,60.416666666666664,69.58333333333333,68.33333333333333,71.25,68.33333333333333,69.16666666666667,70.41666666666667,68.33333333333333,67.91666666666667,66.66666666666666,70.0,68.75,63.33333333333333,66.66666666666666,70.41666666666667,66.66666666666666,70.0,69.16666666666667,69.58333333333333,67.5,68.75,68.75,66.25,68.75,69.58333333333333,68.33333333333333,65.0,67.91666666666667,64.58333333333334,65.41666666666667,70.83333333333334,71.25,71.66666666666667,65.41666666666667,70.41666666666667,69.16666666666667,47.91666666666667,63.33333333333333,68.33333333333333,67.08333333333333,47.91666666666667,69.16666666666667,69.16666666666667,66.66666666666666,69.16666666666667,68.75,70.83333333333334,67.91666666666667,67.5,67.5,67.5,68.33333333333333,52.916666666666664,67.08333333333333,68.75,50.0,69.58333333333333,69.58333333333333,72.08333333333333,67.91666666666667,70.41666666666667,70.0,67.08333333333333,67.91666666666667,67.5,69.16666666666667,66.25,68.75,70.41666666666667,60.83333333333333,69.58333333333333,70.0,66.66666666666666,70.83333333333334,71.25,65.83333333333333,71.25,67.08333333333333,70.83333333333334,70.83333333333334,71.25,71.25,70.41666666666667,70.83333333333334,71.25,67.91666666666667,71.66666666666667,70.83333333333334,69.58333333333333,67.91666666666667,70.41666666666667,65.83333333333333,69.16666666666667,69.58333333333333,68.33333333333333,69.58333333333333,72.08333333333333,67.5,68.75,68.33333333333333,68.75,69.58333333333333,66.66666666666666,69.58333333333333,69.16666666666667,68.75,65.41666666666667,68.33333333333333,72.91666666666666,68.33333333333333,68.33333333333333,69.58333333333333,65.83333333333333,69.16666666666667,72.08333333333333,68.75,66.25,69.16666666666667,67.08333333333333,68.33333333333333,70.83333333333334,68.33333333333333,70.0,70.41666666666667,67.91666666666667,61.25000000000001,68.75,69.58333333333333,68.33333333333333,69.16666666666667,68.33333333333333,71.25,65.41666666666667,71.66666666666667,70.83333333333334,63.33333333333333,70.0,65.83333333333333,68.75,56.25,67.08333333333333,67.91666666666667,67.08333333333333,68.33333333333333,68.33333333333333,70.83333333333334,69.16666666666667,70.41666666666667,71.25,70.0,68.33333333333333,70.83333333333334,66.25,67.5,70.83333333333334,71.25,66.25,71.25,68.75,70.41666666666667,67.91666666666667,67.08333333333333,67.08333333333333,67.91666666666667,62.083333333333336,69.58333333333333,67.91666666666667,70.41666666666667,72.08333333333333,65.83333333333333,70.0,67.5,66.66666666666666,69.16666666666667,71.25,69.16666666666667,67.91666666666667,65.83333333333333,67.5,70.83333333333334,68.75,67.91666666666667,69.16666666666667,73.75,60.83333333333333,66.25,70.83333333333334,61.66666666666667,71.66666666666667,67.91666666666667,72.5,60.416666666666664,67.5,63.74999999999999,69.16666666666667,68.75,67.5,67.91666666666667,68.75,50.0,71.25,68.75,70.0,70.41666666666667,67.5,67.91666666666667,59.583333333333336,67.5,69.16666666666667,67.5,69.58333333333333,65.83333333333333,68.75,69.58333333333333,69.58333333333333,71.66666666666667,68.33333333333333,73.75,67.08333333333333,66.66666666666666,69.16666666666667,68.33333333333333,67.5,63.74999999999999,68.75,65.41666666666667,68.33333333333333,68.33333333333333,70.41666666666667,70.0,68.33333333333333,69.16666666666667,69.58333333333333,66.66666666666666,67.08333333333333,68.75,69.58333333333333,56.666666666666664,72.08333333333333,67.08333333333333,70.41666666666667,70.41666666666667,68.33333333333333,67.91666666666667,67.91666666666667,67.08333333333333,70.0,67.91666666666667,67.91666666666667,67.08333333333333,69.16666666666667,68.33333333333333,69.16666666666667,65.41666666666667,67.91666666666667,70.83333333333334,62.5,69.58333333333333,70.0,68.75,57.08333333333333,72.08333333333333,65.41666666666667,68.33333333333333,68.33333333333333,68.75,62.5,68.75,70.0,68.33333333333333,68.75,67.08333333333333,72.91666666666666,69.16666666666667,65.41666666666667,71.66666666666667,70.83333333333334,69.58333333333333,67.91666666666667,68.33333333333333,70.41666666666667,66.66666666666666,65.41666666666667,68.33333333333333,70.0,67.08333333333333,68.75,69.58333333333333,68.33333333333333,49.166666666666664,69.58333333333333,71.25,67.5,68.75,68.33333333333333,70.0,68.33333333333333,69.16666666666667,72.5,68.75,67.91666666666667,47.91666666666667,57.08333333333333,70.0,67.91666666666667,68.33333333333333,69.58333333333333,67.08333333333333,69.58333333333333,47.91666666666667,67.91666666666667,72.08333333333333,70.83333333333334,69.58333333333333,70.41666666666667,69.58333333333333,72.5,72.08333333333333,67.91666666666667,69.16666666666667,70.0,70.83333333333334,70.41666666666667,47.91666666666667,70.41666666666667,68.33333333333333,67.91666666666667,71.25,70.83333333333334,70.83333333333334,70.83333333333334,71.66666666666667,67.91666666666667,69.58333333333333,69.16666666666667,72.5,70.41666666666667,69.58333333333333,67.91666666666667,69.16666666666667,68.33333333333333,72.91666666666666,63.74999999999999,72.08333333333333,64.58333333333334,70.0,67.5,62.5,68.75,70.0,70.83333333333334,71.25,67.91666666666667,68.75,67.91666666666667,67.91666666666667,67.08333333333333,52.083333333333336,67.08333333333333,69.16666666666667,68.33333333333333,67.91666666666667,69.16666666666667,70.41666666666667,70.41666666666667,67.91666666666667,67.5,67.91666666666667,68.33333333333333,70.0,70.83333333333334,67.91666666666667,66.66666666666666,70.0,71.66666666666667,68.33333333333333,67.5,70.41666666666667,70.41666666666667,68.33333333333333,67.91666666666667,70.0,65.41666666666667,67.08333333333333,68.75,67.91666666666667,67.5,68.33333333333333,62.5,69.58333333333333,72.08333333333333,69.58333333333333,69.16666666666667,69.58333333333333,70.0,71.25,69.58333333333333,67.5,70.41666666666667,67.91666666666667,68.75,70.0,67.91666666666667,69.16666666666667,69.16666666666667,47.91666666666667,70.0,69.16666666666667,70.41666666666667,70.0,65.0,67.91666666666667,68.75,69.58333333333333,69.58333333333333,69.58333333333333,65.41666666666667,67.5,70.83333333333334,70.41666666666667,70.41666666666667,61.66666666666667,70.0,67.91666666666667,70.41666666666667,69.58333333333333,67.5,66.66666666666666,68.75,67.91666666666667,70.83333333333334,68.75,70.0,67.5,71.25,71.66666666666667,67.5,47.91666666666667,69.16666666666667,71.66666666666667,71.25,67.5,68.75,70.41666666666667,66.25,69.16666666666667,47.91666666666667,70.0,65.83333333333333,70.0,67.91666666666667,68.75,67.91666666666667,68.33333333333333,69.58333333333333,65.41666666666667,68.75,69.16666666666667,69.58333333333333,69.16666666666667,68.33333333333333,69.58333333333333,72.08333333333333,71.66666666666667,69.16666666666667,70.0,69.16666666666667,67.91666666666667,68.33333333333333,69.16666666666667,70.41666666666667,57.91666666666667,71.25,68.75,68.33333333333333,47.91666666666667,69.58333333333333,67.91666666666667,67.91666666666667,70.0,70.41666666666667,68.75,66.25,61.25000000000001,67.5,69.58333333333333,69.58333333333333,68.75,67.91666666666667,69.16666666666667,68.33333333333333,68.33333333333333,67.5,69.16666666666667,47.91666666666667,69.16666666666667,69.16666666666667,69.16666666666667,70.0,71.66666666666667,67.91666666666667,69.58333333333333,71.25,66.25,69.58333333333333,69.58333333333333,67.5,71.66666666666667,70.83333333333334,70.41666666666667,68.33333333333333,70.41666666666667,71.66666666666667,65.83333333333333,59.583333333333336,47.5,70.83333333333334,47.91666666666667,69.58333333333333,70.0,70.41666666666667,68.75,64.16666666666667,70.83333333333334,66.66666666666666,70.41666666666667,71.25,69.58333333333333,69.58333333333333,68.33333333333333,70.0,69.58333333333333,65.83333333333333,71.25,60.416666666666664,70.83333333333334,71.25,68.75,69.58333333333333,66.66666666666666,70.83333333333334,69.16666666666667,69.58333333333333,66.66666666666666,71.66666666666667,60.83333333333333,67.5,65.83333333333333,70.0,68.33333333333333,67.08333333333333,68.33333333333333,70.0,65.0,68.75,69.58333333333333,69.16666666666667,70.41666666666667,70.0,69.58333333333333,67.91666666666667,68.33333333333333,70.41666666666667,69.16666666666667,53.75,67.5,69.58333333333333,69.16666666666667,70.83333333333334,70.83333333333334,70.83333333333334,68.75,68.75,68.75,69.58333333333333,69.16666666666667,68.33333333333333,68.33333333333333,69.16666666666667,69.58333333333333,69.16666666666667,45.0,70.0,68.33333333333333,70.0,68.33333333333333,70.41666666666667,68.75,67.5,71.25,70.83333333333334,66.66666666666666,72.08333333333333,68.75,67.91666666666667,70.0,68.33333333333333,68.33333333333333,70.83333333333334,66.66666666666666,70.0,68.75,68.33333333333333,67.91666666666667,71.25,67.5,68.33333333333333,71.25,69.58333333333333,72.08333333333333,47.91666666666667,71.25,71.25,67.91666666666667,70.41666666666667,70.41666666666667,68.33333333333333,67.5,67.5,71.25,70.0,68.75,70.83333333333334,71.66666666666667,69.58333333333333,70.41666666666667,67.5,67.5,68.33333333333333,69.16666666666667,66.25,71.66666666666667,65.41666666666667,69.58333333333333,70.41666666666667,69.58333333333333,70.41666666666667,71.25,72.08333333333333,69.58333333333333,70.0,68.75,70.0,69.58333333333333,69.58333333333333,70.0,68.75,70.41666666666667,67.91666666666667,69.16666666666667,67.5,70.0,67.91666666666667,67.08333333333333,72.08333333333333,65.41666666666667,68.33333333333333,70.41666666666667,69.58333333333333,67.91666666666667,70.0,71.66666666666667,71.66666666666667,69.58333333333333,71.66666666666667,69.58333333333333,70.41666666666667,69.58333333333333,70.41666666666667,64.16666666666667,70.0,65.41666666666667,70.83333333333334,68.75,67.91666666666667,67.91666666666667,68.75,55.41666666666667,70.41666666666667,65.0,72.91666666666666,70.41666666666667,68.33333333333333,67.5,68.33333333333333,69.16666666666667,67.5,70.83333333333334,69.16666666666667,68.75,70.83333333333334,67.5,69.16666666666667,67.91666666666667,70.83333333333334,69.16666666666667,65.41666666666667,73.33333333333333,68.75,69.58333333333333,69.58333333333333,71.66666666666667,69.58333333333333,68.75,67.08333333333333,67.5,69.16666666666667,68.33333333333333,52.916666666666664,68.75,71.66666666666667,71.25,71.25,47.91666666666667,70.0,70.83333333333334,70.0,72.08333333333333,69.16666666666667,70.0,68.75,67.91666666666667,65.0,68.75,57.49999999999999,69.16666666666667,71.66666666666667,69.16666666666667,71.66666666666667,70.83333333333334,70.0,67.91666666666667,66.66666666666666,69.58333333333333,67.91666666666667,67.91666666666667,68.33333333333333,69.58333333333333,69.16666666666667,68.33333333333333,69.16666666666667,62.916666666666664,69.16666666666667,67.08333333333333,69.16666666666667,69.58333333333333,70.41666666666667,67.5,70.83333333333334,70.41666666666667,69.16666666666667,71.66666666666667,70.0,68.75,69.58333333333333,67.5,67.91666666666667,67.91666666666667,69.16666666666667,68.75,71.25,69.16666666666667,70.0,70.41666666666667,68.33333333333333,70.41666666666667,62.083333333333336,68.75,66.66666666666666,68.75,68.33333333333333,67.5,67.08333333333333,70.0,68.75,69.58333333333333,69.58333333333333,65.83333333333333,70.41666666666667,70.0,68.33333333333333,67.5,69.58333333333333,68.75,66.25,67.5,67.08333333333333,69.58333333333333,65.0,68.75,68.75,70.0,67.91666666666667,67.5,69.58333333333333,61.25000000000001,69.58333333333333,71.25,70.83333333333334,68.75,67.5,67.5,68.75,70.41666666666667,66.25,68.33333333333333,67.5,70.0,72.08333333333333,68.75,47.91666666666667,68.75,69.58333333333333,66.66666666666666,70.41666666666667,68.75,70.41666666666667,47.91666666666667,67.91666666666667,71.66666666666667,67.08333333333333,70.0,70.83333333333334,58.75,69.16666666666667,67.91666666666667,67.08333333333333,64.58333333333334,70.41666666666667,70.0,67.08333333333333,67.5,69.58333333333333,73.33333333333333,67.5,72.08333333333333,65.0,67.91666666666667,69.16666666666667,70.41666666666667,68.33333333333333,68.75,69.58333333333333,67.08333333333333,70.41666666666667,70.0,67.91666666666667,68.75,67.5,68.75,68.75,67.5,65.41666666666667,67.91666666666667,69.16666666666667,69.58333333333333,70.0,69.16666666666667,68.33333333333333,66.66666666666666,70.41666666666667,67.91666666666667,47.91666666666667,69.16666666666667,70.41666666666667,70.41666666666667,69.58333333333333,65.83333333333333,67.08333333333333,70.0,67.91666666666667,69.16666666666667,68.75,71.25,68.75,69.16666666666667,69.58333333333333,68.75,68.75,66.25,70.0,71.25,68.75,67.91666666666667,67.91666666666667,47.91666666666667,72.5,68.75,68.33333333333333,72.08333333333333,67.91666666666667,69.58333333333333,68.75,69.58333333333333,69.58333333333333,68.75,71.66666666666667,65.83333333333333,69.16666666666667,69.58333333333333,69.58333333333333,69.58333333333333,70.0,70.0,74.58333333333333,67.08333333333333,67.5,67.91666666666667,68.75,69.16666666666667,68.75,70.0,70.83333333333334,65.41666666666667,69.58333333333333,70.0,67.08333333333333,72.5,69.16666666666667,70.41666666666667,70.83333333333334,67.5,70.41666666666667,69.16666666666667,69.58333333333333,72.08333333333333,68.33333333333333,68.75,69.58333333333333,70.0,67.08333333333333,69.58333333333333,69.58333333333333,66.66666666666666,70.0,69.58333333333333,71.25,65.83333333333333,69.58333333333333,69.58333333333333,70.41666666666667,70.83333333333334,67.5,70.0,68.33333333333333,72.08333333333333,66.66666666666666,69.58333333333333,68.33333333333333,69.58333333333333,68.75,70.0,69.58333333333333,70.0,67.91666666666667,70.83333333333334,66.25,67.5,70.41666666666667,69.16666666666667,70.0,66.66666666666666,69.58333333333333,64.58333333333334,68.33333333333333,71.66666666666667,70.0,72.08333333333333,68.33333333333333,70.83333333333334,69.16666666666667,67.5,69.16666666666667,68.75,62.916666666666664,68.75,67.5,68.75,69.58333333333333,68.33333333333333,69.58333333333333,69.58333333333333,65.83333333333333,70.0,69.58333333333333,68.75,68.33333333333333,69.16666666666667,67.91666666666667,67.91666666666667,69.16666666666667,69.58333333333333,69.58333333333333,67.5,58.333333333333336,67.5,67.5,67.91666666666667,68.75,67.08333333333333,70.0,67.91666666666667,68.33333333333333,67.08333333333333,69.58333333333333,71.25,68.33333333333333,69.16666666666667,69.58333333333333,69.16666666666667,71.25,67.08333333333333,69.16666666666667,70.41666666666667,68.75,70.41666666666667,69.16666666666667,69.16666666666667,47.91666666666667,70.0,70.83333333333334,67.91666666666667,67.08333333333333,67.91666666666667,69.16666666666667,70.41666666666667,67.5,72.5,67.5,67.08333333333333,69.16666666666667,68.33333333333333,67.91666666666667,69.16666666666667,71.66666666666667,69.58333333333333,69.16666666666667,67.08333333333333,67.91666666666667,68.33333333333333,71.66666666666667,61.66666666666667,69.58333333333333,66.66666666666666,70.0,70.41666666666667,68.75,47.91666666666667,69.58333333333333,70.0,70.41666666666667,67.08333333333333,64.16666666666667,66.66666666666666,67.08333333333333,69.58333333333333,69.58333333333333,69.16666666666667,65.83333333333333,67.08333333333333,47.91666666666667,70.0,68.75,61.25000000000001,68.75,69.16666666666667,66.25,69.58333333333333,70.41666666666667,67.91666666666667,67.08333333333333,70.41666666666667,70.83333333333334,70.0,67.08333333333333,68.75,65.83333333333333,70.41666666666667,70.83333333333334,70.0,69.58333333333333,67.5,69.58333333333333,70.41666666666667,54.58333333333333,70.0,70.41666666666667,70.0,65.41666666666667,69.16666666666667,68.75,69.16666666666667,70.41666666666667,65.83333333333333,65.83333333333333,68.33333333333333,70.83333333333334,71.25,67.08333333333333,71.25,47.91666666666667,69.58333333333333,68.75,71.25,68.33333333333333,66.25,70.0,69.58333333333333,72.91666666666666,67.91666666666667,69.16666666666667,67.08333333333333,69.16666666666667,67.08333333333333,69.58333333333333,69.16666666666667,67.91666666666667,68.75,65.0,70.41666666666667,68.33333333333333,47.91666666666667,66.66666666666666,68.75,69.58333333333333,57.08333333333333,67.91666666666667,65.0,67.08333333333333,68.33333333333333,70.83333333333334,70.41666666666667,64.58333333333334,69.58333333333333,68.33333333333333,70.0,68.75,62.083333333333336,63.33333333333333,70.83333333333334,70.0,47.91666666666667,70.0,69.16666666666667,68.33333333333333,65.0,70.83333333333334,67.5,67.08333333333333,68.75,67.91666666666667,67.5,69.58333333333333,69.58333333333333,68.33333333333333,68.75,69.16666666666667,69.16666666666667,70.83333333333334,65.0,70.41666666666667,67.5,67.5,67.91666666666667,69.58333333333333,68.75,67.91666666666667,70.83333333333334,66.25,67.91666666666667,67.91666666666667,70.83333333333334,67.91666666666667,68.75,69.16666666666667,71.66666666666667,69.16666666666667,69.58333333333333,69.58333333333333,70.83333333333334,70.83333333333334,65.83333333333333,62.5,69.16666666666667,47.91666666666667,67.5,69.16666666666667,68.75,67.91666666666667,72.91666666666666,66.66666666666666,61.25000000000001,68.33333333333333,67.91666666666667,68.75,67.91666666666667,65.83333333333333,47.91666666666667,68.33333333333333,66.66666666666666,65.83333333333333,70.83333333333334,71.25,71.25,66.66666666666666,63.33333333333333,70.0,68.33333333333333,70.0,69.16666666666667,69.16666666666667,69.58333333333333,61.66666666666667,69.16666666666667,70.0,67.08333333333333,67.08333333333333,69.58333333333333,67.08333333333333,68.33333333333333,71.25,67.5,64.58333333333334,69.16666666666667,68.75,70.41666666666667,69.58333333333333,71.66666666666667,69.16666666666667,67.08333333333333,71.25,70.41666666666667,69.16666666666667,70.41666666666667,70.41666666666667,69.58333333333333,71.25,69.58333333333333,69.58333333333333,67.91666666666667,69.16666666666667,70.83333333333334,69.16666666666667,72.5,70.83333333333334,68.33333333333333,67.5,68.75,72.5,69.58333333333333,68.75,70.0,71.66666666666667,70.41666666666667,66.66666666666666,68.75,71.25,70.0,71.25,71.66666666666667,69.16666666666667,70.41666666666667,70.41666666666667,68.75,69.16666666666667,69.58333333333333,70.0,70.41666666666667,70.0,71.66666666666667,72.08333333333333,68.33333333333333,70.83333333333334,67.91666666666667,69.58333333333333,70.0,67.91666666666667,68.33333333333333,71.66666666666667,68.75,70.0,67.5,69.58333333333333,68.75,70.41666666666667,68.33333333333333,69.58333333333333,70.83333333333334,72.08333333333333,47.91666666666667,68.33333333333333,70.0,67.5,69.16666666666667,70.41666666666667,67.08333333333333,71.66666666666667,66.25,53.75,68.75,68.33333333333333,70.41666666666667,67.5,70.83333333333334,69.58333333333333,67.08333333333333,71.25,72.5,69.58333333333333,71.25,69.16666666666667,69.58333333333333,67.91666666666667,70.0,51.66666666666667,68.75,68.33333333333333,72.08333333333333,67.5,70.83333333333334,67.91666666666667,70.0,71.66666666666667,70.83333333333334,71.25,68.75,67.5,70.41666666666667,70.0,71.25,70.83333333333334,67.08333333333333,68.33333333333333,67.5,69.58333333333333,69.16666666666667,68.33333333333333,69.58333333333333,67.5,72.5,67.91666666666667,69.16666666666667,69.58333333333333,70.41666666666667,72.08333333333333,68.75,68.33333333333333,69.16666666666667,68.33333333333333,69.58333333333333,69.58333333333333,70.0,55.833333333333336,69.16666666666667,70.83333333333334,67.5,70.0,69.16666666666667,69.58333333333333,69.16666666666667,70.41666666666667,71.25,68.75,68.33333333333333,68.75,70.41666666666667,66.25,69.16666666666667,68.33333333333333,68.75,69.16666666666667,65.83333333333333,69.58333333333333,71.66666666666667,66.25,69.16666666666667,69.58333333333333,69.16666666666667,62.083333333333336,72.08333333333333,67.08333333333333,68.33333333333333,68.33333333333333,69.16666666666667,70.41666666666667,70.0,71.25,69.16666666666667,67.08333333333333,70.0,66.25,68.33333333333333,69.16666666666667,67.91666666666667,68.33333333333333,70.0,67.5,69.16666666666667,70.41666666666667,67.91666666666667,68.33333333333333,66.25,70.83333333333334,62.916666666666664,68.75,72.08333333333333,68.75,67.91666666666667,67.08333333333333,68.75,67.08333333333333,68.75,67.91666666666667,68.75,70.0,70.41666666666667,67.5,69.16666666666667,70.0,70.0,68.75,68.33333333333333,71.25,66.25,63.33333333333333,67.5,70.83333333333334,70.41666666666667,62.083333333333336,70.83333333333334,67.91666666666667,69.58333333333333,71.25,67.5,71.66666666666667,67.5,68.33333333333333,70.0,70.0,71.25,67.91666666666667,64.58333333333334,67.91666666666667,68.75,70.0,70.41666666666667,68.33333333333333,70.0,71.25,70.83333333333334,70.41666666666667,69.16666666666667,69.58333333333333,68.33333333333333,72.08333333333333,67.08333333333333,67.08333333333333,70.83333333333334,66.25,70.41666666666667,65.41666666666667,67.08333333333333,62.083333333333336,69.58333333333333,68.75,70.41666666666667,71.66666666666667,69.16666666666667,70.0,68.33333333333333,68.33333333333333,67.5,66.66666666666666,69.16666666666667,70.0,71.25,69.16666666666667,68.75,69.16666666666667,68.33333333333333,70.83333333333334,70.41666666666667,68.33333333333333,67.5,67.91666666666667,68.75,68.33333333333333,68.75,68.75,68.33333333333333,70.0,66.66666666666666,68.75,68.33333333333333,64.58333333333334,70.83333333333334,65.0,65.83333333333333,66.25,68.33333333333333,66.25,67.5,67.91666666666667,68.75,67.91666666666667,71.25,69.16666666666667,70.83333333333334,69.58333333333333,70.0,67.08333333333333,69.58333333333333,70.41666666666667,67.08333333333333,69.16666666666667,69.16666666666667,71.25,69.16666666666667,66.66666666666666,67.91666666666667,68.75,71.25,68.33333333333333,67.91666666666667,70.0,67.08333333333333,70.0,67.5,66.25,61.66666666666667,67.5,69.16666666666667,68.75,66.25,68.75,68.33333333333333,67.08333333333333,68.33333333333333,69.16666666666667,68.75,67.08333333333333,70.41666666666667,66.66666666666666,70.0,67.08333333333333,72.08333333333333,69.58333333333333,69.58333333333333,67.91666666666667,67.91666666666667,68.75,69.16666666666667,67.5,66.25,67.5,70.41666666666667,70.0,68.33333333333333,69.58333333333333,66.66666666666666,70.0,67.08333333333333,69.58333333333333,65.0,68.75,68.33333333333333,67.91666666666667,68.33333333333333,69.16666666666667,52.916666666666664,68.75,68.33333333333333,67.08333333333333,65.83333333333333,73.33333333333333,69.58333333333333,66.66666666666666,57.49999999999999,70.0,70.0,68.33333333333333,69.16666666666667,68.75,67.91666666666667,68.33333333333333,66.66666666666666,69.16666666666667,66.66666666666666,68.75,68.75,69.16666666666667,70.0,69.16666666666667,68.75,70.0,69.58333333333333,70.0,68.33333333333333,68.33333333333333,67.08333333333333,67.5,67.5,69.58333333333333,70.0,69.16666666666667,70.0,71.25,71.25,69.16666666666667,68.75,71.25,69.16666666666667,69.58333333333333,68.75,69.16666666666667,47.91666666666667,69.16666666666667,70.83333333333334,69.16666666666667,68.75,70.41666666666667,72.08333333333333,68.75,67.08333333333333,70.0,68.75,67.91666666666667,68.33333333333333,68.33333333333333,67.91666666666667,70.0,69.16666666666667,72.08333333333333,67.91666666666667,70.41666666666667,67.91666666666667,70.41666666666667,69.58333333333333,69.16666666666667,69.58333333333333,69.16666666666667,69.16666666666667,68.75,68.75,69.58333333333333,67.08333333333333,70.0,68.33333333333333,70.41666666666667,69.58333333333333,70.41666666666667,68.75,69.16666666666667,72.91666666666666,70.0,66.66666666666666,68.75,66.25,67.91666666666667,71.66666666666667,69.58333333333333,69.58333333333333,70.41666666666667,67.08333333333333,67.5,67.5,65.0,68.75,68.33333333333333,67.91666666666667,67.08333333333333,68.75,70.0,70.0,67.91666666666667,70.41666666666667,69.58333333333333,67.08333333333333,68.75,69.58333333333333,67.5,69.16666666666667,69.16666666666667,65.83333333333333,71.66666666666667,66.66666666666666,66.25,68.33333333333333,67.08333333333333,70.83333333333334,70.41666666666667,69.58333333333333,68.75,69.58333333333333,69.58333333333333,69.58333333333333,70.83333333333334,69.58333333333333,65.0,70.0,69.16666666666667,67.08333333333333,68.33333333333333,67.5,65.0,68.33333333333333,68.75,67.08333333333333,67.08333333333333,66.66666666666666,67.91666666666667,67.91666666666667,68.33333333333333,70.0,69.16666666666667,69.58333333333333,67.91666666666667,71.25,68.75,67.5,68.33333333333333,64.16666666666667,69.16666666666667,67.08333333333333,61.66666666666667,67.5,68.75,66.66666666666666,71.66666666666667,69.58333333333333,69.16666666666667,68.33333333333333,68.75,67.08333333333333,67.5,68.33333333333333,72.08333333333333,70.83333333333334,68.75,69.58333333333333,70.0,67.08333333333333,67.91666666666667,68.33333333333333,71.66666666666667,72.91666666666666,69.58333333333333,72.5,68.33333333333333,68.75,67.91666666666667,67.91666666666667,69.58333333333333,70.41666666666667,61.66666666666667,70.41666666666667,47.91666666666667,69.16666666666667,67.91666666666667,67.91666666666667,73.33333333333333,71.25,70.83333333333334,62.916666666666664,66.25,70.41666666666667,66.66666666666666,67.91666666666667,70.0,67.91666666666667,67.91666666666667,68.75,72.5,67.08333333333333,69.58333333333333,67.5,68.75,69.58333333333333,69.58333333333333,70.41666666666667,69.16666666666667,72.5,71.66666666666667,70.41666666666667,70.83333333333334,67.91666666666667,62.5,66.25,72.5,65.83333333333333,64.16666666666667,71.66666666666667,68.33333333333333,70.41666666666667,70.83333333333334,70.41666666666667,69.16666666666667,69.58333333333333,67.5,47.91666666666667,69.16666666666667,68.75,68.33333333333333,70.0,67.91666666666667,70.41666666666667,70.0,47.91666666666667,67.5,67.5,68.33333333333333,54.166666666666664,67.5,69.16666666666667,67.08333333333333,70.0,68.33333333333333,72.08333333333333,71.66666666666667,68.33333333333333,69.58333333333333,67.5,69.58333333333333,67.91666666666667,65.41666666666667,69.58333333333333,66.66666666666666,70.0,70.0,69.16666666666667,69.58333333333333,66.25,70.41666666666667,68.75,68.33333333333333,69.16666666666667,66.66666666666666,67.5,70.0,67.5,61.25000000000001,66.25,69.58333333333333,68.75,70.41666666666667,66.25,70.0,68.75,68.75,69.16666666666667,71.25,69.58333333333333,70.41666666666667,69.58333333333333,68.33333333333333,68.75,69.16666666666667,68.33333333333333,69.16666666666667,69.16666666666667,70.41666666666667,69.16666666666667,69.58333333333333,68.33333333333333,68.75,60.83333333333333,68.33333333333333,70.0,69.58333333333333,67.5,71.25,70.41666666666667,69.16666666666667,69.58333333333333,70.0,70.0,70.0,69.58333333333333,69.16666666666667,68.33333333333333,68.75,67.91666666666667,65.41666666666667,68.33333333333333,70.0,66.66666666666666,70.0,68.75,67.91666666666667,67.5,67.91666666666667,68.75,70.0,67.91666666666667,66.66666666666666,68.33333333333333,70.41666666666667,65.83333333333333,71.25,70.0,47.91666666666667,70.41666666666667,69.58333333333333,66.66666666666666,68.33333333333333,69.16666666666667,65.0,67.5,68.75,68.75,47.91666666666667,70.0,66.66666666666666,70.41666666666667,67.08333333333333,67.91666666666667,70.83333333333334,67.5,70.0,67.91666666666667,65.41666666666667,71.25,72.08333333333333,65.41666666666667,67.08333333333333,67.08333333333333,70.83333333333334,68.33333333333333,47.91666666666667,67.91666666666667,72.08333333333333,70.0,71.25,66.66666666666666,67.5,63.74999999999999,68.33333333333333,70.41666666666667,66.66666666666666,70.41666666666667,69.58333333333333,71.25,70.0,68.33333333333333,67.08333333333333,67.91666666666667,69.58333333333333,68.33333333333333,70.0,65.0,69.16666666666667,47.91666666666667,65.0,69.58333333333333,67.5,69.16666666666667,67.5,68.75,72.08333333333333,68.33333333333333,47.91666666666667,69.58333333333333,69.16666666666667,67.5,70.0,70.41666666666667,64.16666666666667,70.41666666666667,69.58333333333333,67.91666666666667,66.66666666666666,69.16666666666667,70.83333333333334,70.0,68.33333333333333,67.08333333333333,66.66666666666666,67.91666666666667,65.83333333333333,69.16666666666667,67.91666666666667,66.66666666666666,68.75,68.33333333333333,70.83333333333334,69.16666666666667,68.33333333333333,52.916666666666664,67.91666666666667,68.33333333333333,69.16666666666667,70.41666666666667,71.25,69.58333333333333,70.0,68.75,70.83333333333334,67.91666666666667,70.83333333333334,69.58333333333333,69.16666666666667,70.83333333333334,68.75,68.75,67.08333333333333,70.83333333333334,72.5,70.83333333333334,71.66666666666667,69.58333333333333,69.58333333333333,70.83333333333334,70.0,65.41666666666667,69.58333333333333,67.91666666666667,71.66666666666667,69.58333333333333,70.41666666666667,68.75,69.58333333333333,67.91666666666667,69.16666666666667,71.25,69.58333333333333,69.16666666666667,64.58333333333334,72.5,71.25,67.08333333333333,68.33333333333333,70.0,71.66666666666667,68.75,71.66666666666667,70.0,71.66666666666667,66.66666666666666,69.58333333333333,67.91666666666667,67.08333333333333,70.83333333333334,69.58333333333333,70.83333333333334,68.33333333333333,70.41666666666667,72.5,71.66666666666667,72.5,67.91666666666667,67.5,69.16666666666667,69.16666666666667,69.16666666666667,65.83333333333333,70.41666666666667,69.58333333333333,70.41666666666667,68.33333333333333,70.83333333333334,70.41666666666667,68.33333333333333,70.41666666666667,70.0,67.91666666666667,69.16666666666667,70.0,70.41666666666667,68.33333333333333,69.16666666666667,68.33333333333333,70.83333333333334,66.66666666666666,69.58333333333333,71.25,69.58333333333333,70.83333333333334,69.58333333333333,70.41666666666667,68.33333333333333,70.0,67.5,70.83333333333334,67.91666666666667,68.75,70.0,71.66666666666667,70.0,67.08333333333333,67.08333333333333,67.91666666666667,71.66666666666667,72.08333333333333,68.75,68.75,68.33333333333333,70.41666666666667,70.0,69.16666666666667,69.58333333333333,70.41666666666667,65.83333333333333,68.75,65.41666666666667,68.75,70.41666666666667,70.0,70.0,69.58333333333333,67.5,68.33333333333333,67.91666666666667,71.66666666666667,70.0,70.0,69.58333333333333,70.41666666666667,66.25,67.08333333333333,68.75,64.58333333333334,68.33333333333333,70.83333333333334,70.41666666666667,68.75,67.08333333333333,70.41666666666667,67.91666666666667,70.41666666666667,68.33333333333333,69.16666666666667,67.5,67.91666666666667,67.5,70.41666666666667,70.41666666666667,69.58333333333333,71.25,70.0,67.5,69.16666666666667,67.5,70.0,68.33333333333333,65.41666666666667,68.75,69.58333333333333,70.0,68.33333333333333,66.66666666666666,70.0,70.83333333333334,71.25,67.91666666666667,68.33333333333333,69.16666666666667,70.0,66.25,67.08333333333333,60.416666666666664,67.91666666666667,70.41666666666667,71.66666666666667,68.75,67.91666666666667,68.75,66.25,70.0,66.25,67.91666666666667,70.83333333333334,70.0,69.16666666666667,68.75,68.75,70.0,66.66666666666666,67.91666666666667,66.25,68.33333333333333,72.91666666666666,70.83333333333334,70.41666666666667,70.83333333333334,67.5,70.0,70.41666666666667,68.33333333333333,63.33333333333333,67.91666666666667,69.58333333333333,71.25,67.5,71.66666666666667,67.5,67.91666666666667,67.08333333333333,67.91666666666667,68.75,71.66666666666667,68.75,68.33333333333333,71.25,68.75,69.16666666666667,70.0,66.66666666666666,69.58333333333333,70.0,67.5,68.75,66.25,71.66666666666667,68.33333333333333,68.33333333333333,70.41666666666667,69.58333333333333,69.16666666666667,70.41666666666667,70.0,70.0,68.33333333333333,68.33333333333333,69.16666666666667,65.41666666666667,67.5,69.16666666666667,67.5,68.33333333333333,66.66666666666666,70.0,66.25,67.91666666666667,69.58333333333333,70.41666666666667,69.58333333333333,67.08333333333333,70.41666666666667,67.91666666666667,68.75,71.66666666666667,66.66666666666666,70.83333333333334,71.25,68.33333333333333,67.5,67.5,67.5,65.0,69.16666666666667,69.58333333333333,70.0,70.0,70.83333333333334,68.75,70.41666666666667,70.0,68.33333333333333,66.66666666666666,69.16666666666667,71.66666666666667,68.33333333333333,62.5,71.25,67.5,56.666666666666664,66.66666666666666,67.5,70.83333333333334,68.75,70.0,70.41666666666667,69.58333333333333,72.08333333333333,71.66666666666667,68.75,67.91666666666667,69.16666666666667,69.16666666666667,69.16666666666667,60.83333333333333,68.75,61.25000000000001,70.0,47.91666666666667,70.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#07F\",\"size\":4},\"mode\":\"markers\",\"name\":\"NEW test dataset accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[58.666666666666664,66.33333333333333,47.66666666666667,47.66666666666667,47.66666666666667,66.0,65.33333333333333,69.33333333333334,60.66666666666667,66.33333333333333,67.33333333333333,66.66666666666666,51.33333333333333,67.66666666666666,47.66666666666667,58.333333333333336,47.66666666666667,62.0,67.66666666666666,64.33333333333333,67.66666666666666,67.66666666666666,67.0,66.33333333333333,66.66666666666666,62.33333333333333,47.66666666666667,67.0,63.66666666666667,67.33333333333333,63.0,67.0,50.66666666666667,69.0,47.66666666666667,65.33333333333333,68.0,64.33333333333333,65.66666666666666,60.0,68.33333333333333,55.666666666666664,68.66666666666667,71.0,64.66666666666666,66.66666666666666,68.0,47.66666666666667,63.0,53.333333333333336,47.66666666666667,47.66666666666667,66.66666666666666,69.0,68.0,62.66666666666667,47.66666666666667,67.66666666666666,67.0,64.0,68.0,60.333333333333336,59.66666666666667,47.66666666666667,67.33333333333333,68.66666666666667,70.0,67.66666666666666,66.33333333333333,64.33333333333333,68.66666666666667,68.0,68.0,68.33333333333333,64.0,67.66666666666666,66.66666666666666,69.0,66.66666666666666,63.33333333333333,62.33333333333333,65.66666666666666,67.33333333333333,63.33333333333333,67.0,61.33333333333333,70.0,67.0,62.0,66.66666666666666,67.66666666666666,67.0,65.66666666666666,64.0,67.0,66.33333333333333,47.66666666666667,65.66666666666666,62.0,47.66666666666667,53.666666666666664,47.66666666666667,47.66666666666667,54.333333333333336,58.333333333333336,63.0,68.33333333333333,67.0,64.0,65.33333333333333,65.66666666666666,47.66666666666667,65.33333333333333,69.66666666666667,65.33333333333333,67.0,69.33333333333334,66.66666666666666,63.33333333333333,68.0,66.0,67.33333333333333,64.66666666666666,47.66666666666667,65.33333333333333,47.66666666666667,61.66666666666667,64.33333333333333,63.66666666666667,65.0,67.0,62.33333333333333,68.0,66.66666666666666,47.66666666666667,67.66666666666666,65.33333333333333,65.0,68.66666666666667,67.33333333333333,69.66666666666667,62.0,66.0,59.66666666666667,62.0,69.33333333333334,66.66666666666666,65.33333333333333,65.33333333333333,63.66666666666667,65.0,68.33333333333333,66.0,63.33333333333333,66.33333333333333,66.33333333333333,64.0,65.33333333333333,67.0,68.0,68.33333333333333,67.66666666666666,64.33333333333333,65.66666666666666,61.33333333333333,67.66666666666666,67.33333333333333,57.333333333333336,64.66666666666666,47.66666666666667,63.33333333333333,68.0,67.33333333333333,67.66666666666666,68.33333333333333,66.66666666666666,62.66666666666667,69.0,66.33333333333333,69.0,65.66666666666666,65.0,66.0,64.33333333333333,63.33333333333333,67.0,54.666666666666664,67.0,67.33333333333333,47.66666666666667,70.0,64.66666666666666,69.0,47.66666666666667,65.0,63.0,67.33333333333333,64.33333333333333,68.0,64.33333333333333,57.99999999999999,68.0,66.0,60.0,67.33333333333333,65.33333333333333,67.66666666666666,65.33333333333333,68.33333333333333,66.0,65.66666666666666,47.66666666666667,60.66666666666667,66.0,68.66666666666667,68.0,66.66666666666666,66.0,67.66666666666666,68.0,64.66666666666666,66.33333333333333,64.33333333333333,47.66666666666667,67.0,66.66666666666666,68.0,63.66666666666667,67.33333333333333,67.33333333333333,66.33333333333333,65.66666666666666,66.66666666666666,68.0,67.33333333333333,62.66666666666667,65.33333333333333,66.33333333333333,64.33333333333333,67.0,64.33333333333333,64.66666666666666,68.0,65.0,67.0,53.666666666666664,65.0,47.66666666666667,47.66666666666667,67.66666666666666,62.33333333333333,52.33333333333333,66.33333333333333,68.0,67.66666666666666,47.66666666666667,67.33333333333333,66.0,67.0,63.66666666666667,64.66666666666666,67.66666666666666,68.33333333333333,64.33333333333333,47.66666666666667,64.66666666666666,65.66666666666666,62.33333333333333,68.0,67.0,64.33333333333333,64.33333333333333,68.33333333333333,56.333333333333336,67.66666666666666,59.66666666666667,69.0,65.33333333333333,68.33333333333333,67.33333333333333,68.66666666666667,66.0,64.0,67.66666666666666,67.66666666666666,66.66666666666666,66.66666666666666,67.66666666666666,67.33333333333333,69.0,65.0,67.66666666666666,67.33333333333333,69.0,65.33333333333333,68.66666666666667,63.33333333333333,67.66666666666666,68.0,62.0,65.33333333333333,69.66666666666667,67.66666666666666,47.66666666666667,68.0,47.66666666666667,66.66666666666666,68.33333333333333,68.33333333333333,66.33333333333333,62.0,67.66666666666666,64.66666666666666,68.33333333333333,54.333333333333336,67.0,63.66666666666667,66.33333333333333,69.33333333333334,69.66666666666667,65.66666666666666,65.33333333333333,65.66666666666666,68.66666666666667,66.66666666666666,64.66666666666666,66.66666666666666,61.66666666666667,67.33333333333333,62.33333333333333,65.33333333333333,65.33333333333333,65.66666666666666,65.0,67.0,66.0,63.33333333333333,66.33333333333333,68.0,65.0,66.33333333333333,68.33333333333333,66.33333333333333,63.33333333333333,67.0,64.33333333333333,67.0,68.33333333333333,66.0,65.33333333333333,67.0,69.0,65.66666666666666,67.66666666666666,67.66666666666666,68.0,64.33333333333333,67.0,47.66666666666667,68.0,65.66666666666666,66.66666666666666,47.66666666666667,53.0,67.33333333333333,66.0,64.33333333333333,66.33333333333333,64.0,64.33333333333333,67.66666666666666,59.333333333333336,65.0,69.0,68.66666666666667,66.33333333333333,65.33333333333333,65.66666666666666,56.333333333333336,67.33333333333333,67.66666666666666,68.33333333333333,59.333333333333336,65.33333333333333,66.33333333333333,68.0,67.0,65.0,68.0,68.33333333333333,65.0,66.0,67.0,65.0,47.66666666666667,67.66666666666666,47.66666666666667,67.0,68.0,62.66666666666667,62.66666666666667,67.33333333333333,68.66666666666667,64.33333333333333,65.66666666666666,64.66666666666666,63.0,65.33333333333333,67.0,66.66666666666666,65.66666666666666,66.0,66.66666666666666,64.66666666666666,66.66666666666666,64.66666666666666,67.66666666666666,65.0,67.66666666666666,67.33333333333333,68.33333333333333,67.0,66.33333333333333,66.33333333333333,61.66666666666667,65.66666666666666,70.33333333333334,68.0,67.66666666666666,66.0,67.0,66.66666666666666,42.66666666666667,65.0,67.66666666666666,68.0,69.33333333333334,69.0,47.66666666666667,67.0,66.33333333333333,67.66666666666666,67.0,65.66666666666666,64.66666666666666,64.66666666666666,64.33333333333333,66.66666666666666,67.33333333333333,66.33333333333333,69.33333333333334,65.33333333333333,65.66666666666666,67.33333333333333,66.66666666666666,65.0,68.0,69.66666666666667,68.0,67.33333333333333,67.66666666666666,65.0,65.66666666666666,64.0,47.66666666666667,70.66666666666667,69.0,67.0,66.0,63.66666666666667,66.0,68.0,66.0,64.33333333333333,47.66666666666667,70.0,68.33333333333333,68.33333333333333,47.0,68.0,65.66666666666666,65.66666666666666,65.66666666666666,65.66666666666666,67.33333333333333,64.66666666666666,67.0,64.33333333333333,65.66666666666666,63.33333333333333,67.0,66.0,67.66666666666666,66.66666666666666,69.66666666666667,68.33333333333333,67.0,67.33333333333333,66.0,66.66666666666666,67.33333333333333,67.0,47.66666666666667,65.33333333333333,64.66666666666666,68.33333333333333,51.33333333333333,60.66666666666667,65.0,66.66666666666666,66.0,67.33333333333333,65.33333333333333,65.33333333333333,66.66666666666666,67.66666666666666,60.0,67.0,66.33333333333333,65.66666666666666,67.33333333333333,47.66666666666667,67.66666666666666,56.00000000000001,65.0,65.0,65.0,68.33333333333333,68.66666666666667,47.66666666666667,67.66666666666666,68.66666666666667,67.66666666666666,66.66666666666666,67.33333333333333,68.0,66.33333333333333,47.66666666666667,68.0,66.33333333333333,51.33333333333333,65.0,65.66666666666666,67.33333333333333,67.0,63.33333333333333,64.66666666666666,69.33333333333334,67.0,65.0,68.66666666666667,66.0,68.0,64.66666666666666,67.0,47.66666666666667,67.33333333333333,66.33333333333333,64.0,68.66666666666667,71.33333333333334,67.66666666666666,67.33333333333333,68.0,66.66666666666666,67.33333333333333,68.66666666666667,47.66666666666667,67.33333333333333,67.0,65.0,61.0,65.66666666666666,68.33333333333333,65.66666666666666,66.66666666666666,65.66666666666666,66.66666666666666,68.0,65.33333333333333,65.66666666666666,69.0,68.33333333333333,66.33333333333333,67.66666666666666,68.0,67.33333333333333,66.33333333333333,68.0,67.66666666666666,66.66666666666666,67.33333333333333,67.33333333333333,65.66666666666666,65.0,67.33333333333333,68.33333333333333,65.0,68.33333333333333,67.33333333333333,69.0,66.33333333333333,64.0,67.33333333333333,65.33333333333333,68.66666666666667,67.0,68.33333333333333,67.33333333333333,67.0,65.66666666666666,67.33333333333333,68.0,64.66666666666666,62.66666666666667,61.0,63.66666666666667,62.66666666666667,65.33333333333333,67.33333333333333,65.33333333333333,66.66666666666666,64.0,66.66666666666666,69.0,66.33333333333333,64.0,67.0,64.33333333333333,63.0,65.33333333333333,68.33333333333333,60.333333333333336,66.66666666666666,64.0,68.66666666666667,66.0,66.66666666666666,65.66666666666666,65.33333333333333,66.66666666666666,64.66666666666666,65.66666666666666,64.33333333333333,70.33333333333334,69.33333333333334,65.0,64.0,67.66666666666666,69.0,69.33333333333334,67.33333333333333,62.66666666666667,68.66666666666667,66.0,67.0,65.66666666666666,67.0,48.0,69.0,68.33333333333333,70.0,65.33333333333333,66.66666666666666,68.0,66.66666666666666,67.33333333333333,64.66666666666666,61.66666666666667,67.33333333333333,66.66666666666666,64.66666666666666,65.66666666666666,67.66666666666666,64.66666666666666,67.33333333333333,63.66666666666667,67.66666666666666,66.0,66.33333333333333,67.0,68.33333333333333,67.0,64.0,61.66666666666667,67.66666666666666,66.66666666666666,66.66666666666666,67.66666666666666,65.33333333333333,67.33333333333333,67.66666666666666,67.66666666666666,64.33333333333333,68.0,69.66666666666667,67.33333333333333,59.333333333333336,65.66666666666666,68.0,67.0,65.66666666666666,69.0,67.0,69.33333333333334,65.0,67.0,69.66666666666667,66.0,66.66666666666666,67.33333333333333,51.66666666666667,67.0,65.0,60.333333333333336,65.66666666666666,68.33333333333333,65.0,68.33333333333333,65.66666666666666,69.0,67.0,65.0,65.0,69.0,66.33333333333333,63.0,67.33333333333333,66.33333333333333,66.33333333333333,67.0,65.66666666666666,66.0,66.0,66.33333333333333,66.66666666666666,67.33333333333333,67.33333333333333,68.0,68.0,61.33333333333333,64.0,64.0,67.66666666666666,66.0,69.33333333333334,68.66666666666667,65.0,64.66666666666666,65.0,47.66666666666667,57.99999999999999,65.33333333333333,65.0,47.66666666666667,64.66666666666666,66.0,67.66666666666666,69.33333333333334,68.0,67.66666666666666,64.0,68.33333333333333,67.0,65.33333333333333,69.0,52.666666666666664,65.33333333333333,67.0,43.333333333333336,67.0,66.66666666666666,66.33333333333333,64.33333333333333,67.0,65.66666666666666,63.33333333333333,63.66666666666667,67.33333333333333,65.0,64.0,65.0,66.66666666666666,60.333333333333336,68.0,68.66666666666667,69.0,66.33333333333333,67.0,67.33333333333333,66.33333333333333,66.66666666666666,66.33333333333333,67.33333333333333,65.66666666666666,68.66666666666667,66.66666666666666,65.66666666666666,67.33333333333333,69.0,67.0,68.33333333333333,65.66666666666666,66.66666666666666,65.66666666666666,66.0,67.0,66.33333333333333,68.33333333333333,66.66666666666666,68.33333333333333,67.66666666666666,65.66666666666666,65.0,66.0,67.33333333333333,65.33333333333333,66.66666666666666,66.66666666666666,67.0,65.0,66.0,64.33333333333333,65.66666666666666,66.33333333333333,65.66666666666666,63.33333333333333,65.0,68.33333333333333,65.66666666666666,64.66666666666666,66.66666666666666,64.33333333333333,67.0,67.66666666666666,68.66666666666667,66.66666666666666,67.33333333333333,65.33333333333333,62.33333333333333,67.66666666666666,65.66666666666666,64.66666666666666,68.33333333333333,63.66666666666667,67.33333333333333,64.33333333333333,68.0,68.66666666666667,62.66666666666667,66.33333333333333,69.33333333333334,67.33333333333333,56.666666666666664,67.0,65.66666666666666,68.33333333333333,65.66666666666666,69.33333333333334,65.66666666666666,68.66666666666667,65.33333333333333,66.66666666666666,65.0,66.66666666666666,66.0,64.0,66.66666666666666,68.33333333333333,68.0,67.66666666666666,68.0,65.33333333333333,67.0,68.66666666666667,67.0,67.33333333333333,68.0,60.0,67.0,65.66666666666666,66.0,68.66666666666667,63.66666666666667,68.0,65.66666666666666,63.0,65.33333333333333,67.33333333333333,66.0,63.66666666666667,69.0,68.0,67.66666666666666,64.0,67.0,66.66666666666666,65.0,59.333333333333336,66.33333333333333,67.33333333333333,64.0,65.33333333333333,68.0,66.66666666666666,58.666666666666664,65.66666666666666,63.33333333333333,68.66666666666667,63.0,68.0,67.0,66.33333333333333,56.333333333333336,65.0,66.0,62.33333333333333,68.66666666666667,66.66666666666666,65.66666666666666,61.0,67.66666666666666,65.0,66.33333333333333,69.33333333333334,66.0,66.66666666666666,68.33333333333333,66.33333333333333,68.0,66.33333333333333,69.33333333333334,69.0,64.33333333333333,68.0,67.0,65.33333333333333,61.66666666666667,64.66666666666666,69.33333333333334,69.33333333333334,65.33333333333333,67.0,68.0,66.33333333333333,67.33333333333333,68.33333333333333,63.33333333333333,67.66666666666666,66.66666666666666,66.0,56.666666666666664,67.0,67.0,67.33333333333333,68.0,68.66666666666667,65.33333333333333,65.66666666666666,65.66666666666666,69.0,65.66666666666666,66.0,66.33333333333333,66.66666666666666,68.66666666666667,64.66666666666666,67.66666666666666,68.33333333333333,66.0,62.33333333333333,66.0,68.0,67.0,52.666666666666664,66.66666666666666,69.66666666666667,67.0,64.33333333333333,67.0,60.333333333333336,67.0,66.0,66.0,68.0,65.0,67.0,66.33333333333333,68.0,64.33333333333333,67.0,69.66666666666667,65.33333333333333,67.66666666666666,67.0,67.0,67.66666666666666,67.33333333333333,69.0,68.33333333333333,67.0,66.66666666666666,66.33333333333333,50.33333333333333,72.0,70.0,66.66666666666666,66.0,64.0,66.66666666666666,67.0,66.33333333333333,66.66666666666666,66.33333333333333,67.33333333333333,47.66666666666667,58.333333333333336,67.66666666666666,65.66666666666666,68.33333333333333,66.33333333333333,66.66666666666666,68.0,47.66666666666667,65.0,68.0,67.66666666666666,67.66666666666666,66.0,68.0,68.0,66.66666666666666,69.0,68.0,69.66666666666667,66.33333333333333,66.66666666666666,47.66666666666667,65.0,68.66666666666667,66.0,65.33333333333333,67.33333333333333,66.33333333333333,69.33333333333334,64.33333333333333,66.33333333333333,67.0,65.0,66.66666666666666,66.33333333333333,68.33333333333333,65.0,66.33333333333333,66.0,69.66666666666667,65.0,66.0,64.0,67.0,68.0,63.66666666666667,67.66666666666666,67.33333333333333,69.66666666666667,68.0,69.0,69.66666666666667,65.33333333333333,67.66666666666666,65.33333333333333,55.666666666666664,67.0,67.66666666666666,65.66666666666666,67.66666666666666,65.33333333333333,67.0,65.66666666666666,66.66666666666666,65.0,67.66666666666666,66.33333333333333,69.0,64.0,66.66666666666666,66.66666666666666,68.33333333333333,66.66666666666666,66.33333333333333,65.0,65.33333333333333,66.66666666666666,68.0,65.33333333333333,69.0,66.0,67.66666666666666,69.66666666666667,66.33333333333333,65.66666666666666,68.0,60.333333333333336,68.33333333333333,65.33333333333333,65.33333333333333,65.33333333333333,66.33333333333333,67.33333333333333,67.66666666666666,66.33333333333333,67.33333333333333,67.66666666666666,67.33333333333333,67.33333333333333,64.66666666666666,68.33333333333333,65.0,68.33333333333333,47.66666666666667,65.0,66.0,68.0,68.66666666666667,63.0,68.0,67.66666666666666,68.0,66.33333333333333,65.0,66.33333333333333,62.66666666666667,66.33333333333333,67.0,68.0,59.333333333333336,67.33333333333333,66.66666666666666,64.33333333333333,68.33333333333333,64.66666666666666,67.0,69.66666666666667,67.33333333333333,66.33333333333333,67.0,66.33333333333333,64.33333333333333,68.33333333333333,68.66666666666667,68.66666666666667,47.66666666666667,68.0,66.33333333333333,68.0,66.66666666666666,67.33333333333333,67.33333333333333,64.66666666666666,66.0,47.66666666666667,64.33333333333333,66.66666666666666,66.33333333333333,68.0,66.66666666666666,66.66666666666666,69.0,68.0,67.0,65.33333333333333,68.66666666666667,67.66666666666666,68.0,67.0,68.66666666666667,67.0,67.0,68.66666666666667,65.66666666666666,68.66666666666667,69.66666666666667,66.66666666666666,65.66666666666666,65.0,56.99999999999999,66.0,66.66666666666666,65.0,47.66666666666667,65.0,68.33333333333333,66.66666666666666,67.0,66.0,66.33333333333333,68.0,61.33333333333333,64.33333333333333,68.0,65.33333333333333,66.0,65.0,67.0,65.66666666666666,66.66666666666666,65.66666666666666,67.66666666666666,47.66666666666667,66.33333333333333,68.66666666666667,67.0,65.66666666666666,66.33333333333333,68.33333333333333,66.0,68.66666666666667,63.0,67.33333333333333,70.33333333333334,65.33333333333333,66.33333333333333,68.66666666666667,65.0,64.33333333333333,67.66666666666666,67.33333333333333,68.33333333333333,61.0,49.0,65.0,47.66666666666667,65.33333333333333,68.0,66.66666666666666,66.33333333333333,66.0,68.66666666666667,65.66666666666666,69.33333333333334,68.33333333333333,69.0,66.33333333333333,66.0,67.66666666666666,68.0,66.66666666666666,67.33333333333333,61.33333333333333,64.66666666666666,67.33333333333333,68.33333333333333,69.66666666666667,69.0,67.66666666666666,66.33333333333333,68.66666666666667,66.33333333333333,67.33333333333333,61.0,64.66666666666666,66.66666666666666,67.66666666666666,69.0,65.0,65.33333333333333,68.66666666666667,64.33333333333333,65.66666666666666,67.66666666666666,69.33333333333334,67.0,66.66666666666666,66.0,67.66666666666666,64.66666666666666,67.66666666666666,67.33333333333333,48.0,66.0,64.33333333333333,68.33333333333333,67.66666666666666,66.66666666666666,66.33333333333333,67.66666666666666,66.66666666666666,70.66666666666667,69.33333333333334,67.0,65.0,67.0,66.66666666666666,68.66666666666667,65.66666666666666,49.0,67.0,66.66666666666666,65.33333333333333,66.0,66.33333333333333,65.66666666666666,68.66666666666667,66.66666666666666,67.66666666666666,68.33333333333333,67.66666666666666,66.33333333333333,70.66666666666667,66.66666666666666,67.33333333333333,68.66666666666667,67.33333333333333,66.66666666666666,67.0,65.66666666666666,68.33333333333333,65.0,69.0,66.33333333333333,68.33333333333333,67.33333333333333,67.33333333333333,65.66666666666666,47.66666666666667,64.33333333333333,68.66666666666667,65.0,69.0,65.66666666666666,67.66666666666666,67.33333333333333,65.33333333333333,68.66666666666667,69.0,68.66666666666667,66.66666666666666,66.66666666666666,68.0,66.66666666666666,66.33333333333333,65.0,65.33333333333333,66.33333333333333,66.0,66.0,65.66666666666666,68.33333333333333,69.0,63.66666666666667,68.33333333333333,67.33333333333333,65.66666666666666,67.0,66.66666666666666,65.33333333333333,65.66666666666666,65.0,67.33333333333333,68.33333333333333,68.66666666666667,68.66666666666667,67.33333333333333,66.33333333333333,66.66666666666666,66.33333333333333,67.66666666666666,66.66666666666666,68.33333333333333,67.0,69.0,67.66666666666666,64.33333333333333,67.0,68.33333333333333,68.33333333333333,68.66666666666667,67.0,66.66666666666666,66.0,66.66666666666666,66.66666666666666,66.66666666666666,63.0,66.33333333333333,65.66666666666666,66.66666666666666,66.33333333333333,66.0,71.66666666666667,65.0,56.99999999999999,66.66666666666666,66.66666666666666,67.0,67.33333333333333,68.66666666666667,67.33333333333333,65.0,66.66666666666666,66.33333333333333,66.66666666666666,68.33333333333333,68.0,65.66666666666666,67.33333333333333,67.0,65.66666666666666,67.33333333333333,67.0,68.0,67.66666666666666,68.0,70.33333333333334,67.0,64.0,67.66666666666666,67.0,68.33333333333333,67.33333333333333,65.66666666666666,67.0,51.66666666666667,66.0,66.33333333333333,68.0,64.33333333333333,47.66666666666667,66.66666666666666,68.66666666666667,67.0,67.0,67.66666666666666,65.66666666666666,66.66666666666666,67.33333333333333,66.0,65.66666666666666,60.0,64.33333333333333,67.66666666666666,68.66666666666667,65.66666666666666,68.33333333333333,68.33333333333333,69.33333333333334,68.33333333333333,69.0,69.0,70.0,67.0,67.33333333333333,65.0,66.33333333333333,67.0,65.66666666666666,66.66666666666666,66.33333333333333,68.0,63.33333333333333,68.33333333333333,68.33333333333333,64.66666666666666,68.0,68.0,66.0,68.0,63.33333333333333,66.0,67.0,69.66666666666667,67.66666666666666,64.66666666666666,66.0,66.0,64.66666666666666,68.0,67.0,67.33333333333333,68.66666666666667,63.33333333333333,67.33333333333333,66.0,68.0,67.66666666666666,66.33333333333333,66.33333333333333,68.66666666666667,68.0,66.33333333333333,68.33333333333333,67.0,66.0,67.66666666666666,66.33333333333333,67.0,67.0,65.66666666666666,69.0,67.66666666666666,67.33333333333333,66.66666666666666,64.0,64.33333333333333,68.0,68.0,66.33333333333333,68.33333333333333,66.33333333333333,59.66666666666667,61.33333333333333,66.33333333333333,68.33333333333333,64.0,66.0,68.66666666666667,66.33333333333333,67.66666666666666,66.0,68.66666666666667,67.33333333333333,68.33333333333333,68.0,68.0,47.66666666666667,65.0,65.0,66.66666666666666,66.0,66.0,66.0,47.66666666666667,67.33333333333333,65.66666666666666,62.66666666666667,68.33333333333333,65.0,56.666666666666664,68.0,69.0,65.66666666666666,61.66666666666667,65.33333333333333,68.33333333333333,68.0,66.66666666666666,66.0,67.0,66.33333333333333,67.0,66.0,67.0,71.0,62.0,67.33333333333333,68.0,67.0,67.0,70.33333333333334,70.33333333333334,64.66666666666666,68.33333333333333,65.0,65.33333333333333,65.33333333333333,66.0,67.66666666666666,66.33333333333333,68.0,67.0,67.0,65.33333333333333,67.33333333333333,70.33333333333334,67.33333333333333,66.0,47.66666666666667,67.66666666666666,68.0,66.0,68.0,64.66666666666666,65.33333333333333,66.0,64.33333333333333,69.33333333333334,65.0,66.33333333333333,71.0,66.0,68.0,67.33333333333333,67.66666666666666,63.0,64.0,68.33333333333333,67.33333333333333,65.33333333333333,66.33333333333333,47.66666666666667,64.33333333333333,67.66666666666666,68.33333333333333,68.33333333333333,66.66666666666666,67.66666666666666,66.66666666666666,66.33333333333333,68.66666666666667,66.66666666666666,66.66666666666666,67.66666666666666,68.0,67.66666666666666,66.33333333333333,67.0,65.66666666666666,68.33333333333333,67.66666666666666,67.0,66.0,66.33333333333333,65.0,67.33333333333333,68.66666666666667,67.33333333333333,65.33333333333333,64.33333333333333,67.0,67.33333333333333,64.33333333333333,67.0,64.66666666666666,67.33333333333333,65.33333333333333,67.33333333333333,68.33333333333333,66.66666666666666,68.33333333333333,67.33333333333333,65.66666666666666,63.66666666666667,65.66666666666666,67.33333333333333,66.0,67.66666666666666,70.0,66.33333333333333,63.33333333333333,70.0,66.33333333333333,65.66666666666666,68.0,67.66666666666666,68.0,68.0,64.66666666666666,65.66666666666666,66.66666666666666,67.66666666666666,67.66666666666666,69.33333333333334,66.33333333333333,66.33333333333333,68.33333333333333,66.0,65.66666666666666,64.66666666666666,67.0,67.33333333333333,70.66666666666667,69.0,67.0,66.0,67.33333333333333,64.33333333333333,66.0,65.33333333333333,66.66666666666666,67.66666666666666,66.66666666666666,69.0,65.0,67.66666666666666,66.0,66.33333333333333,67.66666666666666,68.33333333333333,60.66666666666667,67.0,64.33333333333333,66.0,65.33333333333333,68.0,68.66666666666667,66.66666666666666,67.66666666666666,67.0,66.66666666666666,68.0,67.0,69.33333333333334,66.66666666666666,68.66666666666667,67.0,66.0,70.33333333333334,68.0,56.00000000000001,66.33333333333333,66.66666666666666,67.66666666666666,66.33333333333333,66.33333333333333,69.66666666666667,68.33333333333333,69.0,66.0,66.0,67.33333333333333,65.66666666666666,66.33333333333333,66.66666666666666,68.33333333333333,68.66666666666667,64.66666666666666,68.33333333333333,67.0,67.0,66.66666666666666,66.33333333333333,66.66666666666666,47.66666666666667,66.33333333333333,66.66666666666666,65.66666666666666,64.0,68.0,67.0,67.66666666666666,63.66666666666667,67.0,68.0,65.33333333333333,67.0,68.66666666666667,67.0,66.0,68.0,64.66666666666666,69.33333333333334,67.0,68.66666666666667,70.33333333333334,65.33333333333333,63.66666666666667,66.33333333333333,65.66666666666666,67.66666666666666,67.33333333333333,67.66666666666666,47.66666666666667,69.66666666666667,65.33333333333333,70.66666666666667,69.66666666666667,66.0,68.0,67.66666666666666,67.66666666666666,67.33333333333333,65.0,62.0,64.66666666666666,47.66666666666667,67.66666666666666,67.66666666666666,62.0,64.33333333333333,67.33333333333333,65.33333333333333,67.0,64.0,67.33333333333333,68.33333333333333,67.33333333333333,65.33333333333333,66.66666666666666,68.66666666666667,66.0,67.33333333333333,66.66666666666666,65.0,66.33333333333333,66.66666666666666,67.0,69.33333333333334,68.33333333333333,54.0,71.33333333333334,65.0,66.66666666666666,67.66666666666666,68.0,68.66666666666667,67.0,66.66666666666666,62.66666666666667,64.66666666666666,66.33333333333333,69.33333333333334,67.0,66.33333333333333,65.66666666666666,47.66666666666667,67.66666666666666,69.66666666666667,68.33333333333333,65.0,67.33333333333333,69.0,68.0,66.33333333333333,66.0,70.33333333333334,67.66666666666666,66.0,69.0,67.0,67.0,64.66666666666666,66.0,63.66666666666667,66.0,66.66666666666666,47.66666666666667,66.0,68.0,68.33333333333333,55.00000000000001,69.33333333333334,65.0,65.66666666666666,65.0,66.33333333333333,66.33333333333333,63.33333333333333,67.66666666666666,67.0,65.33333333333333,70.33333333333334,60.66666666666667,69.0,66.33333333333333,68.0,47.66666666666667,69.66666666666667,71.66666666666667,66.66666666666666,63.33333333333333,69.0,65.66666666666666,67.66666666666666,66.33333333333333,67.33333333333333,68.66666666666667,67.33333333333333,66.66666666666666,68.0,68.33333333333333,65.33333333333333,70.33333333333334,67.0,66.0,66.0,67.33333333333333,66.0,64.33333333333333,66.33333333333333,67.0,65.66666666666666,66.66666666666666,66.0,66.0,68.0,66.66666666666666,67.0,67.33333333333333,66.0,66.33333333333333,67.33333333333333,64.33333333333333,65.66666666666666,66.0,65.66666666666666,68.66666666666667,61.33333333333333,68.0,47.66666666666667,66.33333333333333,67.33333333333333,66.66666666666666,68.33333333333333,65.33333333333333,69.66666666666667,57.666666666666664,67.0,63.33333333333333,68.66666666666667,66.66666666666666,69.66666666666667,47.66666666666667,64.0,67.0,66.33333333333333,66.66666666666666,67.33333333333333,65.33333333333333,67.0,67.66666666666666,68.0,67.0,66.66666666666666,66.0,68.33333333333333,65.66666666666666,63.0,68.0,69.33333333333334,66.66666666666666,64.66666666666666,68.33333333333333,63.66666666666667,66.0,66.66666666666666,66.0,64.0,66.0,67.66666666666666,66.33333333333333,68.33333333333333,68.33333333333333,66.66666666666666,66.0,67.66666666666666,69.0,66.66666666666666,67.0,68.33333333333333,68.66666666666667,69.0,65.0,68.0,67.66666666666666,66.66666666666666,67.66666666666666,64.66666666666666,65.66666666666666,66.66666666666666,66.0,68.33333333333333,65.33333333333333,67.0,68.0,69.33333333333334,68.33333333333333,67.66666666666666,64.66666666666666,66.0,65.33333333333333,65.33333333333333,67.0,67.66666666666666,66.66666666666666,68.66666666666667,67.33333333333333,67.0,66.0,69.33333333333334,67.66666666666666,69.66666666666667,66.66666666666666,66.33333333333333,65.33333333333333,66.0,66.66666666666666,68.33333333333333,69.0,65.33333333333333,68.0,67.66666666666666,65.66666666666666,68.33333333333333,65.33333333333333,69.33333333333334,65.66666666666666,68.0,70.0,67.33333333333333,66.66666666666666,67.66666666666666,68.0,64.33333333333333,47.66666666666667,65.33333333333333,67.33333333333333,68.0,65.33333333333333,66.33333333333333,67.33333333333333,68.66666666666667,67.33333333333333,61.66666666666667,68.66666666666667,69.33333333333334,66.0,66.33333333333333,67.0,66.66666666666666,67.33333333333333,67.0,66.66666666666666,69.33333333333334,66.0,70.0,66.66666666666666,64.66666666666666,69.0,51.33333333333333,66.33333333333333,64.33333333333333,69.0,67.0,66.66666666666666,65.33333333333333,63.66666666666667,65.0,68.66666666666667,66.66666666666666,66.33333333333333,66.0,65.66666666666666,67.66666666666666,67.66666666666666,66.0,67.66666666666666,70.0,65.33333333333333,66.66666666666666,67.0,66.66666666666666,66.0,69.66666666666667,68.0,66.66666666666666,67.66666666666666,67.0,65.66666666666666,67.0,68.0,66.66666666666666,67.33333333333333,65.66666666666666,66.33333333333333,66.33333333333333,68.33333333333333,56.333333333333336,67.66666666666666,67.0,65.0,67.66666666666666,66.0,66.0,69.0,68.33333333333333,70.33333333333334,67.0,65.66666666666666,68.66666666666667,69.33333333333334,68.66666666666667,69.0,66.0,67.66666666666666,67.66666666666666,68.33333333333333,69.66666666666667,66.66666666666666,67.0,66.33333333333333,69.0,65.66666666666666,63.0,68.66666666666667,66.33333333333333,67.0,65.33333333333333,66.66666666666666,66.33333333333333,68.33333333333333,68.66666666666667,67.0,65.33333333333333,65.0,64.33333333333333,68.66666666666667,67.33333333333333,63.0,66.33333333333333,65.66666666666666,66.33333333333333,66.0,66.33333333333333,68.66666666666667,67.33333333333333,65.0,64.33333333333333,62.66666666666667,68.66666666666667,69.0,67.0,67.33333333333333,66.66666666666666,66.66666666666666,68.0,67.66666666666666,71.0,66.33333333333333,67.66666666666666,68.0,66.33333333333333,67.33333333333333,64.66666666666666,66.33333333333333,67.0,69.66666666666667,67.0,64.66666666666666,62.66666666666667,68.66666666666667,69.66666666666667,68.33333333333333,66.66666666666666,67.33333333333333,69.33333333333334,65.66666666666666,69.0,63.66666666666667,68.33333333333333,64.0,67.33333333333333,70.0,66.66666666666666,66.0,69.0,69.33333333333334,64.33333333333333,66.66666666666666,66.33333333333333,69.33333333333334,66.33333333333333,67.33333333333333,67.33333333333333,67.66666666666666,68.0,67.66666666666666,66.0,68.0,68.0,67.33333333333333,66.66666666666666,67.0,66.0,69.33333333333334,68.0,64.0,61.0,69.33333333333334,68.33333333333333,69.33333333333334,64.0,68.66666666666667,68.33333333333333,64.33333333333333,66.0,64.0,72.33333333333334,66.33333333333333,66.0,70.66666666666667,69.66666666666667,64.66666666666666,67.33333333333333,64.66666666666666,68.0,68.0,67.66666666666666,66.66666666666666,67.33333333333333,65.66666666666666,68.0,67.66666666666666,67.33333333333333,67.66666666666666,67.33333333333333,67.0,68.33333333333333,69.0,63.33333333333333,68.66666666666667,63.66666666666667,63.0,68.33333333333333,66.33333333333333,69.0,63.66666666666667,64.66666666666666,66.0,65.33333333333333,66.0,68.33333333333333,70.0,68.0,67.33333333333333,67.33333333333333,69.66666666666667,67.0,66.0,63.0,66.66666666666666,71.0,67.66666666666666,64.0,68.66666666666667,65.33333333333333,66.33333333333333,68.33333333333333,66.0,69.33333333333334,69.66666666666667,67.33333333333333,66.66666666666666,68.66666666666667,59.333333333333336,69.0,67.33333333333333,65.0,65.66666666666666,70.0,66.66666666666666,68.33333333333333,68.33333333333333,69.0,62.33333333333333,69.66666666666667,67.66666666666666,64.66666666666666,67.33333333333333,64.66666666666666,68.33333333333333,64.66666666666666,64.33333333333333,66.33333333333333,66.0,70.33333333333334,70.66666666666667,64.0,64.33333333333333,65.66666666666666,66.0,68.0,66.33333333333333,65.66666666666666,67.0,66.33333333333333,66.0,66.66666666666666,64.66666666666666,65.66666666666666,65.66666666666666,67.66666666666666,66.66666666666666,69.33333333333334,53.0,67.66666666666666,65.66666666666666,68.0,68.0,67.66666666666666,66.0,67.33333333333333,55.666666666666664,69.0,68.0,66.66666666666666,68.33333333333333,68.66666666666667,66.66666666666666,67.66666666666666,63.66666666666667,68.66666666666667,65.66666666666666,65.33333333333333,70.0,68.33333333333333,68.0,68.66666666666667,67.33333333333333,65.66666666666666,68.66666666666667,67.33333333333333,70.0,67.66666666666666,67.33333333333333,67.33333333333333,67.0,66.33333333333333,68.66666666666667,64.33333333333333,66.33333333333333,65.0,68.33333333333333,65.66666666666666,69.0,66.66666666666666,67.33333333333333,66.66666666666666,66.0,66.33333333333333,47.66666666666667,66.0,66.0,68.0,65.0,66.66666666666666,67.66666666666666,67.0,66.66666666666666,65.33333333333333,66.66666666666666,67.33333333333333,67.66666666666666,68.0,69.66666666666667,66.66666666666666,67.33333333333333,67.0,64.0,68.66666666666667,67.33333333333333,69.66666666666667,66.66666666666666,65.66666666666666,67.66666666666666,64.0,66.66666666666666,66.66666666666666,65.0,69.0,65.66666666666666,68.0,66.0,65.66666666666666,68.33333333333333,66.33333333333333,67.0,67.66666666666666,65.0,67.33333333333333,66.0,65.66666666666666,65.33333333333333,70.33333333333334,67.66666666666666,67.66666666666666,66.33333333333333,69.0,66.66666666666666,68.0,68.33333333333333,62.0,66.33333333333333,68.66666666666667,66.66666666666666,67.33333333333333,64.66666666666666,69.0,69.33333333333334,66.0,66.66666666666666,69.33333333333334,66.33333333333333,65.66666666666666,63.66666666666667,66.33333333333333,66.66666666666666,67.33333333333333,69.0,66.66666666666666,65.33333333333333,62.66666666666667,67.66666666666666,67.33333333333333,67.66666666666666,69.0,67.66666666666666,63.66666666666667,68.0,68.33333333333333,68.33333333333333,68.33333333333333,64.66666666666666,66.33333333333333,68.0,65.66666666666666,68.0,64.66666666666666,66.0,67.66666666666666,67.0,61.33333333333333,66.0,70.33333333333334,66.0,65.66666666666666,66.0,68.66666666666667,67.66666666666666,67.66666666666666,64.66666666666666,65.33333333333333,68.66666666666667,69.66666666666667,68.0,67.33333333333333,66.66666666666666,66.66666666666666,65.33333333333333,61.66666666666667,67.0,66.66666666666666,65.66666666666666,68.0,68.66666666666667,66.66666666666666,67.33333333333333,66.66666666666666,62.66666666666667,67.66666666666666,68.0,66.66666666666666,70.0,63.66666666666667,67.33333333333333,66.66666666666666,68.33333333333333,65.33333333333333,65.33333333333333,67.33333333333333,66.66666666666666,70.0,67.33333333333333,69.33333333333334,68.0,68.66666666666667,67.0,64.33333333333333,67.66666666666666,61.66666666666667,69.0,47.66666666666667,66.33333333333333,66.33333333333333,69.0,68.0,66.66666666666666,67.33333333333333,60.66666666666667,67.66666666666666,68.33333333333333,64.33333333333333,68.0,66.33333333333333,66.66666666666666,68.66666666666667,69.66666666666667,66.66666666666666,68.0,68.33333333333333,68.0,67.66666666666666,68.0,70.33333333333334,67.66666666666666,70.33333333333334,66.0,67.0,67.33333333333333,68.33333333333333,64.33333333333333,62.66666666666667,66.0,66.0,65.66666666666666,59.66666666666667,66.33333333333333,66.0,70.66666666666667,67.33333333333333,68.0,67.33333333333333,67.33333333333333,66.33333333333333,47.66666666666667,66.0,66.33333333333333,68.0,68.33333333333333,68.66666666666667,65.66666666666666,66.33333333333333,47.66666666666667,68.33333333333333,67.0,66.33333333333333,54.0,65.66666666666666,65.66666666666666,66.0,71.0,68.0,66.66666666666666,68.0,67.33333333333333,67.33333333333333,67.0,69.66666666666667,66.33333333333333,66.33333333333333,68.66666666666667,67.33333333333333,67.33333333333333,65.0,65.66666666666666,65.33333333333333,64.0,64.33333333333333,65.66666666666666,69.0,67.33333333333333,65.33333333333333,65.66666666666666,67.66666666666666,68.66666666666667,62.66666666666667,70.33333333333334,66.0,65.33333333333333,67.33333333333333,66.33333333333333,69.66666666666667,63.33333333333333,70.33333333333334,67.33333333333333,67.0,67.33333333333333,67.66666666666666,64.66666666666666,67.33333333333333,67.0,69.66666666666667,68.0,67.66666666666666,68.0,67.66666666666666,66.66666666666666,65.0,65.66666666666666,68.0,58.666666666666664,66.33333333333333,65.33333333333333,66.0,65.33333333333333,69.0,65.0,68.0,66.0,69.66666666666667,67.66666666666666,65.66666666666666,67.33333333333333,66.33333333333333,66.0,67.33333333333333,65.0,67.66666666666666,64.0,68.66666666666667,68.0,68.66666666666667,68.66666666666667,63.66666666666667,67.33333333333333,66.0,67.0,66.33333333333333,67.0,69.0,68.0,66.66666666666666,70.0,69.66666666666667,67.66666666666666,47.66666666666667,66.33333333333333,67.33333333333333,69.33333333333334,65.66666666666666,65.0,64.33333333333333,67.33333333333333,65.33333333333333,69.0,47.66666666666667,67.33333333333333,67.0,66.66666666666666,64.66666666666666,63.33333333333333,67.0,64.66666666666666,68.0,64.66666666666666,64.0,67.33333333333333,70.33333333333334,62.33333333333333,66.66666666666666,66.66666666666666,66.33333333333333,67.33333333333333,47.66666666666667,67.33333333333333,67.66666666666666,67.66666666666666,68.66666666666667,67.33333333333333,68.66666666666667,61.33333333333333,66.33333333333333,67.33333333333333,65.33333333333333,65.33333333333333,67.33333333333333,65.33333333333333,67.0,65.33333333333333,65.0,66.66666666666666,67.33333333333333,66.33333333333333,68.66666666666667,61.33333333333333,68.0,47.66666666666667,62.0,66.0,67.66666666666666,66.0,66.33333333333333,66.66666666666666,66.66666666666666,64.66666666666666,47.66666666666667,67.0,69.33333333333334,67.66666666666666,66.66666666666666,69.66666666666667,64.66666666666666,65.66666666666666,66.0,66.33333333333333,68.66666666666667,63.66666666666667,68.33333333333333,69.0,64.0,69.66666666666667,65.0,67.0,63.33333333333333,67.66666666666666,66.66666666666666,63.0,67.33333333333333,67.33333333333333,63.33333333333333,66.0,65.33333333333333,52.666666666666664,70.66666666666667,72.0,67.66666666666666,68.66666666666667,69.0,70.0,67.33333333333333,65.66666666666666,67.66666666666666,65.33333333333333,69.0,69.0,67.0,68.66666666666667,68.0,71.66666666666667,69.33333333333334,69.0,68.33333333333333,69.0,67.0,70.33333333333334,65.0,68.0,65.0,69.66666666666667,69.0,69.66666666666667,66.66666666666666,66.66666666666666,67.33333333333333,66.33333333333333,66.0,66.66666666666666,67.33333333333333,67.33333333333333,66.33333333333333,66.33333333333333,69.66666666666667,67.33333333333333,69.33333333333334,67.66666666666666,69.66666666666667,68.66666666666667,66.66666666666666,66.33333333333333,65.0,65.66666666666666,70.33333333333334,65.33333333333333,65.66666666666666,68.66666666666667,67.0,67.66666666666666,67.0,68.0,68.0,66.0,67.33333333333333,67.66666666666666,67.33333333333333,65.66666666666666,69.0,68.0,66.0,66.66666666666666,65.33333333333333,66.66666666666666,69.33333333333334,68.33333333333333,68.0,69.0,65.0,65.33333333333333,66.0,68.66666666666667,68.0,63.66666666666667,69.33333333333334,68.0,67.33333333333333,67.0,68.33333333333333,66.33333333333333,67.66666666666666,67.66666666666666,67.33333333333333,65.66666666666666,67.0,66.0,69.66666666666667,67.33333333333333,68.33333333333333,67.0,67.0,66.33333333333333,65.33333333333333,68.66666666666667,66.66666666666666,66.33333333333333,69.33333333333334,66.66666666666666,70.33333333333334,68.33333333333333,65.0,64.33333333333333,66.33333333333333,67.66666666666666,68.33333333333333,66.0,68.33333333333333,67.33333333333333,65.33333333333333,63.66666666666667,65.33333333333333,65.66666666666666,64.0,67.0,66.66666666666666,67.0,68.33333333333333,66.33333333333333,68.0,65.66666666666666,69.33333333333334,66.0,65.0,67.0,68.0,67.0,66.33333333333333,66.33333333333333,64.66666666666666,61.0,64.66666666666666,65.0,69.0,69.0,68.66666666666667,67.0,65.66666666666666,63.33333333333333,68.33333333333333,66.0,67.33333333333333,69.0,66.66666666666666,67.0,65.66666666666666,65.33333333333333,67.33333333333333,68.0,67.33333333333333,69.0,65.33333333333333,67.33333333333333,67.33333333333333,65.33333333333333,68.33333333333333,66.66666666666666,66.33333333333333,68.33333333333333,69.0,68.33333333333333,65.33333333333333,68.33333333333333,68.0,68.33333333333333,66.33333333333333,65.66666666666666,64.33333333333333,59.66666666666667,69.33333333333334,66.33333333333333,66.33333333333333,66.0,69.66666666666667,66.66666666666666,68.33333333333333,67.0,67.33333333333333,69.66666666666667,68.66666666666667,67.0,67.33333333333333,68.66666666666667,65.0,67.66666666666666,66.0,65.66666666666666,62.66666666666667,66.0,67.0,65.66666666666666,67.66666666666666,67.66666666666666,68.33333333333333,66.66666666666666,68.0,69.66666666666667,63.33333333333333,64.33333333333333,67.66666666666666,65.33333333333333,65.33333333333333,68.0,67.33333333333333,68.0,64.33333333333333,69.33333333333334,68.0,66.0,66.0,72.0,67.33333333333333,67.33333333333333,69.0,68.0,64.33333333333333,66.0,69.33333333333334,68.66666666666667,70.0,65.0,65.66666666666666,64.0,68.33333333333333,70.0,67.66666666666666,67.33333333333333,67.66666666666666,69.0,66.66666666666666,68.0,67.33333333333333,68.66666666666667,64.33333333333333,65.33333333333333,67.66666666666666,68.33333333333333,71.0,66.33333333333333,65.33333333333333,64.66666666666666,68.0,66.33333333333333,69.33333333333334,65.66666666666666,66.33333333333333,66.33333333333333,67.66666666666666,64.66666666666666,66.66666666666666,66.0,67.0,67.33333333333333,65.66666666666666,67.33333333333333,70.0,65.33333333333333,65.33333333333333,64.66666666666666,67.0,67.66666666666666,67.33333333333333,65.0,68.66666666666667,66.33333333333333,66.66666666666666,65.0,64.0,68.33333333333333,67.0,67.0,62.0,66.66666666666666,65.0,56.99999999999999,69.66666666666667,66.66666666666666,67.66666666666666,66.0,69.66666666666667,66.66666666666666,69.33333333333334,67.33333333333333,68.33333333333333,68.33333333333333,68.66666666666667,68.33333333333333,67.33333333333333,64.33333333333333,58.666666666666664,65.33333333333333,60.0,69.0,47.66666666666667,68.66666666666667],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FA0\"},\"mode\":\"lines\",\"name\":\"HPO test dataset accuracy (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[61.54166666666665,61.63888888888887,61.76388888888887,61.88888888888887,62.583333333333314,62.583333333333314,62.70833333333332,62.76388888888887,62.61111111111109,62.833333333333314,62.76388888888888,62.80555555555555,62.43055555555555,62.972222222222214,62.94444444444444,63.54166666666666,63.736111111111114,64.41666666666666,63.97222222222223,63.791666666666664,63.555555555555564,62.861111111111114,62.19444444444445,62.09722222222223,62.23611111111111,62.361111111111114,62.48611111111111,62.486111111111114,62.430555555555564,62.56944444444445,62.56944444444445,62.777777777777786,62.611111111111114,62.83333333333333,62.138888888888886,62.80555555555555,62.7361111111111,62.74999999999999,62.847222222222214,62.79166666666666,62.99999999999999,63.01388888888888,63.38888888888888,63.38888888888887,63.458333333333314,63.41666666666665,63.43055555555554,63.27777777777777,63.86111111111111,63.93055555555555,64.25,64.70833333333333,65.29166666666666,65.375,65.20833333333333,65.19444444444446,65.02777777777779,65.75,65.65277777777779,65.3888888888889,65.29166666666667,65.36111111111111,65.55555555555556,65.875,66.45833333333334,66.4861111111111,66.4861111111111,65.77777777777777,65.70833333333331,65.6111111111111,64.94444444444443,64.4722222222222,63.79166666666665,63.09722222222221,62.66666666666666,62.47222222222221,62.291666666666664,62.43055555555555,62.597222222222214,62.68055555555554,62.81944444444444,63.06944444444444,62.48611111111111,62.38888888888888,62.6111111111111,62.54166666666666,62.958333333333336,62.9861111111111,63.15277777777778,63.388888888888886,63.54166666666666,63.4861111111111,63.513888888888886,63.47222222222221,62.88888888888888,62.88888888888888,62.22222222222221,62.7361111111111,62.77777777777776,62.84722222222221,63.49999999999998,63.94444444444442,64.44444444444443,65.15277777777776,65.61111111111109,65.24999999999999,65.49999999999999,65.5,65.44444444444443,65.51388888888889,65.51388888888889,65.5,65.97222222222221,66.06944444444444,65.68055555555554,65.68055555555554,65.51388888888889,65.47222222222221,65.40277777777776,65.44444444444444,65.41666666666666,65.44444444444444,65.5,65.58333333333331,66.23611111111111,66.22222222222221,66.93055555555556,67.04166666666667,67.08333333333334,67.29166666666666,67.38888888888889,67.40277777777777,67.62499999999999,67.69444444444444,67.69444444444444,68.18055555555554,68.13888888888889,68.13888888888889,67.72222222222221,67.72222222222221,67.0,66.93055555555556,67.16666666666667,67.19444444444443,67.55555555555556,67.66666666666666,67.72222222222223,67.65277777777779,67.69444444444444,67.66666666666667,67.69444444444444,67.73611111111111,67.66666666666667,67.625,67.54166666666667,67.52777777777779,67.55555555555556,67.22222222222221,67.15277777777777,66.94444444444444,66.19444444444444,66.2222222222222,66.18055555555554,66.2361111111111,65.5,65.70833333333333,65.69444444444443,65.72222222222221,66.02777777777777,66.04166666666667,66.79166666666667,66.51388888888889,66.4861111111111,66.47222222222221,66.2361111111111,66.18055555555554,66.09722222222221,66.19444444444443,66.08333333333333,66.08333333333333,66.13888888888889,66.13888888888889,65.43055555555556,65.11111111111111,65.19444444444446,65.20833333333333,65.26388888888889,65.65277777777777,65.65277777777779,65.83333333333333,66.52777777777779,66.47222222222221,66.3472222222222,66.15277777777777,66.15277777777779,66.15277777777777,66.15277777777776,66.22222222222221,66.3611111111111,66.25,66.29166666666666,66.65277777777777,66.69444444444443,66.63888888888889,66.81944444444444,66.76388888888889,66.6388888888889,66.59722222222223,66.63888888888889,66.4861111111111,66.43055555555556,66.16666666666666,66.875,67.15277777777777,67.16666666666666,67.13888888888887,66.59722222222221,66.63888888888887,66.01388888888889,65.26388888888887,65.2222222222222,65.02777777777776,64.77777777777776,64.83333333333333,65.44444444444443,65.375,64.69444444444444,64.59722222222221,64.54166666666666,64.69444444444443,64.34722222222221,64.3611111111111,64.29166666666666,64.37499999999999,64.43055555555554,63.77777777777777,63.91666666666666,63.861111111111114,63.76388888888888,63.95833333333333,63.94444444444444,64.19444444444444,64.05555555555556,64.13888888888889,63.86111111111112,63.8888888888889,64.23611111111113,64.25,64.98611111111111,65.56944444444446,65.58333333333334,65.81944444444446,66.2638888888889,66.2638888888889,66.43055555555556,66.48611111111111,67.19444444444444,67.30555555555556,67.3611111111111,67.31944444444444,67.55555555555554,67.47222222222221,67.44444444444444,67.43055555555556,67.5,68.125,68.22222222222221,68.29166666666666,68.44444444444444,68.47222222222221,68.34722222222221,68.27777777777777,68.38888888888889,68.33333333333334,67.94444444444446,67.93055555555556,67.33333333333334,67.37500000000001,67.3888888888889,67.43055555555557,67.52777777777779,67.44444444444444,67.43055555555556,67.33333333333333,67.22222222222223,66.73611111111113,66.73611111111111,66.56944444444443,66.59722222222223,66.5138888888889,66.5,66.43055555555556,66.41666666666667,66.5138888888889,66.43055555555556,66.52777777777779,66.54166666666667,66.49999999999999,66.29166666666667,66.15277777777777,66.06944444444444,66.15277777777777,66.11111111111111,66.13888888888887,66.77777777777777,66.66666666666666,67.38888888888887,67.22222222222221,67.06944444444443,67.18055555555554,67.04166666666666,67.1111111111111,66.95833333333333,67.06944444444444,66.875,67.41666666666667,67.48611111111111,67.62500000000001,67.54166666666667,67.61111111111111,67.58333333333334,67.70833333333334,67.75,67.66666666666666,67.61111111111111,67.58333333333334,67.48611111111111,67.45833333333334,67.65277777777779,67.02777777777779,67.26388888888887,67.2361111111111,67.31944444444443,66.6388888888889,66.26388888888889,66.44444444444443,66.41666666666666,66.34722222222221,66.51388888888889,66.34722222222223,66.27777777777779,66.36111111111111,66.20833333333333,66.11111111111111,66.25,66.1388888888889,65.98611111111111,65.94444444444444,65.97222222222223,65.61111111111111,65.73611111111111,65.77777777777779,65.87500000000001,65.625,65.66666666666667,65.54166666666667,65.54166666666667,65.72222222222223,65.72222222222223,66.34722222222223,66.30555555555556,66.33333333333331,66.31944444444444,67.0138888888889,67.44444444444446,66.70833333333334,66.70833333333333,66.16666666666666,66.13888888888887,66.19444444444443,66.06944444444443,65.91666666666666,66.20833333333333,66.33333333333333,66.44444444444443,66.47222222222221,66.58333333333333,66.5,66.56944444444444,66.95833333333333,66.8888888888889,66.8888888888889,66.77777777777779,67.12500000000001,67.04166666666667,67.20833333333333,67.29166666666667,67.22222222222224,67.1527777777778,67.20833333333334,67.23611111111111,67.18055555555556,67.22222222222223,67.26388888888889,67.31944444444446,67.95833333333334,67.97222222222223,68.66666666666667,68.59722222222223,68.6388888888889,68.8611111111111,68.93055555555554,68.79166666666664,67.91666666666666,67.97222222222221,68.02777777777779,68.0,68.04166666666666,67.98611111111111,67.25,67.19444444444444,67.11111111111111,67.20833333333333,67.19444444444444,67.29166666666667,67.2638888888889,67.23611111111111,67.23611111111111,67.37500000000001,67.33333333333333,67.36111111111111,67.37500000000001,67.30555555555556,67.08333333333333,67.09722222222223,67.08333333333334,67.04166666666667,67.05555555555556,67.06944444444443,67.01388888888889,67.01388888888889,66.98611111111111,67.06944444444443,67.76388888888889,67.54166666666667,66.83333333333334,66.8888888888889,66.81944444444444,66.66666666666667,67.33333333333333,67.22222222222223,67.31944444444444,67.23611111111111,67.18055555555556,67.13888888888889,66.43055555555557,66.48611111111111,66.47222222222221,66.45833333333334,65.95833333333334,65.93055555555556,66.02777777777779,66.05555555555556,66.27777777777779,66.20833333333334,66.33333333333334,66.43055555555557,66.44444444444444,66.30555555555556,66.41666666666667,66.3888888888889,66.375,66.38888888888889,66.45833333333333,66.58333333333333,67.24999999999999,67.22222222222221,67.41666666666666,67.54166666666666,67.5972222222222,67.70833333333333,67.6111111111111,67.59722222222221,66.88888888888889,66.76388888888889,67.47222222222221,67.29166666666666,66.72222222222221,66.47222222222223,66.98611111111111,67.02777777777777,66.93055555555556,66.87500000000001,66.83333333333333,66.70833333333333,66.59722222222223,66.52777777777777,66.25,66.40277777777777,66.3611111111111,66.30555555555554,66.30555555555556,65.62499999999999,65.74999999999999,65.43055555555553,65.4722222222222,65.43055555555554,65.30555555555553,65.33333333333331,65.38888888888887,64.75,64.70833333333333,64.77777777777779,65.51388888888889,65.72222222222223,65.73611111111111,65.875,66.30555555555556,65.80555555555557,65.80555555555556,65.72222222222223,65.19444444444444,65.125,64.97222222222223,65.16666666666667,65.26388888888889,65.125,65.40277777777779,65.26388888888889,65.31944444444444,65.44444444444446,65.54166666666667,66.27777777777779,66.1388888888889,66.52777777777779,66.48611111111113,65.79166666666669,65.70833333333334,65.7638888888889,65.75,66.47222222222223,66.56944444444446,66.54166666666667,66.37500000000001,66.25000000000001,66.20833333333334,66.16666666666667,66.25000000000001,66.25000000000001,66.29166666666669,66.18055555555557,66.70833333333336,66.54166666666666,66.70833333333333,66.65277777777777,66.45833333333333,66.56944444444444,66.55555555555556,66.76388888888887,66.72222222222221,66.81944444444443,66.83333333333333,66.81944444444443,66.90277777777777,66.76388888888887,66.79166666666666,67.52777777777777,67.74999999999999,67.66666666666664,67.56944444444443,67.59722222222223,67.5,67.4861111111111,67.59722222222221,67.72222222222221,67.72222222222221,67.69444444444444,67.7638888888889,68.47222222222223,68.48611111111111,68.625,68.59722222222221,68.90277777777777,68.80555555555556,68.875,69.11111111111111,69.19444444444446,69.27777777777779,69.19444444444444,69.13888888888889,68.98611111111111,68.98611111111111,69.0138888888889,69.06944444444446,69.22222222222223,69.16666666666667,68.79166666666666,68.51388888888889,68.51388888888887,68.56944444444444,68.55555555555554,68.63888888888889,68.65277777777777,68.66666666666667,68.52777777777777,68.51388888888889,68.52777777777777,68.43055555555556,68.44444444444443,68.38888888888889,68.20833333333331,68.33333333333331,68.26388888888887,68.24999999999999,68.13888888888887,68.02777777777776,67.9583333333333,67.87499999999997,67.86111111111109,67.84722222222221,67.9861111111111,67.93055555555554,67.86111111111109,67.93055555555554,67.80555555555554,67.88888888888887,68.16666666666666,68.37499999999999,68.23611111111109,68.33333333333333,68.27777777777776,68.34722222222221,68.36111111111111,68.26388888888889,68.40277777777776,68.41666666666664,68.4861111111111,68.49999999999999,68.44444444444444,67.84722222222221,67.9861111111111,67.84722222222221,67.84722222222221,68.01388888888889,68.19444444444443,68.30555555555556,68.3611111111111,68.45833333333333,68.51388888888889,68.33333333333333,68.2361111111111,68.2361111111111,68.25,68.01388888888889,68.02777777777777,68.06944444444444,68.18055555555556,68.06944444444446,68.31944444444444,68.22222222222221,68.26388888888889,68.27777777777777,68.45833333333333,68.61111111111111,68.41666666666666,68.26388888888889,68.29166666666666,68.33333333333333,68.375,69.04166666666666,69.08333333333333,69.09722222222221,69.15277777777777,69.11111111111111,68.95833333333333,68.97222222222223,68.94444444444444,68.86111111111111,68.45833333333333,68.75,68.68055555555554,68.70833333333331,68.7361111111111,68.84722222222223,68.87499999999999,68.88888888888887,68.80555555555554,68.86111111111109,68.72222222222221,68.7361111111111,68.74999999999999,68.72222222222221,68.0,67.875,68.05555555555556,67.94444444444444,67.90277777777777,67.875,67.94444444444444,67.90277777777777,67.90277777777777,67.98611111111111,67.95833333333333,67.90277777777776,67.83333333333333,67.77777777777777,67.76388888888889,67.55555555555556,67.86111111111111,67.87500000000001,67.88888888888889,67.90277777777777,67.88888888888889,67.91666666666666,67.88888888888889,67.80555555555556,67.83333333333334,67.76388888888887,67.80555555555556,67.79166666666666,67.7361111111111,67.55555555555554,68.06944444444444,67.99999999999999,67.8611111111111,68.20833333333331,68.26388888888887,68.375,68.18055555555556,68.25,68.25,67.5,67.33333333333334,67.34722222222221,67.36111111111111,66.625,66.6388888888889,66.83333333333333,66.83333333333333,66.79166666666667,66.86111111111111,66.8888888888889,66.84722222222221,66.77777777777779,66.77777777777777,66.73611111111111,66.7222222222222,66.27777777777777,66.22222222222221,66.19444444444444,65.58333333333333,65.7361111111111,65.79166666666666,66.04166666666666,66.12499999999999,66.11111111111109,66.06944444444443,65.91666666666664,65.99999999999999,65.90277777777776,65.90277777777776,66.51388888888887,66.69444444444443,66.76388888888889,66.55555555555554,67.27777777777777,67.30555555555554,67.22222222222221,67.36111111111111,67.43055555555556,67.33333333333333,67.34722222222221,67.31944444444444,67.43055555555556,67.54166666666667,67.66666666666667,67.7638888888889,68.34722222222224,68.47222222222224,68.55555555555556,69.15277777777777,69.22222222222223,69.2638888888889,69.18055555555557,69.18055555555556,69.18055555555557,69.04166666666667,69.11111111111111,69.16666666666666,69.19444444444443,69.20833333333331,69.40277777777776,69.3611111111111,69.30555555555554,69.55555555555556,69.52777777777777,69.51388888888887,69.51388888888889,69.47222222222221,69.40277777777777,69.5,69.30555555555554,69.34722222222221,69.41666666666666,69.33333333333331,69.23611111111109,69.18055555555554,69.02777777777777,68.97222222222223,69.0,69.02777777777777,68.84722222222221,68.79166666666666,68.70833333333333,68.72222222222221,68.73611111111111,68.81944444444444,68.84722222222221,68.87500000000001,68.86111111111111,68.58333333333334,68.47222222222223,68.54166666666666,68.52777777777777,68.55555555555554,68.54166666666666,68.59722222222221,68.55555555555556,68.62499999999999,68.68055555555556,68.5,68.65277777777777,68.56944444444443,68.43055555555557,68.02777777777777,67.98611111111111,67.93055555555556,67.97222222222223,67.94444444444444,67.81944444444444,67.8888888888889,67.98611111111111,68.0277777777778,68.16666666666669,68.22222222222221,68.13888888888889,68.22222222222223,68.09722222222223,68.00000000000001,68.09722222222224,68.43055555555557,68.34722222222224,68.40277777777779,68.41666666666669,68.45833333333336,68.44444444444446,68.30555555555557,68.36111111111111,68.23611111111111,67.94444444444444,68.15277777777777,68.08333333333331,68.2361111111111,68.34722222222221,68.66666666666666,68.76388888888887,68.74999999999999,68.7361111111111,68.7638888888889,68.8611111111111,68.80555555555554,68.76388888888887,68.6111111111111,68.4861111111111,68.51388888888889,68.52777777777779,68.43055555555556,68.52777777777777,68.7361111111111,68.40277777777776,68.2361111111111,68.38888888888889,68.06944444444444,68.16666666666666,68.08333333333333,68.23611111111111,68.01388888888889,68.02777777777779,67.88888888888889,68.125,68.09722222222223,68.08333333333333,68.0,67.88888888888889,67.3611111111111,67.40277777777776,67.44444444444443,67.55555555555554,67.59722222222221,67.47222222222221,67.43055555555554,67.15277777777777,67.20833333333331,67.26388888888887,67.15277777777776,67.18055555555556,67.11111111111111,67.09722222222221,66.95833333333333,67.24999999999999,67.43055555555554,67.3472222222222,67.74999999999999,67.59722222222221,67.55555555555556,67.44444444444444,67.70833333333331,67.70833333333333,67.70833333333333,67.69444444444444,67.58333333333333,67.6111111111111,67.625,67.68055555555556,68.34722222222223,68.24999999999999,68.2638888888889,68.25,68.12500000000001,68.11111111111111,68.13888888888889,68.47222222222223,68.11111111111111,68.20833333333333,68.19444444444444,68.22222222222223,68.37500000000001,68.3611111111111,68.30555555555554,68.24999999999999,68.09722222222221,68.15277777777776,67.95833333333331,67.9861111111111,67.99999999999999,67.99999999999997,67.99999999999997,68.05555555555553,68.1111111111111,68.08333333333331,68.26388888888889,68.06944444444443,68.11111111111111,68.09722222222221,68.05555555555556,67.68055555555554,67.77777777777777,67.6388888888889,67.69444444444444,67.73611111111111,67.73611111111111,67.5,67.90277777777779,67.83333333333333,67.875,67.81944444444444,67.70833333333334,67.86111111111111,67.90277777777779,67.81944444444444,67.97222222222223,68.00000000000001,68.05555555555556,68.05555555555556,68.09722222222221,68.13888888888889,68.08333333333334,67.95833333333334,68.05555555555554,68.125,68.0,68.20833333333334,68.20833333333334,68.15277777777777,67.5,67.91666666666666,67.88888888888889,67.95833333333333,67.97222222222221,67.97222222222221,68.01388888888889,68.20833333333331,68.22222222222221,68.30555555555556,68.31944444444444,68.29166666666666,67.65277777777779,67.12499999999999,67.15277777777777,67.2361111111111,67.12499999999999,67.08333333333333,67.0,67.05555555555556,66.375,66.29166666666666,66.47222222222221,66.65277777777777,66.69444444444443,66.70833333333333,66.79166666666667,66.91666666666667,66.99999999999999,66.98611111111109,67.65277777777777,67.66666666666664,67.65277777777777,67.75,67.05555555555556,67.12500000000001,67.06944444444444,67.05555555555554,67.125,67.06944444444444,67.13888888888889,67.23611111111111,68.02777777777777,68.3888888888889,68.37500000000001,68.41666666666667,68.55555555555556,68.58333333333334,68.66666666666667,68.61111111111111,69.31944444444444,69.33333333333333,69.3611111111111,69.12499999999999,69.20833333333331,69.01388888888886,69.02777777777776,68.8611111111111,68.54166666666667,68.56944444444446,68.59722222222223,68.625,68.63888888888889,68.55555555555557,69.25000000000001,69.16666666666667,69.15277777777777,69.125,68.48611111111111,68.36111111111111,68.30555555555556,68.22222222222221,68.09722222222221,68.1388888888889,68.16666666666666,68.20833333333333,68.05555555555554,67.95833333333333,67.90277777777777,67.91666666666667,67.94444444444444,68.02777777777777,67.8611111111111,67.95833333333334,67.88888888888889,68.12499999999999,68.06944444444444,68.06944444444444,68.33333333333334,68.3888888888889,68.33333333333333,68.2361111111111,68.19444444444444,68.11111111111111,68.05555555555556,68.08333333333333,68.08333333333333,68.09722222222223,68.63888888888889,68.4861111111111,68.49999999999999,68.625,68.68055555555554,68.68055555555556,68.65277777777777,68.63888888888889,68.75,68.81944444444444,68.80555555555556,68.87500000000001,68.80555555555556,68.73611111111111,68.80555555555556,68.84722222222221,68.81944444444443,68.7361111111111,68.05555555555556,68.13888888888889,68.09722222222221,68.09722222222221,68.15277777777777,68.05555555555556,67.98611111111111,68.09722222222223,68.18055555555554,68.20833333333333,68.26388888888889,68.19444444444444,68.16666666666666,68.44444444444444,68.47222222222221,68.41666666666667,68.15277777777777,68.18055555555554,68.12499999999999,68.13888888888889,68.08333333333333,68.01388888888889,67.98611111111111,67.93055555555556,67.93055555555556,68.0,67.95833333333333,68.02777777777777,67.97222222222221,68.04166666666666,68.83333333333331,68.74999999999999,68.04166666666667,68.0,68.05555555555554,68.26388888888889,68.25,68.25,68.27777777777779,68.16666666666666,68.15277777777777,67.56944444444444,67.65277777777777,67.4861111111111,67.47222222222223,67.38888888888889,67.625,67.55555555555556,67.56944444444444,67.54166666666666,67.40277777777777,67.44444444444444,67.52777777777779,67.55555555555554,67.59722222222221,67.51388888888887,67.54166666666666,67.6111111111111,67.74999999999999,67.68055555555556,67.62499999999999,67.68055555555556,68.34722222222221,68.31944444444444,68.2361111111111,68.20833333333334,67.8888888888889,67.97222222222223,67.91666666666667,67.98611111111111,67.27777777777779,68.0,67.93055555555556,68.0,67.99999999999999,68.08333333333333,68.08333333333334,68.02777777777777,67.79166666666666,67.72222222222221,67.8611111111111,67.88888888888889,67.875,67.81944444444443,67.81944444444443,67.81944444444443,67.77777777777776,67.62499999999999,67.54166666666666,66.83333333333333,66.80555555555556,66.80555555555554,66.84722222222223,66.90277777777777,66.9861111111111,66.90277777777779,67.29166666666667,67.29166666666667,67.20833333333333,67.25,67.97222222222223,67.90277777777779,68.02777777777777,68.125,68.1388888888889,68.06944444444444,68.125,68.30555555555554,68.45833333333333,68.19444444444444,67.45833333333333,67.5,66.80555555555556,66.86111111111111,66.88888888888889,66.95833333333334,66.97222222222224,66.86111111111111,66.91666666666667,67.54166666666667,67.58333333333334,67.65277777777779,67.66666666666667,67.65277777777777,67.54166666666666,67.6111111111111,67.6111111111111,67.43055555555556,67.59722222222221,67.29166666666666,67.33333333333333,67.45833333333333,67.36111111111111,67.31944444444444,67.19444444444444,67.27777777777777,67.2361111111111,67.16666666666666,67.19444444444446,67.59722222222221,68.04166666666666,67.93055555555554,68.52777777777777,68.54166666666666,68.4861111111111,68.375,68.3611111111111,68.55555555555554,68.36111111111111,68.43055555555556,68.40277777777777,68.33333333333333,68.36111111111111,68.375,68.41666666666667,68.34722222222221,68.30555555555554,68.45833333333333,68.38888888888889,68.16666666666667,68.05555555555556,67.99999999999999,68.01388888888889,68.05555555555554,68.19444444444444,68.19444444444444,68.18055555555557,68.15277777777779,68.22222222222223,68.15277777777777,68.43055555555556,68.45833333333333,68.54166666666666,68.51388888888889,68.55555555555556,68.625,67.84722222222223,67.84722222222221,67.95833333333333,67.99999999999999,67.95833333333333,68.00000000000001,67.94444444444446,67.86111111111113,67.91666666666667,68.01388888888889,67.95833333333334,68.0138888888889,68.00000000000001,68.47222222222223,68.55555555555556,68.51388888888889,68.4861111111111,68.48611111111111,68.34722222222223,68.31944444444444,68.31944444444446,68.30555555555556,68.27777777777777,68.33333333333334,68.27777777777777,68.27777777777777,68.375,68.38888888888889,68.47222222222221,67.76388888888889,68.63888888888889,68.68055555555554,68.66666666666666,68.68055555555554,68.75,68.68055555555554,68.63888888888889,68.63888888888889,68.63888888888889,68.6111111111111,68.68055555555554,68.6388888888889,68.7361111111111,68.79166666666666,68.80555555555556,68.77777777777779,68.75,68.66666666666666,68.74999999999999,68.62499999999999,68.72222222222221,68.625,68.68055555555556,68.65277777777779,68.72222222222223,68.79166666666667,68.79166666666667,68.875,68.79166666666666,69.52777777777776,69.44444444444444,69.40277777777777,69.45833333333333,69.43055555555554,69.41666666666666,69.43055555555556,69.52777777777779,69.54166666666667,69.47222222222221,69.38888888888889,69.43055555555554,69.33333333333333,69.18055555555556,69.26388888888889,69.09722222222221,69.12499999999999,69.22222222222221,69.26388888888889,69.22222222222221,69.34722222222223,69.34722222222221,69.55555555555554,69.55555555555554,69.59722222222221,69.59722222222221,69.59722222222221,69.54166666666667,69.48611111111111,69.30555555555554,69.30555555555553,69.19444444444443,69.2222222222222,69.19444444444443,69.13888888888887,69.06944444444443,69.06944444444444,68.56944444444444,68.65277777777779,68.51388888888889,68.69444444444444,68.70833333333333,68.72222222222221,68.7361111111111,68.61111111111109,68.7361111111111,68.70833333333331,68.72222222222221,68.70833333333333,68.73611111111111,68.7638888888889,68.625,68.54166666666667,68.48611111111111,68.45833333333334,68.44444444444446,68.27777777777779,68.40277777777779,68.34722222222224,68.52777777777779,68.5138888888889,68.72222222222223,68.68055555555556,68.68055555555556,68.65277777777779,68.63888888888889,68.65277777777777,69.08333333333333,68.49999999999999,68.62499999999999,68.58333333333331,68.6111111111111,68.70833333333331,68.05555555555554,68.1111111111111,68.16666666666666,68.24999999999999,68.29166666666666,68.29166666666667,68.33333333333333,68.26388888888889,68.27777777777777,68.1388888888889,68.16666666666667,67.72222222222223,67.72222222222223,67.93055555555554,67.79166666666667,67.88888888888887,67.93055555555556,67.94444444444443,67.81944444444443,67.72222222222221,67.74999999999999,67.77777777777776,67.79166666666666,67.76388888888887,67.80555555555554,68.34722222222221,68.33333333333331,68.25,67.97222222222223,67.90277777777779,68.54166666666666,68.51388888888889,68.47222222222221,68.48611111111111,68.33333333333333,68.38888888888889,68.40277777777779,68.41666666666667,68.54166666666667,68.70833333333333,68.70833333333333,69.1111111111111,69.05555555555556,68.93055555555556,68.88888888888889,68.80555555555554,68.73611111111111,68.77777777777777,68.81944444444444,68.93055555555554,68.95833333333333,68.97222222222221,69.05555555555556,68.84722222222221,68.81944444444446,68.73611111111113,68.75000000000001,68.72222222222223,68.87499999999999,68.80555555555554,68.90277777777777,68.88888888888889,68.88888888888889,68.8611111111111,68.80555555555554,68.79166666666666,68.77777777777777,68.74999999999999,68.6111111111111,68.59722222222221,68.59722222222223,68.4861111111111,68.4861111111111,68.45833333333334,68.51388888888889,68.375,68.375,68.29166666666666,68.31944444444444,68.24999999999999,68.15277777777776,68.19444444444443,67.88888888888889,68.13888888888889,68.22222222222221,68.36111111111109,68.3611111111111,68.33333333333331,68.33333333333331,68.38888888888887,68.40277777777777,68.31944444444443,68.27777777777776,68.20833333333333,68.34722222222221,68.40277777777776,68.36111111111111,67.68055555555556,67.72222222222223,67.72222222222221,67.65277777777779,67.79166666666667,67.83333333333334,67.94444444444444,67.22222222222223,67.31944444444444,67.41666666666664,67.3611111111111,67.36111111111109,67.45833333333331,67.16666666666664,67.15277777777777,67.37499999999999,67.29166666666666,67.06944444444444,67.05555555555556,67.09722222222221,67.08333333333333,67.08333333333334,67.11111111111111,67.20833333333334,67.25,67.37499999999999,67.29166666666666,67.22222222222221,67.12499999999999,67.18055555555556,67.8611111111111,67.86111111111111,67.86111111111111,67.875,67.87499999999999,67.91666666666666,67.83333333333333,68.52777777777777,68.51388888888889,68.41666666666667,68.47222222222221,68.38888888888889,68.20833333333333,68.51388888888887,68.51388888888889,68.56944444444443,68.66666666666664,68.81944444444443,68.74999999999999,68.63888888888887,68.75,68.76388888888889,68.04166666666667,67.90277777777779,68.0,67.94444444444444,68.09722222222221,68.02777777777779,67.95833333333334,67.94444444444443,67.93055555555554,67.94444444444444,67.91666666666666,68.05555555555554,68.0,67.97222222222221,68.02777777777777,68.02777777777779,68.06944444444444,67.9861111111111,68.02777777777777,68.15277777777777,68.2638888888889,68.26388888888889,68.22222222222221,67.5,67.58333333333333,67.56944444444444,67.56944444444443,67.74999999999997,67.66666666666664,67.72222222222221,68.41666666666666,68.43055555555553,68.40277777777776,68.34722222222221,68.41666666666664,68.41666666666664,68.4861111111111,68.4722222222222,68.52777777777776,68.54166666666666,68.58333333333331,68.54166666666664,68.7361111111111,68.66666666666666,68.59722222222221,68.56944444444444,68.56944444444444,68.66666666666667,68.62500000000001,68.58333333333333,68.65277777777777,68.56944444444444,68.625,69.3611111111111,69.18055555555556,69.30555555555557,69.33333333333334,69.2777777777778,69.375,69.30555555555556,69.36111111111113,69.34722222222223,69.34722222222224,69.45833333333333,69.34722222222221,69.44444444444444,69.45833333333333,69.47222222222221,69.38888888888889,69.38888888888889,69.375,69.26388888888889,69.11111111111111,69.19444444444444,69.31944444444444,69.25,69.27777777777777,69.29166666666666,69.34722222222223,69.375,69.26388888888889,69.41666666666666,69.37499999999999,69.44444444444443,69.43055555555554,69.33333333333333,69.30555555555554,69.27777777777777,69.20833333333333,69.29166666666667,69.26388888888889,69.29166666666666,69.23611111111111,69.19444444444444,69.125,69.08333333333331,69.11111111111111,69.08333333333334,69.18055555555556,69.08333333333333,69.08333333333334,69.01388888888889,68.95833333333333,69.02777777777777,68.9861111111111,69.19444444444443,69.15277777777777,69.19444444444444,69.15277777777779,69.04166666666667,69.09722222222223,69.05555555555557,68.87500000000001,68.7638888888889,68.79166666666669,68.7638888888889,68.80555555555556,68.76388888888889,68.79166666666666,68.77777777777777,68.65277777777777,68.65277777777777,68.70833333333333,68.63888888888889,68.70833333333333,68.76388888888887,68.68055555555554,68.63888888888887,68.6111111111111,68.70833333333333,68.70833333333333,68.80555555555556,68.47222222222221,68.33333333333333,68.24999999999999,68.11111111111109,68.12499999999999,67.99999999999999,68.02777777777776,68.04166666666664,68.01388888888887,67.95833333333333,68.18055555555554,68.26388888888889,68.29166666666666,68.30555555555554,68.30555555555554,68.33333333333333,68.38888888888887,68.30555555555557,68.41666666666667,68.43055555555556,68.40277777777779,68.45833333333333,68.48611111111111,68.4861111111111,67.81944444444444,67.88888888888889,67.94444444444444,67.88888888888889,67.80555555555557,67.81944444444444,68.18055555555556,68.27777777777779,68.27777777777779,68.43055555555556,68.38888888888889,68.38888888888889,68.36111111111111,68.375,68.3611111111111,68.43055555555556,68.49999999999999,68.44444444444444,68.47222222222223,68.40277777777777,68.34722222222221,68.31944444444443,68.33333333333331,68.15277777777777,68.16666666666664,68.04166666666667,68.08333333333331,68.08333333333333,68.06944444444444,67.36111111111111,68.08333333333334,68.08333333333333,68.06944444444444,68.04166666666667,67.94444444444444,67.90277777777777,67.83333333333333,67.80555555555554,67.87499999999999,67.76388888888889,67.70833333333331,67.70833333333333,67.0,67.05555555555554,67.08333333333333,66.81944444444444,66.72222222222221,66.70833333333333,66.6111111111111,66.69444444444444,66.77777777777777,66.76388888888889,66.61111111111111,66.90277777777777,66.94444444444444,67.05555555555554,66.95833333333333,66.90277777777777,66.80555555555556,67.55555555555557,67.59722222222223,67.59722222222221,67.56944444444444,67.58333333333334,67.7638888888889,67.88888888888891,67.47222222222221,67.4861111111111,67.51388888888889,67.54166666666666,67.52777777777777,67.59722222222223,68.29166666666667,68.2638888888889,68.31944444444446,68.47222222222221,68.375,68.34722222222221,68.5,68.55555555555556,68.44444444444446,68.55555555555556,67.91666666666669,67.88888888888889,67.81944444444446,67.8611111111111,67.90277777777777,67.81944444444443,67.95833333333333,67.93055555555554,68.00000000000001,67.93055555555554,67.91666666666667,67.90277777777777,67.88888888888889,67.77777777777779,68.27777777777779,68.25000000000001,68.16666666666667,68.12500000000001,68.11111111111113,68.15277777777779,68.13888888888889,67.43055555555556,67.30555555555556,67.40277777777779,67.52777777777777,67.15277777777777,67.05555555555554,66.84722222222221,66.84722222222221,66.74999999999997,67.51388888888887,67.54166666666666,67.40277777777776,67.34722222222221,67.34722222222221,67.47222222222221,67.43055555555554,67.18055555555554,66.86111111111111,66.95833333333333,66.9861111111111,66.34722222222223,66.375,66.44444444444444,66.40277777777777,66.2638888888889,66.36111111111113,66.31944444444444,66.38888888888891,66.33333333333334,66.31944444444446,66.97222222222223,67.06944444444444,67.09722222222223,67.05555555555556,67.44444444444444,67.48611111111111,67.62499999999999,67.74999999999999,67.63888888888889,67.625,67.52777777777779,67.625,67.56944444444443,67.6111111111111,67.56944444444444,67.54166666666666,67.83333333333333,67.93055555555554,67.83333333333333,67.76388888888889,68.52777777777777,68.45833333333331,68.44444444444444,68.47222222222221,68.69444444444443,68.63888888888889,68.70833333333333,68.79166666666664,68.86111111111111,68.95833333333333,68.90277777777777,68.66666666666666,68.65277777777777,67.97222222222223,67.93055555555556,67.93055555555556,67.91666666666667,67.81944444444444,68.08333333333334,67.95833333333334,67.75000000000001,67.77777777777777,67.77777777777777,67.75,67.72222222222221,67.65277777777777,66.88888888888889,66.95833333333331,66.91666666666666,66.8472222222222,66.84722222222221,66.95833333333331,67.04166666666666,66.95833333333333,66.68055555555556,66.70833333333331,66.66666666666664,66.68055555555554,66.625,66.56944444444444,66.69444444444444,66.66666666666669,66.66666666666667,67.40277777777777,67.3888888888889,67.31944444444446,67.34722222222224,67.31944444444447,67.16666666666667,67.31944444444444,67.5277777777778,67.40277777777777,67.44444444444446,67.44444444444446,67.5277777777778,67.65277777777779,68.44444444444444,68.47222222222223,68.48611111111111,68.66666666666667,68.65277777777779,68.58333333333334,68.55555555555556,68.68055555555556,68.88888888888889,68.93055555555556,68.97222222222221,68.95833333333331,68.91666666666667,68.91666666666667,68.95833333333334,69.20833333333333,69.31944444444444,69.34722222222221,69.38888888888889,69.40277777777776,69.375,69.55555555555557,69.59722222222223,69.51388888888889,69.59722222222221,69.83333333333333,69.875,69.80555555555557,69.75000000000001,69.80555555555556,69.74999999999999,69.81944444444443,69.97222222222221,69.90277777777777,69.90277777777779,69.94444444444444,69.8888888888889,69.84722222222223,69.84722222222221,69.80555555555554,69.83333333333333,69.84722222222221,69.97222222222221,70.06944444444443,69.9861111111111,70.04166666666666,69.88888888888889,69.84722222222221,69.90277777777777,69.91666666666666,69.90277777777777,69.87499999999999,69.84722222222221,69.88888888888889,69.80555555555554,69.7361111111111,69.68055555555556,69.80555555555557,69.79166666666666,69.7361111111111,69.76388888888889,69.79166666666666,68.99999999999999,68.97222222222221,68.95833333333333,68.8611111111111,68.875,68.91666666666667,68.83333333333334,68.88888888888889,68.75,68.20833333333334,68.11111111111111,67.9861111111111,68.05555555555556,67.94444444444444,68.04166666666666,68.04166666666666,67.94444444444446,68.05555555555554,68.19444444444444,68.125,68.20833333333333,68.18055555555556,68.24999999999999,68.19444444444444,68.23611111111111,67.61111111111111,67.62500000000001,67.58333333333333,67.62499999999999,67.47222222222221,68.23611111111111,68.22222222222221,68.22222222222221,68.3611111111111,68.41666666666667,68.44444444444444,68.50000000000001,68.36111111111111,68.5,69.04166666666667,69.125,69.20833333333334,69.09722222222223,69.125,69.01388888888889,69.01388888888889,69.08333333333334,68.98611111111111,68.88888888888887,68.81944444444444,68.86111111111111,68.81944444444446,68.80555555555556,68.86111111111111,68.875,69.55555555555556,69.55555555555556,69.55555555555554,69.45833333333333,69.4861111111111,69.44444444444443,69.49999999999999,69.49999999999999,68.97222222222221,68.91666666666666,68.90277777777779,68.86111111111111,68.94444444444444,68.90277777777779,68.8888888888889,68.81944444444446,68.80555555555559,68.94444444444446,68.95833333333334,68.98611111111113,68.95833333333334,69.00000000000001,68.93055555555557,68.91666666666667,68.94444444444444,68.81944444444444,68.86111111111111,68.75,68.75,68.79166666666666,68.59722222222221,68.6111111111111,68.65277777777777,68.65277777777777,68.44444444444444,68.52777777777777,68.44444444444444,68.38888888888889,68.80555555555554,68.80555555555554,68.79166666666667,68.875,68.91666666666667,68.91666666666667,68.83333333333334,68.86111111111111,68.72222222222223,68.62499999999999,68.6388888888889,68.62500000000001,68.61111111111111,68.59722222222223,68.6388888888889,68.6388888888889,68.70833333333336,68.68055555555557,68.65277777777779,68.66666666666666,68.70833333333333,68.41666666666667,68.50000000000001,68.59722222222223,68.56944444444446,68.52777777777779,68.69444444444444,68.58333333333334,68.58333333333334,68.59722222222223,68.58333333333333,68.56944444444444,68.55555555555553,68.56944444444443,68.44444444444443,68.44444444444443,68.54166666666664,68.54166666666664,68.625,68.625,68.69444444444444,68.63888888888889,68.47222222222221,68.38888888888889,68.50000000000001,68.54166666666669,68.2638888888889,68.36111111111113,68.34722222222221,68.45833333333334,68.47222222222223,68.625,68.72222222222223,68.56944444444444,68.55555555555556,68.62499999999999,68.7222222222222,68.80555555555554,68.83333333333333,68.69444444444443,68.69444444444444,68.69444444444444,68.69444444444444,68.69444444444444,68.72222222222221,68.74999999999999,68.79166666666666,68.81944444444444,68.875,68.90277777777779,68.84722222222223,68.91666666666666,69.20833333333333,69.19444444444444,69.06944444444446,69.08333333333336,69.22222222222223,69.20833333333334,69.12500000000001,69.04166666666669,68.73611111111113,68.80555555555557,68.70833333333336,68.80555555555557,68.91666666666669,68.88888888888889,68.88888888888889,68.79166666666666,68.80555555555554,68.90277777777777,68.86111111111111,68.87500000000001,68.87499999999999,68.90277777777777,68.93055555555556,68.88888888888889,68.81944444444446,68.73611111111111,68.75,68.79166666666669,68.75000000000001,68.72222222222223,68.58333333333334,68.6388888888889,68.68055555555557,68.61111111111111,68.69444444444446,68.625,68.77777777777776,68.76388888888889,68.98611111111111,68.94444444444444,68.80555555555554,68.81944444444443,68.59722222222221,68.4861111111111,68.3611111111111,68.3611111111111,68.29166666666666,68.29166666666667,68.33333333333334,68.31944444444446,68.25,68.25,68.25,68.31944444444444,68.33333333333333,68.38888888888889,68.26388888888889,68.23611111111111,68.30555555555556,68.29166666666667,68.33333333333333,68.34722222222221,68.44444444444444,68.45833333333333,68.3888888888889,68.375,68.33333333333334,68.4861111111111,68.47222222222221,68.45833333333331,68.63888888888887,68.51388888888889,68.68055555555556,68.7361111111111,68.7361111111111,68.51388888888889,68.55555555555556,68.61111111111111,68.6388888888889,68.55555555555556,68.58333333333334,68.48611111111111,68.41666666666667,68.33333333333334,68.31944444444446,68.27777777777779,68.27777777777779,68.30555555555557,68.18055555555557,68.27777777777777,68.20833333333333,68.30555555555554,68.24999999999999,68.2638888888889,68.30555555555556,68.30555555555556,68.30555555555556,68.2361111111111,68.20833333333331,68.15277777777776,68.06944444444443,68.18055555555554,68.18055555555554,68.20833333333331,68.31944444444443,68.48611111111111,68.56944444444444,68.49999999999999,68.52777777777777,68.48611111111111,68.48611111111111,68.4861111111111,68.51388888888887,68.51388888888889,68.51388888888889,67.9861111111111,68.04166666666666,67.97222222222221,67.9861111111111,67.84722222222221,68.05555555555554,67.9722222222222,67.87499999999999,67.47222222222221,67.54166666666666,67.61111111111109,67.5972222222222,67.59722222222221,67.63888888888887,67.69444444444443,67.72222222222221,67.59722222222221,67.56944444444444,67.51388888888889,67.48611111111111,67.55555555555556,67.52777777777777,67.62499999999999,67.6111111111111,67.73611111111111,67.77777777777777,67.81944444444443,67.88888888888889,67.88888888888889,67.8611111111111,68.33333333333333,68.29166666666667,68.2638888888889,68.34722222222223,68.48611111111111,68.34722222222223,68.3611111111111,68.51388888888889,68.97222222222223,68.94444444444446,68.90277777777779,69.00000000000001,69.00000000000001,69.02777777777777,69.05555555555556,69.08333333333334,68.45833333333334,68.45833333333334,68.59722222222223,68.61111111111111,68.61111111111111,68.65277777777779,68.72222222222223,68.70833333333334,68.65277777777779,68.65277777777777,68.625,68.55555555555556,68.55555555555554,68.55555555555554,68.58333333333331,68.66666666666666,68.72222222222221,68.80555555555554,68.73611111111109,68.77777777777779,68.70833333333333,68.68055555555557,68.625,68.625,68.65277777777777,68.58333333333333,68.58333333333333,68.55555555555556,68.55555555555556,68.56944444444444,69.20833333333333,69.2361111111111,69.15277777777776,69.19444444444443,69.22222222222221,69.22222222222223,69.11111111111113,69.125,69.31944444444446,69.31944444444443,69.24999999999999,69.27777777777779,69.20833333333334,69.19444444444444,69.31944444444444,69.30555555555556,69.31944444444444,69.26388888888889,69.23611111111111,69.13888888888889,69.12499999999999,68.94444444444444,68.91666666666667,68.88888888888889,68.83333333333331,68.76388888888887,68.74999999999999,68.79166666666664,68.83333333333331,68.77777777777776,68.88888888888887,68.875,68.83333333333333,68.77777777777777,68.77777777777777,68.68055555555556,68.69444444444444,68.69444444444443,68.45833333333333,68.51388888888889,68.51388888888889,68.43055555555554,68.49999999999997,68.47222222222221,68.44444444444444,68.47222222222223,68.47222222222223,68.41666666666667,68.49999999999999,68.56944444444444,68.63888888888887,68.83333333333333,68.8611111111111,68.75,68.81944444444444,68.88888888888889,68.83333333333333,68.77777777777777,68.69444444444443,68.59722222222221,68.52777777777776,68.5,68.5,68.44444444444444,68.34722222222223,68.36111111111111,68.31944444444446,68.29166666666666,68.43055555555554,68.34722222222221,68.44444444444444,68.5,68.59722222222221,68.65277777777779,68.54166666666666,68.47222222222221,68.29166666666664,68.30555555555554,68.22222222222221,67.95833333333333,67.88888888888889,67.81944444444444,67.72222222222223,67.94444444444443,67.93055555555554,67.93055555555554,67.97222222222221,67.9861111111111,67.97222222222221,68.05555555555556,68.05555555555554,68.16666666666664,68.29166666666667,68.34722222222223,68.44444444444444,68.51388888888889,68.48611111111111,68.47222222222223,68.41666666666667,68.5,68.61111111111111,68.66666666666666,68.70833333333334,68.69444444444443,68.7361111111111,68.72222222222221,68.84722222222221,68.8611111111111,68.97222222222221,68.97222222222221,69.06944444444444,68.375,68.45833333333333,68.33333333333331,68.27777777777776,68.41666666666664,68.51388888888887,68.58333333333331,68.44444444444443,68.40277777777777,68.47222222222221,68.29166666666667,68.19444444444444,68.2361111111111,68.18055555555554,68.1111111111111,68.16666666666667,68.31944444444444,68.27777777777777,68.20833333333331,68.02777777777776,67.99999999999999,67.90277777777777,67.94444444444443,68.0,68.04166666666664,68.19444444444443,68.26388888888887,68.26388888888889,68.56944444444443,68.4861111111111,68.97222222222221,68.87499999999997,69.02777777777776,68.95833333333333,68.65277777777777,68.66666666666666,68.58333333333331,68.83333333333333,68.9861111111111,68.98611111111111,69.06944444444444,69.125,69.04166666666666,68.375,68.41666666666667,68.41666666666666,68.27777777777777,68.37499999999999,68.31944444444444,68.41666666666669,68.45833333333333,67.73611111111111,67.66666666666667,67.56944444444446,67.54166666666666,66.93055555555556,66.79166666666666,66.75,66.625,66.69444444444444,66.88888888888889,67.08333333333333,67.05555555555556,67.1388888888889,67.31944444444444,67.18055555555556,67.22222222222223,67.13888888888889,66.95833333333334,66.93055555555556,66.84722222222223,66.86111111111111,66.94444444444444,67.65277777777777,67.66666666666666,67.58333333333333,67.65277777777779,67.61111111111111,67.62499999999999,67.58333333333333,67.47222222222223,68.125,68.20833333333333,68.20833333333333,67.97222222222223,68.375,68.44444444444444,68.43055555555556,68.54166666666667,68.41666666666666,68.47222222222221,68.36111111111111,68.2638888888889,68.29166666666667,68.34722222222221,68.41666666666667,68.44444444444444,68.5,68.59722222222221,68.56944444444444,68.65277777777777,68.59722222222221,68.56944444444444,68.56944444444444,68.59722222222223,68.69444444444444,68.66666666666667,68.65277777777776,68.66666666666667,68.38888888888889,68.44444444444443,68.52777777777777,68.51388888888889,68.5138888888889,68.84722222222223,68.98611111111111,68.97222222222223,69.0,68.9861111111111,69.1111111111111,69.1111111111111,69.13888888888889,69.15277777777779,69.125,69.04166666666667,68.98611111111111,68.81944444444444,68.77777777777777,68.83333333333333,68.7638888888889,68.79166666666667,68.80555555555556,68.7638888888889,68.70833333333333,68.625,68.6111111111111,68.62499999999999,68.6111111111111,68.54166666666666,68.79166666666666,68.8611111111111,68.72222222222221,68.77777777777776,68.8611111111111,68.08333333333331,68.08333333333333,68.09722222222221,68.0,67.94444444444443,67.91666666666666,67.75,67.68055555555556,67.66666666666667,67.68055555555556,66.98611111111111,67.05555555555554,67.09722222222221,67.16666666666666,67.06944444444444,67.1111111111111,67.13888888888889,67.09722222222221,67.16666666666666,67.18055555555553,67.09722222222223,67.18055555555554,67.25,67.16666666666667,67.18055555555556,67.1388888888889,67.15277777777779,67.23611111111111,66.45833333333334,66.3888888888889,67.19444444444444,67.18055555555554,67.23611111111111,67.23611111111113,67.20833333333334,67.02777777777777,67.13888888888889,67.23611111111113,67.16666666666669,67.22222222222223,67.94444444444444,67.98611111111111,68.09722222222221,68.02777777777777,68.02777777777779,68.02777777777777,67.9861111111111,68.01388888888889,68.01388888888887,67.91666666666667,68.04166666666667,67.26388888888889,67.02777777777777,67.16666666666667,67.18055555555556,67.24999999999999,67.13888888888887,67.15277777777779,67.95833333333331,67.9722222222222,67.16666666666667,67.15277777777777,67.08333333333333,67.1111111111111,67.19444444444443,67.41666666666667,67.27777777777777,67.27777777777779,67.375,67.29166666666666,67.19444444444444,67.125,67.15277777777777,67.20833333333331,67.24999999999999,67.22222222222223,67.125,67.11111111111111,66.97222222222221,67.11111111111111,67.06944444444443,67.69444444444446,67.81944444444444,67.77777777777777,67.88888888888889,67.88888888888889,67.91666666666666,67.38888888888887,67.25,67.24999999999999,67.95833333333333,67.98611111111111,68.05555555555556,68.12499999999999,68.125,68.06944444444444,68.29166666666667,68.20833333333333,68.25,68.30555555555554,68.38888888888889,68.44444444444444,68.37500000000001,68.33333333333334,68.29166666666667,68.41666666666667,68.61111111111111,68.70833333333334,68.90277777777779,68.91666666666666,68.97222222222223,69.11111111111111,69.15277777777779,69.05555555555554,69.01388888888889,68.97222222222221,69.08333333333333,69.63888888888889,69.72222222222223,69.73611111111111,69.75,69.66666666666666,69.59722222222221,69.65277777777777,69.63888888888887,69.65277777777777,69.44444444444443,69.5972222222222,69.6111111111111,69.52777777777777,69.49999999999999,69.4722222222222,69.56944444444443,69.56944444444444,69.72222222222223,69.69444444444444,69.66666666666666,69.52777777777777,69.45833333333333,69.40277777777777,69.31944444444444,69.31944444444444,69.30555555555554,69.4861111111111,69.44444444444443,69.52777777777777,69.55555555555556,69.625,69.69444444444444,69.66666666666667,69.59722222222221,69.63888888888887,69.63888888888889,69.56944444444444,69.44444444444444,69.48611111111111,69.65277777777777,69.58333333333333,69.4861111111111,69.6111111111111,69.68055555555556,69.625,69.58333333333333,69.625,69.5,69.47222222222221,69.41666666666667,69.54166666666666,69.5,69.54166666666667,69.58333333333333,69.58333333333333,69.48611111111113,69.44444444444446,69.54166666666667,69.5138888888889,69.45833333333334,69.3888888888889,69.31944444444446,69.33333333333334,69.41666666666667,69.3611111111111,69.41666666666667,69.375,69.47222222222223,69.45833333333334,69.52777777777777,69.51388888888889,69.47222222222223,69.34722222222223,69.26388888888889,69.375,69.43055555555554,69.38888888888889,69.41666666666667,69.38888888888889,69.40277777777777,69.38888888888889,69.41666666666667,69.43055555555554,69.5,69.33333333333334,69.40277777777779,69.2638888888889,69.18055555555556,69.20833333333334,69.18055555555556,69.19444444444443,69.16666666666666,69.13888888888889,69.08333333333333,69.09722222222221,69.12499999999999,69.19444444444444,69.2361111111111,69.22222222222221,69.18055555555556,69.05555555555556,69.05555555555556,69.11111111111111,69.0,68.88888888888889,68.84722222222221,68.90277777777779,68.90277777777779,68.86111111111113,68.86111111111113,68.79166666666667,68.83333333333334,68.79166666666667,68.74999999999999,68.80555555555554,68.77777777777777,68.84722222222223,68.90277777777779,68.90277777777777,68.88888888888889,68.93055555555554,68.94444444444444,68.94444444444444,68.97222222222221,68.95833333333333,68.90277777777777,68.84722222222221,68.69444444444444,68.66666666666667,68.6388888888889,68.76388888888889,68.80555555555556,68.73611111111111,68.91666666666667,69.00000000000001,69.0138888888889,68.93055555555556,68.91666666666666,68.98611111111111,68.97222222222221,68.91666666666666,68.80555555555556,68.54166666666667,68.5,68.59722222222223,68.72222222222223,68.7638888888889,68.68055555555556,68.625,68.51388888888889,68.47222222222221,68.3472222222222,68.3611111111111,68.41666666666666,68.49999999999999,68.47222222222221,68.4861111111111,68.59722222222223,68.63888888888889,68.54166666666667,68.47222222222223,68.40277777777779,68.45833333333333,68.55555555555556,68.55555555555556,68.52777777777779,68.62500000000001,68.59722222222223,68.625,68.6388888888889,68.70833333333334,68.58333333333334,68.83333333333334,68.8888888888889,68.91666666666667,68.77777777777779,68.875,68.86111111111111,68.83333333333333,68.8611111111111,68.79166666666666,68.875,69.0,68.93055555555556,68.87499999999999,68.94444444444441,68.94444444444443,68.95833333333331,68.95833333333331,68.95833333333331,69.01388888888887,69.13888888888887,69.1111111111111,68.97222222222221,68.81944444444443,68.8611111111111,68.77777777777777,68.80555555555554,68.81944444444444,68.79166666666667,68.81944444444444,69.05555555555556,69.125,69.13888888888889,69.04166666666666,69.06944444444443,68.9861111111111,68.91666666666667,68.90277777777779,68.97222222222223,68.95833333333334,68.94444444444444,68.77777777777779,68.81944444444446,68.75,68.63888888888889,68.66666666666667,68.70833333333334,68.69444444444446,68.70833333333334,68.73611111111113,68.66666666666667,68.70833333333334,68.80555555555556,68.81944444444443,68.79166666666666,68.88888888888889,68.88888888888886,68.79166666666666,68.72222222222221,68.66666666666666,68.4861111111111,68.45833333333333,68.44444444444443,68.49999999999999,68.55555555555554,68.61111111111111,68.72222222222223,68.81944444444446,68.84722222222223,68.87499999999999,68.81944444444444,68.90277777777779,68.95833333333334,69.02777777777777,68.84722222222221,68.90277777777777,68.80555555555556,68.375,68.36111111111111,68.26388888888889,68.36111111111111,68.36111111111111,68.30555555555556,68.43055555555556,68.38888888888889,68.41666666666666,68.52777777777777,68.56944444444444,68.58333333333334,68.63888888888889,68.77777777777777,68.77777777777777,68.4861111111111,68.44444444444444,68.15277777777779,68.125,67.43055555555554,67.41666666666666],\"type\":\"scatter\"},{\"line\":{\"color\":\"#0AF\"},\"mode\":\"lines\",\"name\":\"NEW test dataset accuracy (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[61.32222222222221,61.46666666666666,61.48888888888888,61.58888888888888,62.29999999999999,62.29999999999999,62.27777777777777,62.36666666666666,62.199999999999996,62.36666666666667,62.15555555555555,62.18888888888889,61.82222222222222,62.400000000000006,62.51111111111111,63.07777777777778,63.35555555555555,64.03333333333333,63.55555555555555,63.400000000000006,63.03333333333334,62.36666666666668,61.70000000000001,61.68888888888888,61.77777777777777,61.82222222222222,61.83333333333333,61.83333333333333,61.85555555555555,61.96666666666666,61.85555555555555,62.02222222222221,61.8,62.099999999999994,61.38888888888888,62.04444444444444,62.15555555555555,62.22222222222222,62.333333333333336,62.35555555555555,62.5,62.51111111111111,62.92222222222223,62.900000000000006,62.81111111111112,62.78888888888889,62.822222222222216,62.77777777777778,63.48888888888889,63.61111111111111,63.94444444444443,64.43333333333332,65.03333333333333,65.05555555555554,64.86666666666666,64.83333333333331,64.78888888888886,65.53333333333333,65.5111111111111,65.34444444444443,65.43333333333334,65.42222222222222,65.64444444444445,65.84444444444443,66.38888888888889,66.37777777777778,66.3,65.55555555555554,65.48888888888888,65.34444444444445,64.78888888888889,64.28888888888889,63.611111111111114,62.93333333333332,62.46666666666666,62.27777777777778,62.12222222222222,62.17777777777777,62.11111111111111,62.022222222222226,62.08888888888889,62.20000000000001,61.6,61.53333333333333,61.74444444444445,61.68888888888889,61.87777777777777,61.855555555555554,61.84444444444444,61.888888888888886,61.93333333333332,61.87777777777778,61.88888888888889,61.85555555555557,61.31111111111112,61.25555555555556,60.63333333333334,61.10000000000001,61.05555555555557,61.111111111111114,61.68888888888889,62.13333333333333,62.62222222222222,63.3,63.711111111111116,63.35555555555556,63.511111111111106,63.411111111111104,63.344444444444434,63.49999999999999,63.56666666666666,63.699999999999996,64.17777777777776,64.19999999999999,63.86666666666667,63.75555555555556,63.833333333333336,63.74444444444444,63.7,63.766666666666666,63.62222222222222,63.58888888888888,63.62222222222222,63.66666666666667,64.1888888888889,64.22222222222223,64.84444444444443,64.92222222222222,64.95555555555556,65.06666666666665,65.16666666666666,65.21111111111111,65.38888888888889,65.26666666666665,65.23333333333333,65.6888888888889,65.68888888888888,65.75555555555555,65.49999999999999,65.36666666666666,64.71111111111111,64.5,64.7,64.74444444444444,65.0111111111111,65.22222222222221,65.13333333333334,65.0,65.12222222222222,65.15555555555555,65.33333333333333,65.35555555555554,65.24444444444444,65.24444444444444,65.27777777777777,65.17777777777776,65.19999999999999,64.88888888888889,64.94444444444444,64.95555555555555,64.27777777777779,64.33333333333333,64.23333333333333,64.38888888888889,63.78888888888889,63.911111111111104,63.75555555555556,63.75555555555557,63.98888888888889,64.10000000000001,64.65555555555555,64.47777777777777,64.47777777777777,64.43333333333334,64.17777777777778,64.14444444444443,64.10000000000001,64.26666666666667,64.14444444444445,64.21111111111111,64.11111111111111,64.11111111111111,63.53333333333334,63.355555555555554,63.41111111111111,63.5888888888889,63.622222222222234,64.02222222222224,63.9888888888889,64.0,64.67777777777778,64.5,64.55555555555556,64.4,64.39999999999999,64.46666666666667,64.58888888888889,64.61111111111111,64.58888888888889,64.56666666666666,64.66666666666666,64.94444444444446,64.86666666666666,64.88888888888889,65.15555555555555,65.15555555555555,65.06666666666668,64.9888888888889,65.02222222222223,64.88888888888889,64.92222222222222,64.87777777777778,65.44444444444444,65.68888888888888,65.65555555555555,65.6,65.1222222222222,65.06666666666666,64.45555555555555,63.78888888888888,63.777777777777764,63.69999999999999,63.23333333333333,63.29999999999999,63.97777777777777,63.999999999999986,63.36666666666666,63.34444444444444,63.422222222222224,63.41111111111111,63.28888888888888,63.233333333333334,63.29999999999999,63.355555555555554,63.233333333333334,62.57777777777778,62.64444444444443,62.655555555555544,62.52222222222221,62.644444444444446,62.644444444444446,62.64444444444443,62.633333333333326,62.64444444444444,62.35555555555555,62.37777777777778,62.577777777777776,62.7111111111111,63.29999999999999,63.98888888888888,63.97777777777778,64.18888888888888,64.64444444444445,64.56666666666668,64.55555555555557,64.55555555555556,65.1888888888889,65.16666666666667,65.22222222222221,65.23333333333332,65.41111111111111,65.42222222222222,65.42222222222222,65.38888888888887,65.54444444444444,66.13333333333333,66.26666666666665,66.18888888888887,66.36666666666666,66.36666666666666,66.19999999999999,66.23333333333332,66.41111111111111,66.38888888888889,66.1,66.11111111111111,65.71111111111111,65.63333333333333,65.73333333333332,65.73333333333333,65.69999999999999,65.47777777777776,65.53333333333332,65.55555555555554,65.57777777777777,65.13333333333333,65.14444444444443,65.04444444444444,65.0,65.06666666666666,65.08888888888887,65.1111111111111,65.03333333333333,64.97777777777776,64.96666666666665,65.0111111111111,64.87777777777777,64.9888888888889,64.78888888888888,64.76666666666667,64.77777777777779,64.77777777777779,64.63333333333334,64.56666666666668,65.14444444444445,65.1111111111111,65.72222222222221,65.61111111111111,65.54444444444444,65.53333333333333,65.4888888888889,65.63333333333334,65.65555555555555,65.7111111111111,65.54444444444444,65.96666666666667,65.87777777777778,65.98888888888888,66.05555555555556,65.94444444444444,65.8,65.84444444444443,65.96666666666667,65.96666666666667,65.93333333333334,65.96666666666665,66.07777777777778,66.0,66.17777777777778,65.52222222222223,65.71111111111111,65.72222222222221,65.76666666666667,65.16666666666667,64.76666666666667,64.77777777777777,64.77777777777777,64.8111111111111,64.81111111111112,64.67777777777778,64.65555555555555,64.7,64.4,64.35555555555555,64.54444444444445,64.6,64.66666666666667,64.61111111111111,64.52222222222221,64.19999999999999,64.26666666666665,64.28888888888888,64.26666666666665,64.05555555555556,63.977777777777774,63.93333333333334,63.93333333333334,64.02222222222221,63.955555555555556,64.63333333333334,64.64444444444445,64.62222222222222,64.6,65.24444444444444,65.64444444444443,64.98888888888888,65.04444444444444,64.48888888888888,64.51111111111109,64.64444444444445,64.58888888888889,64.42222222222222,64.68888888888888,64.8111111111111,64.65555555555555,64.55555555555556,64.5,64.42222222222222,64.41111111111113,64.76666666666667,64.74444444444445,64.67777777777778,64.60000000000001,64.84444444444446,64.82222222222222,64.83333333333334,64.72222222222223,64.74444444444445,64.74444444444444,64.73333333333333,64.7,64.8111111111111,64.84444444444443,64.82222222222222,64.86666666666667,65.33333333333333,65.26666666666667,66.02222222222223,66.05555555555554,66.04444444444442,66.15555555555555,66.29999999999998,66.27777777777777,65.4111111111111,65.43333333333332,65.49999999999999,65.6111111111111,65.82222222222221,65.94444444444444,65.3,65.31111111111109,65.33333333333331,65.38888888888887,65.39999999999999,65.43333333333331,65.36666666666666,65.36666666666665,65.25555555555555,65.3111111111111,65.3,65.26666666666667,65.3,65.24444444444444,65.22222222222221,65.25555555555555,65.42222222222222,65.4,65.32222222222222,65.37777777777777,65.3888888888889,65.43333333333334,65.45555555555556,65.39999999999999,66.16666666666666,66.13333333333333,65.46666666666667,65.55555555555556,65.54444444444444,65.47777777777776,66.08888888888887,65.97777777777777,65.96666666666665,65.97777777777777,65.94444444444443,65.89999999999999,65.33333333333334,65.5111111111111,65.64444444444445,65.7,65.02222222222224,65.0777777777778,64.95555555555556,64.96666666666668,64.96666666666668,64.91111111111113,64.93333333333335,64.92222222222225,64.88888888888891,64.71111111111114,64.63333333333334,64.50000000000001,64.47777777777779,64.51111111111112,64.5777777777778,64.66666666666667,65.4,65.32222222222222,65.25555555555556,65.26666666666668,65.26666666666667,65.36666666666669,65.41111111111113,65.37777777777778,64.76666666666668,64.80000000000001,65.36666666666667,65.3111111111111,64.74444444444445,64.4888888888889,65.08888888888889,65.04444444444444,65.05555555555556,65.1111111111111,65.10000000000001,65.08888888888889,65.06666666666666,65.16666666666666,64.93333333333331,65.02222222222221,65.04444444444445,65.12222222222222,65.13333333333333,64.52222222222223,64.52222222222223,64.16666666666666,64.0111111111111,63.89999999999999,63.83333333333332,63.86666666666665,63.95555555555554,63.322222222222216,63.33333333333332,63.38888888888888,64.05555555555556,64.1,64.18888888888888,64.17777777777776,64.67777777777776,64.24444444444444,64.34444444444443,64.33333333333333,63.844444444444434,63.76666666666665,63.77777777777776,63.84444444444443,63.85555555555555,63.71111111111111,63.86666666666666,63.944444444444436,63.96666666666665,63.94444444444443,63.98888888888888,64.6,64.6111111111111,64.89999999999999,64.96666666666665,64.38888888888889,64.46666666666665,64.4,64.24444444444444,64.94444444444444,65.06666666666668,65.03333333333335,65.02222222222223,65.06666666666666,65.04444444444445,65.02222222222223,65.10000000000001,65.10000000000001,65.07777777777778,65.10000000000001,65.55555555555556,65.42222222222223,65.42222222222223,65.45555555555556,65.41111111111111,65.52222222222223,65.55555555555556,65.46666666666667,65.50000000000001,65.51111111111112,65.41111111111111,65.51111111111112,65.52222222222221,65.57777777777777,65.6,66.27777777777777,66.27777777777777,66.27777777777777,66.41111111111111,66.37777777777777,66.22222222222221,66.2111111111111,66.2111111111111,66.13333333333333,66.07777777777777,66.07777777777777,66.06666666666666,66.64444444444445,66.67777777777778,66.68888888888888,66.82222222222221,67.0,66.94444444444446,66.91111111111111,66.89999999999999,66.96666666666667,67.0111111111111,67.06666666666666,67.04444444444444,67.10000000000001,67.1,67.04444444444444,67.03333333333333,66.97777777777779,66.81111111111112,66.57777777777778,66.45555555555556,66.33333333333334,66.24444444444445,66.23333333333333,66.18888888888888,66.16666666666667,66.05555555555556,66.08888888888889,66.22222222222221,66.18888888888888,66.04444444444444,66.1111111111111,65.97777777777776,65.83333333333333,65.71111111111111,65.77777777777777,65.65555555555555,65.63333333333333,65.58888888888889,65.58888888888889,65.55555555555556,65.5,65.44444444444444,65.3888888888889,65.42222222222223,65.33333333333334,65.25555555555556,65.24444444444444,65.5,65.77777777777779,65.82222222222222,65.86666666666667,65.94444444444444,65.99999999999999,66.13333333333333,66.15555555555555,66.1111111111111,66.17777777777778,66.07777777777777,66.1,66.15555555555555,66.15555555555555,65.6111111111111,65.81111111111112,65.91111111111111,65.96666666666667,66.13333333333334,66.13333333333335,66.26666666666668,66.20000000000002,66.24444444444445,66.17777777777778,66.04444444444445,66.11111111111111,66.11111111111111,66.11111111111111,66.11111111111111,66.22222222222223,66.03333333333333,65.96666666666665,65.92222222222223,66.04444444444444,65.98888888888888,65.89999999999999,65.82222222222221,65.85555555555554,65.99999999999999,65.84444444444443,65.69999999999999,65.72222222222221,65.75555555555555,65.74444444444444,66.4,66.27777777777777,66.24444444444443,66.16666666666666,66.24444444444444,66.16666666666666,66.16666666666666,66.26666666666665,66.26666666666665,66.08888888888887,66.2222222222222,66.24444444444444,66.25555555555556,66.28888888888888,66.39999999999999,66.37777777777778,66.53333333333335,66.45555555555556,66.56666666666666,66.63333333333334,66.63333333333334,66.64444444444446,66.65555555555555,66.10000000000001,66.1,66.13333333333334,66.08888888888889,66.02222222222223,66.07777777777778,66.02222222222223,66.04444444444445,66.05555555555556,66.11111111111111,66.08888888888889,66.0,66.02222222222223,66.05555555555556,65.94444444444444,65.79999999999998,66.06666666666666,66.08888888888889,66.03333333333332,66.03333333333332,66.03333333333332,65.93333333333332,65.89999999999999,65.8,65.85555555555555,65.86666666666666,65.78888888888889,65.85555555555557,65.9,65.7,66.11111111111111,66.01111111111112,66.10000000000001,66.28888888888889,66.41111111111111,66.42222222222223,66.42222222222223,66.3,66.27777777777779,65.56666666666668,65.26666666666665,65.27777777777777,65.27777777777777,64.56666666666666,64.5111111111111,64.61111111111111,64.62222222222222,64.72222222222221,64.77777777777777,64.8,64.74444444444443,64.82222222222221,64.85555555555554,64.82222222222221,64.89999999999999,64.4111111111111,64.34444444444443,64.3111111111111,63.48888888888888,63.67777777777776,63.76666666666665,63.84444444444443,63.73333333333333,63.766666666666666,63.644444444444446,63.466666666666654,63.42222222222222,63.5111111111111,63.511111111111106,64.05555555555556,64.28888888888889,64.33333333333334,64.17777777777778,64.85555555555555,64.98888888888888,65.08888888888889,65.04444444444444,64.96666666666665,64.94444444444444,64.9,64.98888888888888,64.92222222222222,64.93333333333332,64.94444444444443,64.93333333333334,65.4,65.41111111111111,65.42222222222222,66.27777777777779,66.27777777777779,66.33333333333333,66.3111111111111,66.3888888888889,66.34444444444445,66.35555555555555,66.47777777777779,66.56666666666668,66.60000000000001,66.65555555555557,66.8,66.8888888888889,66.85555555555555,67.01111111111112,66.94444444444444,66.89999999999999,66.77777777777777,66.7888888888889,66.77777777777779,66.76666666666667,66.72222222222221,66.7,66.63333333333333,66.57777777777777,66.6,66.5,66.38888888888889,66.36666666666667,66.4,66.28888888888888,66.2111111111111,66.15555555555557,66.1111111111111,66.12222222222222,66.1888888888889,66.27777777777779,66.26666666666668,66.3,66.2,66.05555555555557,66.03333333333333,65.96666666666665,65.93333333333334,66.04444444444444,65.96666666666667,65.96666666666665,65.93333333333332,65.97777777777777,66.04444444444445,65.9,65.94444444444444,66.05555555555556,66.15555555555555,65.85555555555554,65.87777777777778,65.87777777777777,66.04444444444444,66.06666666666666,66.10000000000001,66.1,66.23333333333333,66.18888888888888,66.26666666666668,66.2,66.16666666666667,66.07777777777777,65.9888888888889,65.96666666666667,66.06666666666666,66.25555555555556,66.25555555555556,66.33333333333333,66.35555555555555,66.31111111111112,66.47777777777777,66.46666666666665,66.56666666666666,66.56666666666666,66.27777777777779,66.42222222222223,66.39999999999999,66.28888888888889,66.33333333333333,66.56666666666666,66.60000000000001,66.60000000000001,66.42222222222222,66.41111111111113,66.34444444444445,66.35555555555557,66.1888888888889,66.31111111111112,66.35555555555557,66.44444444444446,66.35555555555557,66.3888888888889,66.47777777777777,66.42222222222223,66.12222222222222,66.06666666666665,66.05555555555554,65.92222222222222,65.92222222222222,65.95555555555553,65.88888888888889,65.6111111111111,65.55555555555554,65.39999999999999,65.68888888888888,65.55555555555554,65.63333333333334,65.66666666666666,65.5888888888889,65.34444444444445,65.24444444444444,65.25555555555556,65.23333333333333,65.34444444444443,65.32222222222222,65.3111111111111,65.22222222222223,65.17777777777778,65.07777777777778,65.03333333333333,65.21111111111111,65.17777777777776,65.17777777777778,65.28888888888888,65.52222222222221,65.57777777777777,65.54444444444444,65.7222222222222,65.84444444444443,65.7222222222222,65.76666666666665,66.04444444444442,66.03333333333332,65.97777777777776,65.84444444444443,66.05555555555556,66.1,66.04444444444444,66.06666666666666,66.45555555555555,66.5,66.54444444444444,66.74444444444443,66.56666666666666,66.60000000000001,66.63333333333334,66.8,66.43333333333334,66.5,66.52222222222221,66.45555555555555,66.52222222222221,66.5888888888889,66.48888888888888,66.46666666666667,66.38888888888889,66.47777777777777,66.35555555555555,66.25555555555556,66.32222222222222,66.27777777777779,66.33333333333334,66.31111111111112,66.51111111111112,66.63333333333334,66.52222222222223,66.28888888888889,66.31111111111112,66.34444444444443,66.31111111111112,65.85555555555555,65.83333333333334,65.87777777777777,66.0,65.88888888888889,65.89999999999999,65.71111111111111,66.05555555555556,66.02222222222223,65.9888888888889,66.01111111111112,65.91111111111111,65.85555555555555,65.8888888888889,65.96666666666667,65.92222222222222,65.85555555555555,65.9888888888889,65.96666666666667,66.01111111111112,66.02222222222223,65.96666666666667,66.06666666666666,66.05555555555554,66.07777777777777,66.15555555555555,66.3111111111111,66.33333333333334,66.27777777777779,65.72222222222223,66.36666666666666,66.47777777777777,66.37777777777778,66.34444444444445,66.33333333333333,66.32222222222222,66.54444444444445,66.52222222222221,66.54444444444445,66.55555555555556,66.53333333333333,65.95555555555555,65.66666666666667,65.71111111111111,65.63333333333333,65.76666666666667,65.74444444444444,65.64444444444443,65.73333333333332,65.06666666666666,64.99999999999999,65.03333333333332,65.03333333333332,65.04444444444444,64.94444444444443,64.93333333333332,64.96666666666665,64.96666666666665,65.05555555555554,65.64444444444443,65.56666666666665,65.44444444444443,65.44444444444443,64.83333333333331,64.86666666666666,64.93333333333331,64.89999999999999,64.86666666666666,64.88888888888889,64.88888888888889,64.95555555555555,65.5111111111111,65.77777777777777,65.75555555555555,65.73333333333333,65.67777777777778,65.67777777777778,65.73333333333332,65.63333333333333,66.25555555555555,66.28888888888888,66.34444444444443,66.25555555555555,66.19999999999999,66.13333333333333,66.1,66.1,65.99999999999999,65.95555555555555,65.93333333333332,65.93333333333332,65.9888888888889,66.06666666666666,66.8,66.8111111111111,66.77777777777777,66.75555555555555,66.43333333333332,66.42222222222222,66.46666666666665,66.34444444444443,66.45555555555555,66.42222222222222,66.42222222222222,66.44444444444443,66.44444444444444,66.4,66.37777777777778,66.42222222222222,66.5111111111111,66.44444444444444,66.34444444444443,66.39999999999999,66.47777777777776,66.56666666666666,66.54444444444444,66.44444444444444,66.49999999999999,66.46666666666665,66.48888888888887,66.34444444444442,66.37777777777777,66.27777777777777,66.2111111111111,66.35555555555555,66.3111111111111,66.32222222222221,66.7333333333333,66.51111111111109,66.5333333333333,66.52222222222221,66.44444444444444,66.44444444444444,66.42222222222222,66.47777777777776,66.5111111111111,66.55555555555554,66.54444444444444,66.58888888888889,66.53333333333333,66.64444444444443,66.57777777777777,66.63333333333333,66.52222222222221,66.57777777777777,65.95555555555555,65.95555555555555,65.97777777777777,66.02222222222223,66.04444444444445,65.96666666666667,65.93333333333334,65.9888888888889,66.0,65.88888888888889,65.84444444444443,65.86666666666666,65.68888888888888,65.88888888888887,65.84444444444443,65.93333333333332,65.73333333333332,65.79999999999998,65.8111111111111,65.7111111111111,65.7333333333333,65.67777777777778,65.66666666666666,65.73333333333333,65.73333333333333,65.70000000000002,65.77777777777777,65.71111111111112,65.68888888888888,65.6888888888889,66.3888888888889,66.51111111111112,65.9,65.9,65.82222222222222,65.9888888888889,65.94444444444444,65.93333333333334,65.91111111111111,65.85555555555555,65.8888888888889,65.26666666666668,65.32222222222224,65.33333333333336,65.31111111111112,65.31111111111112,65.55555555555556,65.53333333333335,65.61111111111111,65.73333333333333,65.68888888888888,65.71111111111111,65.76666666666665,65.69999999999999,65.72222222222221,65.74444444444443,65.79999999999998,65.82222222222221,65.9111111111111,65.92222222222222,65.82222222222222,65.82222222222222,66.55555555555556,66.51111111111112,66.4888888888889,66.3888888888889,66.06666666666669,66.02222222222223,66.00000000000001,66.01111111111112,65.4,65.97777777777777,66.1111111111111,66.11111111111111,66.13333333333333,66.06666666666666,66.05555555555556,66.1,65.84444444444443,65.72222222222221,65.75555555555556,65.75555555555555,65.66666666666666,65.57777777777778,65.54444444444444,65.5,65.43333333333334,65.38888888888889,65.41111111111111,64.71111111111111,64.73333333333333,64.73333333333333,64.64444444444443,64.6111111111111,64.63333333333334,64.74444444444444,65.04444444444444,65.13333333333334,65.01111111111112,65.08888888888889,65.84444444444445,65.85555555555557,65.7888888888889,65.85555555555555,65.78888888888889,65.73333333333333,65.77777777777779,65.75555555555555,65.9888888888889,65.8777777777778,65.24444444444444,65.23333333333333,64.62222222222222,64.63333333333333,64.66666666666666,64.7,64.68888888888888,64.69999999999999,64.73333333333333,65.33333333333333,65.43333333333334,65.42222222222222,65.48888888888888,65.5111111111111,65.5,65.47777777777777,65.54444444444445,65.47777777777777,65.62222222222222,65.42222222222222,65.23333333333333,65.3,65.36666666666667,65.39999999999999,65.53333333333333,65.64444444444445,65.6,65.64444444444443,65.57777777777777,65.78888888888889,66.18888888888888,66.17777777777776,66.8111111111111,66.88888888888889,66.9222222222222,66.86666666666666,66.83333333333333,66.92222222222222,66.77777777777776,66.77777777777776,66.72222222222223,66.75555555555556,66.68888888888888,66.69999999999999,66.69999999999999,66.69999999999999,66.58888888888887,66.62222222222222,66.62222222222222,66.17777777777776,66.22222222222221,66.12222222222222,66.12222222222222,66.05555555555556,65.97777777777777,65.93333333333332,65.97777777777777,65.91111111111111,66.05555555555554,66.12222222222222,66.32222222222222,66.33333333333333,66.34444444444443,66.3111111111111,66.3,66.32222222222221,65.77777777777777,65.72222222222221,65.8,65.78888888888889,65.73333333333332,65.63333333333333,65.58888888888889,65.65555555555555,65.67777777777778,65.67777777777778,65.8,65.8,65.76666666666667,66.52222222222223,66.54444444444445,66.64444444444443,66.65555555555555,66.64444444444443,66.64444444444445,66.66666666666667,66.6,66.65555555555554,66.46666666666667,66.45555555555556,66.43333333333332,66.54444444444444,66.55555555555554,66.57777777777777,66.47777777777777,65.87777777777778,66.3888888888889,66.44444444444444,66.38888888888889,66.5111111111111,66.5,66.54444444444444,66.6,66.4888888888889,66.55555555555556,66.6,66.61111111111111,66.57777777777778,66.5888888888889,66.5,66.5,66.46666666666667,66.34444444444445,66.27777777777777,66.26666666666667,66.23333333333333,66.24444444444444,66.15555555555555,66.26666666666667,66.26666666666667,66.17777777777778,66.17777777777778,66.17777777777778,66.12222222222222,66.16666666666666,66.80000000000001,66.83333333333334,66.73333333333333,66.73333333333335,66.67777777777778,66.76666666666665,66.8,66.84444444444445,66.91111111111111,66.83333333333334,66.75555555555557,66.67777777777778,66.71111111111112,66.71111111111112,66.72222222222221,66.73333333333333,66.82222222222222,66.91111111111113,66.87777777777778,66.89999999999999,66.97777777777776,67.05555555555554,67.15555555555555,67.1111111111111,67.03333333333333,67.11111111111111,67.05555555555556,67.03333333333335,67.06666666666668,66.93333333333334,66.92222222222222,66.93333333333334,66.96666666666668,67.01111111111112,66.96666666666667,67.07777777777777,66.95555555555556,66.56666666666666,66.54444444444444,66.55555555555556,66.56666666666666,66.59999999999998,66.63333333333333,66.65555555555554,66.54444444444445,66.53333333333333,66.44444444444444,66.41111111111111,66.54444444444444,66.57777777777777,66.4888888888889,66.45555555555555,66.39999999999999,66.35555555555555,66.37777777777778,66.41111111111111,66.45555555555555,66.4888888888889,66.53333333333333,66.77777777777779,66.8,66.74444444444444,66.77777777777779,66.8,66.87777777777777,66.73333333333332,66.75555555555555,67.08888888888889,66.58888888888889,66.56666666666666,66.54444444444444,66.56666666666668,66.42222222222223,65.76666666666667,65.82222222222224,65.8888888888889,65.91111111111111,65.92222222222223,65.9,65.82222222222222,65.85555555555557,65.85555555555555,65.82222222222222,65.82222222222222,65.57777777777778,65.4888888888889,65.47777777777779,65.51111111111112,65.43333333333334,65.36666666666667,65.41111111111111,65.5888888888889,65.61111111111111,65.67777777777779,65.7,65.78888888888889,65.83333333333333,65.84444444444445,66.28888888888889,66.3,66.32222222222222,66.24444444444444,66.32222222222222,66.94444444444444,66.98888888888888,66.81111111111112,66.85555555555554,66.89999999999998,66.8,66.87777777777777,66.92222222222222,66.87777777777777,66.94444444444444,66.86666666666666,67.06666666666666,67.15555555555555,67.22222222222223,67.1888888888889,67.15555555555557,67.07777777777778,67.00000000000001,66.84444444444445,66.83333333333334,66.76666666666667,66.71111111111111,66.66666666666667,66.54444444444445,66.54444444444444,66.57777777777778,66.63333333333333,66.65555555555557,66.67777777777778,66.66666666666667,66.74444444444444,66.74444444444444,66.84444444444443,66.84444444444443,66.8,66.84444444444445,66.83333333333333,66.77777777777777,66.8111111111111,66.77777777777776,66.85555555555554,66.95555555555555,66.97777777777777,66.89999999999999,66.86666666666666,66.84444444444445,66.78888888888889,66.85555555555555,66.96666666666667,66.9111111111111,66.95555555555555,66.92222222222222,66.62222222222222,66.55555555555554,66.52222222222221,66.6,66.46666666666667,66.41111111111111,66.48888888888888,66.48888888888888,66.45555555555556,66.38888888888889,66.46666666666667,66.43333333333332,66.47777777777777,66.54444444444444,66.55555555555556,65.93333333333334,65.86666666666667,65.8,65.83333333333334,65.73333333333333,65.67777777777778,65.63333333333334,65.00000000000001,65.11111111111111,65.15555555555555,64.97777777777779,64.9888888888889,64.94444444444446,64.55555555555556,64.61111111111111,64.92222222222223,65.06666666666666,64.91111111111111,64.81111111111112,64.95555555555556,65.02222222222223,64.95555555555555,64.94444444444444,64.92222222222222,64.93333333333334,64.87777777777777,64.83333333333333,64.78888888888889,64.8888888888889,64.6888888888889,65.34444444444445,65.44444444444446,65.51111111111112,65.52222222222223,65.66666666666667,65.81111111111113,65.76666666666668,66.45555555555555,66.37777777777778,66.36666666666667,66.45555555555555,66.37777777777778,66.46666666666667,66.78888888888889,66.78888888888888,66.72222222222221,66.76666666666665,66.88888888888887,66.95555555555555,67.02222222222223,67.0,66.97777777777777,66.36666666666666,66.3888888888889,66.44444444444446,66.41111111111111,66.47777777777777,66.4,66.21111111111111,66.34444444444445,66.24444444444444,66.28888888888889,66.22222222222224,66.2,66.22222222222221,66.07777777777777,66.1888888888889,66.15555555555555,66.24444444444445,66.16666666666667,66.12222222222223,66.2,66.1888888888889,66.15555555555557,66.1,65.45555555555555,65.36666666666666,65.44444444444444,65.47777777777777,65.41111111111111,65.38888888888889,65.44444444444444,66.07777777777778,66.03333333333333,66.05555555555556,66.07777777777777,66.03333333333332,66.13333333333333,66.22222222222221,66.27777777777779,66.34444444444443,66.26666666666667,66.28888888888886,66.35555555555554,66.24444444444444,66.27777777777777,66.2111111111111,66.17777777777778,66.08888888888889,66.23333333333332,66.38888888888889,66.35555555555555,66.28888888888888,66.25555555555556,66.27777777777779,66.93333333333334,66.93333333333334,66.91111111111111,66.78888888888889,66.75555555555556,66.71111111111111,66.70000000000002,66.75555555555556,66.76666666666668,66.75555555555556,66.77777777777779,66.74444444444445,66.61111111111111,66.53333333333335,66.52222222222223,66.51111111111112,66.53333333333335,66.67777777777779,66.61111111111111,66.46666666666668,66.56666666666666,66.57777777777777,66.55555555555556,66.65555555555557,66.66666666666667,66.64444444444445,66.66666666666667,66.64444444444445,66.68888888888888,66.67777777777778,66.68888888888888,66.8,66.87777777777778,66.93333333333332,66.89999999999999,66.99999999999999,66.95555555555555,66.86666666666665,66.79999999999998,66.75555555555555,66.75555555555555,66.92222222222222,67.1,67.14444444444445,67.09999999999998,67.14444444444443,67.03333333333333,66.9,66.86666666666667,66.97777777777779,66.90000000000002,66.91111111111111,67.02222222222223,66.92222222222223,66.92222222222223,66.85555555555555,66.8,66.89999999999999,66.98888888888888,66.78888888888888,66.76666666666665,66.65555555555554,66.54444444444444,66.5111111111111,66.56666666666666,66.57777777777777,66.60000000000001,66.66666666666667,66.74444444444444,66.73333333333333,66.75555555555556,66.63333333333334,66.64444444444445,66.63333333333334,66.72222222222223,66.71111111111111,66.76666666666667,66.91111111111111,67.0,66.64444444444443,66.6,66.60000000000001,66.55555555555556,66.6,66.55555555555554,66.67777777777776,66.74444444444443,66.78888888888888,66.71111111111111,66.88888888888889,66.89999999999998,66.94444444444443,66.95555555555555,67.00000000000001,67.0111111111111,67.0111111111111,66.94444444444444,66.96666666666667,66.96666666666667,66.97777777777777,66.93333333333334,66.91111111111111,66.82222222222224,66.1888888888889,66.11111111111111,66.1,66.08888888888887,65.87777777777778,65.87777777777777,66.24444444444444,66.28888888888889,66.18888888888888,66.16666666666666,66.22222222222221,66.18888888888888,66.1,66.1111111111111,66.04444444444444,66.04444444444444,66.11111111111111,66.02222222222223,66.14444444444445,66.16666666666666,66.23333333333333,66.3,66.18888888888888,66.15555555555555,66.08888888888889,66.04444444444444,66.06666666666666,66.08888888888887,66.13333333333333,65.49999999999999,66.23333333333332,66.19999999999999,66.33333333333333,66.46666666666667,66.53333333333332,66.53333333333333,66.55555555555556,66.55555555555556,66.67777777777776,66.61111111111111,66.41111111111111,66.38888888888889,65.74444444444444,65.71111111111111,65.73333333333332,65.59999999999998,65.47777777777776,65.56666666666665,65.43333333333332,65.43333333333331,65.27777777777776,65.17777777777776,65.27777777777777,65.39999999999999,65.36666666666667,65.4,65.43333333333334,65.3888888888889,65.37777777777778,66.01111111111112,65.85555555555557,65.8888888888889,65.75555555555556,65.66666666666666,65.77777777777779,65.78888888888889,65.33333333333333,65.45555555555555,65.37777777777778,65.43333333333334,65.62222222222222,65.73333333333332,66.43333333333332,66.4111111111111,66.37777777777778,66.4,66.4111111111111,66.37777777777777,66.5111111111111,66.5111111111111,66.58888888888887,66.53333333333332,65.84444444444445,65.85555555555555,65.99999999999999,66.05555555555556,65.93333333333334,65.97777777777777,66.03333333333332,66.07777777777777,66.1222222222222,66.1111111111111,66.23333333333333,66.25555555555555,66.14444444444443,66.16666666666666,66.6,66.45555555555555,66.44444444444443,66.42222222222222,66.28888888888889,66.22222222222221,66.15555555555557,65.51111111111112,65.48888888888888,65.66666666666667,65.78888888888889,65.41111111111111,65.41111111111111,65.34444444444445,65.32222222222222,65.30000000000001,65.92222222222223,65.87777777777778,65.66666666666666,65.64444444444445,65.7111111111111,65.64444444444445,65.68888888888888,65.44444444444444,65.53333333333332,65.54444444444444,65.46666666666665,64.79999999999998,64.9222222222222,65.01111111111109,65.0,64.87777777777777,65.0222222222222,65.01111111111109,65.14444444444442,65.15555555555552,65.17777777777775,65.87777777777775,65.9222222222222,65.87777777777777,65.86666666666666,66.3111111111111,66.17777777777776,66.35555555555555,66.4,66.43333333333332,66.42222222222222,66.45555555555555,66.54444444444445,66.43333333333335,66.41111111111111,66.46666666666668,66.3111111111111,66.51111111111112,66.41111111111113,66.4,66.4,67.03333333333336,66.94444444444446,66.8,66.77777777777779,66.8777777777778,66.82222222222222,66.77777777777779,66.71111111111111,66.70000000000002,66.64444444444445,66.64444444444446,66.44444444444446,66.4888888888889,65.81111111111113,65.74444444444445,65.81111111111112,65.6888888888889,65.73333333333333,65.71111111111112,65.83333333333334,65.51111111111112,65.54444444444445,65.51111111111112,65.58888888888889,65.57777777777778,65.71111111111111,65.0777777777778,65.01111111111112,65.04444444444445,64.9888888888889,64.9888888888889,65.0,64.93333333333334,64.96666666666667,65.01111111111112,65.03333333333333,65.12222222222222,65.15555555555555,65.15555555555555,65.24444444444444,65.14444444444445,65.2,65.2,65.92222222222222,65.93333333333334,65.84444444444445,65.89999999999999,65.74444444444445,65.76666666666667,65.66666666666667,65.94444444444444,65.84444444444446,65.93333333333334,65.9,65.88888888888889,65.84444444444443,66.53333333333332,66.62222222222223,66.5888888888889,66.63333333333334,66.71111111111111,66.6888888888889,66.74444444444444,66.78888888888888,66.82222222222222,66.85555555555555,66.78888888888889,66.83333333333333,66.88888888888889,66.83333333333333,66.89999999999999,66.95555555555555,66.87777777777777,66.78888888888888,66.76666666666665,66.88888888888887,66.78888888888888,66.9,66.96666666666665,67.05555555555556,67.13333333333333,67.25555555555555,67.2111111111111,67.15555555555555,67.12222222222222,67.02222222222221,66.97777777777777,67.0111111111111,67.03333333333333,67.06666666666666,67.0111111111111,67.02222222222221,66.98888888888888,67.02222222222223,66.9888888888889,67.01111111111112,67.06666666666666,67.0111111111111,66.93333333333334,66.91111111111111,66.87777777777778,67.0,67.11111111111111,67.06666666666666,67.13333333333333,67.11111111111111,67.1222222222222,67.16666666666664,67.07777777777777,67.07777777777778,66.98888888888888,66.99999999999999,67.17777777777778,67.22222222222221,67.26666666666667,67.34444444444445,67.37777777777778,67.26666666666667,66.63333333333333,66.52222222222223,66.52222222222223,66.55555555555554,66.53333333333333,66.43333333333334,66.42222222222222,66.38888888888889,66.4111111111111,66.25555555555556,66.36666666666667,66.47777777777779,66.45555555555556,66.3888888888889,66.32222222222224,66.36666666666669,66.34444444444445,66.32222222222222,66.35555555555557,66.38888888888891,66.41111111111113,66.43333333333334,66.46666666666668,66.35555555555557,66.32222222222222,65.78888888888889,65.77777777777777,65.66666666666667,65.69999999999999,65.78888888888889,66.42222222222223,66.42222222222222,66.3,66.2,66.3111111111111,66.32222222222222,66.28888888888888,66.19999999999999,66.14444444444443,66.34444444444443,66.31111111111112,66.19999999999999,66.25555555555556,66.37777777777777,66.32222222222221,66.32222222222222,66.3111111111111,66.3,66.27777777777779,66.28888888888889,66.35555555555555,66.24444444444445,66.27777777777779,66.35555555555555,66.24444444444444,66.76666666666667,66.82222222222222,66.9,66.84444444444445,66.8,66.78888888888888,66.82222222222222,66.97777777777777,66.68888888888888,66.65555555555555,66.66666666666667,66.62222222222222,66.67777777777779,66.6888888888889,66.63333333333333,66.67777777777776,66.75555555555555,66.84444444444445,66.74444444444444,66.75555555555555,66.82222222222222,66.9,66.96666666666667,67.06666666666666,66.94444444444444,66.93333333333334,66.96666666666668,66.98888888888888,67.07777777777777,67.11111111111111,67.11111111111111,67.05555555555556,67.13333333333333,67.07777777777777,66.98888888888887,67.06666666666666,67.06666666666666,67.02222222222221,67.32222222222221,67.28888888888889,67.26666666666667,67.37777777777777,67.4111111111111,67.44444444444444,67.42222222222222,67.28888888888889,67.15555555555555,67.1,67.1111111111111,67.02222222222223,66.94444444444444,66.82222222222222,66.74444444444444,66.64444444444445,66.65555555555555,66.6888888888889,66.67777777777778,66.56666666666668,66.3888888888889,66.25555555555556,66.31111111111113,66.39999999999999,66.33333333333334,66.38888888888889,66.51111111111112,66.44444444444446,66.5,66.52222222222223,66.71111111111111,66.69999999999999,66.74444444444445,66.73333333333333,66.65555555555555,66.66666666666666,66.64444444444442,66.68888888888888,66.77777777777777,66.8111111111111,66.8,66.85555555555554,66.73333333333332,66.83333333333333,66.94444444444443,67.02222222222221,67.03333333333333,66.98888888888888,67.05555555555556,67.07777777777777,67.23333333333333,67.26666666666668,67.25555555555556,67.08888888888889,67.1,67.18888888888888,67.1888888888889,67.16666666666667,67.2,67.25555555555557,67.03333333333335,67.04444444444445,67.0,67.04444444444445,67.04444444444444,67.04444444444444,67.13333333333333,67.17777777777778,67.21111111111111,67.14444444444445,67.11111111111111,67.2222222222222,67.39999999999999,67.35555555555554,67.25555555555555,67.21111111111111,67.18888888888888,67.25555555555556,67.21111111111112,67.15555555555557,66.88888888888889,67.07777777777778,67.07777777777777,67.25555555555556,67.14444444444445,67.1,67.15555555555555,67.1,67.0,66.82222222222222,67.08888888888889,67.07777777777778,67.06666666666668,67.11111111111111,67.22222222222223,67.13333333333333,67.13333333333334,67.03333333333333,67.03333333333335,67.04444444444445,67.10000000000001,67.05555555555557,67.03333333333333,66.97777777777776,67.02222222222223,67.04444444444445,67.08888888888889,67.03333333333335,67.0111111111111,67.11111111111111,67.35555555555554,67.34444444444443,67.17777777777778,67.15555555555555,67.14444444444445,66.95555555555555,66.95555555555555,67.02222222222221,67.1222222222222,67.1111111111111,66.85555555555554,66.84444444444443,66.82222222222221,66.66666666666666,66.6222222222222,66.79999999999998,66.82222222222222,66.91111111111111,66.88888888888889,66.94444444444444,66.92222222222222,66.9,66.75555555555556,66.7888888888889,66.8888888888889,66.8888888888889,66.7777777777778,66.81111111111113,66.74444444444445,66.72222222222223,66.72222222222223,66.62222222222222,66.82222222222224,66.85555555555557,66.97777777777777,67.10000000000001,67.11111111111111,66.87777777777778,66.87777777777778,67.0,67.01111111111112,67.0,67.15555555555555,67.17777777777779,67.17777777777779,67.12222222222222,67.15555555555555,66.9888888888889,67.06666666666666,67.0,66.92222222222222,66.96666666666665,67.02222222222221,67.07777777777777,66.86666666666666,66.75555555555556,66.83333333333334,66.74444444444445,66.91111111111113,67.05555555555556,66.91111111111113,66.85555555555555,66.73333333333333,66.61111111111111,66.63333333333334,66.62222222222223,66.52222222222223,66.77777777777777,66.68888888888888,66.64444444444445,66.7,66.66666666666666,66.52222222222221,66.48888888888888,66.46666666666667,66.41111111111113,66.42222222222222,66.11111111111111,66.04444444444444,65.97777777777776,66.08888888888889,66.11111111111111,66.2111111111111,66.13333333333333,66.22222222222221,65.93333333333332,66.02222222222221,66.08888888888889,65.96666666666667,65.88888888888887,66.04444444444444,66.12222222222222,66.18888888888888,66.1111111111111,66.13333333333333,66.1111111111111,66.1,66.19999999999999,66.26666666666667,66.33333333333333,66.4,66.48888888888888,66.48888888888888,66.58888888888889,66.57777777777778,66.6888888888889,66.63333333333335,67.11111111111113,67.10000000000001,67.14444444444446,67.0888888888889,67.11111111111113,67.00000000000001,67.01111111111112,66.93333333333335,67.35555555555557,67.24444444444444,67.27777777777777,67.27777777777779,67.24444444444444,67.17777777777778,67.15555555555557,67.11111111111111,66.57777777777778,66.4888888888889,66.5,66.58888888888889,66.42222222222223,66.36666666666667,66.35555555555555,66.3,66.27777777777779,66.26666666666667,66.2,66.19999999999999,66.12222222222222,66.13333333333333,66.2111111111111,66.18888888888888,66.19999999999999,66.22222222222221,66.06666666666666,66.21111111111111,66.24444444444444,66.4,66.34444444444445,66.34444444444445,66.30000000000001,66.21111111111112,66.1888888888889,66.1888888888889,66.15555555555557,66.24444444444445,66.84444444444445,66.91111111111111,66.91111111111111,66.83333333333331,66.94444444444443,66.93333333333332,66.91111111111111,66.93333333333332,66.87777777777778,66.94444444444443,66.92222222222222,66.86666666666666,66.78888888888889,66.86666666666667,66.80000000000001,66.83333333333334,66.8,66.86666666666666,66.95555555555555,66.93333333333332,66.96666666666664,66.7111111111111,66.69999999999999,66.79999999999998,66.76666666666665,66.87777777777777,66.81111111111109,66.88888888888887,67.03333333333333,66.93333333333334,66.96666666666665,67.0111111111111,67.02222222222223,67.02222222222221,66.86666666666665,66.86666666666666,66.85555555555555,66.84444444444443,66.97777777777777,66.95555555555555,66.93333333333332,66.83333333333333,66.91111111111111,66.8111111111111,66.8111111111111,66.85555555555554,66.89999999999999,66.72222222222221,66.76666666666665,66.77777777777776,66.77777777777776,66.98888888888887,66.93333333333331,66.85555555555554,66.89999999999999,66.84444444444442,66.95555555555553,66.8111111111111,66.69999999999999,66.75555555555556,66.76666666666667,66.5,66.4888888888889,66.64444444444445,66.72222222222223,66.69999999999999,66.67777777777778,66.72222222222223,66.67777777777779,66.71111111111112,66.68888888888888,66.77777777777777,66.81111111111112,66.8888888888889,66.9,66.84444444444445,66.81111111111112,66.91111111111113,66.82222222222222,66.60000000000001,66.55555555555554,66.5,66.53333333333333,66.58888888888889,66.61111111111111,66.64444444444445,66.62222222222222,66.6888888888889,66.57777777777778,66.57777777777778,66.61111111111111,66.7888888888889,66.92222222222222,66.7,66.74444444444444,66.77777777777779,66.85555555555555,66.74444444444444,66.66666666666667,66.65555555555555,66.72222222222223,66.87777777777778,66.83333333333333,66.82222222222222,66.82222222222222,66.86666666666667,66.87777777777778,66.80000000000001,66.87777777777778,66.8777777777778,66.94444444444444,66.31111111111112,66.33333333333334,66.27777777777779,66.28888888888888,66.33333333333333,66.3111111111111,66.33333333333331,66.26666666666665,66.26666666666665,66.27777777777776,66.19999999999999,66.13333333333333,66.22222222222221,66.2,66.26666666666665,66.3111111111111,66.35555555555555,66.44444444444444,66.47777777777777,66.52222222222221,66.44444444444446,66.46666666666665,66.5,66.4888888888889,66.54444444444444,66.5111111111111,66.59999999999998,66.58888888888887,66.81111111111109,66.65555555555554,67.15555555555554,67.14444444444445,67.13333333333333,67.02222222222221,66.74444444444445,66.73333333333333,66.6888888888889,67.02222222222223,67.01111111111112,67.0,67.10000000000001,67.07777777777778,67.07777777777778,66.44444444444446,66.35555555555557,66.24444444444444,66.28888888888889,66.3,66.31111111111112,66.23333333333333,66.1888888888889,65.51111111111112,65.44444444444444,65.42222222222222,65.28888888888889,64.88888888888889,64.84444444444443,64.78888888888888,64.71111111111111,64.93333333333334,65.11111111111111,65.13333333333334,65.2,65.25555555555555,65.5111111111111,65.53333333333333,65.65555555555555,65.51111111111112,65.47777777777779,65.5,65.5,65.5,65.45555555555556,66.05555555555556,66.03333333333335,65.95555555555556,65.83333333333334,65.74444444444444,65.75555555555556,65.81111111111112,65.77777777777779,66.37777777777778,66.35555555555557,66.41111111111113,66.28888888888889,66.83333333333334,66.84444444444445,66.83333333333333,66.87777777777778,66.72222222222221,66.77777777777779,66.66666666666667,66.74444444444445,66.74444444444444,66.73333333333333,66.74444444444444,66.67777777777778,66.62222222222222,66.65555555555555,66.6,66.67777777777776,66.69999999999999,66.7888888888889,66.86666666666666,66.94444444444444,67.03333333333335,67.05555555555556,67.05555555555554,67.02222222222221,66.73333333333332,66.76666666666665,66.75555555555555,66.69999999999999,66.58888888888887,66.79999999999998,66.6222222222222,66.68888888888887,66.7111111111111,66.78888888888888,66.83333333333333,66.69999999999999,66.83333333333331,66.69999999999999,66.65555555555555,66.66666666666666,66.58888888888889,66.58888888888889,66.56666666666668,66.61111111111111,66.64444444444445,66.61111111111111,66.63333333333333,66.5,66.47777777777777,66.42222222222223,66.43333333333334,66.47777777777777,66.52222222222224,66.55555555555556,66.86666666666667,66.8777777777778,67.03333333333333,67.15555555555555,67.23333333333333,66.52222222222223,66.56666666666666,66.54444444444444,66.65555555555557,66.52222222222221,66.43333333333334,66.38888888888889,66.38888888888887,66.35555555555555,66.45555555555555,65.8,65.87777777777777,65.85555555555555,65.94444444444444,65.81111111111112,65.65555555555557,65.60000000000001,65.46666666666667,65.61111111111111,65.52222222222223,65.45555555555556,65.46666666666665,65.6,65.44444444444444,65.36666666666666,65.32222222222221,65.3111111111111,65.2222222222222,64.48888888888888,64.47777777777777,65.14444444444445,65.18888888888888,65.23333333333332,65.16666666666666,65.26666666666667,65.14444444444445,65.21111111111111,65.21111111111111,65.21111111111111,65.08888888888889,65.74444444444445,65.67777777777779,65.67777777777778,65.63333333333334,65.64444444444445,65.75555555555556,65.76666666666667,65.82222222222222,65.84444444444445,65.73333333333333,65.86666666666667,65.21111111111111,64.93333333333334,65.05555555555556,65.08888888888889,65.06666666666666,65.06666666666668,65.04444444444444,65.67777777777779,65.58888888888889,64.92222222222222,64.9,64.92222222222223,64.93333333333332,64.86666666666667,65.14444444444443,65.08888888888889,65.03333333333332,65.05555555555554,65.08888888888889,65.13333333333333,65.07777777777778,65.12222222222222,65.24444444444444,65.21111111111111,65.3111111111111,65.23333333333332,65.25555555555555,65.07777777777778,65.28888888888889,65.24444444444444,65.75555555555555,65.93333333333332,65.97777777777776,65.83333333333331,65.83333333333333,65.8,65.33333333333334,65.46666666666667,65.71111111111111,66.37777777777778,66.43333333333334,66.4222222222222,66.5,66.52222222222221,66.38888888888889,66.4888888888889,66.47777777777779,66.57777777777778,66.66666666666666,66.6111111111111,66.77777777777777,66.76666666666667,66.85555555555555,67.03333333333333,67.0111111111111,67.12222222222222,67.18888888888887,67.3111111111111,67.39999999999999,67.34444444444443,67.51111111111109,67.43333333333332,67.5111111111111,67.69999999999997,67.82222222222221,67.86666666666665,68.33333333333333,68.2222222222222,68.03333333333332,67.97777777777777,67.91111111111111,67.85555555555554,67.76666666666665,67.73333333333332,67.75555555555556,67.82222222222222,67.88888888888889,67.9,67.85555555555557,67.94444444444444,67.94444444444444,67.9,67.72222222222223,67.57777777777778,67.46666666666665,67.53333333333333,67.41111111111111,67.36666666666666,67.3111111111111,67.37777777777778,67.36666666666666,67.43333333333334,67.37777777777778,67.34444444444445,67.22222222222221,67.24444444444443,67.27777777777779,67.27777777777777,67.25555555555555,67.35555555555555,67.4,67.35555555555557,67.33333333333334,67.3,67.31111111111113,67.30000000000001,67.33333333333333,67.28888888888889,67.33333333333333,67.17777777777778,67.06666666666666,67.04444444444444,67.12222222222222,67.22222222222221,67.15555555555555,67.12222222222222,67.21111111111111,67.26666666666665,67.2111111111111,67.25555555555555,67.21111111111111,67.23333333333333,67.22222222222223,67.2,67.18888888888888,67.17777777777778,67.12222222222222,67.19999999999999,67.25555555555555,67.23333333333333,67.2,67.23333333333333,67.22222222222221,67.22222222222223,67.2888888888889,67.20000000000002,67.13333333333334,67.17777777777779,67.10000000000002,67.27777777777779,67.37777777777777,67.34444444444443,67.2,67.14444444444443,67.27777777777777,67.24444444444443,67.17777777777776,67.2111111111111,67.2222222222222,67.1222222222222,67.03333333333333,66.95555555555555,66.88888888888889,66.77777777777777,66.82222222222222,66.81111111111112,66.84444444444445,66.79999999999998,66.76666666666667,66.75555555555556,66.71111111111111,66.78888888888889,66.77777777777777,66.76666666666667,66.71111111111111,66.75555555555555,66.77777777777777,66.67777777777776,66.66666666666667,66.47777777777777,66.23333333333332,66.22222222222221,66.24444444444444,66.33333333333333,66.37777777777777,66.38888888888889,66.4222222222222,66.3333333333333,66.19999999999999,66.29999999999998,66.37777777777777,66.44444444444443,66.55555555555556,66.64444444444445,66.64444444444445,66.6111111111111,66.55555555555556,66.52222222222221,66.57777777777777,66.55555555555556,66.66666666666667,66.53333333333335,66.57777777777778,66.65555555555555,66.6,66.6111111111111,66.60000000000001,66.60000000000001,66.66666666666667,66.8111111111111,67.05555555555556,67.07777777777777,67.18888888888888,67.15555555555555,67.13333333333333,67.05555555555556,67.0111111111111,66.96666666666665,66.84444444444443,66.87777777777778,66.88888888888889,66.85555555555555,66.75555555555555,66.85555555555555,66.84444444444443,66.93333333333332,66.98888888888888,66.98888888888888,67.04444444444444,67.08888888888889,67.02222222222223,67.08888888888889,67.13333333333334,67.05555555555557,67.13333333333335,67.05555555555557,67.02222222222223,66.9,66.82222222222224,66.75555555555557,66.66666666666667,66.74444444444445,66.72222222222224,66.73333333333333,66.67777777777779,66.73333333333333,66.86666666666666,66.83333333333333,66.9888888888889,66.93333333333334,66.9,66.86666666666667,66.93333333333334,66.85555555555555,66.89999999999999,66.76666666666667,66.84444444444445,66.86666666666666,66.74444444444445,66.65555555555555,66.82222222222222,66.82222222222222,66.77777777777777,66.91111111111111,66.92222222222223,66.86666666666667,66.87777777777778,67.10000000000001,67.1888888888889,67.28888888888889,67.26666666666668,67.2,67.07777777777778,67.07777777777778,67.18888888888888,67.17777777777779,67.1,67.24444444444445,67.4,67.36666666666667,67.45555555555556,67.52222222222221,67.54444444444444,67.44444444444444,67.35555555555555,67.46666666666667,67.43333333333332,67.53333333333332,67.54444444444444,67.52222222222223,67.27777777777777,67.3,67.26666666666667,67.27777777777777,67.19999999999999,67.26666666666665,67.27777777777777,67.22222222222221,67.08888888888887,66.97777777777777,67.0111111111111,67.05555555555553,67.16666666666664,67.07777777777777,66.98888888888887,67.06666666666666,67.0,66.92222222222223,66.77777777777779,66.7888888888889,66.7777777777778,66.77777777777779,66.65555555555557,66.80000000000001,66.83333333333333,66.80000000000001,66.6888888888889,66.45555555555556,66.52222222222221,66.57777777777777,66.65555555555554,66.45555555555553,66.46666666666667,66.32222222222222,66.03333333333333,66.14444444444443,66.15555555555554,66.15555555555555,66.19999999999999,66.3,66.32222222222222,66.4,66.39999999999999,66.48888888888888,66.5222222222222,66.47777777777777,66.57777777777777,66.64444444444445,66.63333333333334,66.35555555555555,66.27777777777779,66.03333333333335,66.16666666666667,65.46666666666667,65.54444444444445],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"width\":1200,\"height\":600,\"xaxis\":{\"title\":{\"text\":\"trial No.\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy (%)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7292d1eb-16f2-4baf-8b57-9fccb21dc1d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 차이 값의 변화\n",
        "\n",
        "# 성능 차이 및 그 이동 평균\n",
        "difference = [float(acc_hpo) - float(acc_new) for acc_hpo, acc_new in zip(hpo_accuracy, new_dataset_accuracy)]\n",
        "difference_ma = np.convolve(difference, np.ones(WINDOW_SIZE) / WINDOW_SIZE, mode='valid')\n",
        "\n",
        "# 그래프로 표시\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=difference,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 5},\n",
        "                         name='Accuracy Difference'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=difference_ma,\n",
        "                         mode='lines',\n",
        "                         name='Accuracy Difference (Moving Average)'))\n",
        "\n",
        "fig.update_layout(width=1200,\n",
        "                  height=600,\n",
        "                  title='Difference : (HPO dataset ACC) - (NEW dataset ACC)',\n",
        "                  xaxis_title='trial No.',\n",
        "                  yaxis_title='Accuracy Difference (%)')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "52_pQReo7ish",
        "outputId": "55fa1951-51c0-4cc9-972c-ba363679ec48"
      },
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"033b8b76-dca7-4c7f-bd99-9d7a396b39e6\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"033b8b76-dca7-4c7f-bd99-9d7a396b39e6\")) {                    Plotly.newPlot(                        \"033b8b76-dca7-4c7f-bd99-9d7a396b39e6\",                        [{\"marker\":{\"size\":5},\"mode\":\"markers\",\"name\":\"Accuracy Difference\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[-0.3333333333333286,-2.166666666666657,0.25,0.25,0.25,0.25,1.75,0.6666666666666572,0.1666666666666572,-2.5833333333333357,-0.25,1.6666666666666714,1.1666666666666714,0.2500000000000142,0.25,3.3333333333333357,0.25,-0.7499999999999929,0.2500000000000142,-1.4166666666666643,1.0833333333333428,0.2500000000000142,0.5,-2.166666666666657,-0.4166666666666572,-1.0833333333333215,0.25,3.0,1.3333333333333286,0.5833333333333428,-1.749999999999993,0.9166666666666714,1.0,-0.25,0.25,4.666666666666671,0.75,1.0833333333333428,1.8333333333333428,1.6666666666666714,0.0,1.4166666666666643,0.0833333333333286,-3.9166666666666714,1.1666666666666714,0.8333333333333428,0.3333333333333286,0.25,-0.5,2.5,0.25,0.25,-2.0833333333333144,-0.6666666666666714,2.0,2.3333333333333286,0.25,0.6666666666666714,2.1666666666666714,3.9166666666666714,-0.5,2.5833333333333286,-1.3333333333333357,0.25,0.5833333333333428,-0.75,-0.8333333333333286,0.6666666666666714,-0.5,3.583333333333343,0.0833333333333286,0.3333333333333286,0.75,0.8333333333333428,0.5833333333333428,0.2500000000000142,-2.9166666666666643,-3.5833333333333286,-2.0833333333333144,2.083333333333343,-0.6666666666666572,-0.2499999999999858,-0.25,0.0,2.5833333333333286,-1.3333333333333286,-0.4166666666666714,-1.5833333333333286,-0.7499999999999929,-1.6666666666666572,1.9166666666666714,1.75,2.250000000000014,1.4166666666666714,1.75,1.5833333333333428,0.25,0.5833333333333428,0.9166666666666643,0.25,0.9166666666666643,0.25,0.25,1.9166666666666643,0.4166666666666643,-0.5,-0.4166666666666572,3.4166666666666714,3.0833333333333286,4.25,3.500000000000014,0.25,-1.1666666666666572,0.3333333333333286,2.1666666666666714,5.5,1.0833333333333286,3.750000000000014,5.0,1.5833333333333286,1.9166666666666714,2.25,2.0,0.25,3.4166666666666714,0.25,1.6666666666666572,3.1666666666666714,1.3333333333333286,2.5,0.9166666666666714,0.5833333333333357,1.1666666666666714,3.333333333333343,0.25,2.333333333333343,2.583333333333343,3.75,0.5,2.25,-0.9166666666666714,0.0833333333333357,1.0833333333333286,-1.3333333333333357,5.5,-1.8333333333333428,2.500000000000014,3.0,4.25,5.083333333333329,3.75,2.9166666666666714,3.1666666666666714,4.166666666666671,2.0,2.833333333333343,2.666666666666657,3.4166666666666714,4.25,2.4166666666666714,0.0,1.9166666666666714,6.916666666666671,4.333333333333343,1.1666666666666714,1.0833333333333428,0.5833333333333428,-1.0833333333333357,4.500000000000014,0.25,3.3333333333333286,1.1666666666666714,0.5833333333333428,1.5000000000000142,2.500000000000014,2.500000000000014,4.416666666666657,0.5833333333333286,2.4166666666666714,0.5833333333333286,4.333333333333343,4.166666666666671,1.9166666666666714,0.6666666666666714,4.583333333333343,3.0,2.0,-0.3333333333333428,-2.3333333333333286,0.25,-0.8333333333333286,3.6666666666666714,3.916666666666657,0.25,3.75,5.333333333333329,1.4166666666666714,1.0833333333333428,1.5833333333333286,6.083333333333343,0.3333333333333428,0.3333333333333286,1.5,2.0833333333333357,1.8333333333333428,1.3333333333333286,2.333333333333343,0.9166666666666714,0.4166666666666714,5.25,4.333333333333343,0.25,-2.3333333333333357,1.5,-0.3333333333333428,3.6666666666666714,1.6666666666666714,0.6666666666666572,2.750000000000014,0.75,2.833333333333343,-1.7499999999999858,2.75,0.25,1.75,1.6666666666666714,2.833333333333343,5.916666666666657,-1.0833333333333286,4.333333333333343,2.833333333333343,3.9166666666666714,-0.8333333333333286,-0.5,0.1666666666666714,0.2499999999999929,3.4166666666666714,1.1666666666666714,-0.1666666666666572,2.5833333333333286,-2.249999999999993,4.500000000000014,-1.3333333333333428,2.9166666666666714,0.5,1.750000000000007,4.583333333333329,0.25,0.25,-0.1666666666666572,-0.6666666666666572,4.75,2.4166666666666714,-1.75,-1.0,0.25,0.5833333333333428,1.9166666666666714,3.833333333333343,-2.4166666666666643,4.916666666666671,-0.1666666666666572,0.0,4.833333333333343,0.25,2.4166666666666714,1.4166666666666714,2.250000000000014,2.0,2.1666666666666714,5.25,0.6666666666666714,0.8333333333333428,3.25,0.6666666666666714,6.166666666666657,1.0,4.666666666666671,-2.916666666666657,0.5833333333333428,0.0833333333333286,4.416666666666671,4.75,3.583333333333343,0.6666666666666714,2.500000000000014,4.583333333333343,1.9166666666666714,2.25,-0.6666666666666714,2.0833333333333286,-1.0,0.5833333333333428,2.25,1.3333333333333286,1.3333333333333286,5.833333333333343,1.5000000000000142,2.833333333333343,3.4166666666666714,2.1666666666666714,-1.3333333333333428,-0.1666666666666572,0.25,-0.0833333333333286,0.25,4.583333333333343,2.083333333333343,-1.6666666666666714,4.500000000000014,4.25,2.333333333333343,1.1666666666666714,-0.4166666666666572,-0.5833333333333357,2.1666666666666714,2.5833333333333286,4.083333333333343,-2.250000000000014,-1.75,-0.6666666666666572,0.9166666666666714,5.166666666666686,0.0833333333333286,2.9166666666666714,5.750000000000014,1.2500000000000142,1.249999999999993,-0.6666666666666714,0.5833333333333357,4.666666666666671,1.75,2.6666666666666714,2.0833333333333286,-2.416666666666657,3.5833333333333286,2.9166666666666714,-0.5,2.0,1.6666666666666572,2.0,-2.916666666666657,2.833333333333343,-1.249999999999993,3.0,6.916666666666671,3.4166666666666714,-0.4166666666666572,3.1666666666666714,1.75,1.75,-1.5,2.6666666666666714,-0.5833333333333286,1.0833333333333428,-0.5,2.75,1.75,0.25,2.0,3.500000000000014,2.9166666666666714,0.25,2.8333333333333357,2.6666666666666714,2.75,-0.1666666666666572,4.500000000000014,1.0,0.2500000000000142,3.1666666666666856,1.499999999999993,1.25,-2.75,-2.000000000000014,0.3333333333333286,3.833333333333343,3.083333333333343,2.0,3.500000000000014,2.333333333333343,2.083333333333343,1.499999999999993,3.0,-1.3333333333333286,-0.5,5.5,3.75,-1.3333333333333428,0.4166666666666714,5.0,3.1666666666666714,1.75,3.75,0.25,1.0833333333333428,0.25,3.0,-1.3333333333333428,-1.8333333333333428,3.5833333333333286,2.25,1.3333333333333286,5.25,1.8333333333333428,5.333333333333343,3.666666666666657,5.500000000000014,3.0,2.083333333333343,4.333333333333343,1.0833333333333286,4.583333333333343,1.1666666666666714,3.333333333333343,5.333333333333343,2.750000000000014,1.6666666666666572,0.6666666666666714,2.25,0.0,3.4166666666666714,3.6666666666666714,4.083333333333343,5.416666666666657,3.500000000000014,-1.5833333333333428,-0.0833333333333286,0.2500000000000142,1.5,1.3333333333333286,-1.2499999999999858,1.0833333333333286,6.25,1.5000000000000142,1.1666666666666714,-1.4166666666666714,0.1666666666666714,0.25,0.0833333333333286,1.1666666666666714,2.333333333333343,3.833333333333343,3.083333333333343,4.500000000000014,4.500000000000014,6.083333333333343,4.166666666666686,-0.25,4.083333333333343,-0.5833333333333428,3.0,-2.3333333333333286,3.500000000000014,0.0,2.9166666666666714,1.1666666666666714,-1.3333333333333428,-1.75,0.1666666666666714,-0.1666666666666572,2.9166666666666714,-1.0833333333333144,0.5833333333333428,0.25,0.1666666666666714,-3.1666666666666714,-2.416666666666657,1.9166666666666714,0.08333333333332149,4.416666666666671,-0.5,3.1666666666666714,3.1666666666666714,0.25,0.8333333333333428,1.6666666666666714,2.083333333333343,5.083333333333336,1.5833333333333286,6.000000000000014,3.500000000000014,4.333333333333343,3.083333333333343,3.083333333333343,6.166666666666686,2.5833333333333286,-0.1666666666666572,3.9166666666666714,3.3333333333333286,0.0833333333333286,2.3333333333333286,-1.0,1.6666666666666714,-1.75,1.6666666666666714,4.666666666666671,1.0,3.5833333333333286,0.4166666666666714,0.1666666666666714,0.0833333333333286,0.25,-1.5833333333333357,4.500000000000014,-2.916666666666657,1.5833333333333357,2.249999999999993,2.5,4.166666666666686,2.75,0.1666666666666714,3.4166666666666714,-0.3333333333333286,0.4166666666666714,1.0833333333333428,1.250000000000007,1.75,2.0,-0.6666666666666572,-0.25,0.25,2.750000000000014,2.749999999999993,4.166666666666671,3.75,2.9166666666666714,0.8333333333333428,2.5833333333333286,0.25,-1.4166666666666572,0.5,2.333333333333343,3.333333333333343,2.25,1.5833333333333286,-0.5,0.25,-0.5,2.0,1.5833333333333357,0.4166666666666714,-1.4999999999999858,3.500000000000014,3.0,1.2500000000000142,4.916666666666671,-4.75,3.0,3.75,1.3333333333333286,4.0,-1.75,5.750000000000014,0.9166666666666714,0.25,-1.9166666666666572,4.500000000000014,6.833333333333343,0.9166666666666572,-2.1666666666666714,0.6666666666666714,-2.3333333333333286,-1.75,1.6666666666666714,1.0,-0.3333333333333428,0.25,1.4166666666666714,-2.0,3.75,-0.5833333333333357,3.500000000000014,0.8333333333333428,-1.4999999999999858,1.2500000000000142,3.500000000000014,4.166666666666686,0.75,6.333333333333343,4.750000000000014,0.5833333333333286,0.4166666666666714,-0.0833333333333286,1.0833333333333428,2.0,4.75,2.0,-0.0833333333333286,2.750000000000014,-0.4166666666666572,0.5833333333333428,1.0,4.333333333333343,3.3333333333333286,0.1666666666666714,2.083333333333343,4.166666666666671,0.8333333333333428,1.8333333333333428,-1.0833333333333286,3.25,2.25,3.9166666666666714,5.916666666666671,1.75,4.666666666666671,0.0,-0.25,0.0833333333333286,4.750000000000014,3.083333333333343,2.4166666666666714,6.166666666666686,4.416666666666657,-2.25,0.08333333333332149,5.666666666666657,4.25,2.6666666666666714,3.4166666666666714,1.6666666666666714,4.75,-0.8333333333333286,-1.0833333333333286,1.5833333333333428,3.5,2.5833333333333286,3.1666666666666714,0.7499999999999929,6.333333333333343,-0.8333333333333286,5.499999999999993,1.2500000000000142,3.9166666666666714,-0.3333333333333428,3.1666666666666714,1.2500000000000142,1.0,5.916666666666671,2.083333333333343,3.6666666666666714,6.833333333333343,2.75,-0.7500000000000142,-2.250000000000014,5.0,0.1666666666666714,4.833333333333343,-0.6666666666666714,1.5,1.4166666666666714,3.166666666666657,1.3333333333333286,2.3333333333333286,3.0,2.250000000000014,0.9166666666666714,1.5833333333333357,-1.0833333333333286,-0.8333333333333286,-2.5,5.500000000000014,6.666666666666671,3.25,3.333333333333343,4.75,4.916666666666671,-0.4166666666666643,1.0,2.083333333333343,4.083333333333343,-0.2499999999999858,-0.1666666666666572,6.166666666666686,3.083333333333343,2.999999999999986,4.000000000000014,3.5833333333333286,3.25,4.25,5.833333333333343,3.4166666666666714,0.1666666666666714,2.0833333333333215,3.1666666666666856,2.500000000000014,2.500000000000014,1.9166666666666714,3.833333333333343,0.5833333333333428,1.5000000000000142,1.9166666666666714,4.416666666666671,3.6666666666666714,-0.5,2.25,-1.8333333333333428,4.333333333333343,-1.75,2.5833333333333286,3.9166666666666714,-0.25,1.3333333333333286,1.9166666666666572,2.9166666666666714,1.3333333333333286,-2.1666666666666714,4.0,3.333333333333343,3.083333333333343,0.8333333333333286,-0.3333333333333428,4.583333333333329,0.0833333333333286,3.9166666666666714,0.0,6.25,0.0,3.500000000000014,1.4166666666666714,1.3333333333333286,2.9166666666666714,1.6666666666666572,1.0,2.4166666666666714,0.3333333333333286,-0.6666666666666714,4.083333333333343,0.3333333333333286,3.0,3.500000000000014,3.5833333333333286,1.5,2.4166666666666714,2.083333333333343,-1.0833333333333286,1.4166666666666714,1.5833333333333286,0.3333333333333286,3.6666666666666714,3.9166666666666714,0.5833333333333428,-2.249999999999986,4.833333333333343,1.9166666666666572,3.0,0.4166666666666714,5.750000000000014,4.166666666666671,0.25,5.333333333333336,3.0,2.0833333333333286,0.25,4.500000000000014,3.1666666666666714,-1.0,-0.1666666666666714,0.75,3.1666666666666856,3.9166666666666714,-0.8333333333333286,0.5,2.1666666666666714,-0.6666666666666714,0.25,1.75,1.75,6.666666666666664,2.5833333333333286,2.9166666666666714,5.75,3.583333333333343,3.4166666666666714,4.333333333333343,3.75,4.25,0.1666666666666714,4.166666666666671,2.25,3.75,3.750000000000014,0.4999999999999929,1.5833333333333286,1.3333333333333286,-2.333333333333343,4.500000000000014,4.25,-1.5,4.916666666666671,0.4166666666666714,4.500000000000014,3.500000000000014,5.583333333333343,2.5833333333333286,3.750000000000014,5.166666666666686,3.9166666666666714,-1.0833333333333286,4.666666666666671,2.500000000000014,3.9166666666666714,1.2500000000000142,4.750000000000014,-0.1666666666666714,2.1666666666666714,3.25,0.0,2.9166666666666714,3.75,-0.1666666666666572,3.083333333333343,3.3333333333333286,2.75,2.25,1.3333333333333286,2.9166666666666714,2.500000000000014,1.75,0.4166666666666714,2.3333333333333286,8.583333333333329,2.6666666666666714,2.0,3.9166666666666714,2.5,4.166666666666671,3.75,3.083333333333343,1.5833333333333428,2.500000000000014,2.75,1.3333333333333286,3.1666666666666856,-0.3333333333333428,3.333333333333343,3.083333333333343,2.583333333333343,-1.0833333333333215,1.0833333333333428,3.9166666666666714,3.6666666666666714,0.8333333333333428,4.666666666666657,3.9166666666666714,1.0833333333333428,3.6666666666666714,2.1666666666666714,0.6666666666666572,3.6666666666666714,-3.500000000000014,1.4166666666666714,-0.4166666666666643,0.0833333333333286,2.250000000000014,-1.25,2.6666666666666714,-1.0000000000000142,5.166666666666686,0.5,5.083333333333343,4.583333333333343,5.0,1.6666666666666714,4.833333333333343,2.25,0.8333333333333428,2.500000000000014,3.25,-1.4166666666666572,3.25,3.4166666666666714,3.4166666666666714,-0.75,0.0833333333333286,-0.25,-0.0833333333333286,2.0833333333333357,2.5833333333333286,2.250000000000014,4.416666666666671,3.416666666666657,2.166666666666657,2.0,1.8333333333333428,3.666666666666657,3.833333333333343,3.9166666666666714,3.1666666666666714,4.25,-3.1666666666666714,-0.5,3.1666666666666856,4.75,0.9166666666666714,2.500000000000014,8.75,1.499999999999993,-0.0833333333333286,3.500000000000014,-2.3333333333333286,6.333333333333343,-0.0833333333333286,5.833333333333343,1.75,1.8333333333333428,0.4166666666666643,0.5,5.75,-0.5,0.9166666666666714,2.4166666666666714,-6.333333333333336,6.25,2.75,7.666666666666671,1.75,0.8333333333333428,2.250000000000014,-1.4166666666666643,-0.1666666666666572,4.166666666666671,1.1666666666666714,0.2499999999999858,-0.1666666666666714,2.083333333333343,1.25,3.25,3.6666666666666714,2.0,4.416666666666657,-1.9166666666666714,2.3333333333333286,1.1666666666666714,1.3333333333333286,2.1666666666666714,2.0833333333333215,4.083333333333343,-3.9166666666666714,-1.0000000000000142,3.0,3.4166666666666714,2.0,2.0,1.8333333333333428,1.25,3.3333333333333286,-0.5833333333333286,2.083333333333343,3.5833333333333286,0.0,5.083333333333329,0.0833333333333286,3.083333333333343,2.4166666666666714,-0.3333333333333428,2.583333333333343,2.250000000000014,1.4166666666666714,1.0,2.250000000000014,1.9166666666666714,0.75,2.500000000000014,-0.3333333333333428,4.500000000000014,-2.249999999999986,-0.4166666666666572,4.833333333333343,0.1666666666666714,3.5833333333333286,2.0,1.75,4.416666666666664,5.416666666666671,-4.25,1.3333333333333286,4.0,1.75,2.1666666666666643,1.75,4.0,2.3333333333333286,0.75,2.0833333333333286,5.916666666666657,2.833333333333343,-2.5833333333333286,7.333333333333343,3.833333333333343,-0.08333333333334281,2.583333333333343,0.6666666666666714,3.4166666666666714,-0.3333333333333428,-2.249999999999986,1.0,1.0,-1.25,1.75,2.9166666666666714,2.0,-1.1666666666666643,-2.4166666666666714,1.25,0.8333333333333428,2.75,4.333333333333329,3.333333333333343,1.3333333333333286,2.833333333333343,5.833333333333343,2.4166666666666714,0.5833333333333428,0.25,-1.250000000000007,2.333333333333343,2.250000000000014,0.0,3.25,0.4166666666666714,1.5833333333333286,0.25,2.9166666666666714,4.083333333333329,3.1666666666666856,1.9166666666666714,4.416666666666671,1.5833333333333286,4.5,5.416666666666671,-1.0833333333333286,1.1666666666666714,0.3333333333333286,4.500000000000014,3.750000000000014,0.25,5.416666666666671,-0.3333333333333428,1.9166666666666714,5.916666666666671,3.500000000000014,4.500000000000014,1.5,7.333333333333343,1.5833333333333428,2.5833333333333286,4.166666666666671,5.833333333333343,4.083333333333343,1.25,2.9166666666666714,2.833333333333343,2.3333333333333286,3.249999999999986,-1.250000000000007,6.083333333333329,0.5833333333333428,3.0,-0.5,-1.1666666666666714,1.0833333333333428,2.6666666666666714,1.1666666666666714,3.25,-1.0833333333333286,-0.9166666666666714,2.583333333333343,0.2500000000000142,1.75,-3.5833333333333286,0.0833333333333286,1.5000000000000142,2.6666666666666714,0.2500000000000142,3.833333333333343,3.4166666666666714,4.750000000000014,1.2500000000000142,2.5,0.2500000000000142,2.0,1.0,6.833333333333343,1.2500000000000142,0.0,1.6666666666666714,5.000000000000014,2.0,2.5,5.083333333333343,3.750000000000014,0.3333333333333286,2.583333333333343,1.0,-0.5833333333333286,-0.5833333333333286,-0.9166666666666714,1.5833333333333428,1.8333333333333428,0.3333333333333286,2.1666666666666643,1.25,6.75,4.25,3.833333333333343,3.25,2.6666666666666714,3.583333333333343,3.25,0.1666666666666714,2.750000000000014,0.5833333333333428,1.4166666666666714,5.333333333333343,-0.4166666666666572,4.166666666666671,0.8333333333333428,0.25,5.0,3.1666666666666714,2.4166666666666714,1.3333333333333286,2.0,-0.0833333333333286,1.0833333333333428,1.5833333333333286,3.25,4.583333333333329,-0.9166666666666572,4.833333333333329,4.500000000000014,3.4166666666666714,2.4166666666666714,2.3333333333333357,2.6666666666666714,1.2500000000000142,6.083333333333343,1.25,2.833333333333343,-0.3333333333333428,-0.9166666666666714,0.5833333333333428,4.500000000000014,1.75,3.6666666666666714,3.1666666666666714,2.9166666666666714,3.0,-1.1666666666666714,0.25,1.1666666666666714,5.333333333333343,3.25,0.8333333333333428,1.4166666666666714,3.083333333333343,1.5833333333333428,3.1666666666666714,0.25,5.666666666666671,-0.8333333333333286,3.6666666666666714,-0.0833333333333286,2.083333333333343,1.2500000000000142,-0.6666666666666714,1.5833333333333286,-1.5833333333333286,3.4166666666666714,0.5,1.9166666666666714,1.1666666666666714,1.3333333333333286,0.9166666666666572,5.083333333333329,4.666666666666671,0.5,4.333333333333343,0.5,-1.75,1.6666666666666714,3.500000000000014,5.416666666666671,0.9166666666666785,5.25,2.083333333333343,3.3333333333333286,0.25,4.583333333333329,-0.4166666666666572,1.2500000000000142,3.0,4.416666666666671,2.4166666666666714,-1.75,-0.08333333333332149,3.1666666666666714,1.5833333333333286,4.25,2.75,2.9166666666666714,2.1666666666666714,2.6666666666666714,1.6666666666666714,1.8333333333333428,1.5000000000000142,0.25,2.833333333333343,0.5,2.1666666666666714,4.333333333333343,5.333333333333343,-0.4166666666666572,3.5833333333333286,2.5833333333333286,3.25,2.25,-0.7500000000000142,2.1666666666666714,5.333333333333343,2.1666666666666714,5.416666666666671,4.0,2.750000000000014,4.333333333333343,-2.5,-1.4166666666666643,-1.5,5.833333333333343,0.25,4.25,2.0,3.750000000000014,2.4166666666666714,-1.8333333333333286,2.1666666666666714,1.0,1.0833333333333286,2.9166666666666714,0.5833333333333286,3.25,2.3333333333333286,2.333333333333343,1.5833333333333286,-0.8333333333333286,3.9166666666666714,-0.9166666666666643,6.166666666666686,3.9166666666666714,0.4166666666666714,-0.08333333333334281,-2.333333333333343,3.1666666666666856,2.833333333333343,0.9166666666666572,0.3333333333333286,4.333333333333343,-0.1666666666666714,2.833333333333343,-0.8333333333333286,2.333333333333343,-0.6666666666666714,2.0833333333333286,3.0,1.3333333333333286,0.6666666666666714,3.083333333333343,1.9166666666666714,-0.1666666666666714,3.4166666666666714,3.333333333333343,3.5833333333333286,0.2500000000000142,3.6666666666666714,2.750000000000014,1.8333333333333428,5.75,1.5,5.25,0.8333333333333428,3.1666666666666856,4.166666666666686,4.500000000000014,1.0833333333333428,2.083333333333343,-1.9166666666666714,0.2499999999999858,2.1666666666666714,3.3333333333333286,1.3333333333333286,2.500000000000014,0.9166666666666572,3.500000000000014,-4.0,3.0,1.6666666666666714,4.666666666666671,2.3333333333333286,4.083333333333343,3.083333333333343,-1.1666666666666714,4.583333333333343,3.1666666666666856,-1.6666666666666714,4.416666666666671,2.4166666666666714,-2.75,3.333333333333343,1.0,-0.3333333333333428,3.500000000000014,0.0,3.0,3.083333333333343,0.0,2.9166666666666714,2.25,1.1666666666666714,0.0,3.9166666666666714,2.25,6.416666666666671,0.25,6.916666666666671,2.5833333333333286,2.9166666666666714,1.4166666666666714,4.750000000000014,0.6666666666666714,0.1666666666666714,2.1666666666666714,2.5833333333333286,1.0,0.0833333333333286,4.166666666666686,5.000000000000014,1.5833333333333286,3.750000000000014,1.1666666666666714,2.5,3.0,2.833333333333343,0.25,5.666666666666671,-0.2499999999999858,1.25,1.4166666666666714,5.916666666666657,2.083333333333343,3.9166666666666714,6.416666666666671,2.5833333333333286,3.333333333333343,3.4166666666666714,4.333333333333343,4.583333333333329,2.25,1.6666666666666714,0.0833333333333286,1.75,0.5833333333333428,2.833333333333343,0.8333333333333428,3.6666666666666714,0.2500000000000142,0.4166666666666714,3.75,-1.5833333333333286,-0.6666666666666714,2.750000000000014,5.25,0.9166666666666714,1.6666666666666714,3.333333333333343,3.0,2.5833333333333286,5.000000000000014,3.5833333333333286,3.750000000000014,2.9166666666666714,3.750000000000014,1.1666666666666714,3.6666666666666714,-0.2499999999999858,4.166666666666686,2.4166666666666714,1.9166666666666714,-3.75,3.75,-1.5833333333333215,3.750000000000014,-1.6666666666666572,5.916666666666657,3.083333333333343,-0.3333333333333428,0.1666666666666714,3.3333333333333286,2.500000000000014,1.1666666666666714,4.166666666666686,0.8333333333333428,0.75,5.166666666666686,0.1666666666666714,2.1666666666666714,2.250000000000014,3.500000000000014,2.1666666666666714,-2.5833333333333286,5.666666666666671,0.75,-0.7500000000000142,2.5833333333333286,7.666666666666671,1.9166666666666714,1.75,-1.25,0.1666666666666714,3.500000000000014,1.3333333333333286,1.249999999999993,2.75,5.333333333333343,3.25,6.916666666666671,0.25,3.333333333333343,2.1666666666666714,3.0,5.083333333333329,1.5000000000000142,4.333333333333343,2.083333333333343,0.5833333333333428,-1.0,3.083333333333343,-2.500000000000007,4.833333333333343,4.000000000000014,0.5,6.000000000000014,2.500000000000014,1.6666666666666714,-1.4166666666666714,-1.6666666666666714,0.5833333333333286,-1.0833333333333286,-2.0833333333333286,1.3333333333333286,2.25,4.166666666666671,2.0,2.1666666666666714,-2.749999999999993,2.500000000000014,0.75,1.1666666666666714,6.25,2.083333333333343,-0.8333333333333286,6.166666666666686,2.4166666666666714,1.1666666666666714,5.666666666666671,2.0,5.416666666666671,3.5833333333333286,0.5,-1.75,0.2500000000000142,4.500000000000014,2.75,5.25,4.500000000000014,2.0,3.4166666666666714,1.0,1.75,-1.249999999999993,1.4166666666666714,0.6666666666666572,0.75,0.6666666666666714,1.1666666666666714,0.75,1.3333333333333286,0.75,3.25,1.25,-1.1666666666666714,4.416666666666671,2.333333333333343,2.0,0.5,2.5833333333333286,3.083333333333343,-2.75,-0.1666666666666572,-0.25,2.9166666666666714,1.0,4.416666666666671,0.75,2.0,1.5833333333333428,-0.8333333333333286,3.25,1.5833333333333357,8.25,4.916666666666671,2.500000000000014,4.75,1.5,-1.1666666666666714,2.4166666666666714,2.750000000000014,0.25,-0.3333333333333428,0.1666666666666714,1.6666666666666714,4.083333333333329,0.75,0.25,3.75,4.583333333333329,0.0,4.416666666666671,2.75,4.416666666666671,0.25,0.5833333333333428,6.000000000000014,4.416666666666657,1.6666666666666714,5.833333333333343,2.0833333333333357,1.1666666666666714,-1.0833333333333286,1.4166666666666714,2.9166666666666714,5.083333333333343,1.6666666666666714,-0.9166666666666714,0.8333333333333428,3.5833333333333286,6.333333333333329,1.1666666666666714,5.083333333333329,-1.0,0.9166666666666714,-1.8333333333333286,8.416666666666671,1.0,0.75,2.5833333333333286,0.0833333333333286,0.0833333333333286,-0.3333333333333428,3.250000000000014,0.4166666666666714,2.5,3.4166666666666714,3.4166666666666714,1.5,-2.249999999999986,1.5833333333333428,1.1666666666666714,2.5833333333333286,3.0,3.833333333333343,1.0,-3.6666666666666856,3.083333333333343,1.9166666666666714,0.25,1.5000000000000142,2.4166666666666714,4.416666666666671,1.5833333333333286,1.1666666666666714,1.75,4.0,3.583333333333343,-0.1666666666666714,3.75,4.916666666666671,-2.25,3.1666666666666714,1.5833333333333286,1.4166666666666714,1.0833333333333428,3.25,6.0,2.9166666666666714,1.4166666666666714,2.583333333333343,1.5833333333333428,0.25,8.166666666666671,1.0833333333333428,0.0,3.75,1.2500000000000142,1.9166666666666714,2.083333333333343,3.25,0.9166666666666572,2.083333333333343,5.000000000000014,-1.8333333333333286,1.1666666666666714,1.9166666666666714,3.25,2.5833333333333286,4.333333333333343,1.6666666666666714,6.916666666666671,0.0833333333333286,1.5,1.5833333333333428,3.75,1.8333333333333428,0.0833333333333286,2.6666666666666714,5.500000000000014,1.0833333333333428,2.5833333333333286,2.6666666666666714,2.75,5.5,4.500000000000014,3.083333333333343,5.500000000000014,0.1666666666666714,2.083333333333343,2.500000000000014,1.25,4.75,2.6666666666666714,5.083333333333329,3.9166666666666714,2.6666666666666714,1.0833333333333286,1.9166666666666714,-0.4166666666666714,0.3333333333333286,6.666666666666671,-0.4166666666666714,4.916666666666671,0.1666666666666714,1.5833333333333286,1.9166666666666714,2.4166666666666714,2.833333333333343,2.833333333333343,4.333333333333343,1.6666666666666714,4.416666666666671,-1.0,0.2499999999999858,2.0,3.25,0.4166666666666714,4.0,3.9166666666666714,5.333333333333343,0.9166666666666714,3.500000000000014,-4.416666666666671,-1.5,3.4166666666666714,3.1666666666666714,2.6666666666666714,2.3333333333333286,3.5833333333333286,-0.7499999999999858,1.6666666666666714,4.000000000000014,3.333333333333343,3.0833333333333286,3.3333333333333286,3.1666666666666856,3.1666666666666714,1.1666666666666714,1.5000000000000142,0.4166666666666714,2.249999999999993,1.75,3.1666666666666714,2.75,4.25,0.3333333333333286,0.9166666666666572,2.9166666666666714,-1.8333333333333286,3.0,2.9166666666666714,0.75,1.3333333333333286,-0.1666666666666714,1.2500000000000142,-0.75,2.1666666666666714,3.5833333333333286,-0.7500000000000142,-0.5,2.3333333333333286,1.1666666666666714,0.8333333333333428,0.2500000000000142,2.4166666666666714,0.75,0.3333333333333286,-0.4166666666666572,-0.6666666666666714,1.0833333333333286,3.5833333333333286,3.9166666666666714,2.6666666666666714,2.833333333333343,2.9166666666666714,0.8333333333333428,2.5833333333333286,2.4166666666666714,0.8333333333333428,3.4166666666666714,1.75,3.750000000000014,2.833333333333343,2.500000000000014,0.25,3.6666666666666714,4.166666666666686,2.250000000000014,3.0833333333333286,-0.0833333333333286,2.1666666666666714,2.750000000000014,3.8333333333333286,5.5,-0.5,1.75,2.1666666666666714,-0.3333333333333428,0.9166666666666714,3.1666666666666714,3.6666666666666714,4.916666666666671,-0.1666666666666714,0.0833333333333286,-0.75,-2.000000000000014,6.333333333333343,-2.0,3.25,1.0,2.333333333333343,3.083333333333343,1.0833333333333428,0.25,-0.08333333333334281,4.666666666666671,-0.25,-2.583333333333343,-1.8333333333333286,-1.3333333333333428,-0.5833333333333286,1.9166666666666714,2.25,4.166666666666671,3.8333333333333286,2.4166666666666714,0.25,2.333333333333343,1.0833333333333428,-0.7499999999999929,4.416666666666671,1.8333333333333428,0.9166666666666714,2.5833333333333286,6.416666666666671,0.5833333333333428,-1.25,3.083333333333343,5.500000000000014,3.333333333333343,-1.5833333333333428,2.75,-1.5,3.750000000000014,5.833333333333343,3.6666666666666714,2.9166666666666714,0.5,0.2499999999999858,2.083333333333343,0.5833333333333286,-1.3333333333333428,5.416666666666671,3.333333333333343,-2.249999999999986,1.1666666666666714,0.0833333333333286,2.1666666666666714,3.750000000000014,3.166666666666657,1.1666666666666714,2.0,1.5,4.25,0.75,5.583333333333343,0.25,1.9166666666666714,-0.9166666666666714,2.9166666666666714,3.3333333333333286,-1.0833333333333286,1.0,1.5833333333333286,6.583333333333329,1.9166666666666714,-1.1666666666666714,-0.5833333333333286,3.1666666666666714,-1.9166666666666714,2.5833333333333286,2.1666666666666714,3.250000000000014,2.75,1.3333333333333286,4.416666666666671,1.6666666666666714,0.25,0.6666666666666572,0.75,1.25,2.0833333333333215,-1.4166666666666714,0.0,1.4166666666666714,3.3333333333333286,4.500000000000014,4.083333333333343,1.2500000000000142,1.9166666666666714,1.3333333333333286,4.666666666666671,-1.5833333333333428,1.4166666666666643,-5.666666666666671,4.500000000000014,2.0,0.25,0.3333333333333286,-2.5,1.6666666666666714,1.6666666666666714,1.8333333333333428,1.8333333333333428,-0.5833333333333286,2.4166666666666714,0.5833333333333428,-1.1666666666666714,2.25,2.9166666666666714,0.3333333333333286,0.4166666666666714,3.833333333333343,-1.1666666666666714,3.833333333333343,-1.0,4.416666666666671,0.1666666666666714,1.5,3.583333333333343,3.25,1.75,2.250000000000014,4.166666666666686,0.25,1.9166666666666714,-0.0833333333333286,4.166666666666686,0.9166666666666714,1.4166666666666714,3.1666666666666714,5.333333333333343,1.8333333333333428,5.25,3.9166666666666714,4.833333333333343,5.166666666666686,-2.833333333333343,1.1666666666666714,1.1666666666666714,0.25,1.1666666666666714,1.8333333333333428,2.083333333333343,-0.4166666666666572,7.583333333333329,-3.000000000000014,3.583333333333343,1.3333333333333286,4.583333333333343,0.0833333333333286,1.2500000000000142,-3.833333333333343,0.25,4.333333333333329,-0.3333333333333428,-0.5,4.166666666666686,3.9166666666666714,5.916666666666671,-0.3333333333333428,-4.333333333333329,2.0,1.3333333333333286,3.333333333333343,3.1666666666666714,0.8333333333333428,3.9166666666666714,-1.3333333333333286,1.1666666666666714,0.6666666666666572,0.4166666666666714,2.4166666666666714,1.25,3.416666666666657,2.3333333333333286,4.583333333333343,1.5,0.5833333333333428,3.1666666666666714,1.0833333333333428,4.083333333333343,1.25,3.333333333333343,2.500000000000014,1.0833333333333286,3.583333333333343,1.4166666666666714,2.500000000000014,3.4166666666666714,2.083333333333343,0.9166666666666572,2.25,4.583333333333329,1.5833333333333286,0.2500000000000142,2.500000000000014,3.1666666666666856,4.500000000000014,6.833333333333343,4.166666666666686,2.3333333333333286,-0.8333333333333286,3.4166666666666714,5.5,1.5833333333333286,-0.5833333333333428,1.6666666666666714,4.000000000000014,5.750000000000014,0.6666666666666572,3.4166666666666714,5.916666666666671,3.0,3.583333333333343,5.000000000000014,0.5,3.083333333333343,3.4166666666666714,2.75,-0.1666666666666714,1.9166666666666714,0.3333333333333286,3.750000000000014,3.6666666666666714,6.333333333333343,6.083333333333329,1.6666666666666714,2.500000000000014,-1.0833333333333286,4.25,2.0,0.2500000000000142,2.6666666666666714,3.333333333333343,3.4166666666666714,0.6666666666666572,1.8333333333333428,1.5833333333333286,-1.25,3.083333333333343,1.6666666666666714,1.9166666666666714,2.833333333333343,7.75,0.25,3.0,2.6666666666666714,-0.5,3.833333333333343,4.083333333333343,-0.25,3.0,-1.0833333333333286,-7.916666666666671,0.0833333333333286,-1.0000000000000142,4.416666666666671,1.1666666666666714,3.833333333333343,2.9166666666666714,-0.25,4.25,5.833333333333343,0.2499999999999858,5.25,-0.8333333333333286,2.9166666666666714,3.250000000000014,1.0,0.3333333333333428,2.4166666666666714,4.0,3.0833333333333286,0.5,4.166666666666686,2.583333333333343,6.333333333333329,6.666666666666671,2.1666666666666714,4.583333333333343,2.4166666666666714,1.5,4.750000000000014,2.333333333333343,3.583333333333343,4.833333333333343,-0.5833333333333286,-1.6666666666666714,2.1666666666666714,2.9166666666666714,2.1666666666666714,1.6666666666666714,3.5833333333333286,-2.1666666666666714,4.5,1.2500000000000142,1.5000000000000142,2.5833333333333286,4.750000000000014,5.083333333333329,0.75,1.6666666666666714,1.8333333333333428,2.6666666666666714,3.25,3.25,1.6666666666666714,-0.5,1.5000000000000142,3.833333333333343,2.5,2.333333333333343,3.1666666666666714,3.5833333333333286,0.1666666666666714,2.083333333333343,0.9166666666666572,1.75,2.6666666666666714,0.0833333333333286,1.0833333333333286,-2.4166666666666714,0.1666666666666714,2.3333333333333286,1.0833333333333428,1.5000000000000142,-2.5,-0.08333333333334281,5.000000000000014,-0.75,2.833333333333343,0.5833333333333286,3.500000000000014,-0.9166666666666643,3.416666666666657,0.75,1.3333333333333286,3.0,2.500000000000014,4.083333333333343,1.6666666666666714,2.5833333333333286,2.1666666666666714,1.75,5.0,1.9166666666666714,-0.3333333333333428,1.8333333333333428,4.916666666666671,2.0,4.333333333333343,1.1666666666666714,3.1666666666666714,4.083333333333343,-0.75,1.0,1.25,6.500000000000014,0.2499999999999929,0.0833333333333286,3.0833333333333286,1.75,0.5833333333333428,0.4166666666666714,2.083333333333343,-0.9166666666666714,1.0833333333333428,-3.0833333333333286,2.4166666666666714,2.333333333333343,2.4166666666666714,1.1666666666666714,1.8333333333333428,5.333333333333343,3.6666666666666714,1.75,-1.3333333333333428,4.25,1.5833333333333428,0.6666666666666572,-1.1666666666666714,1.1666666666666714,2.083333333333343,-4.5833333333333215,3.500000000000014,-1.4166666666666714,3.9166666666666714,2.25,3.8333333333333286,3.333333333333343,3.5,1.0,0.0,3.333333333333343,5.25,-1.0833333333333286,-4.75,3.583333333333343,2.083333333333343,3.6666666666666714,1.0833333333333286,2.0,2.6666666666666714,3.9166666666666714,3.1666666666666856,2.4166666666666714,1.5000000000000142,3.5833333333333286,0.3333333333333286,4.083333333333329,-0.25,0.4166666666666714,3.833333333333343,0.25,1.0833333333333286,-2.5833333333333286,3.0833333333333286,1.0833333333333357,0.2499999999999858,0.4166666666666714,1.0833333333333286,7.666666666666671,0.5,1.6666666666666714,4.0,2.3333333333333286,3.5,-5.666666666666686,2.833333333333343,4.0,0.5833333333333286,-0.5,4.083333333333343,1.8333333333333428,3.6666666666666714,2.833333333333343,2.4166666666666714,0.6666666666666714,0.8333333333333428,0.5833333333333428,3.083333333333343,0.3333333333333286,1.0833333333333428,1.4166666666666714,0.6666666666666714,2.6666666666666714,-0.3333333333333428,0.4166666666666714,-0.6666666666666714,1.2500000000000142,2.1666666666666714,1.3333333333333286,2.8333333333333286,-2.0833333333333286,2.0,-2.75,3.8333333333333286,3.250000000000014,2.75,2.583333333333343,5.25,0.8333333333333428,0.8333333333333428,1.5833333333333286,2.6666666666666714,-0.25,-0.08333333333334281,3.4166666666666714,1.0833333333333286,6.166666666666671,2.500000000000014,0.25,1.5000000000000142,2.666666666666657,-0.75,3.4166666666666714,4.916666666666671,0.0,1.9166666666666714,0.6666666666666572,-2.583333333333343,2.6666666666666714,0.8333333333333428,-2.4166666666666714,2.3333333333333357,-1.5,1.8333333333333428,3.75,0.5833333333333428,-1.25,1.6666666666666714,-1.25,0.0,0.1666666666666714,6.416666666666671,-2.583333333333343,2.750000000000014,2.0,2.6666666666666714,2.4166666666666714,3.75,4.916666666666671,5.25,1.5833333333333428,1.9166666666666714,-1.5833333333333428,-1.5,3.5,1.9166666666666714,1.8333333333333428,4.416666666666671,2.0,2.0,3.9166666666666714,-0.3333333333333428,3.6666666666666714,1.0833333333333286,2.9166666666666714,0.3333333333333428,3.083333333333343,2.6666666666666714,0.2500000000000142,1.6666666666666714,-0.1666666666666714,-0.0833333333333357,1.0833333333333428,2.6666666666666714,-0.9166666666666714,-2.1666666666666714,5.666666666666671,3.5833333333333286,-0.6666666666666714,1.8333333333333286,1.0,2.0,1.6666666666666714,0.8333333333333428,0.0833333333333286,1.2500000000000142,0.6666666666666714,2.999999999999986,0.5,1.0,3.4166666666666714,-1.25,0.8333333333333428,2.0,0.5,1.4166666666666714,4.333333333333343,0.9166666666666572,2.6666666666666714,-1.6666666666666714,0.6666666666666714,-0.25,0.1666666666666714,0.5,3.25,1.3333333333333286,4.833333333333343,3.6666666666666714,6.25,2.9166666666666714,3.500000000000014,-0.25,4.583333333333343,1.8333333333333428,2.9166666666666714,2.75,2.833333333333343,0.25,3.1666666666666714,4.833333333333343,1.1666666666666714,3.75,3.750000000000014,4.416666666666671,1.75,0.4166666666666714,4.666666666666671,2.083333333333343,0.5833333333333428,0.6666666666666714,0.3333333333333286,-1.75,3.333333333333343,1.8333333333333428,5.083333333333329,3.9166666666666714,1.75,0.5833333333333428,0.75,2.9166666666666714,3.500000000000014,1.9166666666666714,5.166666666666671,2.500000000000014,2.083333333333343,3.75,0.5833333333333286,1.4166666666666714,2.0,2.3333333333333286,4.750000000000014,1.25,4.083333333333343,1.75,1.5000000000000142,7.916666666666657,2.6666666666666714,0.6666666666666572,3.083333333333343,0.9166666666666714,-2.4166666666666714,4.000000000000014,1.9166666666666714,3.25,1.4166666666666714,0.4166666666666714,-0.5,-0.8333333333333286,3.0,2.4166666666666714,-0.3333333333333428,1.2500000000000142,-0.25,4.083333333333343,1.0,0.6666666666666572,1.9166666666666714,3.750000000000014,0.2499999999999858,0.75,3.083333333333343,5.916666666666657,1.1666666666666714,2.500000000000014,1.8333333333333428,-3.1666666666666714,5.000000000000014,1.3333333333333286,3.5833333333333286,0.6666666666666714,-0.25,3.1666666666666856,1.4166666666666714,1.9166666666666714,5.083333333333329,1.5833333333333286,1.25,1.25,2.500000000000014,4.916666666666671,-1.3333333333333286,2.0,3.500000000000014,-0.9166666666666714,3.6666666666666714,1.5,-2.666666666666657,1.3333333333333286,7.416666666666671,1.0833333333333286,-3.250000000000014,0.6666666666666572,2.250000000000014,1.9166666666666714,-0.3333333333333428,2.333333333333343,1.5000000000000142,4.916666666666671,2.583333333333343,2.5833333333333286,-0.9166666666666714,-0.5,1.0,-2.499999999999986,2.500000000000014,1.75,0.0,0.5,2.083333333333343,1.0,3.6666666666666714,0.9166666666666572,2.500000000000014,1.0,2.083333333333343,4.416666666666657,-0.1666666666666572,0.3333333333333286,5.416666666666671,0.8333333333333428,5.083333333333329,2.25,3.333333333333343,-1.25,2.583333333333343,3.0,4.333333333333343,6.25,-0.4166666666666714,5.166666666666671,-1.0000000000000142,0.75,-0.75,0.9166666666666714,5.25,2.750000000000014,0.0,1.4166666666666714,0.25,2.833333333333343,1.5833333333333428,-1.0833333333333286,5.333333333333329,4.583333333333343,3.500000000000014,2.249999999999993,-1.4166666666666572,2.083333333333343,2.3333333333333286,-0.0833333333333286,3.6666666666666714,1.2500000000000142,-0.75,-0.9166666666666714,5.833333333333343,-0.9166666666666714,1.25,-0.5,1.0833333333333428,1.5833333333333286,-0.7500000000000142,2.750000000000014,-1.1666666666666714,6.5,4.666666666666671,3.083333333333343,2.500000000000014,3.583333333333343,-0.1666666666666714,0.25,6.5,0.1666666666666714,4.5,5.333333333333343,2.3333333333333286,-0.25,3.500000000000014,2.4166666666666714,1.8333333333333428,2.25,1.1666666666666714,0.25,3.1666666666666714,2.4166666666666714,0.3333333333333286,1.6666666666666714,-0.75,4.750000000000014,3.6666666666666714,0.25,-0.8333333333333286,0.5,2.0,0.1666666666666643,1.8333333333333428,3.500000000000014,1.0833333333333286,-1.0,0.3333333333333286,5.416666666666671,3.6666666666666714,1.0,2.25,0.5,-0.08333333333334281,1.5833333333333428,-0.9166666666666572,0.9166666666666572,-0.6666666666666714,2.6666666666666714,5.0,3.500000000000014,4.25,2.25,6.083333333333343,3.083333333333343,-0.6666666666666714,1.8333333333333428,1.3333333333333286,1.8333333333333428,2.333333333333343,-1.1666666666666714,-1.4166666666666643,-4.083333333333343,3.5833333333333286,3.4166666666666714,3.083333333333343,-0.0833333333333286,0.3333333333333286,5.416666666666671,-1.5833333333333428,1.8333333333333428,4.25,2.25,2.750000000000014,4.916666666666671,1.0,1.75,-0.5,0.3333333333333286,1.5000000000000142,1.1666666666666714,2.750000000000014,2.500000000000014,4.583333333333329,2.6666666666666714,0.75,2.1666666666666643,2.0,4.666666666666671,3.5833333333333286,2.1666666666666714,2.25,5.416666666666671,1.1666666666666714,3.5833333333333286,0.3333333333333286,2.333333333333343,4.333333333333343,2.25,2.833333333333343,2.3333333333333286,1.4166666666666714,2.9166666666666714,-2.249999999999986,4.333333333333329,1.3333333333333286,-1.3333333333333428,1.3333333333333286,0.0833333333333286,4.25,0.1666666666666714,1.9166666666666714,1.75,3.6666666666666714,0.9166666666666714,-2.333333333333343,0.3333333333333286,3.750000000000014,-4.166666666666671,1.5833333333333286,2.333333333333343,0.25,4.083333333333343,2.25,-2.6666666666666856,2.6666666666666714,4.166666666666671,0.6666666666666714,0.1666666666666714,3.4166666666666714,-0.25,0.25,2.6666666666666714,-0.3333333333333428,3.750000000000014,2.4166666666666714,4.583333333333343,3.833333333333343,2.833333333333343,2.0,3.250000000000014,1.4166666666666714,3.9166666666666714,1.7499999999999858,3.083333333333343,0.4166666666666714,0.4166666666666714,4.500000000000014,1.0,0.25,0.5833333333333428,4.416666666666671,2.333333333333343,2.5833333333333286,-0.6666666666666714,-1.1666666666666714,2.4166666666666643,2.0,3.083333333333343,1.3333333333333286,5.083333333333343,2.25,5.916666666666671,3.0,3.0,2.0833333333333286,1.2500000000000142,2.25,2.0,1.3333333333333286,3.6666666666666714,1.1666666666666714,0.25,3.0,3.5833333333333286,-0.1666666666666572,3.1666666666666714,1.1666666666666714,2.083333333333343,5.416666666666671,3.6666666666666714,0.25,2.5833333333333286,-0.1666666666666714,-0.1666666666666572,3.333333333333343,0.75,-0.4999999999999858,4.750000000000014,3.5833333333333286,1.5833333333333428,-2.000000000000014,5.5,2.500000000000014,1.0,4.333333333333329,-2.583333333333343,1.6666666666666572,0.9166666666666714,2.5,1.5000000000000142,1.2500000000000142,3.666666666666657,1.4166666666666714,1.0,7.500000000000014,3.1666666666666714,3.0,0.25,-2.75,-3.6666666666666714,1.5000000000000142,1.75,2.25,-0.4166666666666714,2.6666666666666714,3.083333333333343,3.1666666666666856,2.583333333333343,1.8333333333333428,0.5833333333333286,2.1666666666666714,2.1666666666666714,0.75,-2.9166666666666714,-2.250000000000014,1.8333333333333428,4.166666666666671,1.8333333333333428,4.666666666666671,-0.7500000000000142,4.583333333333329,2.833333333333343,5.0,-4.25,0.5833333333333286,-1.75,5.000000000000014,2.9166666666666714,3.083333333333343,2.4166666666666714,3.5833333333333286,1.2500000000000142,1.8333333333333428,3.9166666666666714,3.25,2.833333333333343,-5.083333333333329,5.166666666666671,1.9166666666666572,-0.5833333333333286,-1.3333333333333428,1.3333333333333286,5.000000000000014,2.4166666666666714,6.666666666666671,4.333333333333343,1.3333333333333286,1.3333333333333286,3.9166666666666714,-0.75,0.0833333333333286,3.1666666666666856,2.5833333333333286,2.833333333333343,0.3333333333333286,4.416666666666671,5.166666666666671,4.000000000000014,5.166666666666671,2.250000000000014,-1.5,1.1666666666666714,3.1666666666666714,2.500000000000014,0.5,3.750000000000014,0.2499999999999858,2.083333333333343,0.3333333333333286,1.8333333333333428,5.416666666666671,3.0,4.416666666666671,1.3333333333333286,-0.0833333333333286,5.5,0.6666666666666572,2.4166666666666714,1.0,2.1666666666666714,0.0,4.500000000000014,-1.0,1.9166666666666714,3.9166666666666714,3.9166666666666714,3.833333333333343,3.5833333333333286,0.75,1.0,1.6666666666666714,0.5,3.833333333333343,1.5833333333333428,3.4166666666666714,1.3333333333333286,5.000000000000014,3.6666666666666714,-2.250000000000014,0.4166666666666714,-2.4166666666666714,3.333333333333343,7.083333333333329,4.416666666666671,2.4166666666666714,0.6666666666666714,2.083333333333343,4.0,0.8333333333333428,2.25,5.083333333333343,2.166666666666657,3.4166666666666714,-0.2499999999999858,4.75,3.4166666666666714,3.333333333333343,3.0,1.25,1.1666666666666714,0.3333333333333286,2.250000000000014,2.3333333333333286,4.0,5.0,2.5833333333333286,2.4166666666666714,-0.75,0.75,2.4166666666666714,-0.08333333333331439,7.333333333333329,6.166666666666686,5.416666666666671,-0.25,-1.9166666666666714,1.75,0.9166666666666714,4.750000000000014,5.0,0.8333333333333428,1.5,0.5833333333333428,-1.5,3.750000000000014,3.4166666666666714,3.9166666666666714,5.916666666666671,2.6666666666666714,-0.5,1.8333333333333428,-1.5,4.666666666666671,1.0,-1.9166666666666572,3.4166666666666714,1.25,3.333333333333343,2.0,-1.6666666666666714,1.0,2.500000000000014,5.916666666666671,-0.4166666666666572,0.3333333333333286,0.8333333333333428,3.6666666666666714,0.5833333333333428,2.75,0.7499999999999929,-1.4166666666666714,4.083333333333343,5.333333333333343,2.75,-1.75,2.083333333333343,-2.0833333333333286,3.0,-1.0833333333333286,-1.75,2.1666666666666714,3.0,1.8333333333333428,0.0833333333333286,3.75,2.333333333333343,0.6666666666666572,2.250000000000014,3.5833333333333286,2.3333333333333286,5.916666666666657,5.166666666666686,2.750000000000014,3.1666666666666856,-0.8333333333333286,3.333333333333343,2.4166666666666714,-1.3333333333333428,0.0,3.583333333333343,1.9166666666666714,5.916666666666671,2.1666666666666714,3.6666666666666714,0.1666666666666714,-0.0833333333333286,2.75,-1.4166666666666714,0.75,5.666666666666671,2.75,-3.6666666666666714,3.9166666666666714,1.4166666666666714,0.1666666666666714,2.0,2.3333333333333286,3.5833333333333286,0.6666666666666572,-1.1666666666666714,-1.25,1.25,6.000000000000014,4.333333333333329,0.0,0.4166666666666714,1.9166666666666714,1.8333333333333428,2.750000000000014,1.0,3.333333333333343,0.3333333333333286,1.0,0.5,1.0833333333333428,2.1666666666666714,1.5000000000000142,-0.8333333333333286,-2.6666666666666714,0.3333333333333286,4.666666666666671,1.5833333333333428,-0.0833333333333286,3.25,1.0833333333333286,3.9166666666666714,0.75,4.083333333333343,0.2500000000000142,4.083333333333343,5.000000000000014,0.6666666666666572,3.833333333333343,3.9166666666666714,2.6666666666666714,0.1666666666666714,-2.5,2.1666666666666714,-0.3333333333333286,4.500000000000014,2.5833333333333286,2.333333333333343,2.6666666666666714,5.833333333333343,0.0833333333333286,4.083333333333343,3.333333333333343,3.3333333333333286,2.666666666666657,0.8333333333333428,4.666666666666671,1.3333333333333286,0.5,4.583333333333343,2.5,-0.3333333333333286,-3.000000000000014,0.8333333333333428,3.1666666666666856,2.75,0.3333333333333286,3.750000000000014,0.2499999999999858,4.75,3.333333333333343,0.4166666666666714,-0.75,0.8333333333333428,1.8333333333333428,4.833333333333343,2.1666666666666643,3.4166666666666714,1.250000000000007,1.0,0.25,1.3333333333333286],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Accuracy Difference (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[0.21944444444444783,0.17222222222222566,0.27500000000000335,0.3000000000000034,0.2833333333333366,0.2833333333333366,0.4305555555555591,0.3972222222222257,0.4111111111111152,0.46666666666667145,0.6083333333333384,0.6166666666666716,0.6083333333333382,0.5722222222222267,0.4333333333333373,0.4638888888888929,0.3805555555555597,0.3833333333333373,0.41666666666667046,0.39166666666667,0.5222222222222255,0.49444444444444735,0.4944444444444469,0.40833333333333643,0.458333333333336,0.5388888888888912,0.6527777777777793,0.6527777777777793,0.5750000000000018,0.6027777777777801,0.713888888888891,0.7555555555555574,0.8111111111111127,0.7333333333333347,0.7500000000000013,0.7611111111111127,0.580555555555557,0.5277777777777793,0.5138888888888904,0.43611111111111234,0.5000000000000014,0.5027777777777791,0.46666666666666784,0.48888888888889026,0.6472222222222241,0.6277777777777798,0.6083333333333355,0.5000000000000024,0.3722222222222247,0.31944444444444775,0.3055555555555591,0.27500000000000374,0.2583333333333376,0.319444444444448,0.3416666666666705,0.36111111111111466,0.23888888888889276,0.21666666666667037,0.14166666666667044,0.04444444444444834,-0.1416666666666626,-0.06111111111110687,-0.08888888888888456,0.030555555555560443,0.0694444444444495,0.10833333333333806,0.18611111111111617,0.22222222222222712,0.21944444444444952,0.26666666666667166,0.15555555555556025,0.18333333333333807,0.18055555555556044,0.1638888888888938,0.20000000000000456,0.19444444444444858,0.16944444444444812,0.25277777777778165,0.48611111111111505,0.6583333333333365,0.7305555555555585,0.8694444444444474,0.8861111111111135,0.8555555555555585,0.8666666666666695,0.8527777777777809,1.0805555555555582,1.1305555555555582,1.3083333333333365,1.5000000000000029,1.6083333333333356,1.6083333333333356,1.6250000000000022,1.6166666666666685,1.5777777777777795,1.6333333333333355,1.5888888888888908,1.6361111111111122,1.722222222222223,1.7361111111111118,1.8111111111111118,1.811111111111112,1.8222222222222233,1.852777777777779,1.9000000000000012,1.8944444444444457,1.988888888888891,2.0888888888888903,2.100000000000002,2.0138888888888906,1.947222222222224,1.8000000000000014,1.7944444444444458,1.8694444444444454,1.81388888888889,1.925000000000001,1.6805555555555562,1.7277777777777792,1.7027777777777788,1.6777777777777787,1.7944444444444454,1.8555555555555563,1.8777777777777787,1.9166666666666676,2.0472222222222234,2.0000000000000013,2.0861111111111126,2.119444444444446,2.127777777777779,2.2250000000000014,2.2222222222222237,2.191666666666668,2.2361111111111125,2.4277777777777794,2.4611111111111126,2.4916666666666685,2.450000000000002,2.3833333333333355,2.222222222222224,2.3555555555555583,2.2888888888888914,2.430555555555558,2.4666666666666694,2.4500000000000033,2.5444444444444483,2.4444444444444486,2.588888888888894,2.6527777777777817,2.572222222222226,2.511111111111115,2.361111111111115,2.3805555555555595,2.422222222222226,2.3805555555555595,2.263888888888893,2.3500000000000045,2.35555555555556,2.3333333333333384,2.2083333333333375,1.9888888888888934,1.916666666666671,1.8888888888888933,1.9472222222222266,1.8472222222222263,1.7111111111111144,1.7972222222222256,1.9388888888888918,1.9666666666666692,2.038888888888892,1.9416666666666689,2.1361111111111137,2.036111111111114,2.0083333333333364,2.0388888888888914,2.0583333333333353,2.036111111111113,1.9972222222222233,1.9277777777777796,1.938888888888891,1.8722222222222245,2.02777777777778,2.0277777777777803,1.8972222222222246,1.7555555555555575,1.7833333333333352,1.6194444444444456,1.641666666666668,1.6305555555555573,1.6638888888888905,1.8333333333333355,1.850000000000002,1.9722222222222243,1.791666666666669,1.7527777777777804,1.7527777777777804,1.6861111111111138,1.5638888888888918,1.6111111111111143,1.7722222222222248,1.6833333333333362,1.6250000000000029,1.7083333333333361,1.827777777777781,1.7500000000000036,1.6638888888888923,1.6083333333333365,1.5722222222222253,1.608333333333336,1.6166666666666696,1.597222222222225,1.5083333333333362,1.2888888888888916,1.430555555555559,1.4638888888888921,1.5111111111111142,1.5388888888888923,1.4750000000000036,1.5722222222222255,1.5583333333333371,1.4750000000000032,1.444444444444448,1.327777777777781,1.544444444444447,1.5333333333333363,1.4666666666666697,1.375000000000003,1.3277777777777806,1.2527777777777804,1.1194444444444478,1.2833333333333368,1.0583333333333365,1.1277777777777809,0.9916666666666699,1.0194444444444475,1.1972222222222255,1.200000000000003,1.272222222222226,1.205555555555559,1.2416666666666707,1.3138888888888924,1.300000000000004,1.5500000000000038,1.4222222222222256,1.4944444444444485,1.5055555555555598,1.5111111111111153,1.6583333333333372,1.5388888888888927,1.6861111111111151,1.5805555555555602,1.60555555555556,1.6305555555555595,1.6194444444444485,1.697222222222226,1.8750000000000042,1.9305555555555598,2.0055555555555604,2.1388888888888933,2.1388888888888933,2.0861111111111152,2.1444444444444484,2.050000000000004,2.0222222222222257,2.0416666666666705,1.9555555555555586,1.9916666666666696,1.9555555555555582,2.1027777777777805,2.0777777777777806,2.1055555555555583,2.1472222222222253,2.044444444444448,1.9777777777777805,1.944444444444447,1.8444444444444474,1.8194444444444473,1.6222222222222258,1.7416666666666702,1.6555555555555594,1.6972222222222255,1.827777777777781,1.96666666666667,1.897222222222226,1.7777777777777817,1.6444444444444482,1.602777777777781,1.5916666666666694,1.525000000000003,1.5972222222222254,1.447222222222225,1.411111111111114,1.319444444444448,1.383333333333337,1.5361111111111152,1.4638888888888926,1.5166666666666706,1.6638888888888936,1.511111111111116,1.502777777777782,1.3861111111111146,1.2916666666666703,1.3750000000000036,1.4777777777777819,1.572222222222226,1.6333333333333369,1.5555555555555594,1.6666666666666703,1.6111111111111145,1.525000000000003,1.6472222222222255,1.55277777777778,1.4777777777777799,1.30277777777778,1.3583333333333358,1.3305555555555577,1.4500000000000024,1.6083333333333356,1.6361111111111137,1.4861111111111136,1.6666666666666698,1.7833333333333368,1.8638888888888918,1.7833333333333363,1.7000000000000024,1.6777777777777803,1.6166666666666694,1.4083333333333354,1.458333333333335,1.4750000000000019,1.5055555555555578,1.5527777777777798,1.5138888888888913,1.5527777777777803,1.4722222222222248,1.497222222222225,1.6666666666666692,1.6388888888888915,1.536111111111114,1.702777777777781,1.6694444444444476,1.6222222222222265,1.6611111111111159,1.8083333333333376,1.7555555555555598,1.7055555555555597,1.5388888888888925,1.3194444444444478,1.333333333333337,1.4500000000000035,1.4111111111111145,1.4694444444444485,1.4888888888888931,1.6083333333333378,1.5694444444444486,1.688888888888893,1.6083333333333374,1.6083333333333374,1.700000000000004,1.7666666666666704,1.7138888888888923,1.661111111111115,1.7111111111111146,1.7194444444444474,1.7694444444444475,1.800000000000003,1.719444444444447,1.6638888888888916,1.6777777777777803,1.62777777777778,1.5500000000000018,1.480555555555557,1.494444444444445,1.519444444444445,1.5222222222222226,1.7888888888888892,1.9166666666666679,2.083333333333335,2.077777777777779,2.158333333333334,2.1916666666666678,2.1444444444444453,2.211111111111112,2.1777777777777785,2.280555555555557,2.219444444444446,2.3750000000000018,2.5694444444444464,2.4777777777777805,2.4083333333333354,2.475000000000003,2.5361111111111145,2.369444444444447,2.3777777777777804,2.441666666666669,2.4527777777777806,2.625000000000002,2.705555555555558,2.6444444444444466,2.5416666666666687,2.594444444444447,2.705555555555559,2.6305555555555586,2.5138888888888924,2.5055555555555595,2.5388888888888927,2.5277777777777817,2.3888888888888933,2.2194444444444485,2.04166666666667,1.9500000000000037,1.8833333333333364,1.7777777777777808,1.819444444444448,1.7944444444444478,1.8583333333333367,1.8972222222222261,1.8694444444444485,1.9805555555555594,2.0638888888888935,2.033333333333338,2.09444444444445,2.075000000000005,2.061111111111116,1.861111111111116,1.8416666666666717,1.6611111111111163,1.6416666666666715,1.7333333333333385,1.6916666666666715,1.6250000000000044,1.58055555555556,1.5305555555555603,1.6694444444444492,1.5972222222222276,1.408333333333339,1.3666666666666716,1.3333333333333386,1.2750000000000052,1.188888888888894,1.2444444444444498,1.2444444444444496,1.352777777777783,1.2583333333333384,1.2361111111111158,1.2388888888888934,1.0972222222222263,0.9750000000000039,0.8277777777777814,0.7583333333333369,0.9361111111111148,0.8527777777777809,1.0722222222222262,1.0888888888888935,1.3111111111111158,1.2972222222222267,1.4000000000000048,1.5083333333333384,1.5555555555555605,1.5944444444444499,1.783333333333339,1.8888888888888942,1.8972222222222273,1.8777777777777822,1.8805555555555593,1.9166666666666703,1.8500000000000036,1.900000000000004,2.161111111111115,2.2750000000000044,2.330555555555559,2.3416666666666703,2.2000000000000037,2.2194444444444485,2.122222222222226,1.9638888888888923,2.1055555555555596,1.9805555555555596,1.9777777777777816,1.9833333333333367,1.8972222222222257,1.9833333333333372,1.875000000000003,1.7638888888888922,1.7333333333333365,1.6194444444444474,1.5305555555555581,1.3611111111111134,1.3166666666666695,1.380555555555558,1.316666666666669,1.1833333333333362,1.1722222222222254,1.102777777777781,1.2277777777777814,1.263888888888892,1.4611111111111146,1.5305555555555588,1.4722222222222252,1.4666666666666701,1.433333333333337,1.4277777777777811,1.3750000000000036,1.3888888888888926,1.4583333333333373,1.6222222222222267,1.547222222222226,1.6972222222222255,1.627777777777781,1.5611111111111147,1.4611111111111148,1.388888888888892,1.350000000000003,1.3583333333333363,1.1944444444444478,1.3222222222222257,1.4083333333333368,1.4138888888888925,1.5361111111111148,1.3194444444444478,1.3527777777777814,1.500000000000003,1.5527777777777811,1.6777777777777811,1.5277777777777806,1.6277777777777813,1.5194444444444477,1.402777777777781,1.24166666666667,1.3638888888888925,1.5055555555555593,1.5277777777777812,1.5027777777777809,1.5083333333333366,1.352777777777781,1.1833333333333365,1.163888888888892,1.144444444444448,1.150000000000003,1.150000000000003,1.213888888888892,1.0805555555555588,1.1527777777777808,1.1194444444444474,1.2861111111111139,1.1972222222222246,1.0472222222222254,1.0472222222222256,1.0000000000000038,1.2972222222222263,1.2222222222222265,1.3083333333333378,1.4222222222222274,1.3083333333333387,1.380555555555561,1.186111111111116,1.1916666666666718,1.250000000000005,1.4722222222222272,1.388888888888893,1.1583333333333372,1.2194444444444494,1.2777777777777832,1.2750000000000055,1.3861111111111168,1.5888888888888948,1.64444444444445,1.6166666666666725,1.6972222222222286,1.8277777777777844,1.80833333333334,1.9361111111111178,1.7750000000000072,1.902777777777785,1.8611111111111178,1.9638888888888955,2.211111111111117,2.227777777777783,2.2666666666666715,2.1277777777777827,2.0944444444444494,1.886111111111115,1.8861111111111153,1.969444444444449,2.036111111111116,2.2444444444444493,2.3555555555555596,2.213888888888893,2.058333333333337,2.180555555555559,2.3250000000000033,2.322222222222225,2.450000000000003,2.486111111111114,2.6111111111111134,2.4388888888888913,2.2916666666666696,2.3388888888888917,2.3861111111111137,2.3333333333333357,2.411111111111113,2.3750000000000018,2.622222222222224,2.486111111111113,2.594444444444446,2.5055555555555578,2.4388888888888904,2.369444444444446,2.3194444444444455,2.3611111111111125,2.402777777777779,2.597222222222224,2.508333333333335,2.5277777777777795,2.6750000000000016,2.5611111111111127,2.388888888888891,2.3888888888888897,2.552777777777779,2.3694444444444467,2.388888888888891,2.27777777777778,2.2138888888888903,2.205555555555557,2.1527777777777795,2.2250000000000014,2.33888888888889,2.386111111111112,2.344444444444446,2.2888888888888905,2.2361111111111134,2.1750000000000025,1.9361111111111127,1.880555555555557,1.8805555555555575,2.0611111111111127,2.03888888888889,2.161111111111113,2.213888888888891,2.336111111111113,2.288888888888891,2.1250000000000013,2.1250000000000018,2.1388888888888906,1.90277777777778,1.8055555555555578,2.036111111111115,2.2138888888888935,2.147222222222226,2.275000000000004,2.2333333333333374,2.363888888888893,2.4555555555555597,2.6027777777777823,2.6111111111111156,2.5722222222222264,2.563888888888893,2.569444444444449,2.5777777777777824,2.630555555555561,2.641666666666672,2.805555555555561,2.852777777777784,2.986111111111118,2.866666666666673,2.791666666666673,2.805555555555562,2.677777777777784,2.59444444444445,2.36944444444445,2.527777777777784,2.4361111111111167,2.452777777777783,2.4472222222222277,2.4472222222222273,2.4972222222222267,2.355555555555559,2.350000000000003,2.2944444444444483,2.0888888888888917,2.102777777777781,2.105555555555559,2.0666666666666704,1.9000000000000032,1.7750000000000028,1.9222222222222247,1.855555555555558,1.8805555555555575,1.7972222222222238,1.9222222222222232,1.858333333333334,1.8472222222222232,1.8750000000000007,1.8694444444444447,1.902777777777778,1.8111111111111104,1.7222222222222217,1.819444444444444,1.7555555555555549,1.7944444444444438,1.7861111111111108,1.855555555555555,1.869444444444444,1.8555555555555556,1.9833333333333332,1.988888888888889,2.005555555555556,1.9777777777777783,1.8972222222222235,2.0166666666666684,1.9361111111111124,1.8361111111111117,1.8555555555555558,1.9583333333333344,1.9888888888888903,1.7611111111111135,1.9194444444444472,1.8527777777777799,1.9527777777777804,1.7583333333333355,1.9500000000000026,1.9722222222222248,1.933333333333336,2.0666666666666695,2.069444444444447,2.083333333333336,2.0583333333333362,2.127777777777781,2.2222222222222254,2.2111111111111144,2.0694444444444478,2.0833333333333366,2.088888888888892,2.1027777777777805,1.9555555555555586,1.9222222222222254,1.913888888888892,1.8222222222222246,1.866666666666669,1.8777777777777802,1.883333333333336,2.094444444444447,2.058333333333336,2.0250000000000026,2.1972222222222246,2.391666666666669,2.3444444444444463,2.425000000000003,2.450000000000003,2.57777777777778,2.391666666666669,2.3916666666666684,2.4583333333333353,2.4055555555555577,2.4305555555555585,2.3777777777777804,2.4222222222222247,2.316666666666669,2.133333333333335,2.3166666666666687,2.463888888888891,2.3888888888888915,2.447222222222224,2.330555555555557,2.508333333333335,2.6083333333333356,2.722222222222224,2.8305555555555575,2.9472222222222246,3.0611111111111144,3.133333333333336,2.8750000000000036,2.9444444444444486,2.93055555555556,2.869444444444449,2.7916666666666714,2.836111111111116,2.6861111111111153,2.633333333333338,2.600000000000005,2.5944444444444494,2.5527777777777825,2.6027777777777823,2.4722222222222276,2.450000000000005,2.54444444444445,2.5833333333333393,2.613888888888895,2.7361111111111174,2.68333333333334,2.6250000000000067,2.7333333333333396,2.583333333333339,2.6472222222222275,2.7833333333333377,2.7555555555555595,2.6361111111111146,2.6805555555555594,2.638888888888893,2.6055555555555587,2.600000000000003,2.7388888888888925,2.6361111111111146,2.636111111111115,2.597222222222226,2.600000000000003,2.5472222222222256,2.5416666666666696,2.580555555555559,2.5750000000000037,2.661111111111115,2.5277777777777817,2.438888888888893,2.5750000000000037,2.594444444444448,2.511111111111115,2.5750000000000037,2.630555555555559,2.6222222222222253,2.647222222222226,2.6361111111111146,2.6000000000000036,2.7083333333333366,2.513888888888892,2.275000000000004,2.172222222222226,2.108333333333337,2.052777777777782,1.9277777777777818,1.8777777777777818,1.7194444444444479,1.7888888888888927,1.7527777777777813,1.838888888888892,1.9000000000000032,2.0222222222222257,1.9722222222222254,2.1444444444444484,2.108333333333337,2.0333333333333377,2.0305555555555594,2.175000000000004,2.0916666666666703,2.0694444444444478,2.061111111111115,2.1472222222222257,1.9666666666666703,1.8388888888888923,1.7944444444444476,1.6694444444444474,1.6666666666666694,1.7305555555555587,1.6833333333333365,1.947222222222226,2.0138888888888924,2.1000000000000028,2.1638888888888923,2.150000000000003,2.3138888888888918,2.3527777777777805,2.5166666666666697,2.450000000000003,2.5750000000000024,2.300000000000002,2.1305555555555573,2.0694444444444478,2.172222222222225,2.0416666666666696,2.050000000000003,2.3138888888888913,2.2805555555555572,2.1694444444444465,2.3333333333333353,2.1472222222222244,2.244444444444447,2.1277777777777804,2.347222222222225,2.4027777777777803,2.472222222222225,2.4888888888888916,2.4361111111111136,2.5416666666666687,2.450000000000003,2.3333333333333366,2.3000000000000034,2.01666666666667,2.158333333333337,2.1888888888888927,2.3222222222222255,2.2527777777777804,2.150000000000003,2.119444444444448,1.9305555555555594,2.0305555555555603,2.186111111111116,2.1194444444444485,1.9694444444444479,1.9333333333333365,1.9194444444444474,1.6694444444444476,1.7277777777777812,1.8527777777777814,1.802777777777781,2.0277777777777803,1.7527777777777795,1.8333333333333348,1.6777777777777791,1.6638888888888903,1.6750000000000014,1.7305555555555565,1.8500000000000014,1.5277777777777788,1.5111111111111115,1.5805555555555557,1.613888888888889,1.8916666666666668,1.75,1.7194444444444446,1.5055555555555562,1.558333333333334,1.5111111111111115,1.5055555555555555,1.6722222222222218,1.677777777777777,1.7083333333333324,1.6722222222222212,1.766666666666666,1.8527777777777776,1.7722222222222215,1.816666666666666,1.783333333333333,1.708333333333333,1.675,1.6027777777777785,1.7305555555555567,1.677777777777779,1.7222222222222237,1.6666666666666679,1.7444444444444462,1.6000000000000025,1.4500000000000024,1.7416666666666694,1.7805555555555592,1.8000000000000034,1.752777777777781,1.744444444444448,1.8250000000000033,1.9444444444444478,1.7611111111111142,1.6944444444444478,1.8472222222222254,1.8361111111111141,1.7888888888888919,1.8472222222222252,1.8111111111111144,1.8861111111111146,1.8083333333333362,1.7972222222222247,2.005555555555558,2.013888888888891,1.8527777777777796,2.0500000000000025,2.1444444444444475,2.066666666666668,2.0888888888888903,2.0861111111111135,2.1166666666666685,2.1166666666666685,1.8916666666666682,2.0000000000000013,2.0472222222222234,1.8444444444444454,1.8972222222222228,1.875000000000001,1.8750000000000009,1.777777777777779,1.5500000000000012,1.411111111111112,1.5805555555555568,1.627777777777779,1.6388888888888902,1.6916666666666682,1.6638888888888903,1.7000000000000015,1.7611111111111133,1.763888888888891,1.758333333333336,1.697222222222225,1.4583333333333361,1.4416666666666693,1.602777777777781,1.358333333333336,1.3388888888888912,1.3555555555555585,1.3222222222222249,1.3083333333333356,1.291666666666669,1.4388888888888913,1.6194444444444467,1.6500000000000026,1.7638888888888917,1.8583333333333363,1.9500000000000026,2.033333333333336,1.9305555555555582,2.008333333333336,2.1000000000000028,2.2083333333333366,2.305555555555559,2.222222222222226,2.2583333333333373,2.136111111111114,2.155555555555559,2.258333333333337,2.180555555555559,2.2500000000000036,2.280555555555559,2.51666666666667,2.611111111111115,2.619444444444448,2.6833333333333367,2.8777777777777813,2.9055555555555594,2.933333333333337,2.9777777777777814,3.0638888888888927,3.044444444444448,3.01666666666667,2.8694444444444467,3.0083333333333355,2.880555555555558,2.9277777777777807,2.761111111111114,2.5416666666666696,2.613888888888892,2.663888888888892,2.69166666666667,2.650000000000003,2.4888888888888916,2.4500000000000024,2.3555555555555583,2.375000000000003,2.3694444444444476,2.0527777777777803,1.9388888888888913,1.8388888888888917,1.8777777777777807,1.6416666666666695,1.7166666666666694,1.7444444444444476,1.7638888888888926,1.6111111111111152,1.558333333333337,1.5250000000000041,1.4944444444444485,1.433333333333337,1.5833333333333375,1.5166666666666717,1.5583333333333387,1.411111111111117,1.5583333333333393,1.525000000000006,1.6250000000000058,1.8333333333333397,1.9222222222222287,1.8444444444444505,1.8916666666666728,1.8166666666666729,1.8333333333333395,1.8444444444444508,1.7277777777777836,1.772222222222228,1.7750000000000057,1.905555555555561,1.9750000000000054,1.9666666666666717,2.1027777777777827,2.2361111111111156,2.236111111111116,2.23055555555556,2.1611111111111154,2.238888888888893,2.2638888888888933,2.261111111111115,2.2861111111111154,2.272222222222227,2.0916666666666717,2.2277777777777823,2.213888888888894,2.297222222222227,2.158333333333338,2.1000000000000045,2.1833333333333376,2.1194444444444485,2.0750000000000037,2.1083333333333374,2.0888888888888926,2.0527777777777816,2.1083333333333374,2.1805555555555594,2.319444444444448,2.419444444444448,2.327777777777781,2.477777777777781,2.5555555555555594,2.6277777777777813,2.483333333333337,2.4194444444444487,2.38055555555556,2.3138888888888935,2.4277777777777825,2.350000000000004,2.3361111111111157,2.3194444444444486,2.1972222222222255,2.1972222222222255,2.3000000000000034,2.1805555555555594,2.3166666666666704,2.2833333333333368,2.352777777777781,2.4444444444444478,2.238888888888892,2.1416666666666697,2.100000000000003,2.233333333333337,2.2750000000000035,2.3055555555555594,2.3166666666666704,2.366666666666671,2.3111111111111153,2.2638888888888937,2.302777777777782,2.33055555555556,2.1527777777777817,2.161111111111115,2.0777777777777815,2.0694444444444486,2.0222222222222266,1.9583333333333375,1.8083333333333371,1.7138888888888926,1.733333333333337,1.761111111111115,1.85555555555556,1.8750000000000042,1.7694444444444482,1.7416666666666698,1.7888888888888919,1.838888888888892,1.7583333333333357,1.802777777777781,1.8583333333333363,1.7916666666666696,1.8083333333333367,1.7472222222222256,1.8194444444444482,1.822222222222226,1.9500000000000035,1.91666666666667,1.975000000000003,1.8777777777777807,2.022222222222225,1.8194444444444473,1.8888888888888922,1.86666666666667,2.01666666666667,2.027777777777781,1.9277777777777805,1.9472222222222253,2.0000000000000036,2.1055555555555587,2.1333333333333364,2.2083333333333366,2.2416666666666694,2.275000000000003,2.3194444444444473,2.344444444444448,2.2361111111111147,2.130555555555559,2.1222222222222262,2.0722222222222264,2.072222222222226,2.2027777777777815,2.291666666666671,2.352777777777782,2.158333333333338,2.2472222222222267,2.158333333333337,2.1972222222222255,2.161111111111115,2.1277777777777813,2.0472222222222256,2.238888888888892,2.2694444444444475,2.3500000000000036,2.3361111111111144,2.347222222222226,2.550000000000004,2.4694444444444477,2.3166666666666704,2.2138888888888926,2.266666666666671,2.1833333333333376,2.2277777777777814,2.2222222222222263,2.2583333333333377,2.2833333333333377,2.1611111111111154,2.183333333333337,2.208333333333337,2.150000000000003,2.2305555555555587,2.177777777777781,2.1416666666666697,2.0416666666666687,2.1333333333333355,2.0666666666666687,1.9527777777777804,1.9750000000000028,1.8694444444444476,2.100000000000004,2.158333333333337,1.9944444444444485,1.919444444444448,1.661111111111114,1.6333333333333364,1.6361111111111144,1.5222222222222248,1.6166666666666691,1.808333333333336,1.85277777777778,1.7527777777777802,1.7166666666666692,1.6527777777777808,1.5638888888888915,1.5083333333333355,1.5277777777777797,1.6333333333333349,1.5833333333333348,1.6527777777777797,1.6805555555555578,1.5777777777777797,1.6722222222222243,1.6750000000000023,1.716666666666669,1.6472222222222248,1.7166666666666697,1.8361111111111146,1.76666666666667,1.988888888888892,1.833333333333336,1.8777777777777804,1.8916666666666697,2.000000000000004,2.2166666666666712,2.2611111111111155,2.202777777777782,2.241666666666672,2.166666666666672,2.03055555555556,2.1083333333333383,2.1250000000000044,2.1972222222222264,2.2027777777777824,2.25555555555556,2.302777777777783,2.069444444444449,2.125000000000005,2.158333333333338,2.211111111111116,2.225000000000004,2.3666666666666716,2.3555555555555605,2.20555555555556,2.238888888888894,2.336111111111116,2.158333333333338,2.213888888888893,2.233333333333338,1.9500000000000048,2.011111111111116,1.869444444444449,1.8305555555555593,1.8416666666666703,1.702777777777781,1.6527777777777803,1.719444444444447,1.6500000000000024,1.8111111111111138,1.8777777777777809,1.8444444444444474,1.7333333333333365,1.819444444444448,1.8111111111111142,1.994444444444448,1.8861111111111142,2.250000000000003,2.236111111111114,2.277777777777781,2.1694444444444474,2.2500000000000036,2.1361111111111146,2.038888888888892,2.1500000000000035,2.0833333333333366,2.0111111111111137,2.069444444444447,2.0611111111111144,2.1472222222222257,2.29166666666667,2.305555555555559,2.311111111111115,2.40555555555556,2.388888888888893,2.4833333333333374,2.3916666666666706,2.4777777777777814,2.4694444444444485,2.4138888888888923,2.3861111111111146,2.544444444444448,2.6138888888888925,2.6138888888888925,2.7527777777777813,2.625000000000003,2.7277777777777814,2.611111111111115,2.6694444444444487,2.7250000000000045,2.7527777777777827,2.6500000000000044,2.6305555555555595,2.683333333333337,2.6305555555555595,2.6388888888888933,2.6333333333333377,2.752777777777782,2.6222222222222267,2.469444444444448,2.5416666666666705,2.3638888888888925,2.302777777777781,2.311111111111115,2.3861111111111146,2.322222222222226,2.369444444444449,2.2916666666666714,2.4000000000000044,2.4444444444444486,2.563888888888893,2.4861111111111156,2.541666666666671,2.5083333333333377,2.4194444444444496,2.3722222222222276,2.383333333333338,2.2611111111111164,2.255555555555561,2.183333333333339,2.172222222222228,1.9916666666666725,2.1138888888888947,2.0027777777777835,2.1083333333333396,1.95833333333334,2.1277777777777835,2.1083333333333396,2.0888888888888943,2.080555555555561,2.0666666666666718,2.2027777777777833,2.263888888888895,2.311111111111117,2.163888888888895,2.1583333333333394,2.275000000000006,2.1694444444444505,2.141666666666673,2.1305555555555626,2.0805555555555624,2.0333333333333403,1.822222222222229,1.9138888888888956,1.8138888888888955,1.7500000000000058,1.7138888888888943,1.977777777777783,1.9027777777777828,1.8805555555555602,1.7750000000000044,1.90555555555556,1.8972222222222273,1.9944444444444491,1.9111111111111152,2.058333333333337,2.038888888888893,2.044444444444448,2.286111111111115,2.288888888888893,2.2888888888888936,2.277777777777782,2.3388888888888935,2.369444444444448,2.39166666666667,2.5111111111111146,2.4083333333333363,2.4222222222222256,2.31666666666667,2.344444444444448,2.1444444444444475,2.2333333333333365,2.452777777777781,2.2805555555555586,2.4555555555555593,2.563888888888894,2.5333333333333385,2.23055555555556,2.111111111111115,2.0722222222222264,2.077777777777782,2.0027777777777818,1.930555555555559,1.9611111111111148,2.058333333333337,2.033333333333337,1.9277777777777816,1.727777777777782,1.5805555555555602,1.5972222222222268,1.5250000000000044,1.661111111111115,1.63055555555556,1.4333333333333376,1.5888888888888935,1.5250000000000048,1.4944444444444487,1.6638888888888934,1.7638888888888933,1.8416666666666708,2.0444444444444487,1.9000000000000041,1.708333333333337,1.700000000000004,1.650000000000004,1.6583333333333365,1.7777777777777812,1.9750000000000036,2.0972222222222263,2.191666666666671,2.261111111111115,2.388888888888893,2.3027777777777816,2.275000000000004,2.1583333333333368,2.1166666666666702,2.066666666666671,2.197222222222226,2.138888888888893,2.158333333333337,2.144444444444448,2.0444444444444474,2.0166666666666693,2.0055555555555573,1.9472222222222242,1.9444444444444466,1.9722222222222243,1.800000000000002,1.8194444444444464,1.741666666666669,1.5305555555555581,1.5083333333333362,1.5583333333333362,1.6472222222222248,1.5305555555555577,1.586111111111113,1.4361111111111131,1.3527777777777792,1.3388888888888906,1.197222222222224,1.2722222222222237,1.2666666666666684,1.5833333333333348,1.7000000000000013,1.7611111111111133,1.8944444444444466,1.922222222222224,1.8444444444444463,1.9000000000000021,1.947222222222225,1.930555555555558,1.8111111111111131,1.7750000000000024,1.8694444444444474,1.8583333333333356,1.805555555555558,1.7472222222222245,1.8555555555555578,1.9222222222222243,1.8194444444444464,2.0583333333333353,2.1555555555555577,2.3111111111111127,2.2222222222222237,2.2083333333333353,2.2611111111111137,2.383333333333335,2.3722222222222245,2.513888888888891,2.611111111111113,2.5416666666666687,2.45277777777778,2.2250000000000028,2.158333333333336,2.2444444444444467,2.1416666666666693,2.061111111111113,2.1277777777777804,2.1666666666666687,2.286111111111113,2.3166666666666687,2.4972222222222245,2.4583333333333353,2.4333333333333353,2.236111111111114,2.49166666666667,2.5166666666666697,2.4166666666666696,2.3500000000000023,2.35277777777778,2.2083333333333353,2.105555555555557,2.066666666666668,2.0722222222222237,2.136111111111113,2.0500000000000016,2.0166666666666684,2.011111111111113,1.7416666666666685,1.7250000000000019,1.725000000000002,1.847222222222224,1.9000000000000017,1.9305555555555576,1.7944444444444463,1.6166666666666676,1.7500000000000016,1.7861111111111125,1.6750000000000014,1.513888888888891,1.5555555555555576,1.533333333333336,1.619444444444447,1.62777777777778,1.7472222222222242,1.6000000000000016,1.6861111111111131,1.6555555555555572,1.6944444444444464,1.8555555555555578,1.7777777777777801,1.8944444444444473,1.838888888888891,1.8722222222222242,1.8250000000000024,1.8194444444444469,1.905555555555558,1.95277777777778,2.0750000000000024,2.108333333333335,2.1222222222222245,2.044444444444447,2.216666666666669,2.1250000000000027,2.091666666666669,2.338888888888892,2.2777777777777812,2.2777777777777812,2.3388888888888926,2.3972222222222253,2.3472222222222254,2.2694444444444475,2.3833333333333373,2.283333333333337,2.263888888888893,2.1944444444444486,2.1833333333333376,2.275000000000004,2.2944444444444487,2.186111111111116,2.491666666666671,2.3888888888888933,2.386111111111115,2.391666666666671,2.4805555555555596,2.433333333333338,2.2361111111111156,2.227777777777782,2.3638888888888934,2.3138888888888935,2.3472222222222254,2.4277777777777816,2.247222222222226,2.3944444444444475,2.544444444444448,2.522222222222226,2.663888888888893,2.6055555555555596,2.6055555555555596,2.58055555555556,2.5916666666666717,2.6805555555555602,2.602777777777782,2.8333333333333375,2.9250000000000034,2.9500000000000033,2.8777777777777813,2.8555555555555596,2.697222222222226,2.6527777777777812,2.644444444444448,2.6277777777777813,2.7416666666666707,2.6944444444444486,2.622222222222226,2.625000000000004,2.702777777777782,2.7083333333333375,2.6194444444444476,2.727777777777781,2.6972222222222255,2.755555555555559,2.630555555555559,2.4555555555555584,2.372222222222226,2.3777777777777804,2.208333333333336,2.3361111111111135,2.3972222222222244,2.491666666666668,2.4805555555555574,2.4388888888888913,2.20277777777778,1.9833333333333358,1.9666666666666686,1.9833333333333356,2.0361111111111136,2.050000000000002,2.183333333333336,2.1472222222222253,1.980555555555558,2.1277777777777813,2.0750000000000033,2.172222222222225,2.2305555555555587,2.2722222222222257,2.2972222222222256,2.2416666666666702,2.1972222222222255,2.06666666666667,2.086111111111114,1.9972222222222253,2.136111111111114,2.219444444444448,2.294444444444448,2.197222222222226,2.213888888888892,2.177777777777781,1.9861111111111143,1.9083333333333359,1.9750000000000025,1.8833333333333355,2.0750000000000024,2.1194444444444467,2.0472222222222247,1.916666666666669,1.9000000000000024,1.941666666666669,1.7972222222222243,1.8055555555555574,1.8277777777777793,1.7333333333333345,1.650000000000001,1.555555555555557,1.525000000000002,1.4444444444444458,1.3500000000000005,1.2972222222222232,1.2250000000000003,1.2472222222222222,1.2916666666666667,1.3638888888888894,1.3472222222222228,1.3500000000000012,1.3055555555555567,1.3222222222222237,1.3777777777777795,1.361111111111113,1.450000000000002,1.4638888888888908,1.4250000000000018,1.5250000000000024,1.5750000000000028,1.663888888888892,1.6305555555555584,1.7777777777777808,1.8444444444444479,1.800000000000004,1.9277777777777823,1.9416666666666713,1.9361111111111162,1.9888888888888943,2.088888888888894,2.2638888888888933,2.166666666666671,2.200000000000004,2.2611111111111155,2.2638888888888924,2.316666666666671,2.3861111111111155,2.3888888888888933,2.4222222222222274,2.327777777777783,2.2361111111111156,2.1138888888888934,2.0194444444444475,2.1444444444444484,1.9972222222222256,2.0777777777777806,1.9972222222222251,2.01666666666667,1.9944444444444478,1.9361111111111144,1.861111111111114,1.8500000000000028,1.883333333333336,1.7361111111111132,1.5750000000000013,1.4111111111111128,1.3694444444444456,1.2777777777777788,1.2500000000000007,1.1972222222222229,1.1527777777777786,1.2972222222222227,1.3194444444444453,1.2555555555555562,1.3444444444444457,1.3500000000000014,1.2194444444444459,1.244444444444446,1.1416666666666682,1.1777777777777796,1.261111111111113,1.500000000000002,1.5861111111111141,1.333333333333336,1.5027777777777804,1.577777777777781,1.655555555555559,1.5250000000000028,1.5138888888888915,1.42777777777778,1.5444444444444472,1.7416666666666698,1.7083333333333368,1.8138888888888924,1.9166666666666707,1.986111111111114,2.1000000000000036,2.138888888888893,2.0305555555555586,2.1361111111111146,2.108333333333337,1.9055555555555599,1.8638888888888931,1.8583333333333374,1.8527777777777819,1.9416666666666704,2.0722222222222255,1.9638888888888923,1.9694444444444472,1.9888888888888918,2.0444444444444474,1.855555555555558,2.022222222222225,2.0722222222222246,2.0333333333333354,1.8194444444444464,1.8055555555555574,1.9694444444444463,1.8416666666666688,1.925000000000002,1.8527777777777792,1.8777777777777789,1.8194444444444458,1.6833333333333345,1.6472222222222235,1.7444444444444462,1.6111111111111123,1.677777777777779,1.794444444444446,1.7222222222222243,1.7027777777777795,1.8222222222222233,1.9305555555555567,1.9833333333333347,1.9194444444444456,1.816666666666667,1.7361111111111116,1.7388888888888896,1.7416666666666667,1.6444444444444446,1.5027777777777778,1.5250000000000001,1.4499999999999997,1.5916666666666668,1.6638888888888892,1.7361111111111123,1.702777777777779,1.6361111111111122,1.8277777777777788,1.7416666666666676,1.736111111111112,1.3277777777777786,1.41388888888889,1.5194444444444455,1.5472222222222232,1.4527777777777784,1.4333333333333342,1.4027777777777788,1.3861111111111122,1.3388888888888897,1.3083333333333347,1.244444444444446,1.1777777777777794,1.1416666666666684,1.094444444444446,1.1472222222222241,1.2194444444444468,1.1888888888888907,1.1333333333333357,1.3083333333333362,1.2694444444444477,1.3500000000000028,1.2055555555555586,1.2027777777777804,1.0722222222222249,1.080555555555558,1.1361111111111135,1.2000000000000028,1.1027777777777803,1.230555555555559,1.3222222222222262,1.5194444444444484,1.4333333333333371,1.3638888888888931,1.4944444444444491,1.5138888888888937,1.6444444444444495,1.6944444444444493,1.8166666666666715,1.8166666666666715,1.93055555555556,2.08055555555556,2.161111111111116,2.313888888888894,2.258333333333338,2.222222222222228,2.1638888888888945,2.1611111111111168,2.186111111111117,2.11944444444445,2.2277777777777836,2.086111111111117,2.372222222222228,2.125000000000005,2.238888888888894,2.2333333333333383,2.2666666666666715,2.161111111111116,2.1444444444444493,1.9416666666666704,1.811111111111115,1.947222222222226,1.8722222222222253,1.8583333333333365,1.8583333333333363,1.9583333333333366,2.1083333333333365,1.9916666666666694,1.669444444444447,1.6750000000000023,1.5444444444444467,1.525000000000002,1.4694444444444463,1.3250000000000017,1.550000000000002,1.4666666666666688,1.466666666666669,1.4805555555555576,1.4555555555555575,1.4750000000000016,1.4472222222222237,1.5750000000000008,1.4000000000000008,1.6527777777777795,1.5833333333333346,1.5583333333333351,1.511111111111113,1.5444444444444467,1.6388888888888908,1.8083333333333358,1.9111111111111139,1.8500000000000032,1.8972222222222257,2.033333333333337,1.94166666666667,1.8944444444444477,1.8111111111111144,1.8916666666666706,2.0666666666666704,2.0750000000000037,2.1833333333333367,2.125000000000003,2.027777777777781,2.0833333333333366,2.058333333333337,2.2527777777777818,2.441666666666671,2.558333333333338,2.622222222222227,2.5138888888888937,2.5861111111111157,2.65555555555556,2.63055555555556,2.458333333333338,2.4638888888888935,2.5777777777777824,2.663888888888894,2.6500000000000044,2.6277777777777818,2.7833333333333377,2.7722222222222266,2.808333333333338,2.938888888888894,2.8361111111111157,2.8916666666666715,2.922222222222227,2.900000000000005,2.8250000000000046,2.8583333333333383,2.794444444444449,2.7666666666666724,2.836111111111117,3.0388888888888945,3.158333333333338,3.108333333333338,3.041666666666671,2.7777777777777817,2.7805555555555586,2.769444444444448,2.8055555555555594,2.7805555555555594,2.708333333333338,2.7694444444444493,2.811111111111116,2.8166666666666713,2.736111111111115,2.5027777777777813,2.5833333333333375,2.5250000000000044,2.3916666666666706,2.386111111111116,2.525000000000004,2.36666666666667,2.4500000000000037,2.4361111111111144,2.305555555555559,2.341666666666671,2.483333333333338,2.4111111111111154,2.5000000000000044,2.3388888888888935,1.9527777777777817,1.744444444444448,1.5083333333333362,1.6000000000000028,1.5555555555555582,1.7194444444444472,1.6750000000000025,1.6000000000000028,1.7333333333333356,1.8388888888888912,1.7361111111111125,1.7972222222222236,1.7472222222222242,1.7833333333333352,1.838888888888891,1.9138888888888914,1.8222222222222246,1.847222222222225,1.9166666666666692,1.9250000000000018,1.6833333333333351,1.8138888888888913,1.8000000000000032,1.9222222222222252,2.161111111111114,2.1055555555555583,2.1222222222222245,2.211111111111114,2.1611111111111136,2.3555555555555583,2.6972222222222255,2.8138888888888927,3.0083333333333377,2.841666666666671,2.7472222222222262,2.6916666666666704,2.6916666666666704,2.772222222222226,2.6861111111111153,2.6111111111111156,2.5305555555555603,2.50555555555556,2.5750000000000046,2.5277777777777826,2.5055555555555595,2.6305555555555595,2.7888888888888927,2.733333333333337,2.6555555555555594,2.613888888888893,2.686111111111116,2.65555555555556,2.6777777777777816,2.522222222222227,2.283333333333338,2.261111111111116,2.236111111111116,2.238888888888894,2.2666666666666715,2.2138888888888935,2.2555555555555595,2.1416666666666706,2.050000000000004,2.1000000000000036,2.2138888888888926,2.2305555555555587,2.136111111111114,2.1000000000000028,1.9638888888888912,1.8500000000000028,2.0000000000000027,1.8861111111111142,1.8944444444444473,1.7611111111111137,1.672222222222225,1.680555555555558,1.4861111111111143,1.5555555555555587,1.5194444444444473,1.575000000000003,1.455555555555559,1.4611111111111141,1.3777777777777802,1.3666666666666685,1.4833333333333356,1.5166666666666686,1.5250000000000021,1.4972222222222245,1.5055555555555578,1.4722222222222243,1.4111111111111134,1.5722222222222244,1.5666666666666689,1.525000000000002,1.52777777777778,1.6027777777777796,1.6666666666666687,1.7750000000000024,1.8944444444444473,1.9944444444444471,2.052777777777781,1.9916666666666694,1.9750000000000028,2.1000000000000023,2.3194444444444478,2.161111111111114,2.1888888888888918,2.1972222222222246,2.2361111111111134,2.138888888888891,2.1833333333333353,2.1388888888888915,2.0833333333333357,2.075000000000003,1.8722222222222258,1.8694444444444476,1.8111111111111142,1.8361111111111141,1.7888888888888923,1.7777777777777812,1.8972222222222261,1.8527777777777816,1.8472222222222259,1.8138888888888927,1.894444444444448,1.7833333333333368,1.738888888888892,1.5555555555555582,1.5555555555555582,1.5194444444444475,1.2305555555555585,1.3722222222222256,1.29166666666667,1.3805555555555593,1.2388888888888923,1.3583333333333365,1.4666666666666701,1.4805555555555592,1.4555555555555593,1.4361111111111144,1.5333333333333368,1.6388888888888922,1.6333333333333369,1.4388888888888922,1.6611111111111143,1.6500000000000035,1.694444444444448,1.6500000000000032,1.6777777777777811,1.7055555555555584,1.658333333333336,1.6416666666666697,1.6638888888888923,1.7583333333333375,1.7361111111111147,1.6944444444444475,1.8083333333333367,1.8388888888888926,1.8138888888888924,1.8722222222222258,2.0333333333333363,1.9527777777777802,1.9138888888888916,1.8861111111111133,1.8472222222222248,1.7277777777777799,1.6305555555555578,1.550000000000002,1.7722222222222241,1.7888888888888912,1.7333333333333354,1.6916666666666689,1.8055555555555576,2.0805555555555575,1.772222222222223,1.7972222222222232,1.8083333333333342,1.7916666666666676,1.7083333333333341,1.7555555555555566,1.6861111111111124,1.7027777777777784,1.7166666666666675,1.747222222222223,1.6500000000000008,1.6666666666666679,1.5500000000000016,1.661111111111113,1.6583333333333348,1.5666666666666682,1.6055555555555572,1.5916666666666686,1.7666666666666686,1.6527777777777795,1.6305555555555573,1.6000000000000023,1.6277777777777802,1.6638888888888916,1.4527777777777802,1.530555555555558,1.405555555555558,1.3388888888888915,1.1694444444444474,1.1805555555555582,1.4777777777777816,1.4750000000000034,1.4277777777777816,1.5833333333333373,1.6277777777777822,1.5194444444444486,1.5111111111111148,1.4777777777777816,1.3750000000000036,1.2916666666666696,1.3833333333333364,1.3916666666666693,1.5777777777777802,1.558333333333336,1.5555555555555582,1.5694444444444473,1.6111111111111134,1.5638888888888913,1.5888888888888908,1.7638888888888913,1.7500000000000024,1.8361111111111137,1.8166666666666687,1.6583333333333348,1.7027777777777795,1.636111111111113,1.6250000000000016,1.636111111111113,1.6777777777777798,1.6111111111111134,1.6277777777777795,1.5555555555555576,1.4277777777777796,1.3083333333333356,1.2388888888888907,1.2111111111111126,1.1638888888888907,1.2888888888888907,1.2111111111111126,1.3055555555555578,1.2583333333333355,1.3111111111111136,1.1861111111111136,1.2277777777777799,1.3833333333333353,1.5083333333333349,1.472222222222224,1.5611111111111136,1.3944444444444464,1.1805555555555574,1.297222222222224,1.297222222222224,1.3361111111111135,1.5694444444444473,1.547222222222225,1.5861111111111135,1.797222222222225,1.7083333333333357,1.8805555555555582,1.8555555555555576,1.82777777777778,1.8194444444444466,1.9638888888888915,1.997222222222225,2.047222222222225,2.102777777777781,2.09166666666667,1.8750000000000027,1.9972222222222256,1.9944444444444474,1.897222222222225,1.7361111111111138,1.844444444444447,1.8388888888888912,1.65277777777778,1.5388888888888907,1.5194444444444462,1.5222222222222237,1.6305555555555575,1.7083333333333357,1.5944444444444468,1.5722222222222246,1.5333333333333354,1.4861111111111125,1.4361111111111124,1.4027777777777792,1.3861111111111124,1.3555555555555572,1.261111111111113,1.2916666666666687,1.211111111111113,1.2472222222222238,1.2888888888888907,1.230555555555557,1.3111111111111122,1.2000000000000006,1.2277777777777787,1.2222222222222234,1.1916666666666675,1.1194444444444451,1.2583333333333342,1.3750000000000009,1.3472222222222234,1.3500000000000016,1.5805555555555573,1.6166666666666687,1.7000000000000024,1.6250000000000024,1.7222222222222248,1.755555555555558,1.8500000000000028,1.9000000000000021,1.9722222222222245,1.8805555555555582,1.9694444444444472,2.097222222222225,2.0222222222222253,2.188888888888892,2.2861111111111145,2.36666666666667,2.4083333333333363,2.3750000000000036,2.3861111111111146,2.4250000000000034,2.3555555555555596,2.4333333333333376,2.4222222222222265,2.3722222222222267,2.4777777777777823,2.522222222222227,2.583333333333339,2.66944444444445,2.5666666666666718,2.463888888888893,2.28055555555556,2.28055555555556,2.2805555555555603,2.3527777777777827,2.372222222222227,2.3944444444444493,2.3666666666666716,2.400000000000005,2.3250000000000046,2.363888888888894,2.325000000000005,2.241666666666671,2.361111111111116,2.2777777777777817,2.288888888888893,2.200000000000004,2.1916666666666713,2.4416666666666704,2.375000000000004,2.327777777777781,2.4111111111111145,2.4194444444444483,2.3277777777777815,2.519444444444449,2.4722222222222263,2.5194444444444484,2.397222222222227,2.28055555555556,2.2055555555555597,2.1583333333333368,2.233333333333337,2.2166666666666703,2.0888888888888917,2.0666666666666695,1.8861111111111144,1.938888888888892,1.9027777777777808,1.8000000000000027,1.8444444444444474,1.9222222222222254,1.8638888888888916,1.8111111111111142,1.7555555555555584,1.9111111111111136,1.813888888888891,1.8388888888888915,1.8500000000000023,1.4805555555555578,1.558333333333336,1.5805555555555586,1.5972222222222245,1.5888888888888912,1.6611111111111136,1.633333333333336,1.6166666666666691,1.5722222222222253,1.694444444444447,1.7333333333333354,1.7916666666666687,1.8611111111111132,1.8444444444444468,1.9277777777777805,1.8944444444444473,1.919444444444447,2.0444444444444474,1.8777777777777802,1.9666666666666694,1.9944444444444478,1.8416666666666701,1.7611111111111137,2.000000000000003,2.011111111111114,1.8000000000000025,1.6250000000000024,1.6611111111111139,1.6416666666666693,1.5694444444444462,1.7527777777777802,1.6361111111111135,1.7555555555555582,1.7222222222222252,1.7861111111111139,1.7638888888888915,1.6416666666666688,1.6277777777777798,1.4805555555555578,1.3944444444444473,1.400000000000003,1.3583333333333365,1.3333333333333364,1.3194444444444473,1.1888888888888915,1.3555555555555583,1.3194444444444466,1.2861111111111134,1.3500000000000025,1.2972222222222247,1.3944444444444468,1.47777777777778,1.4444444444444466,1.3777777777777798,1.3694444444444471,1.647222222222225,1.7000000000000033,1.736111111111114,1.6305555555555582,1.7277777777777812,1.750000000000003,1.8444444444444477,1.888888888888892,1.7888888888888914,1.875000000000003,1.8722222222222247,1.9138888888888912,1.855555555555558,1.9694444444444468,2.0611111111111127,2.0944444444444463,2.0944444444444468,2.125000000000002,2.063888888888891,2.125000000000002,2.0555555555555576,1.988888888888892,2.0833333333333357,2.2027777777777806,2.2500000000000027,2.1777777777777807,2.1361111111111137,2.1944444444444473,2.09166666666667,2.0611111111111136,2.013888888888892,1.9805555555555594,1.8444444444444479,1.8555555555555592,1.9638888888888921,1.8333333333333368,1.7305555555555587,1.5055555555555586,1.555555555555559,1.4361111111111144,1.4444444444444475,1.5111111111111148,1.4972222222222258,1.6833333333333371,1.6638888888888925,1.6750000000000034,1.758333333333337,1.8305555555555593,1.8166666666666702,1.7305555555555585,1.894444444444447,1.9361111111111138,1.908333333333336,1.933333333333336,1.8944444444444466,1.8111111111111136,1.9750000000000028,1.9861111111111134,1.9694444444444477,2.047222222222225,1.9638888888888917,1.9305555555555576,2.0611111111111136,2.1722222222222247,1.988888888888891,2.0750000000000024,2.0083333333333355,2.1833333333333362,2.269444444444447,2.2250000000000028,2.222222222222226,2.1472222222222253,2.2527777777777813,2.0416666666666705,1.947222222222226,1.961111111111115,1.913888888888892,1.761111111111114,1.7777777777777806,1.950000000000003,1.8555555555555587,1.8833333333333364,1.8083333333333362,1.647222222222225,1.5666666666666693,1.6277777777777807,1.4805555555555583,1.430555555555558,1.3472222222222243,1.3611111111111132,1.4888888888888907,1.5972222222222245,1.6333333333333355,1.6277777777777798,1.8194444444444469,1.8666666666666691,1.869444444444447,1.7722222222222246,1.6944444444444464,1.7472222222222242,1.8527777777777799,1.7972222222222243,1.6833333333333358,1.5416666666666687,1.6000000000000016,1.5972222222222237,1.6638888888888907,1.6944444444444464,1.6944444444444462,1.6944444444444462,1.519444444444446,1.547222222222224,1.613888888888891,1.6722222222222243,1.7666666666666697,1.8777777777777802,1.9416666666666687,1.969444444444447,1.9750000000000025,1.8972222222222246,1.7805555555555583,1.7027777777777802,1.6527777777777808,1.6611111111111145,1.611111111111114,1.597222222222225,1.6444444444444473,1.6555555555555581,1.6777777777777803,1.7722222222222246,1.8138888888888907,1.9250000000000023,2.0472222222222243,2.363888888888892,2.2833333333333363,2.288888888888892,2.1972222222222246,2.2777777777777803,2.411111111111114,2.305555555555558,2.452777777777781,2.469444444444447,2.375000000000003,2.3972222222222253,2.2305555555555583,2.211111111111114,2.222222222222225,2.1194444444444467,2.1805555555555576,2.1722222222222247,2.263888888888891,2.2305555555555574,2.2027777777777793,2.1777777777777785,2.147222222222223,2.0888888888888903,1.9861111111111123,1.9250000000000007,1.9833333333333347,1.68888888888889,1.6222222222222231,1.6277777777777789,1.5611111111111122,1.5166666666666682,1.552777777777779,1.3444444444444452,1.4222222222222232,1.4833333333333343,1.3611111111111118,1.2916666666666676,1.3111111111111118,1.225000000000001,1.1861111111111118,1.1777777777777785,1.2416666666666663,1.2222222222222228,1.2583333333333342,1.455555555555557,1.538888888888891,1.630555555555558,1.555555555555558,1.6583333333333363,1.6416666666666695,1.7138888888888917,1.6500000000000024,1.7222222222222245,1.813888888888892,1.81666666666667,1.84166666666667,2.013888888888892,1.9694444444444479,1.9111111111111148,2.050000000000004,1.991666666666671,2.0027777777777818,2.069444444444448,1.9416666666666709,1.883333333333337,1.9277777777777816,2.025000000000004,1.955555555555559,2.1333333333333373,2.200000000000004,2.308333333333337,2.4194444444444487,2.394444444444448,2.3833333333333364,2.2722222222222253,2.2194444444444477,2.19166666666667,2.169444444444447,2.1833333333333353,2.175000000000002,2.05277777777778,2.0944444444444468,2.1111111111111134,2.091666666666669,2.183333333333336,2.072222222222224,2.108333333333335,2.2805555555555577,2.383333333333335,2.244444444444446,2.2527777777777787,2.1611111111111123,2.1777777777777794,2.32777777777778,2.272222222222225,2.1888888888888927,2.2444444444444476,2.3194444444444478,2.202777777777781,2.061111111111114,2.0472222222222247,2.0305555555555586,1.9638888888888917,2.038888888888892,1.9111111111111132,1.8916666666666684,1.8555555555555574,1.8944444444444466,1.8222222222222246,1.8250000000000028,1.9388888888888913,1.8861111111111135,1.800000000000003,2.0555555555555585,2.055555555555558,2.1166666666666694,2.055555555555558,1.7833333333333357,1.538888888888891,1.5805555555555582,1.5527777777777807,1.6333333333333362,1.6250000000000022,1.6027777777777796,1.680555555555558,1.8027777777777803,1.730555555555558,1.672222222222225,1.6388888888888913,1.777777777777781,1.6666666666666703,1.6083333333333363,1.4777777777777803,1.2583333333333355,1.4055555555555586,1.4888888888888923,1.5194444444444482,1.5916666666666703,1.5166666666666693,1.6277777777777798,1.6000000000000028,1.7194444444444468,1.544444444444447,1.3138888888888913,1.1500000000000021,1.2166666666666694,1.3055555555555582,1.500000000000003,1.702777777777781,1.7722222222222248,1.7555555555555586,1.74166666666667,1.8861111111111148,1.9055555555555592,1.8972222222222257,1.6222222222222251,1.7083333333333361,1.7111111111111135,1.6722222222222247,1.5555555555555576,1.5277777777777795,1.6694444444444467,1.8472222222222248,2.144444444444448,2.2277777777777814,2.1333333333333364,2.116666666666669,2.091666666666669,2.09166666666667,1.9416666666666698,1.952777777777781,1.8722222222222251,2.1083333333333365,2.1000000000000036,2.305555555555559,2.3111111111111144,2.347222222222226,2.41666666666667,2.411111111111115,2.241666666666671,2.238888888888893,2.283333333333337,2.2361111111111156,2.1444444444444484,2.1750000000000034,2.352777777777781,2.2500000000000027,2.197222222222225,2.277777777777781,2.5027777777777813,2.558333333333337,2.5388888888888923,2.502777777777781,2.277777777777781,2.3166666666666695,2.294444444444447,2.3305555555555584,2.233333333333336,2.330555555555559,2.327777777777781,2.3722222222222253,2.2527777777777813,2.222222222222226,2.3416666666666703,2.3250000000000037,2.2805555555555594,2.26666666666667,2.1194444444444476,2.0777777777777806,2.1833333333333362,2.1611111111111136,2.1833333333333362,2.1527777777777803,2.2500000000000027,2.1694444444444465,2.327777777777781,2.380555555555558,2.2944444444444465,2.247222222222224,1.9861111111111125,1.9972222222222247,2.0861111111111135,2.1888888888888918,2.272222222222225,2.111111111111114,2.158333333333337,2.2111111111111144,2.2055555555555593,2.208333333333337,2.3777777777777818,2.300000000000003,2.4472222222222255,2.375000000000003,2.402777777777781,2.3861111111111137,2.3694444444444476,2.3500000000000036,2.36666666666667,2.372222222222226,2.327777777777781,2.386111111111115,2.336111111111114,2.416666666666669,2.469444444444447,2.5111111111111133,2.425000000000002,2.2777777777777795,2.37777777777778,2.444444444444447,2.522222222222225,2.6555555555555577,2.6250000000000036,2.658333333333337,2.569444444444448,2.483333333333337,2.4722222222222254,2.369444444444448,2.500000000000003,2.5916666666666694,2.450000000000003,2.4277777777777807,2.3333333333333366,2.2916666666666696,2.258333333333337,2.2583333333333373,2.2777777777777812,2.3750000000000036,2.422222222222226,2.3666666666666707,2.416666666666671,2.2916666666666705,2.369444444444449,2.269444444444449,2.038888888888893,2.0666666666666713,2.0277777777777817,2.1638888888888936,2.2055555555555606,2.069444444444449,2.1055555555555596,1.9444444444444489,1.9361111111111151,1.7416666666666707,1.7611111111111148,1.852777777777782,1.9166666666666714,1.9055555555555603,1.8388888888888932,1.6972222222222262,1.6222222222222258,1.7083333333333373,1.8666666666666707,2.0083333333333373,1.8250000000000033,1.780555555555559,1.5805555555555593,1.483333333333337,1.358333333333337,1.3166666666666702,1.3277777777777813,1.4777777777777812,1.383333333333337,1.352777777777781,1.5416666666666696,1.5055555555555589,1.4861111111111143,1.450000000000003,1.5027777777777804,1.6361111111111137,1.8000000000000025,1.8888888888888915,1.7833333333333363,1.9027777777777812,1.8638888888888925,1.9472222222222257,1.9055555555555592,1.8416666666666697,1.7500000000000033,1.844444444444448,1.9555555555555597,2.0166666666666706,1.911111111111115,1.9416666666666706,2.005555555555559,1.9333333333333373,2.0944444444444477,1.9472222222222257,2.008333333333337,2.255555555555559,2.2750000000000035,2.052777777777781,2.1222222222222253,2.1666666666666705,2.0472222222222256,2.0361111111111145,2.09166666666667,2.1361111111111137,2.0388888888888914,1.9222222222222245,1.6833333333333358,1.55277777777778,1.6611111111111132,1.7000000000000015,1.7277777777777792,1.6305555555555566,1.61388888888889,1.719444444444446,1.8111111111111133,1.7250000000000023,1.7722222222222244,1.5861111111111128,1.5472222222222238,1.4416666666666682,1.4722222222222237,1.5472222222222238,1.5055555555555578,1.5250000000000024,1.4111111111111132,1.2333333333333352,1.297222222222224,1.4722222222222245,1.3388888888888912,1.4000000000000024,1.4305555555555576,1.4944444444444467,1.441666666666669,1.4583333333333364,1.4444444444444482,1.6194444444444487,1.8277777777777826,1.808333333333338,1.7361111111111152,1.7222222222222265,1.8111111111111156,1.8027777777777825,1.65555555555556,1.6666666666666712,1.563888888888893,1.6805555555555602,1.6555555555555597,1.7222222222222272,1.7777777777777826,1.9555555555555606,1.9222222222222267,1.9861111111111158,2.047222222222227,2.186111111111116,2.3638888888888934,2.3805555555555604,2.3805555555555604,2.3722222222222267,2.3916666666666706,2.4361111111111153,2.4833333333333383,2.341666666666671,2.2166666666666703,2.108333333333337,2.2055555555555593,2.1611111111111145,2.005555555555558,2.108333333333337,1.9888888888888916,2.0166666666666693,2.038888888888892,2.0472222222222247,2.1055555555555583,2.061111111111114,2.1333333333333364,2.144444444444447,2.130555555555558,2.166666666666669,2.1194444444444476,1.9583333333333364,1.963888888888892,1.8722222222222251],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"width\":1200,\"height\":600,\"title\":{\"text\":\"Difference : (HPO dataset ACC) - (NEW dataset ACC)\"},\"xaxis\":{\"title\":{\"text\":\"trial No.\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy Difference (%)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('033b8b76-dca7-4c7f-bd99-9d7a396b39e6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Optuna 를 이용한 성능 테스트**"
      ],
      "metadata": {
        "id": "S4Dz-POi4JQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective Function 정의\n",
        "\n",
        "models = []\n",
        "\n",
        "def objective_optuna(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 1.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 100),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 50, 4000),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
        "        'lambda_l1': trial.suggest_uniform('lambda_l1', 0.0, 1.0),\n",
        "        'lambda_l2': trial.suggest_uniform('lambda_l2', 0.0, 5.0)\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective='multiclass',\n",
        "        metric='multi_logloss',\n",
        "        boosting_type='gbdt',\n",
        "        num_iterations=10,  # 일반적으로 너무 작은 값이나, 여기서는 빠른 실험을 위해 사용\n",
        "        verbosity=-1,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    # LigthGBM 용 valid set 인 X_valid_lgbm, y_valid_lgbm 로 데이터를 분리\n",
        "    X_train__, X_valid_lgbm, y_train__, y_valid_lgbm =\\\n",
        "        train_test_split(X_train_, y_train_,\n",
        "                         test_size=0.25,\n",
        "                         random_state=2025)\n",
        "\n",
        "    # X_valid_lgbm, y_valid_lgbm 를 이용하여 LightGBM 모델을 valid\n",
        "    model.fit(X_train__, y_train__,\n",
        "              eval_set=[(X_valid_lgbm, y_valid_lgbm)])\n",
        "\n",
        "    # HPO 용 test set인 X_test_hpo, y_test_hpo 를 이용하여 하이퍼파라미터 조합 성능 테스트\n",
        "    preds_hpo = model.predict(X_test_hpo)\n",
        "\n",
        "    accuracy_hpo = accuracy_score(preds_hpo, y_test_hpo)\n",
        "    acc = f'{(100 * accuracy_hpo):6.2f}'\n",
        "\n",
        "    print(f'[HPO] metrics with {params} : acc={acc}%')\n",
        "\n",
        "    # 학습한 모델을 최종 테스트를 위해 배열에 저장\n",
        "    models.append(model)\n",
        "\n",
        "    # Accuracy 최대화\n",
        "    return accuracy_hpo"
      ],
      "metadata": {
        "id": "NAfgqjY8LH3_"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna warning 미 출력 설정\n",
        "\n",
        "import logging\n",
        "optuna.logging.set_verbosity(logging.WARNING)"
      ],
      "metadata": {
        "id": "uFLRW91KMUZH"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 최적화 실시\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective_optuna, n_trials=TRIAL_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b77H6adTLvO7",
        "outputId": "28602d97-a745-4172-d4f5-02caf706336e"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HPO] metrics with {'learning_rate': 0.011961135263093722, 'max_depth': 20, 'num_leaves': 3525, 'min_data_in_leaf': 22, 'lambda_l1': 0.3979650269067234, 'lambda_l2': 3.7851226111179495} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.17910195222766065, 'max_depth': 87, 'num_leaves': 944, 'min_data_in_leaf': 96, 'lambda_l1': 0.6791906422104688, 'lambda_l2': 4.565109924455812} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.38550086676403617, 'max_depth': 4, 'num_leaves': 2137, 'min_data_in_leaf': 55, 'lambda_l1': 0.18040491977378093, 'lambda_l2': 0.7209764830666199} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.012589723889484697, 'max_depth': 76, 'num_leaves': 754, 'min_data_in_leaf': 8, 'lambda_l1': 0.5879934026555943, 'lambda_l2': 1.9441415307792487} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.04316586881262808, 'max_depth': 75, 'num_leaves': 304, 'min_data_in_leaf': 66, 'lambda_l1': 0.5392474653456676, 'lambda_l2': 2.6488817515986} : acc= 60.00%\n",
            "[HPO] metrics with {'learning_rate': 0.0024020274976825798, 'max_depth': 93, 'num_leaves': 3651, 'min_data_in_leaf': 69, 'lambda_l1': 0.7057807107987535, 'lambda_l2': 4.210154431067052} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24885236777493033, 'max_depth': 2, 'num_leaves': 221, 'min_data_in_leaf': 70, 'lambda_l1': 0.48123502340527435, 'lambda_l2': 4.947084390518481} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.0013041227156891236, 'max_depth': 49, 'num_leaves': 3140, 'min_data_in_leaf': 30, 'lambda_l1': 0.8297649568757115, 'lambda_l2': 2.177910373838317} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.0023820559935696047, 'max_depth': 15, 'num_leaves': 1203, 'min_data_in_leaf': 77, 'lambda_l1': 0.30705129949796317, 'lambda_l2': 0.6891222999601554} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.755495843101806, 'max_depth': 10, 'num_leaves': 2787, 'min_data_in_leaf': 36, 'lambda_l1': 0.42281738941626457, 'lambda_l2': 3.0816306361357455} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8134447492692588, 'max_depth': 37, 'num_leaves': 2010, 'min_data_in_leaf': 51, 'lambda_l1': 0.007594854344858015, 'lambda_l2': 0.3104670988800491} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.18610236777378708, 'max_depth': 4, 'num_leaves': 1913, 'min_data_in_leaf': 52, 'lambda_l1': 0.150957801017299, 'lambda_l2': 1.2345443645082765} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.17154106691649856, 'max_depth': 29, 'num_leaves': 2565, 'min_data_in_leaf': 94, 'lambda_l1': 0.19342193728507878, 'lambda_l2': 1.3263324915390164} : acc= 63.33%\n",
            "[HPO] metrics with {'learning_rate': 0.06435523096959626, 'max_depth': 2, 'num_leaves': 1454, 'min_data_in_leaf': 78, 'lambda_l1': 0.9402038542364349, 'lambda_l2': 4.930345383326207} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.36525778050834196, 'max_depth': 43, 'num_leaves': 402, 'min_data_in_leaf': 57, 'lambda_l1': 0.02360853958923481, 'lambda_l2': 3.3814638409778937} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.37317850453438844, 'max_depth': 56, 'num_leaves': 2507, 'min_data_in_leaf': 42, 'lambda_l1': 0.006341471381207504, 'lambda_l2': 3.3293798623691466} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.09719998694872214, 'max_depth': 60, 'num_leaves': 1663, 'min_data_in_leaf': 38, 'lambda_l1': 0.04065388318001075, 'lambda_l2': 3.3787351379696324} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.021712073830573646, 'max_depth': 52, 'num_leaves': 2555, 'min_data_in_leaf': 18, 'lambda_l1': 0.2850839437315369, 'lambda_l2': 3.6184719249327406} : acc= 55.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4582064634725155, 'max_depth': 40, 'num_leaves': 637, 'min_data_in_leaf': 40, 'lambda_l1': 0.07141878807063712, 'lambda_l2': 2.785598564012555} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.9801595947973573, 'max_depth': 61, 'num_leaves': 3900, 'min_data_in_leaf': 40, 'lambda_l1': 0.1228591733902128, 'lambda_l2': 2.743414592412255} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.08305788408531653, 'max_depth': 31, 'num_leaves': 3200, 'min_data_in_leaf': 1, 'lambda_l1': 0.30193840967921987, 'lambda_l2': 1.8832106746689878} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.08308205390995535, 'max_depth': 27, 'num_leaves': 3039, 'min_data_in_leaf': 3, 'lambda_l1': 0.27239093140562415, 'lambda_l2': 1.846024616127846} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.36025747217300663, 'max_depth': 38, 'num_leaves': 2385, 'min_data_in_leaf': 22, 'lambda_l1': 0.1037216565577796, 'lambda_l2': 2.225297510459259} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.11886245369985782, 'max_depth': 31, 'num_leaves': 2314, 'min_data_in_leaf': 17, 'lambda_l1': 0.21443585522397993, 'lambda_l2': 2.25356464910389} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.035479989294933824, 'max_depth': 58, 'num_leaves': 3118, 'min_data_in_leaf': 10, 'lambda_l1': 0.38135315149465787, 'lambda_l2': 1.6497357891148736} : acc= 63.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3320414275156154, 'max_depth': 71, 'num_leaves': 3345, 'min_data_in_leaf': 29, 'lambda_l1': 0.10625859500550144, 'lambda_l2': 2.393925143155572} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5572807694274042, 'max_depth': 46, 'num_leaves': 2512, 'min_data_in_leaf': 3, 'lambda_l1': 0.31388112445410526, 'lambda_l2': 1.3952773094945183} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.0483328863032942, 'max_depth': 36, 'num_leaves': 2860, 'min_data_in_leaf': 24, 'lambda_l1': 0.24614344765527205, 'lambda_l2': 3.0040916871281595} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.023041770409599486, 'max_depth': 23, 'num_leaves': 1672, 'min_data_in_leaf': 15, 'lambda_l1': 0.10607708269733215, 'lambda_l2': 2.0762376131899147} : acc= 57.08%\n",
            "[HPO] metrics with {'learning_rate': 0.007289220762036883, 'max_depth': 68, 'num_leaves': 3508, 'min_data_in_leaf': 44, 'lambda_l1': 0.4039021543767086, 'lambda_l2': 3.980803836898872} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.17506296237716062, 'max_depth': 21, 'num_leaves': 2314, 'min_data_in_leaf': 26, 'lambda_l1': 0.1521787459796144, 'lambda_l2': 0.876686384999998} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.24419065129967882, 'max_depth': 18, 'num_leaves': 2286, 'min_data_in_leaf': 25, 'lambda_l1': 0.0009459265661141969, 'lambda_l2': 0.9655419528002868} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.10802516845057698, 'max_depth': 23, 'num_leaves': 2797, 'min_data_in_leaf': 31, 'lambda_l1': 0.16144705191861136, 'lambda_l2': 0.05253889314124838} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.13901500340378212, 'max_depth': 34, 'num_leaves': 2318, 'min_data_in_leaf': 12, 'lambda_l1': 0.07881925631589502, 'lambda_l2': 0.7875113395830626} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23907419843074254, 'max_depth': 53, 'num_leaves': 1910, 'min_data_in_leaf': 45, 'lambda_l1': 0.35381503978186196, 'lambda_l2': 1.6289133916106433} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5988797004032652, 'max_depth': 15, 'num_leaves': 3363, 'min_data_in_leaf': 21, 'lambda_l1': 0.22570692944952658, 'lambda_l2': 2.4211487100755638} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.06076636238596763, 'max_depth': 43, 'num_leaves': 2639, 'min_data_in_leaf': 8, 'lambda_l1': 0.16998432575590358, 'lambda_l2': 1.0717155194786392} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.27560644854173655, 'max_depth': 26, 'num_leaves': 2934, 'min_data_in_leaf': 61, 'lambda_l1': 0.07239444208388995, 'lambda_l2': 0.40306921681154595} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.17051724448176464, 'max_depth': 9, 'num_leaves': 3808, 'min_data_in_leaf': 34, 'lambda_l1': 0.6481458271965129, 'lambda_l2': 4.4282178256287015} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4539213327098615, 'max_depth': 100, 'num_leaves': 2113, 'min_data_in_leaf': 1, 'lambda_l1': 0.47913690976099343, 'lambda_l2': 1.7083907843224067} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.008724532762637802, 'max_depth': 80, 'num_leaves': 1158, 'min_data_in_leaf': 45, 'lambda_l1': 0.15258926060112785, 'lambda_l2': 3.002948203860074} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5060715325230194, 'max_depth': 40, 'num_leaves': 698, 'min_data_in_leaf': 25, 'lambda_l1': 0.0572674462838704, 'lambda_l2': 2.5968060832228272} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3453821989376113, 'max_depth': 48, 'num_leaves': 1657, 'min_data_in_leaf': 41, 'lambda_l1': 0.09718555015544036, 'lambda_l2': 2.802782001727528} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.298472504933041, 'max_depth': 49, 'num_leaves': 1675, 'min_data_in_leaf': 32, 'lambda_l1': 0.11032336078449698, 'lambda_l2': 3.2698314043184307} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2134937965035139, 'max_depth': 32, 'num_leaves': 1389, 'min_data_in_leaf': 43, 'lambda_l1': 0.2145803674377501, 'lambda_l2': 2.029112792693871} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.14550259909082014, 'max_depth': 55, 'num_leaves': 2143, 'min_data_in_leaf': 48, 'lambda_l1': 0.13686457354331777, 'lambda_l2': 3.677261495508279} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.717413823233845, 'max_depth': 46, 'num_leaves': 1847, 'min_data_in_leaf': 27, 'lambda_l1': 0.322496004333879, 'lambda_l2': 3.9415045939849893} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.07624589906763743, 'max_depth': 64, 'num_leaves': 2412, 'min_data_in_leaf': 56, 'lambda_l1': 0.0016112983173182799, 'lambda_l2': 2.885042386419747} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3809875899666369, 'max_depth': 20, 'num_leaves': 1441, 'min_data_in_leaf': 36, 'lambda_l1': 0.19172725995563583, 'lambda_l2': 2.2461125103685626} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.19010173988323958, 'max_depth': 38, 'num_leaves': 2716, 'min_data_in_leaf': 13, 'lambda_l1': 0.04160214963696171, 'lambda_l2': 2.545803418800899} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.12875658542449073, 'max_depth': 12, 'num_leaves': 3245, 'min_data_in_leaf': 21, 'lambda_l1': 0.7896990110302884, 'lambda_l2': 3.229205336359344} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4287197108391795, 'max_depth': 41, 'num_leaves': 373, 'min_data_in_leaf': 41, 'lambda_l1': 0.07769550081322905, 'lambda_l2': 2.732504543778022} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.973060485200604, 'max_depth': 44, 'num_leaves': 860, 'min_data_in_leaf': 49, 'lambda_l1': 0.0834473566780842, 'lambda_l2': 3.4384043970060256} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.37937318336662257, 'max_depth': 48, 'num_leaves': 87, 'min_data_in_leaf': 61, 'lambda_l1': 0.2634929952171686, 'lambda_l2': 1.9049515271047281} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6801274181493325, 'max_depth': 40, 'num_leaves': 1084, 'min_data_in_leaf': 39, 'lambda_l1': 0.03780186922053114, 'lambda_l2': 2.758809704187899} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.29799216642471943, 'max_depth': 56, 'num_leaves': 533, 'min_data_in_leaf': 100, 'lambda_l1': 0.45082389595712613, 'lambda_l2': 3.128047344941021} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.0966535154557443, 'max_depth': 29, 'num_leaves': 2136, 'min_data_in_leaf': 6, 'lambda_l1': 0.11993053917228934, 'lambda_l2': 2.394284351533736} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4318925175907101, 'max_depth': 35, 'num_leaves': 3005, 'min_data_in_leaf': 52, 'lambda_l1': 0.5695374560187629, 'lambda_l2': 1.3851291203456246} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.16166915558297826, 'max_depth': 24, 'num_leaves': 2507, 'min_data_in_leaf': 35, 'lambda_l1': 0.17618838425605002, 'lambda_l2': 2.897437171201042} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.21928436282264432, 'max_depth': 51, 'num_leaves': 3520, 'min_data_in_leaf': 19, 'lambda_l1': 0.05568606660544202, 'lambda_l2': 3.5473076652499413} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5643880698232321, 'max_depth': 63, 'num_leaves': 3703, 'min_data_in_leaf': 29, 'lambda_l1': 0.24163712821792738, 'lambda_l2': 2.201036941047813} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.34445250298036545, 'max_depth': 40, 'num_leaves': 360, 'min_data_in_leaf': 48, 'lambda_l1': 0.09718365367519206, 'lambda_l2': 2.688831464333906} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4621223387628333, 'max_depth': 43, 'num_leaves': 610, 'min_data_in_leaf': 42, 'lambda_l1': 0.027021732236743437, 'lambda_l2': 2.76068302059676} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.7930413144605832, 'max_depth': 32, 'num_leaves': 539, 'min_data_in_leaf': 41, 'lambda_l1': 0.02226579721013683, 'lambda_l2': 3.0941675118611047} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.8255945062746554, 'max_depth': 44, 'num_leaves': 516, 'min_data_in_leaf': 40, 'lambda_l1': 0.0272295022334704, 'lambda_l2': 3.204847105361104} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6403782904652108, 'max_depth': 34, 'num_leaves': 257, 'min_data_in_leaf': 53, 'lambda_l1': 0.02170944819985432, 'lambda_l2': 2.860338697967614} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4766677710550962, 'max_depth': 53, 'num_leaves': 858, 'min_data_in_leaf': 42, 'lambda_l1': 0.14577228073631993, 'lambda_l2': 3.86360516646707} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.8706951740957121, 'max_depth': 29, 'num_leaves': 94, 'min_data_in_leaf': 33, 'lambda_l1': 0.06759901019180065, 'lambda_l2': 3.4873217813351016} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.30333405747122566, 'max_depth': 57, 'num_leaves': 487, 'min_data_in_leaf': 36, 'lambda_l1': 0.0023017504683480452, 'lambda_l2': 4.139095473105916} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5430956850010726, 'max_depth': 47, 'num_leaves': 1046, 'min_data_in_leaf': 88, 'lambda_l1': 0.12601141318965925, 'lambda_l2': 3.011679497256913} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.0013352254989218355, 'max_depth': 37, 'num_leaves': 626, 'min_data_in_leaf': 60, 'lambda_l1': 0.09536104568089315, 'lambda_l2': 3.7249420107300097} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4081718500706851, 'max_depth': 31, 'num_leaves': 1304, 'min_data_in_leaf': 47, 'lambda_l1': 0.04651984183805741, 'lambda_l2': 2.5738224641953305} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2391682837642632, 'max_depth': 21, 'num_leaves': 2296, 'min_data_in_leaf': 37, 'lambda_l1': 0.2012203097997689, 'lambda_l2': 2.3579321582184027} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6977998896142678, 'max_depth': 26, 'num_leaves': 1994, 'min_data_in_leaf': 42, 'lambda_l1': 0.08488221874187436, 'lambda_l2': 2.0729621611125157} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.19915718676446748, 'max_depth': 42, 'num_leaves': 2659, 'min_data_in_leaf': 30, 'lambda_l1': 0.1344376378553838, 'lambda_l2': 3.32755228097914} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.19568490864161156, 'max_depth': 42, 'num_leaves': 2435, 'min_data_in_leaf': 32, 'lambda_l1': 0.13614388806218414, 'lambda_l2': 3.3225873697873887} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.34694319141074076, 'max_depth': 50, 'num_leaves': 2593, 'min_data_in_leaf': 27, 'lambda_l1': 0.03802902937270926, 'lambda_l2': 3.099141816833123} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5629361592726069, 'max_depth': 39, 'num_leaves': 1803, 'min_data_in_leaf': 24, 'lambda_l1': 0.9868413916866672, 'lambda_l2': 2.9678536309700685} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.004696408682989537, 'max_depth': 33, 'num_leaves': 2712, 'min_data_in_leaf': 28, 'lambda_l1': 0.1715560896966165, 'lambda_l2': 2.750976226393647} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27592734176380374, 'max_depth': 59, 'num_leaves': 198, 'min_data_in_leaf': 40, 'lambda_l1': 0.0634060271803355, 'lambda_l2': 0.5329607797476421} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4573587780300412, 'max_depth': 43, 'num_leaves': 828, 'min_data_in_leaf': 45, 'lambda_l1': 0.10358856724936405, 'lambda_l2': 3.355604152891162} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.32826577747707153, 'max_depth': 49, 'num_leaves': 2617, 'min_data_in_leaf': 26, 'lambda_l1': 0.024448644124229486, 'lambda_l2': 3.091792203233915} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.36638110810266095, 'max_depth': 54, 'num_leaves': 2389, 'min_data_in_leaf': 22, 'lambda_l1': 0.04785673855814032, 'lambda_l2': 3.5727342147105174} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2548170816848564, 'max_depth': 51, 'num_leaves': 2205, 'min_data_in_leaf': 16, 'lambda_l1': 0.019748461085749916, 'lambda_l2': 3.1231483242329348} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.7605876050101169, 'max_depth': 46, 'num_leaves': 2878, 'min_data_in_leaf': 31, 'lambda_l1': 0.0812410981238541, 'lambda_l2': 2.4641182476666064} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40453019309069765, 'max_depth': 42, 'num_leaves': 2734, 'min_data_in_leaf': 38, 'lambda_l1': 0.1247235536706914, 'lambda_l2': 0.09178366504106417} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.625134430407794, 'max_depth': 36, 'num_leaves': 2528, 'min_data_in_leaf': 34, 'lambda_l1': 0.15255025054488208, 'lambda_l2': 2.6575199043288853} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.160076971957498, 'max_depth': 68, 'num_leaves': 1564, 'min_data_in_leaf': 19, 'lambda_l1': 0.06208417991595646, 'lambda_l2': 2.802339398940282} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.48957899255596005, 'max_depth': 45, 'num_leaves': 411, 'min_data_in_leaf': 29, 'lambda_l1': 0.10927107128776738, 'lambda_l2': 4.735649652582175} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.9842133731656243, 'max_depth': 17, 'num_leaves': 371, 'min_data_in_leaf': 30, 'lambda_l1': 0.2291105391358889, 'lambda_l2': 4.647366716029692} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.026268612832094935, 'max_depth': 47, 'num_leaves': 710, 'min_data_in_leaf': 50, 'lambda_l1': 0.18092067929120617, 'lambda_l2': 4.633448913925081} : acc= 54.17%\n",
            "[HPO] metrics with {'learning_rate': 0.32840042932869606, 'max_depth': 50, 'num_leaves': 448, 'min_data_in_leaf': 27, 'lambda_l1': 0.10635539046920954, 'lambda_l2': 4.267808456691638} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.016098639892609554, 'max_depth': 44, 'num_leaves': 597, 'min_data_in_leaf': 22, 'lambda_l1': 0.001209667446342197, 'lambda_l2': 3.1473397325027093} : acc= 52.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4592920725240766, 'max_depth': 39, 'num_leaves': 2263, 'min_data_in_leaf': 42, 'lambda_l1': 0.03933822851815658, 'lambda_l2': 1.5265660921338338} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5179655047672748, 'max_depth': 37, 'num_leaves': 2019, 'min_data_in_leaf': 42, 'lambda_l1': 0.08655672955591151, 'lambda_l2': 1.1382900241258458} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.45986697145846217, 'max_depth': 41, 'num_leaves': 2177, 'min_data_in_leaf': 46, 'lambda_l1': 0.12782640353642014, 'lambda_l2': 1.6827791039175681} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.21801559049837674, 'max_depth': 45, 'num_leaves': 195, 'min_data_in_leaf': 54, 'lambda_l1': 0.06613357809151774, 'lambda_l2': 1.4618941977967408} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.8668589381311547, 'max_depth': 39, 'num_leaves': 302, 'min_data_in_leaf': 38, 'lambda_l1': 0.6571728090384039, 'lambda_l2': 1.2221359765135986} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.26157502920846126, 'max_depth': 35, 'num_leaves': 2429, 'min_data_in_leaf': 35, 'lambda_l1': 0.022120544564787972, 'lambda_l2': 1.5417025934747335} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4101491505382918, 'max_depth': 30, 'num_leaves': 2247, 'min_data_in_leaf': 44, 'lambda_l1': 0.15666927566759936, 'lambda_l2': 4.904918562304113} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6273857115176453, 'max_depth': 7, 'num_leaves': 2364, 'min_data_in_leaf': 41, 'lambda_l1': 0.8544412004018604, 'lambda_l2': 0.8181806601097033} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3473464251895157, 'max_depth': 53, 'num_leaves': 2632, 'min_data_in_leaf': 24, 'lambda_l1': 0.035825634585678605, 'lambda_l2': 0.9735173408638476} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5060067466990856, 'max_depth': 48, 'num_leaves': 2080, 'min_data_in_leaf': 30, 'lambda_l1': 0.034622797400820915, 'lambda_l2': 2.303535579429023} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.1869560018997274, 'max_depth': 50, 'num_leaves': 2602, 'min_data_in_leaf': 50, 'lambda_l1': 0.1095796425954366, 'lambda_l2': 2.932515635221137} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3133013496574023, 'max_depth': 41, 'num_leaves': 2793, 'min_data_in_leaf': 14, 'lambda_l1': 0.05008899540866257, 'lambda_l2': 3.272172384008423} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3759871660614702, 'max_depth': 56, 'num_leaves': 2457, 'min_data_in_leaf': 33, 'lambda_l1': 0.07761441699181396, 'lambda_l2': 3.468220761818574} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7654680704179514, 'max_depth': 45, 'num_leaves': 770, 'min_data_in_leaf': 37, 'lambda_l1': 0.014796295837417778, 'lambda_l2': 2.4793919177377246} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.27288291744043974, 'max_depth': 61, 'num_leaves': 2316, 'min_data_in_leaf': 28, 'lambda_l1': 0.09497544768199043, 'lambda_l2': 3.0300093600704137} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.1125831043001243, 'max_depth': 27, 'num_leaves': 1915, 'min_data_in_leaf': 47, 'lambda_l1': 0.20629117334185482, 'lambda_l2': 2.6223385488025386} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.571661084649616, 'max_depth': 38, 'num_leaves': 558, 'min_data_in_leaf': 39, 'lambda_l1': 0.5301490854985911, 'lambda_l2': 0.5735283034925047} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5833460016924094, 'max_depth': 38, 'num_leaves': 380, 'min_data_in_leaf': 40, 'lambda_l1': 0.5017987601627577, 'lambda_l2': 3.827828243765964} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6001406688153669, 'max_depth': 33, 'num_leaves': 567, 'min_data_in_leaf': 43, 'lambda_l1': 0.1387845970164553, 'lambda_l2': 4.003517159725565} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4914027965180306, 'max_depth': 38, 'num_leaves': 428, 'min_data_in_leaf': 38, 'lambda_l1': 0.539544087304555, 'lambda_l2': 0.6584135684727197} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6865508319835117, 'max_depth': 36, 'num_leaves': 674, 'min_data_in_leaf': 40, 'lambda_l1': 0.5204361932224806, 'lambda_l2': 0.3388218439838351} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.42180555411523263, 'max_depth': 42, 'num_leaves': 133, 'min_data_in_leaf': 44, 'lambda_l1': 0.6023901343724142, 'lambda_l2': 0.5710652145669353} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.571935888750904, 'max_depth': 40, 'num_leaves': 307, 'min_data_in_leaf': 35, 'lambda_l1': 0.5800712637813071, 'lambda_l2': 0.9312496396306816} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.556135268149621, 'max_depth': 38, 'num_leaves': 954, 'min_data_in_leaf': 35, 'lambda_l1': 0.45542633222421, 'lambda_l2': 0.9232002223451029} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5532547818809198, 'max_depth': 38, 'num_leaves': 964, 'min_data_in_leaf': 35, 'lambda_l1': 0.48618317695983115, 'lambda_l2': 0.7589678494070243} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.45397645770376693, 'max_depth': 34, 'num_leaves': 323, 'min_data_in_leaf': 36, 'lambda_l1': 0.5946489206937777, 'lambda_l2': 1.0640563877507943} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.689397069235332, 'max_depth': 40, 'num_leaves': 288, 'min_data_in_leaf': 32, 'lambda_l1': 0.5691502049789833, 'lambda_l2': 0.8732994986020874} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5339620745168775, 'max_depth': 89, 'num_leaves': 423, 'min_data_in_leaf': 39, 'lambda_l1': 0.44903338530268544, 'lambda_l2': 1.814933459496841} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.9760218688350295, 'max_depth': 44, 'num_leaves': 553, 'min_data_in_leaf': 41, 'lambda_l1': 0.6220583271670544, 'lambda_l2': 0.5316101652638201} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.8075245693337402, 'max_depth': 31, 'num_leaves': 775, 'min_data_in_leaf': 46, 'lambda_l1': 0.7367751149282755, 'lambda_l2': 0.20113475424205118} : acc= 60.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5878190185323117, 'max_depth': 28, 'num_leaves': 210, 'min_data_in_leaf': 34, 'lambda_l1': 0.5024039260076646, 'lambda_l2': 0.4862177537866176} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.8469498271992394, 'max_depth': 38, 'num_leaves': 505, 'min_data_in_leaf': 43, 'lambda_l1': 0.5570202120373547, 'lambda_l2': 0.9028609796724274} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4005494952990417, 'max_depth': 24, 'num_leaves': 919, 'min_data_in_leaf': 39, 'lambda_l1': 0.42120525210989035, 'lambda_l2': 1.22211406749366} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6621831639212453, 'max_depth': 32, 'num_leaves': 359, 'min_data_in_leaf': 41, 'lambda_l1': 0.3690511470281172, 'lambda_l2': 1.0068637718579443} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.48810808986850207, 'max_depth': 47, 'num_leaves': 648, 'min_data_in_leaf': 48, 'lambda_l1': 0.5214298738098272, 'lambda_l2': 4.494372892694685} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.745221836537134, 'max_depth': 36, 'num_leaves': 132, 'min_data_in_leaf': 37, 'lambda_l1': 0.5385546467609854, 'lambda_l2': 2.874267510063316} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2968881545699767, 'max_depth': 40, 'num_leaves': 489, 'min_data_in_leaf': 32, 'lambda_l1': 0.467267762166735, 'lambda_l2': 0.6661514367853623} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.42975871242066277, 'max_depth': 43, 'num_leaves': 584, 'min_data_in_leaf': 45, 'lambda_l1': 0.49642628426163754, 'lambda_l2': 2.1501978877311165} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.35375727423917275, 'max_depth': 42, 'num_leaves': 232, 'min_data_in_leaf': 30, 'lambda_l1': 0.3416880671545458, 'lambda_l2': 3.7307869938784357} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5774583161377773, 'max_depth': 35, 'num_leaves': 1245, 'min_data_in_leaf': 25, 'lambda_l1': 0.06196607755223859, 'lambda_l2': 4.776154909847061} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5948791140921637, 'max_depth': 33, 'num_leaves': 1233, 'min_data_in_leaf': 24, 'lambda_l1': 0.0586041867363292, 'lambda_l2': 4.704869903643971} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5186836505085343, 'max_depth': 35, 'num_leaves': 1068, 'min_data_in_leaf': 19, 'lambda_l1': 0.7103482729543229, 'lambda_l2': 4.827388268171501} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.45783889073724954, 'max_depth': 37, 'num_leaves': 1446, 'min_data_in_leaf': 21, 'lambda_l1': 0.002938255990287769, 'lambda_l2': 4.27237340825769} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6469332426924099, 'max_depth': 46, 'num_leaves': 1612, 'min_data_in_leaf': 25, 'lambda_l1': 0.07743165593388275, 'lambda_l2': 4.353296144677123} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8712377150790414, 'max_depth': 40, 'num_leaves': 405, 'min_data_in_leaf': 35, 'lambda_l1': 0.04335119603579611, 'lambda_l2': 0.7219290293789902} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.39545680231594255, 'max_depth': 39, 'num_leaves': 700, 'min_data_in_leaf': 78, 'lambda_l1': 0.11244437347137218, 'lambda_l2': 4.731222457559971} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.745145057660521, 'max_depth': 45, 'num_leaves': 1237, 'min_data_in_leaf': 41, 'lambda_l1': 0.6117618149381397, 'lambda_l2': 4.998033076645587} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.058791347025012826, 'max_depth': 52, 'num_leaves': 940, 'min_data_in_leaf': 28, 'lambda_l1': 0.5803643747603209, 'lambda_l2': 2.786463831509838} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3021357581025802, 'max_depth': 41, 'num_leaves': 2506, 'min_data_in_leaf': 30, 'lambda_l1': 0.06406993666044522, 'lambda_l2': 3.8458142307285623} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5528860528883575, 'max_depth': 48, 'num_leaves': 50, 'min_data_in_leaf': 33, 'lambda_l1': 0.09060387321414731, 'lambda_l2': 3.6110017573976676} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5302818718949905, 'max_depth': 49, 'num_leaves': 82, 'min_data_in_leaf': 39, 'lambda_l1': 0.08843766975998626, 'lambda_l2': 4.808391124427815} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.507114117857254, 'max_depth': 48, 'num_leaves': 68, 'min_data_in_leaf': 33, 'lambda_l1': 0.0984441149968395, 'lambda_l2': 4.903038841945806} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5730947746450932, 'max_depth': 55, 'num_leaves': 65, 'min_data_in_leaf': 37, 'lambda_l1': 0.6359520289690787, 'lambda_l2': 4.834438213033417} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.37628672476659675, 'max_depth': 51, 'num_leaves': 192, 'min_data_in_leaf': 39, 'lambda_l1': 0.08329764108321414, 'lambda_l2': 4.57148046259843} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4461592515353074, 'max_depth': 13, 'num_leaves': 1342, 'min_data_in_leaf': 43, 'lambda_l1': 0.1115483848382394, 'lambda_l2': 3.67240625773342} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6164411600651262, 'max_depth': 49, 'num_leaves': 1751, 'min_data_in_leaf': 23, 'lambda_l1': 0.055100595529423715, 'lambda_l2': 4.151927888638483} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5072192751554079, 'max_depth': 1, 'num_leaves': 262, 'min_data_in_leaf': 26, 'lambda_l1': 0.15947181923986678, 'lambda_l2': 1.349293705350325} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23112929527054962, 'max_depth': 58, 'num_leaves': 162, 'min_data_in_leaf': 34, 'lambda_l1': 0.290511200779258, 'lambda_l2': 4.779652763550204} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6930208155344512, 'max_depth': 45, 'num_leaves': 365, 'min_data_in_leaf': 37, 'lambda_l1': 0.010271133462073458, 'lambda_l2': 3.4187745364638378} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3408541827277498, 'max_depth': 37, 'num_leaves': 2225, 'min_data_in_leaf': 40, 'lambda_l1': 0.02935139004332262, 'lambda_l2': 2.554136681962939} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5315898027006228, 'max_depth': 43, 'num_leaves': 292, 'min_data_in_leaf': 43, 'lambda_l1': 0.0418590010014851, 'lambda_l2': 2.6949573498870096} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.42929413017389534, 'max_depth': 35, 'num_leaves': 456, 'min_data_in_leaf': 36, 'lambda_l1': 0.07704983696038864, 'lambda_l2': 3.208827153750144} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.03862432123307042, 'max_depth': 35, 'num_leaves': 463, 'min_data_in_leaf': 36, 'lambda_l1': 0.09104450249189021, 'lambda_l2': 3.584323040570294} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4241710952977683, 'max_depth': 47, 'num_leaves': 338, 'min_data_in_leaf': 32, 'lambda_l1': 0.14081228274805455, 'lambda_l2': 3.2488670125259076} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.37626731851364775, 'max_depth': 39, 'num_leaves': 2326, 'min_data_in_leaf': 39, 'lambda_l1': 0.12071217907778138, 'lambda_l2': 1.1423859197031356} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.46268600038461266, 'max_depth': 44, 'num_leaves': 1134, 'min_data_in_leaf': 28, 'lambda_l1': 0.0764173578806163, 'lambda_l2': 0.8629218730907736} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.59102201933642, 'max_depth': 53, 'num_leaves': 2073, 'min_data_in_leaf': 35, 'lambda_l1': 0.5184898024742978, 'lambda_l2': 4.488968056621581} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.32501143001131116, 'max_depth': 78, 'num_leaves': 132, 'min_data_in_leaf': 70, 'lambda_l1': 0.06215673039737989, 'lambda_l2': 3.530303143563164} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7388365639103321, 'max_depth': 30, 'num_leaves': 607, 'min_data_in_leaf': 42, 'lambda_l1': 0.5519167606333687, 'lambda_l2': 2.954224492711477} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5512145249438968, 'max_depth': 33, 'num_leaves': 517, 'min_data_in_leaf': 39, 'lambda_l1': 0.017284295769257566, 'lambda_l2': 3.210506769337558} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8284707329137471, 'max_depth': 38, 'num_leaves': 767, 'min_data_in_leaf': 46, 'lambda_l1': 0.03395536503853913, 'lambda_l2': 2.8250934618036636} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6463238683870791, 'max_depth': 42, 'num_leaves': 425, 'min_data_in_leaf': 44, 'lambda_l1': 0.08947732190692244, 'lambda_l2': 1.99662771366004} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4665931404752889, 'max_depth': 35, 'num_leaves': 1514, 'min_data_in_leaf': 37, 'lambda_l1': 0.05484263858790486, 'lambda_l2': 3.394141344722462} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.41467686336633724, 'max_depth': 41, 'num_leaves': 261, 'min_data_in_leaf': 33, 'lambda_l1': 0.121175421548496, 'lambda_l2': 3.031659580024742} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.004066100910967186, 'max_depth': 37, 'num_leaves': 52, 'min_data_in_leaf': 42, 'lambda_l1': 0.46217401815916725, 'lambda_l2': 3.072427406960382} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.26315751870563964, 'max_depth': 49, 'num_leaves': 540, 'min_data_in_leaf': 17, 'lambda_l1': 0.07336392669588439, 'lambda_l2': 0.42792386631540985} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.9994170410308083, 'max_depth': 32, 'num_leaves': 381, 'min_data_in_leaf': 31, 'lambda_l1': 0.10000769017135018, 'lambda_l2': 0.647796037593227} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5287061089854175, 'max_depth': 46, 'num_leaves': 682, 'min_data_in_leaf': 49, 'lambda_l1': 0.0014864702675029817, 'lambda_l2': 3.1561547134968895} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5455961323601054, 'max_depth': 46, 'num_leaves': 670, 'min_data_in_leaf': 51, 'lambda_l1': 0.023950930442000553, 'lambda_l2': 3.1503017639536313} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6451165774331772, 'max_depth': 43, 'num_leaves': 996, 'min_data_in_leaf': 48, 'lambda_l1': 0.007314138452801762, 'lambda_l2': 2.6899325015572755} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.48269922206846205, 'max_depth': 39, 'num_leaves': 864, 'min_data_in_leaf': 41, 'lambda_l1': 0.03869134990592442, 'lambda_l2': 3.3046699754533906} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3667516171789709, 'max_depth': 47, 'num_leaves': 445, 'min_data_in_leaf': 57, 'lambda_l1': 0.048198527722785114, 'lambda_l2': 2.9168399117321364} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.41105005441433645, 'max_depth': 41, 'num_leaves': 647, 'min_data_in_leaf': 38, 'lambda_l1': 0.07029773071304765, 'lambda_l2': 4.609188950309174} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.41098683674488173, 'max_depth': 44, 'num_leaves': 751, 'min_data_in_leaf': 38, 'lambda_l1': 0.06611471538954565, 'lambda_l2': 4.596202778727256} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2999290033918634, 'max_depth': 41, 'num_leaves': 657, 'min_data_in_leaf': 35, 'lambda_l1': 0.11110941471585056, 'lambda_l2': 4.399732538952477} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4914562500171769, 'max_depth': 49, 'num_leaves': 321, 'min_data_in_leaf': 46, 'lambda_l1': 0.08179156941562707, 'lambda_l2': 4.013016955092487} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3486879099914247, 'max_depth': 51, 'num_leaves': 2405, 'min_data_in_leaf': 82, 'lambda_l1': 0.13946693357807158, 'lambda_l2': 4.821947192654058} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5551358590454871, 'max_depth': 45, 'num_leaves': 562, 'min_data_in_leaf': 67, 'lambda_l1': 0.09111527848132667, 'lambda_l2': 4.711590557497535} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7043355782436664, 'max_depth': 35, 'num_leaves': 819, 'min_data_in_leaf': 40, 'lambda_l1': 0.024786525911675288, 'lambda_l2': 4.952264738077032} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.45696239729236443, 'max_depth': 39, 'num_leaves': 507, 'min_data_in_leaf': 36, 'lambda_l1': 0.004549541461261672, 'lambda_l2': 0.2858183209467118} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6186881041512152, 'max_depth': 41, 'num_leaves': 596, 'min_data_in_leaf': 39, 'lambda_l1': 0.05536597103096764, 'lambda_l2': 3.1656678300117993} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6300323069789686, 'max_depth': 41, 'num_leaves': 613, 'min_data_in_leaf': 44, 'lambda_l1': 0.054359758321833235, 'lambda_l2': 0.9480387278260579} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3932509726683042, 'max_depth': 43, 'num_leaves': 691, 'min_data_in_leaf': 38, 'lambda_l1': 0.07151624597301208, 'lambda_l2': 3.198710113571532} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5464347387284079, 'max_depth': 38, 'num_leaves': 900, 'min_data_in_leaf': 38, 'lambda_l1': 0.10191459362593336, 'lambda_l2': 3.452504007700477} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3934807459265145, 'max_depth': 43, 'num_leaves': 421, 'min_data_in_leaf': 34, 'lambda_l1': 0.07219522259222289, 'lambda_l2': 3.232752012833871} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.39652273658764253, 'max_depth': 47, 'num_leaves': 2246, 'min_data_in_leaf': 29, 'lambda_l1': 0.8523554044611965, 'lambda_l2': 3.7989146957640028} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3245911424719477, 'max_depth': 40, 'num_leaves': 692, 'min_data_in_leaf': 26, 'lambda_l1': 0.43925358117638563, 'lambda_l2': 3.3745044641735253} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3392951422779078, 'max_depth': 36, 'num_leaves': 687, 'min_data_in_leaf': 38, 'lambda_l1': 0.40254972201539235, 'lambda_l2': 3.358330461965897} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.29506942941524117, 'max_depth': 40, 'num_leaves': 764, 'min_data_in_leaf': 20, 'lambda_l1': 0.426086594843484, 'lambda_l2': 3.5950261497925937} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.44274222159693283, 'max_depth': 4, 'num_leaves': 2492, 'min_data_in_leaf': 26, 'lambda_l1': 0.4782481287579915, 'lambda_l2': 3.1555535779878032} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5954393517150064, 'max_depth': 42, 'num_leaves': 208, 'min_data_in_leaf': 22, 'lambda_l1': 0.5366892749786613, 'lambda_l2': 1.5328312623007507} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5166313307999062, 'max_depth': 45, 'num_leaves': 612, 'min_data_in_leaf': 32, 'lambda_l1': 0.505985658034071, 'lambda_l2': 3.504447405516608} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.43077496469252363, 'max_depth': 38, 'num_leaves': 714, 'min_data_in_leaf': 24, 'lambda_l1': 0.07259237159128828, 'lambda_l2': 1.7677638642319784} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.36307712768145245, 'max_depth': 64, 'num_leaves': 827, 'min_data_in_leaf': 27, 'lambda_l1': 0.44339134645190503, 'lambda_l2': 3.3297977606137388} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5005152820021589, 'max_depth': 41, 'num_leaves': 476, 'min_data_in_leaf': 40, 'lambda_l1': 0.12727419487119276, 'lambda_l2': 3.252886045678291} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.27652702677583935, 'max_depth': 40, 'num_leaves': 1931, 'min_data_in_leaf': 36, 'lambda_l1': 0.04055257087223819, 'lambda_l2': 4.655624533050736} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5947751338154481, 'max_depth': 37, 'num_leaves': 374, 'min_data_in_leaf': 30, 'lambda_l1': 0.09661271202798244, 'lambda_l2': 1.056142618976042} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3353167091983221, 'max_depth': 48, 'num_leaves': 537, 'min_data_in_leaf': 33, 'lambda_l1': 0.05747819239284384, 'lambda_l2': 3.7009154686370116} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.32410934541782993, 'max_depth': 48, 'num_leaves': 579, 'min_data_in_leaf': 34, 'lambda_l1': 0.06445117380080474, 'lambda_l2': 3.666556880581012} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3846912863451021, 'max_depth': 50, 'num_leaves': 499, 'min_data_in_leaf': 36, 'lambda_l1': 0.049099436113997176, 'lambda_l2': 0.7950176020238365} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4515994163070037, 'max_depth': 53, 'num_leaves': 2366, 'min_data_in_leaf': 39, 'lambda_l1': 0.09226960364512474, 'lambda_l2': 3.4106602730641837} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2549680666187012, 'max_depth': 45, 'num_leaves': 285, 'min_data_in_leaf': 33, 'lambda_l1': 0.10863578808041116, 'lambda_l2': 4.5184419330545085} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5030837032652328, 'max_depth': 43, 'num_leaves': 610, 'min_data_in_leaf': 42, 'lambda_l1': 0.07780711602205893, 'lambda_l2': 3.73361270472708} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6905623246583544, 'max_depth': 46, 'num_leaves': 2139, 'min_data_in_leaf': 26, 'lambda_l1': 0.4815831721683653, 'lambda_l2': 3.0714436862301158} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.41340738976741437, 'max_depth': 18, 'num_leaves': 688, 'min_data_in_leaf': 31, 'lambda_l1': 0.043710114581352946, 'lambda_l2': 3.6094099787425438} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34504833787863526, 'max_depth': 34, 'num_leaves': 1018, 'min_data_in_leaf': 37, 'lambda_l1': 0.5726654388226042, 'lambda_l2': 4.857087657686537} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5661728864812254, 'max_depth': 39, 'num_leaves': 465, 'min_data_in_leaf': 29, 'lambda_l1': 0.00046209556478361466, 'lambda_l2': 3.951318121963701} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3017284271160529, 'max_depth': 55, 'num_leaves': 343, 'min_data_in_leaf': 40, 'lambda_l1': 0.1296360807458068, 'lambda_l2': 3.5039748170067253} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4471350779189996, 'max_depth': 42, 'num_leaves': 550, 'min_data_in_leaf': 42, 'lambda_l1': 0.030524247801587547, 'lambda_l2': 2.488673029258476} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5022877025688639, 'max_depth': 100, 'num_leaves': 645, 'min_data_in_leaf': 44, 'lambda_l1': 0.026294922341284915, 'lambda_l2': 2.836009692626236} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4076863179480035, 'max_depth': 44, 'num_leaves': 794, 'min_data_in_leaf': 38, 'lambda_l1': 0.06393198588763754, 'lambda_l2': 2.9935141972152977} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.015317716252545611, 'max_depth': 48, 'num_leaves': 429, 'min_data_in_leaf': 41, 'lambda_l1': 0.055976251254966455, 'lambda_l2': 3.1480415480661668} : acc= 52.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6279473855627499, 'max_depth': 40, 'num_leaves': 146, 'min_data_in_leaf': 35, 'lambda_l1': 0.09615469345501894, 'lambda_l2': 2.7536081982778806} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.47254012390830635, 'max_depth': 37, 'num_leaves': 527, 'min_data_in_leaf': 39, 'lambda_l1': 0.08016105949806554, 'lambda_l2': 1.2662056425855306} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5440301981637479, 'max_depth': 43, 'num_leaves': 735, 'min_data_in_leaf': 45, 'lambda_l1': 0.022539529215413974, 'lambda_l2': 3.835770658986752} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3660555135769998, 'max_depth': 51, 'num_leaves': 2571, 'min_data_in_leaf': 23, 'lambda_l1': 0.049438607527298714, 'lambda_l2': 2.637854445891631} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7664434219404881, 'max_depth': 46, 'num_leaves': 1146, 'min_data_in_leaf': 33, 'lambda_l1': 0.6660478395285248, 'lambda_l2': 4.771192947880309} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.32840044027386894, 'max_depth': 41, 'num_leaves': 248, 'min_data_in_leaf': 37, 'lambda_l1': 0.1114028187736134, 'lambda_l2': 3.302237870300239} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8389051324813948, 'max_depth': 36, 'num_leaves': 595, 'min_data_in_leaf': 42, 'lambda_l1': 0.0010074090893092968, 'lambda_l2': 2.9519738266402706} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6670435366657682, 'max_depth': 33, 'num_leaves': 477, 'min_data_in_leaf': 41, 'lambda_l1': 0.025871421613463376, 'lambda_l2': 3.1846959815170384} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5775642355188236, 'max_depth': 38, 'num_leaves': 688, 'min_data_in_leaf': 39, 'lambda_l1': 0.06646396795504503, 'lambda_l2': 3.0959975042337087} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4717271227694907, 'max_depth': 39, 'num_leaves': 540, 'min_data_in_leaf': 43, 'lambda_l1': 0.03907724343301763, 'lambda_l2': 3.380174087715343} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6868051866484688, 'max_depth': 35, 'num_leaves': 392, 'min_data_in_leaf': 36, 'lambda_l1': 0.08226701735941404, 'lambda_l2': 3.248181641732924} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4156421130902367, 'max_depth': 44, 'num_leaves': 627, 'min_data_in_leaf': 40, 'lambda_l1': 0.5067262306684642, 'lambda_l2': 3.0266661486831854} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5329452548793079, 'max_depth': 41, 'num_leaves': 554, 'min_data_in_leaf': 25, 'lambda_l1': 0.04907271322200459, 'lambda_l2': 4.716956016356583} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.7711372950386313, 'max_depth': 22, 'num_leaves': 2333, 'min_data_in_leaf': 28, 'lambda_l1': 0.01910914963379489, 'lambda_l2': 0.6201023481850282} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.381764011749617, 'max_depth': 47, 'num_leaves': 1723, 'min_data_in_leaf': 38, 'lambda_l1': 0.062028925427553255, 'lambda_l2': 0.8898970655965656} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.47070354204429643, 'max_depth': 37, 'num_leaves': 2476, 'min_data_in_leaf': 34, 'lambda_l1': 0.08797437539543743, 'lambda_l2': 1.1151932049419009} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.24228350189138365, 'max_depth': 42, 'num_leaves': 2609, 'min_data_in_leaf': 28, 'lambda_l1': 0.15471047176435945, 'lambda_l2': 3.3213186588376744} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5999785742343344, 'max_depth': 43, 'num_leaves': 2709, 'min_data_in_leaf': 30, 'lambda_l1': 0.12148538736334458, 'lambda_l2': 3.2072357066854096} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5995218195269962, 'max_depth': 44, 'num_leaves': 4000, 'min_data_in_leaf': 31, 'lambda_l1': 0.12836370435119943, 'lambda_l2': 3.1552327988878877} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6259150761940266, 'max_depth': 49, 'num_leaves': 2235, 'min_data_in_leaf': 35, 'lambda_l1': 0.26163471555784773, 'lambda_l2': 2.910803011535993} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5347021418266599, 'max_depth': 50, 'num_leaves': 2425, 'min_data_in_leaf': 32, 'lambda_l1': 0.31543048996788925, 'lambda_l2': 2.836003049916183} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5940925533967274, 'max_depth': 49, 'num_leaves': 2306, 'min_data_in_leaf': 36, 'lambda_l1': 0.18577020829797064, 'lambda_l2': 2.911601582658054} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.44012852698618526, 'max_depth': 7, 'num_leaves': 2126, 'min_data_in_leaf': 34, 'lambda_l1': 0.11372875363351151, 'lambda_l2': 3.4590500110046736} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6617078401162769, 'max_depth': 46, 'num_leaves': 2242, 'min_data_in_leaf': 31, 'lambda_l1': 0.16480270153834448, 'lambda_l2': 2.7343370703822583} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.0011166946800771765, 'max_depth': 43, 'num_leaves': 2296, 'min_data_in_leaf': 26, 'lambda_l1': 0.23622133803811646, 'lambda_l2': 3.2143184461153593} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5038766404573622, 'max_depth': 47, 'num_leaves': 2178, 'min_data_in_leaf': 35, 'lambda_l1': 0.258303472008263, 'lambda_l2': 4.99810712458631} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7308376892531738, 'max_depth': 40, 'num_leaves': 2724, 'min_data_in_leaf': 40, 'lambda_l1': 0.5356084496050422, 'lambda_l2': 3.18186930192623} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6182593553173854, 'max_depth': 39, 'num_leaves': 2919, 'min_data_in_leaf': 38, 'lambda_l1': 0.10227792503585709, 'lambda_l2': 3.0522647709963104} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8402147477187782, 'max_depth': 48, 'num_leaves': 479, 'min_data_in_leaf': 43, 'lambda_l1': 0.43849345767952613, 'lambda_l2': 2.9670663308669574} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5052733583542814, 'max_depth': 52, 'num_leaves': 735, 'min_data_in_leaf': 41, 'lambda_l1': 0.38290690885977163, 'lambda_l2': 3.1104562072581916} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4027014506418332, 'max_depth': 36, 'num_leaves': 331, 'min_data_in_leaf': 36, 'lambda_l1': 0.08358755311409968, 'lambda_l2': 2.8403033252028216} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5625664632060268, 'max_depth': 25, 'num_leaves': 425, 'min_data_in_leaf': 21, 'lambda_l1': 0.03600130005738003, 'lambda_l2': 3.0495355502779296} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3650959361445379, 'max_depth': 42, 'num_leaves': 1279, 'min_data_in_leaf': 38, 'lambda_l1': 0.46604323669627706, 'lambda_l2': 3.270429017602769} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4346493268308649, 'max_depth': 45, 'num_leaves': 55, 'min_data_in_leaf': 29, 'lambda_l1': 0.06842605831613068, 'lambda_l2': 2.5716808937029065} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6930870484689957, 'max_depth': 39, 'num_leaves': 1382, 'min_data_in_leaf': 45, 'lambda_l1': 0.0004511605499374141, 'lambda_l2': 0.7960493068344144} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4939876533713613, 'max_depth': 34, 'num_leaves': 2806, 'min_data_in_leaf': 33, 'lambda_l1': 0.1186810085645408, 'lambda_l2': 4.580347289223043} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.327054282918237, 'max_depth': 49, 'num_leaves': 627, 'min_data_in_leaf': 24, 'lambda_l1': 0.5575260773533136, 'lambda_l2': 0.9708601647598404} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6052182477631616, 'max_depth': 37, 'num_leaves': 571, 'min_data_in_leaf': 40, 'lambda_l1': 0.04533232605761217, 'lambda_l2': 4.845756366522233} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7642900702232236, 'max_depth': 16, 'num_leaves': 852, 'min_data_in_leaf': 37, 'lambda_l1': 0.07420936449473012, 'lambda_l2': 0.16211329838733235} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4440198772348093, 'max_depth': 20, 'num_leaves': 177, 'min_data_in_leaf': 42, 'lambda_l1': 0.13992447876992753, 'lambda_l2': 2.9364860093169662} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5561593361575395, 'max_depth': 61, 'num_leaves': 1988, 'min_data_in_leaf': 47, 'lambda_l1': 0.5917757197767348, 'lambda_l2': 2.3528393348745484} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27980862257723854, 'max_depth': 42, 'num_leaves': 2380, 'min_data_in_leaf': 30, 'lambda_l1': 0.019909495581658762, 'lambda_l2': 3.3366618682977434} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3784600133879127, 'max_depth': 45, 'num_leaves': 678, 'min_data_in_leaf': 34, 'lambda_l1': 0.0989880915087207, 'lambda_l2': 4.662585115506674} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.13796039532067872, 'max_depth': 41, 'num_leaves': 412, 'min_data_in_leaf': 53, 'lambda_l1': 0.052322818466146455, 'lambda_l2': 2.730486083776383} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.8950639425484544, 'max_depth': 31, 'num_leaves': 3022, 'min_data_in_leaf': 27, 'lambda_l1': 0.3509833404513808, 'lambda_l2': 4.062756036754638} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4675571865267953, 'max_depth': 38, 'num_leaves': 3102, 'min_data_in_leaf': 26, 'lambda_l1': 0.2111999391402688, 'lambda_l2': 4.154741533401482} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.32623367960793875, 'max_depth': 44, 'num_leaves': 2207, 'min_data_in_leaf': 23, 'lambda_l1': 0.3833562502458778, 'lambda_l2': 3.7193082418430454} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.941621473099499, 'max_depth': 31, 'num_leaves': 2974, 'min_data_in_leaf': 27, 'lambda_l1': 0.2978115289107443, 'lambda_l2': 3.9331013280097213} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4016538737510609, 'max_depth': 47, 'num_leaves': 256, 'min_data_in_leaf': 32, 'lambda_l1': 0.42730785867914217, 'lambda_l2': 3.629969578867087} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6573924202763345, 'max_depth': 51, 'num_leaves': 3291, 'min_data_in_leaf': 29, 'lambda_l1': 0.4984308407235151, 'lambda_l2': 3.8307267193849697} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.531295414595732, 'max_depth': 39, 'num_leaves': 2441, 'min_data_in_leaf': 25, 'lambda_l1': 0.525826884482376, 'lambda_l2': 4.09185151113776} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.42369888711141124, 'max_depth': 35, 'num_leaves': 350, 'min_data_in_leaf': 36, 'lambda_l1': 0.09318009233472994, 'lambda_l2': 3.5771506625888665} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.48996007652481266, 'max_depth': 28, 'num_leaves': 3063, 'min_data_in_leaf': 38, 'lambda_l1': 0.12335617525022446, 'lambda_l2': 0.3940327422870266} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6129337371020428, 'max_depth': 26, 'num_leaves': 3331, 'min_data_in_leaf': 39, 'lambda_l1': 0.13656724203106552, 'lambda_l2': 3.435209093576713} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5011625187674105, 'max_depth': 29, 'num_leaves': 3093, 'min_data_in_leaf': 34, 'lambda_l1': 0.11492276498305305, 'lambda_l2': 0.38009416968957244} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3735392485956684, 'max_depth': 30, 'num_leaves': 3210, 'min_data_in_leaf': 31, 'lambda_l1': 0.3589385576649375, 'lambda_l2': 0.5098417307897157} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.558353311911286, 'max_depth': 34, 'num_leaves': 127, 'min_data_in_leaf': 28, 'lambda_l1': 0.26770120985313417, 'lambda_l2': 0.23284653018623785} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7225859193302153, 'max_depth': 33, 'num_leaves': 3062, 'min_data_in_leaf': 37, 'lambda_l1': 0.17031898467638218, 'lambda_l2': 0.3454319682418885} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.30095913163374594, 'max_depth': 28, 'num_leaves': 3676, 'min_data_in_leaf': 38, 'lambda_l1': 0.3341414765462959, 'lambda_l2': 4.254019115738433} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4781104501762431, 'max_depth': 37, 'num_leaves': 2289, 'min_data_in_leaf': 34, 'lambda_l1': 0.4042357231045114, 'lambda_l2': 0.4498548517104322} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6384362243085426, 'max_depth': 54, 'num_leaves': 3187, 'min_data_in_leaf': 36, 'lambda_l1': 0.4851762260459998, 'lambda_l2': 0.6845244478547765} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44198237285928127, 'max_depth': 40, 'num_leaves': 3400, 'min_data_in_leaf': 93, 'lambda_l1': 0.12312574996251127, 'lambda_l2': 4.3751691679547235} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.0018283533847706333, 'max_depth': 32, 'num_leaves': 2981, 'min_data_in_leaf': 22, 'lambda_l1': 0.0826083707243064, 'lambda_l2': 1.9124581731247088} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.36267134855995886, 'max_depth': 49, 'num_leaves': 1832, 'min_data_in_leaf': 59, 'lambda_l1': 0.45152727357483724, 'lambda_l2': 4.784896196410554} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.07209894559438113, 'max_depth': 57, 'num_leaves': 2543, 'min_data_in_leaf': 32, 'lambda_l1': 0.1439810125392308, 'lambda_l2': 3.767261369256338} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.9015022691515339, 'max_depth': 36, 'num_leaves': 1548, 'min_data_in_leaf': 19, 'lambda_l1': 0.10548203506002295, 'lambda_l2': 3.5452302064630103} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.09324866022153287, 'max_depth': 43, 'num_leaves': 961, 'min_data_in_leaf': 40, 'lambda_l1': 0.06260905971926328, 'lambda_l2': 1.4492629097603384} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5408193899997212, 'max_depth': 46, 'num_leaves': 786, 'min_data_in_leaf': 28, 'lambda_l1': 0.09793934584799047, 'lambda_l2': 2.174203733517261} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.05359014226961861, 'max_depth': 40, 'num_leaves': 469, 'min_data_in_leaf': 35, 'lambda_l1': 0.07764808058093706, 'lambda_l2': 0.5653785734486467} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.02685282393806038, 'max_depth': 67, 'num_leaves': 3020, 'min_data_in_leaf': 39, 'lambda_l1': 0.12208915901608278, 'lambda_l2': 3.3495408524367565} : acc= 57.08%\n",
            "[HPO] metrics with {'learning_rate': 0.760746889690206, 'max_depth': 51, 'num_leaves': 208, 'min_data_in_leaf': 30, 'lambda_l1': 0.0680556635834295, 'lambda_l2': 4.893175152861198} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32713265641758077, 'max_depth': 13, 'num_leaves': 318, 'min_data_in_leaf': 24, 'lambda_l1': 0.1554008010999361, 'lambda_l2': 0.06616229890304481} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.30185702646609425, 'max_depth': 13, 'num_leaves': 2855, 'min_data_in_leaf': 24, 'lambda_l1': 0.6185789621423318, 'lambda_l2': 0.04613966800259262} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3387753496062925, 'max_depth': 38, 'num_leaves': 300, 'min_data_in_leaf': 37, 'lambda_l1': 0.4103893258348957, 'lambda_l2': 0.2904041957495996} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.008526586586499902, 'max_depth': 9, 'num_leaves': 378, 'min_data_in_leaf': 43, 'lambda_l1': 0.09351167171543472, 'lambda_l2': 0.10670704833695172} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42170631006839093, 'max_depth': 82, 'num_leaves': 270, 'min_data_in_leaf': 41, 'lambda_l1': 0.46832133580632246, 'lambda_l2': 0.127893347636859} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4907772979303526, 'max_depth': 42, 'num_leaves': 503, 'min_data_in_leaf': 33, 'lambda_l1': 0.5531630624840769, 'lambda_l2': 3.9155556512348118} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.26157130263387685, 'max_depth': 48, 'num_leaves': 363, 'min_data_in_leaf': 49, 'lambda_l1': 0.04680605896667878, 'lambda_l2': 0.021008442478261224} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3775617383893591, 'max_depth': 45, 'num_leaves': 2671, 'min_data_in_leaf': 21, 'lambda_l1': 0.5058098119954768, 'lambda_l2': 3.252547005309502} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5779519259542459, 'max_depth': 41, 'num_leaves': 123, 'min_data_in_leaf': 26, 'lambda_l1': 0.2812869362166669, 'lambda_l2': 4.490440102254186} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6583472089871779, 'max_depth': 36, 'num_leaves': 649, 'min_data_in_leaf': 35, 'lambda_l1': 0.1566553036991647, 'lambda_l2': 1.6171908165781699} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.44587338320280473, 'max_depth': 53, 'num_leaves': 1099, 'min_data_in_leaf': 38, 'lambda_l1': 0.11415521172771496, 'lambda_l2': 3.690509978205432} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32856116126710133, 'max_depth': 38, 'num_leaves': 569, 'min_data_in_leaf': 41, 'lambda_l1': 0.07507234178418074, 'lambda_l2': 4.745809598410754} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.532318377394065, 'max_depth': 44, 'num_leaves': 206, 'min_data_in_leaf': 45, 'lambda_l1': 0.09327946835766529, 'lambda_l2': 4.058253509904977} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.40689719926558593, 'max_depth': 47, 'num_leaves': 899, 'min_data_in_leaf': 39, 'lambda_l1': 0.18643825657453134, 'lambda_l2': 3.4758184283798226} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6339126153906522, 'max_depth': 40, 'num_leaves': 2045, 'min_data_in_leaf': 32, 'lambda_l1': 0.3383956977118179, 'lambda_l2': 3.1719436745850005} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.48687424428276305, 'max_depth': 50, 'num_leaves': 441, 'min_data_in_leaf': 36, 'lambda_l1': 0.05677859409698702, 'lambda_l2': 4.641226249830076} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.8258238596439692, 'max_depth': 34, 'num_leaves': 748, 'min_data_in_leaf': 23, 'lambda_l1': 0.13773634797277345, 'lambda_l2': 3.1163459119822776} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5694666543871387, 'max_depth': 43, 'num_leaves': 3166, 'min_data_in_leaf': 27, 'lambda_l1': 0.033292281787176164, 'lambda_l2': 3.271143599730674} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.22832148678077197, 'max_depth': 39, 'num_leaves': 506, 'min_data_in_leaf': 30, 'lambda_l1': 0.08222981660274167, 'lambda_l2': 3.4236678280120434} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3662767129523842, 'max_depth': 46, 'num_leaves': 260, 'min_data_in_leaf': 42, 'lambda_l1': 0.11172033325782256, 'lambda_l2': 3.0171125052494046} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.0050164968301008965, 'max_depth': 41, 'num_leaves': 2887, 'min_data_in_leaf': 38, 'lambda_l1': 0.01830992197004354, 'lambda_l2': 0.2717147755544508} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4577855924247074, 'max_depth': 37, 'num_leaves': 53, 'min_data_in_leaf': 34, 'lambda_l1': 0.060826304452449284, 'lambda_l2': 1.363490656600658} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.7138044155971696, 'max_depth': 49, 'num_leaves': 3439, 'min_data_in_leaf': 63, 'lambda_l1': 0.10244012625727567, 'lambda_l2': 2.9008129319255516} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3022908641622216, 'max_depth': 6, 'num_leaves': 1649, 'min_data_in_leaf': 44, 'lambda_l1': 0.5150909308491989, 'lambda_l2': 1.1900289729805265} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.40078963220244446, 'max_depth': 31, 'num_leaves': 348, 'min_data_in_leaf': 25, 'lambda_l1': 0.5818388511639813, 'lambda_l2': 0.44115997697208925} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5234694113726978, 'max_depth': 30, 'num_leaves': 342, 'min_data_in_leaf': 25, 'lambda_l1': 0.6076665325496049, 'lambda_l2': 0.45130470588236454} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40728516992215513, 'max_depth': 29, 'num_leaves': 399, 'min_data_in_leaf': 28, 'lambda_l1': 0.5888938687564997, 'lambda_l2': 0.39509176680026964} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6090805723722874, 'max_depth': 27, 'num_leaves': 310, 'min_data_in_leaf': 40, 'lambda_l1': 0.5568450645713049, 'lambda_l2': 0.47475244420681445} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5103597561291047, 'max_depth': 32, 'num_leaves': 446, 'min_data_in_leaf': 37, 'lambda_l1': 0.5339083299857087, 'lambda_l2': 4.935601070580097} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4580611146178609, 'max_depth': 35, 'num_leaves': 172, 'min_data_in_leaf': 32, 'lambda_l1': 0.5886180873645969, 'lambda_l2': 0.19643548896253907} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3526080692693801, 'max_depth': 52, 'num_leaves': 582, 'min_data_in_leaf': 30, 'lambda_l1': 0.0416093972522199, 'lambda_l2': 3.855810714912231} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5856703829623423, 'max_depth': 44, 'num_leaves': 691, 'min_data_in_leaf': 35, 'lambda_l1': 0.6438884885571204, 'lambda_l2': 0.3563199674712294} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.7165116965913815, 'max_depth': 32, 'num_leaves': 2772, 'min_data_in_leaf': 39, 'lambda_l1': 0.5627949989824041, 'lambda_l2': 0.5200995748612021} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40569815590574465, 'max_depth': 47, 'num_leaves': 528, 'min_data_in_leaf': 26, 'lambda_l1': 0.5742310947748362, 'lambda_l2': 0.7250554305620365} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.49120274890460724, 'max_depth': 42, 'num_leaves': 389, 'min_data_in_leaf': 42, 'lambda_l1': 0.06911613937351962, 'lambda_l2': 0.6136083981628904} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6421561252986986, 'max_depth': 45, 'num_leaves': 281, 'min_data_in_leaf': 37, 'lambda_l1': 0.9447408233195739, 'lambda_l2': 3.620523316676436} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.8336959392478611, 'max_depth': 59, 'num_leaves': 456, 'min_data_in_leaf': 33, 'lambda_l1': 0.490796102833472, 'lambda_l2': 3.3817293139685503} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2790587183870074, 'max_depth': 49, 'num_leaves': 1201, 'min_data_in_leaf': 29, 'lambda_l1': 0.4557200807640235, 'lambda_l2': 3.212773575634883} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4068416654743693, 'max_depth': 34, 'num_leaves': 833, 'min_data_in_leaf': 40, 'lambda_l1': 0.01831965650910508, 'lambda_l2': 4.8190581113810484} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5534750042000562, 'max_depth': 40, 'num_leaves': 1482, 'min_data_in_leaf': 55, 'lambda_l1': 0.3593093051431752, 'lambda_l2': 3.5111493719100717} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.33294786310336716, 'max_depth': 43, 'num_leaves': 633, 'min_data_in_leaf': 36, 'lambda_l1': 0.036995066259971676, 'lambda_l2': 4.714215235092921} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44830240487369993, 'max_depth': 36, 'num_leaves': 524, 'min_data_in_leaf': 44, 'lambda_l1': 0.07715725652774022, 'lambda_l2': 2.640840056733792} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6833485887107094, 'max_depth': 55, 'num_leaves': 168, 'min_data_in_leaf': 51, 'lambda_l1': 0.25041037447191355, 'lambda_l2': 3.093520076914941} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5217020081487191, 'max_depth': 38, 'num_leaves': 743, 'min_data_in_leaf': 31, 'lambda_l1': 0.432919263993768, 'lambda_l2': 3.310189914165408} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.36450338556282547, 'max_depth': 46, 'num_leaves': 234, 'min_data_in_leaf': 24, 'lambda_l1': 0.13135792575592428, 'lambda_l2': 4.565839267220622} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5972019263142408, 'max_depth': 31, 'num_leaves': 367, 'min_data_in_leaf': 47, 'lambda_l1': 0.3124118274330937, 'lambda_l2': 3.7523800043015143} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4472428815211735, 'max_depth': 48, 'num_leaves': 646, 'min_data_in_leaf': 34, 'lambda_l1': 0.39083740656104066, 'lambda_l2': 3.154402795619188} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.46824024782967716, 'max_depth': 48, 'num_leaves': 657, 'min_data_in_leaf': 34, 'lambda_l1': 0.3857710982036459, 'lambda_l2': 3.1713916488268965} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5482001067852876, 'max_depth': 45, 'num_leaves': 609, 'min_data_in_leaf': 33, 'lambda_l1': 0.3719841671449165, 'lambda_l2': 2.9467562382077057} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.7498504955434935, 'max_depth': 50, 'num_leaves': 740, 'min_data_in_leaf': 36, 'lambda_l1': 0.4479906811415236, 'lambda_l2': 3.0210813509241268} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40716900388745225, 'max_depth': 42, 'num_leaves': 540, 'min_data_in_leaf': 27, 'lambda_l1': 0.4791061825918341, 'lambda_l2': 3.119284683729237} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4882788999519613, 'max_depth': 48, 'num_leaves': 1932, 'min_data_in_leaf': 30, 'lambda_l1': 0.4207724976237978, 'lambda_l2': 2.8541435032562643} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.9812040616930588, 'max_depth': 40, 'num_leaves': 458, 'min_data_in_leaf': 35, 'lambda_l1': 0.10389059338178268, 'lambda_l2': 0.25411115580550253} : acc= 61.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6421828191381177, 'max_depth': 44, 'num_leaves': 685, 'min_data_in_leaf': 38, 'lambda_l1': 0.3970373564011887, 'lambda_l2': 4.889614757422276} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.44448296937826, 'max_depth': 19, 'num_leaves': 860, 'min_data_in_leaf': 32, 'lambda_l1': 0.08518055282196886, 'lambda_l2': 3.21175290693065} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5600661566992375, 'max_depth': 24, 'num_leaves': 101, 'min_data_in_leaf': 34, 'lambda_l1': 0.15299640461230923, 'lambda_l2': 0.6265250089001865} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.35999482510895703, 'max_depth': 47, 'num_leaves': 1766, 'min_data_in_leaf': 38, 'lambda_l1': 0.417065207062956, 'lambda_l2': 0.7501344082001311} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7996907130189982, 'max_depth': 52, 'num_leaves': 328, 'min_data_in_leaf': 25, 'lambda_l1': 0.625450796908614, 'lambda_l2': 4.638810864128048} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.49661062908036974, 'max_depth': 12, 'num_leaves': 600, 'min_data_in_leaf': 29, 'lambda_l1': 0.05651884018918838, 'lambda_l2': 3.962922580007514} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6293311009062915, 'max_depth': 36, 'num_leaves': 799, 'min_data_in_leaf': 40, 'lambda_l1': 0.5413350142610308, 'lambda_l2': 0.022945098545493092} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4115769443476858, 'max_depth': 39, 'num_leaves': 3256, 'min_data_in_leaf': 22, 'lambda_l1': 0.22687694129407537, 'lambda_l2': 4.424040600612718} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5471222003572668, 'max_depth': 33, 'num_leaves': 483, 'min_data_in_leaf': 36, 'lambda_l1': 0.09277878956681615, 'lambda_l2': 2.764030017046181} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7085844681497717, 'max_depth': 43, 'num_leaves': 1035, 'min_data_in_leaf': 32, 'lambda_l1': 0.12280674736788323, 'lambda_l2': 2.987744403701261} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.32716094051781996, 'max_depth': 28, 'num_leaves': 415, 'min_data_in_leaf': 27, 'lambda_l1': 0.059803602496240144, 'lambda_l2': 3.29516017888997} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4347235339850892, 'max_depth': 41, 'num_leaves': 569, 'min_data_in_leaf': 38, 'lambda_l1': 0.3503000113832937, 'lambda_l2': 1.0278717160046515} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5133746817652454, 'max_depth': 50, 'num_leaves': 1351, 'min_data_in_leaf': 34, 'lambda_l1': 0.11467622566322568, 'lambda_l2': 3.6620129471944285} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3903582101515388, 'max_depth': 46, 'num_leaves': 248, 'min_data_in_leaf': 41, 'lambda_l1': 0.5200659831281137, 'lambda_l2': 0.1555612217549885} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6242620613072186, 'max_depth': 38, 'num_leaves': 934, 'min_data_in_leaf': 36, 'lambda_l1': 0.07915305377893067, 'lambda_l2': 0.8609754009328491} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2699085449180667, 'max_depth': 42, 'num_leaves': 692, 'min_data_in_leaf': 31, 'lambda_l1': 0.47114408466203994, 'lambda_l2': 4.770533571812022} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.479492632312385, 'max_depth': 97, 'num_leaves': 333, 'min_data_in_leaf': 73, 'lambda_l1': 0.43681874641389096, 'lambda_l2': 0.3489978667822013} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.581395119537507, 'max_depth': 44, 'num_leaves': 419, 'min_data_in_leaf': 39, 'lambda_l1': 0.051533980741645474, 'lambda_l2': 3.0706777770613423} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31357604849675214, 'max_depth': 35, 'num_leaves': 2943, 'min_data_in_leaf': 28, 'lambda_l1': 0.1405293423178462, 'lambda_l2': 0.5568140440004372} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.8438062719438337, 'max_depth': 48, 'num_leaves': 540, 'min_data_in_leaf': 24, 'lambda_l1': 0.400572169692039, 'lambda_l2': 3.7804065686729675} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.011273056140486664, 'max_depth': 40, 'num_leaves': 57, 'min_data_in_leaf': 37, 'lambda_l1': 0.7956997580501765, 'lambda_l2': 4.275232308163535} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4574829410216081, 'max_depth': 37, 'num_leaves': 3056, 'min_data_in_leaf': 42, 'lambda_l1': 0.20387631970685738, 'lambda_l2': 3.181457128266151} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3815351763136837, 'max_depth': 51, 'num_leaves': 655, 'min_data_in_leaf': 34, 'lambda_l1': 0.09223086797015807, 'lambda_l2': 3.4007252359128177} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6751646519591865, 'max_depth': 30, 'num_leaves': 3141, 'min_data_in_leaf': 30, 'lambda_l1': 0.5782558564649903, 'lambda_l2': 2.474677252976631} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5315351075974966, 'max_depth': 2, 'num_leaves': 144, 'min_data_in_leaf': 40, 'lambda_l1': 0.17831087150210967, 'lambda_l2': 2.865083010924399} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.45835818928380506, 'max_depth': 33, 'num_leaves': 785, 'min_data_in_leaf': 35, 'lambda_l1': 0.07197963446176411, 'lambda_l2': 3.549606702609086} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.0436094751038474, 'max_depth': 47, 'num_leaves': 301, 'min_data_in_leaf': 32, 'lambda_l1': 0.1045205169058846, 'lambda_l2': 4.988778879612546} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.35411714324910926, 'max_depth': 45, 'num_leaves': 509, 'min_data_in_leaf': 20, 'lambda_l1': 0.03841953710223672, 'lambda_l2': 0.4348932983201952} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5894583578646588, 'max_depth': 38, 'num_leaves': 610, 'min_data_in_leaf': 26, 'lambda_l1': 0.32475974890721204, 'lambda_l2': 3.2732224301148176} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7297384868042414, 'max_depth': 41, 'num_leaves': 411, 'min_data_in_leaf': 37, 'lambda_l1': 0.49731423557102017, 'lambda_l2': 3.04873182891348} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2161985105921172, 'max_depth': 43, 'num_leaves': 1867, 'min_data_in_leaf': 39, 'lambda_l1': 0.12259781202575906, 'lambda_l2': 2.6763020445396477} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4159199445096952, 'max_depth': 35, 'num_leaves': 210, 'min_data_in_leaf': 43, 'lambda_l1': 0.0642540193969079, 'lambda_l2': 4.7465394347624335} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5203097747617863, 'max_depth': 49, 'num_leaves': 728, 'min_data_in_leaf': 29, 'lambda_l1': 0.08770623033659286, 'lambda_l2': 3.148587384672514} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.019242680775577357, 'max_depth': 46, 'num_leaves': 470, 'min_data_in_leaf': 33, 'lambda_l1': 0.05217377980728815, 'lambda_l2': 4.524116610414414} : acc= 54.17%\n",
            "[HPO] metrics with {'learning_rate': 0.903942010769734, 'max_depth': 39, 'num_leaves': 1594, 'min_data_in_leaf': 23, 'lambda_l1': 0.1544378584110544, 'lambda_l2': 4.006859441890937} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.30622608384902955, 'max_depth': 42, 'num_leaves': 339, 'min_data_in_leaf': 36, 'lambda_l1': 0.596056017395968, 'lambda_l2': 3.4842939987910784} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6259483794340166, 'max_depth': 44, 'num_leaves': 569, 'min_data_in_leaf': 41, 'lambda_l1': 0.10684785244982918, 'lambda_l2': 4.853242062100194} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4552495652441076, 'max_depth': 31, 'num_leaves': 654, 'min_data_in_leaf': 27, 'lambda_l1': 0.03441336964183619, 'lambda_l2': 2.980241918326502} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.37887056585412104, 'max_depth': 37, 'num_leaves': 1284, 'min_data_in_leaf': 38, 'lambda_l1': 0.4597844628276577, 'lambda_l2': 3.8962853083029874} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5561426591071704, 'max_depth': 40, 'num_leaves': 255, 'min_data_in_leaf': 35, 'lambda_l1': 0.0763184202900237, 'lambda_l2': 3.318945444031213} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6971742562103647, 'max_depth': 53, 'num_leaves': 483, 'min_data_in_leaf': 45, 'lambda_l1': 0.13450716643395522, 'lambda_l2': 3.6865286388169767} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.48690018466682006, 'max_depth': 50, 'num_leaves': 372, 'min_data_in_leaf': 32, 'lambda_l1': 0.29574804423919293, 'lambda_l2': 1.2604010217989283} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3355794853528159, 'max_depth': 34, 'num_leaves': 3572, 'min_data_in_leaf': 39, 'lambda_l1': 0.015716626359937702, 'lambda_l2': 0.3171373600564686} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.41761520400387114, 'max_depth': 26, 'num_leaves': 865, 'min_data_in_leaf': 31, 'lambda_l1': 0.06546626174820358, 'lambda_l2': 4.647483368537595} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5873583074529966, 'max_depth': 46, 'num_leaves': 146, 'min_data_in_leaf': 37, 'lambda_l1': 0.0887524319149227, 'lambda_l2': 2.815519331623666} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.7885072627583358, 'max_depth': 22, 'num_leaves': 599, 'min_data_in_leaf': 25, 'lambda_l1': 0.54332182800273, 'lambda_l2': 3.201375610266451} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.26378246678637923, 'max_depth': 41, 'num_leaves': 2854, 'min_data_in_leaf': 43, 'lambda_l1': 0.04510210588137892, 'lambda_l2': 0.6954443290619687} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.510730916614027, 'max_depth': 48, 'num_leaves': 719, 'min_data_in_leaf': 34, 'lambda_l1': 0.11749897521618322, 'lambda_l2': 4.1783461475351915} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.40493597844730894, 'max_depth': 36, 'num_leaves': 3018, 'min_data_in_leaf': 41, 'lambda_l1': 0.3646819113833703, 'lambda_l2': 0.22666862774605787} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.003347157880175885, 'max_depth': 44, 'num_leaves': 2010, 'min_data_in_leaf': 29, 'lambda_l1': 0.6839322598045223, 'lambda_l2': 2.553746473526999} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4665260335055074, 'max_depth': 38, 'num_leaves': 519, 'min_data_in_leaf': 49, 'lambda_l1': 0.5129477973457486, 'lambda_l2': 2.9413568404463257} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6229975977330906, 'max_depth': 42, 'num_leaves': 421, 'min_data_in_leaf': 22, 'lambda_l1': 0.48764867121207267, 'lambda_l2': 3.4066383756169687} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3560455517564778, 'max_depth': 51, 'num_leaves': 1422, 'min_data_in_leaf': 35, 'lambda_l1': 0.3907788526391254, 'lambda_l2': 3.0789933161385488} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5522150669360234, 'max_depth': 32, 'num_leaves': 218, 'min_data_in_leaf': 38, 'lambda_l1': 0.07623414093733251, 'lambda_l2': 0.5634791362508872} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.686376988912639, 'max_depth': 39, 'num_leaves': 1142, 'min_data_in_leaf': 27, 'lambda_l1': 0.09804221314407188, 'lambda_l2': 1.1134022347615282} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.8538076842180428, 'max_depth': 40, 'num_leaves': 1177, 'min_data_in_leaf': 27, 'lambda_l1': 0.09232329532950126, 'lambda_l2': 0.8180976994027358} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6694822065934756, 'max_depth': 38, 'num_leaves': 898, 'min_data_in_leaf': 17, 'lambda_l1': 0.0545704315930396, 'lambda_l2': 1.2918752391439892} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.7784550141566527, 'max_depth': 39, 'num_leaves': 1053, 'min_data_in_leaf': 24, 'lambda_l1': 0.4398057660974079, 'lambda_l2': 0.908225367150205} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.9922919221081548, 'max_depth': 72, 'num_leaves': 1098, 'min_data_in_leaf': 26, 'lambda_l1': 0.0014887531020105066, 'lambda_l2': 0.9848973775841139} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6944014747178097, 'max_depth': 43, 'num_leaves': 953, 'min_data_in_leaf': 28, 'lambda_l1': 0.033778131956671925, 'lambda_l2': 1.125849424203701} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.7541104364867758, 'max_depth': 46, 'num_leaves': 1149, 'min_data_in_leaf': 25, 'lambda_l1': 0.6082126984305996, 'lambda_l2': 1.0341611949777736} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.032789388872805136, 'max_depth': 40, 'num_leaves': 1206, 'min_data_in_leaf': 82, 'lambda_l1': 0.10099964561617138, 'lambda_l2': 0.9042111280292} : acc= 57.92%\n",
            "[HPO] metrics with {'learning_rate': 0.62686087334641, 'max_depth': 37, 'num_leaves': 315, 'min_data_in_leaf': 30, 'lambda_l1': 0.06810903602519454, 'lambda_l2': 0.7796788482514975} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2907900592159415, 'max_depth': 48, 'num_leaves': 780, 'min_data_in_leaf': 6, 'lambda_l1': 0.08517633999545238, 'lambda_l2': 1.1011203433458823} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5631937645526418, 'max_depth': 42, 'num_leaves': 635, 'min_data_in_leaf': 31, 'lambda_l1': 0.5634392951538156, 'lambda_l2': 3.83220177264163} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6834452519867208, 'max_depth': 44, 'num_leaves': 548, 'min_data_in_leaf': 28, 'lambda_l1': 0.416512846092364, 'lambda_l2': 3.5693272427228018} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4348684089948092, 'max_depth': 35, 'num_leaves': 421, 'min_data_in_leaf': 21, 'lambda_l1': 0.05036182636319107, 'lambda_l2': 3.2464057034166798} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.8422583086111242, 'max_depth': 46, 'num_leaves': 2091, 'min_data_in_leaf': 33, 'lambda_l1': 0.016205227446013486, 'lambda_l2': 0.952863878955698} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5298237029459009, 'max_depth': 41, 'num_leaves': 1004, 'min_data_in_leaf': 23, 'lambda_l1': 0.47002509078753363, 'lambda_l2': 4.823826318290698} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3724132529467222, 'max_depth': 39, 'num_leaves': 124, 'min_data_in_leaf': 29, 'lambda_l1': 0.5297407001581624, 'lambda_l2': 3.149957814182253} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6100684399813636, 'max_depth': 49, 'num_leaves': 680, 'min_data_in_leaf': 26, 'lambda_l1': 0.10860058522283819, 'lambda_l2': 3.362189060406254} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7278300713852214, 'max_depth': 37, 'num_leaves': 1340, 'min_data_in_leaf': 57, 'lambda_l1': 0.07756805746407562, 'lambda_l2': 1.5250891574973198} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.47450165248771964, 'max_depth': 45, 'num_leaves': 301, 'min_data_in_leaf': 46, 'lambda_l1': 0.030457807539796516, 'lambda_l2': 3.0617705486305047} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3211466514035037, 'max_depth': 42, 'num_leaves': 483, 'min_data_in_leaf': 33, 'lambda_l1': 0.06341105565612257, 'lambda_l2': 4.706931660406003} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5587838711929571, 'max_depth': 52, 'num_leaves': 813, 'min_data_in_leaf': 31, 'lambda_l1': 0.10033368784532648, 'lambda_l2': 2.7871759802099296} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.38879987986843595, 'max_depth': 36, 'num_leaves': 372, 'min_data_in_leaf': 36, 'lambda_l1': 0.04914939961867987, 'lambda_l2': 4.560622374652582} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4334472067710307, 'max_depth': 39, 'num_leaves': 55, 'min_data_in_leaf': 40, 'lambda_l1': 0.2649430859584001, 'lambda_l2': 1.732936982615935} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6333602329150709, 'max_depth': 47, 'num_leaves': 1270, 'min_data_in_leaf': 43, 'lambda_l1': 0.1258215947281363, 'lambda_l2': 4.9074988175624235} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.8965418860473213, 'max_depth': 44, 'num_leaves': 567, 'min_data_in_leaf': 35, 'lambda_l1': 0.08464603369445481, 'lambda_l2': 2.9055423560373104} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.251739951978843, 'max_depth': 41, 'num_leaves': 1715, 'min_data_in_leaf': 28, 'lambda_l1': 0.5764661949010504, 'lambda_l2': 3.6784285645067474} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5190121018527977, 'max_depth': 49, 'num_leaves': 210, 'min_data_in_leaf': 41, 'lambda_l1': 0.4973726167354957, 'lambda_l2': 3.238439572088155} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3440136412990638, 'max_depth': 34, 'num_leaves': 3776, 'min_data_in_leaf': 25, 'lambda_l1': 0.15436043615263964, 'lambda_l2': 4.05079335639476} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7542015107696616, 'max_depth': 43, 'num_leaves': 728, 'min_data_in_leaf': 33, 'lambda_l1': 0.06352505282045329, 'lambda_l2': 3.469182127848488} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4413756492700773, 'max_depth': 39, 'num_leaves': 465, 'min_data_in_leaf': 30, 'lambda_l1': 0.3716984546421834, 'lambda_l2': 1.1653801466672258} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5002682113709489, 'max_depth': 46, 'num_leaves': 630, 'min_data_in_leaf': 52, 'lambda_l1': 0.1048426870580352, 'lambda_l2': 3.7856022435869177} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5875663772109108, 'max_depth': 54, 'num_leaves': 296, 'min_data_in_leaf': 37, 'lambda_l1': 0.45676717661560784, 'lambda_l2': 3.3219216951178154} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6944877780172675, 'max_depth': 37, 'num_leaves': 548, 'min_data_in_leaf': 40, 'lambda_l1': 0.0403681390399176, 'lambda_l2': 2.6367047372911587} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.39547805152808574, 'max_depth': 4, 'num_leaves': 413, 'min_data_in_leaf': 35, 'lambda_l1': 0.026169562880039663, 'lambda_l2': 2.9868540969726287} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5101482861924614, 'max_depth': 41, 'num_leaves': 2172, 'min_data_in_leaf': 23, 'lambda_l1': 0.1365463690481188, 'lambda_l2': 3.1352027985712465} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.29841913099379624, 'max_depth': 51, 'num_leaves': 809, 'min_data_in_leaf': 27, 'lambda_l1': 0.07658365600557035, 'lambda_l2': 0.792995452206425} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5987815458407568, 'max_depth': 44, 'num_leaves': 1527, 'min_data_in_leaf': 20, 'lambda_l1': 0.3414549601756672, 'lambda_l2': 2.7645952098396243} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4344611373168147, 'max_depth': 10, 'num_leaves': 361, 'min_data_in_leaf': 44, 'lambda_l1': 0.10533013228696413, 'lambda_l2': 4.445413033718651} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7963630971151916, 'max_depth': 48, 'num_leaves': 183, 'min_data_in_leaf': 38, 'lambda_l1': 0.41857663312860927, 'lambda_l2': 4.320982104696453} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35039232328071296, 'max_depth': 36, 'num_leaves': 697, 'min_data_in_leaf': 31, 'lambda_l1': 0.16875608645232823, 'lambda_l2': 3.61599673270272} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.1794414873309698, 'max_depth': 40, 'num_leaves': 615, 'min_data_in_leaf': 33, 'lambda_l1': 0.05843482463770283, 'lambda_l2': 4.732874124217268} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.498971180533521, 'max_depth': 45, 'num_leaves': 521, 'min_data_in_leaf': 39, 'lambda_l1': 0.0850677417274567, 'lambda_l2': 3.3975386001015986} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5786554756531386, 'max_depth': 38, 'num_leaves': 465, 'min_data_in_leaf': 36, 'lambda_l1': 0.017674413093507545, 'lambda_l2': 3.2071475279625576} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.38740336735049796, 'max_depth': 42, 'num_leaves': 275, 'min_data_in_leaf': 42, 'lambda_l1': 0.43699939887077943, 'lambda_l2': 1.0506612641769375} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3208197441659026, 'max_depth': 14, 'num_leaves': 247, 'min_data_in_leaf': 42, 'lambda_l1': 0.43691926388270486, 'lambda_l2': 0.7186078224211176} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27402613060216324, 'max_depth': 34, 'num_leaves': 304, 'min_data_in_leaf': 43, 'lambda_l1': 0.43106876260189886, 'lambda_l2': 1.1966928707932043} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.38263748019467697, 'max_depth': 42, 'num_leaves': 401, 'min_data_in_leaf': 48, 'lambda_l1': 0.3970037046749567, 'lambda_l2': 1.0023796781367276} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3975438431715187, 'max_depth': 39, 'num_leaves': 137, 'min_data_in_leaf': 45, 'lambda_l1': 0.44646219683675514, 'lambda_l2': 1.4086322901255484} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.45018522318377263, 'max_depth': 49, 'num_leaves': 299, 'min_data_in_leaf': 98, 'lambda_l1': 0.47936207516176116, 'lambda_l2': 1.0868253813341153} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4129126043454026, 'max_depth': 47, 'num_leaves': 230, 'min_data_in_leaf': 41, 'lambda_l1': 0.4617773406122241, 'lambda_l2': 1.0129936023515156} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3406969653410015, 'max_depth': 41, 'num_leaves': 1056, 'min_data_in_leaf': 39, 'lambda_l1': 0.4047890280885038, 'lambda_l2': 0.9656553248827738} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2844855058437835, 'max_depth': 36, 'num_leaves': 353, 'min_data_in_leaf': 42, 'lambda_l1': 0.510332286980596, 'lambda_l2': 1.1085180840240998} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3609363695911001, 'max_depth': 38, 'num_leaves': 146, 'min_data_in_leaf': 40, 'lambda_l1': 0.3783391879639037, 'lambda_l2': 0.9051428479314407} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.47746555910301114, 'max_depth': 43, 'num_leaves': 965, 'min_data_in_leaf': 47, 'lambda_l1': 0.6405134846621848, 'lambda_l2': 0.8645218146499278} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.12151532574021923, 'max_depth': 17, 'num_leaves': 456, 'min_data_in_leaf': 37, 'lambda_l1': 0.5487944991424235, 'lambda_l2': 3.932464672045909} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4572885537781645, 'max_depth': 50, 'num_leaves': 60, 'min_data_in_leaf': 38, 'lambda_l1': 0.41375286998304434, 'lambda_l2': 2.3986940255820937} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5211430617104074, 'max_depth': 52, 'num_leaves': 89, 'min_data_in_leaf': 38, 'lambda_l1': 0.4223117869226631, 'lambda_l2': 1.6161387671454135} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.44806535201739733, 'max_depth': 50, 'num_leaves': 93, 'min_data_in_leaf': 44, 'lambda_l1': 0.001070362153862038, 'lambda_l2': 2.4389610599544502} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.49271327661282904, 'max_depth': 54, 'num_leaves': 176, 'min_data_in_leaf': 40, 'lambda_l1': 0.23810130728856335, 'lambda_l2': 2.7006427100250523} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6862879032365713, 'max_depth': 50, 'num_leaves': 216, 'min_data_in_leaf': 37, 'lambda_l1': 0.39108279372752036, 'lambda_l2': 4.105329052795732} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5575952833324587, 'max_depth': 87, 'num_leaves': 69, 'min_data_in_leaf': 42, 'lambda_l1': 0.044107617933767176, 'lambda_l2': 2.3501751338943335} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.42187206669854393, 'max_depth': 52, 'num_leaves': 244, 'min_data_in_leaf': 35, 'lambda_l1': 0.07218330895427243, 'lambda_l2': 1.8153230512474432} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6394517686161493, 'max_depth': 48, 'num_leaves': 121, 'min_data_in_leaf': 39, 'lambda_l1': 0.35336894643400146, 'lambda_l2': 4.811253201106964} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.46551045027934806, 'max_depth': 47, 'num_leaves': 54, 'min_data_in_leaf': 37, 'lambda_l1': 0.05411594968436921, 'lambda_l2': 2.838586019403436} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.39112183387121247, 'max_depth': 45, 'num_leaves': 335, 'min_data_in_leaf': 35, 'lambda_l1': 0.606944741529113, 'lambda_l2': 2.064026493809414} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5518611335895696, 'max_depth': 50, 'num_leaves': 278, 'min_data_in_leaf': 41, 'lambda_l1': 0.41576990869528296, 'lambda_l2': 1.9115474143426054} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.8676196072039309, 'max_depth': 33, 'num_leaves': 163, 'min_data_in_leaf': 39, 'lambda_l1': 0.04143674773367912, 'lambda_l2': 1.2610285654002649} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.680560171432433, 'max_depth': 46, 'num_leaves': 1134, 'min_data_in_leaf': 45, 'lambda_l1': 0.029161866099829695, 'lambda_l2': 2.5497884544828553} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.9959406583469544, 'max_depth': 48, 'num_leaves': 385, 'min_data_in_leaf': 34, 'lambda_l1': 0.08942212758095769, 'lambda_l2': 4.606136113738528} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5064424226301049, 'max_depth': 52, 'num_leaves': 508, 'min_data_in_leaf': 37, 'lambda_l1': 0.19752068777571863, 'lambda_l2': 0.6353523125022258} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4181961780130209, 'max_depth': 44, 'num_leaves': 405, 'min_data_in_leaf': 43, 'lambda_l1': 0.3225103803630587, 'lambda_l2': 2.2242887150066366} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5899612702641793, 'max_depth': 56, 'num_leaves': 184, 'min_data_in_leaf': 54, 'lambda_l1': 0.4070084370732244, 'lambda_l2': 4.976605065038023} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3746007965179517, 'max_depth': 50, 'num_leaves': 59, 'min_data_in_leaf': 40, 'lambda_l1': 0.06773985129099805, 'lambda_l2': 4.673528787217553} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4693584590984246, 'max_depth': 36, 'num_leaves': 1231, 'min_data_in_leaf': 36, 'lambda_l1': 0.8972725360742627, 'lambda_l2': 2.9052787768165915} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.006728690417434616, 'max_depth': 46, 'num_leaves': 1635, 'min_data_in_leaf': 33, 'lambda_l1': 0.37574967938898046, 'lambda_l2': 4.881465857264453} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7418465671699723, 'max_depth': 42, 'num_leaves': 1947, 'min_data_in_leaf': 50, 'lambda_l1': 0.5782568859114836, 'lambda_l2': 2.643962171206463} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5302267528543457, 'max_depth': 40, 'num_leaves': 271, 'min_data_in_leaf': 38, 'lambda_l1': 0.2806994260688895, 'lambda_l2': 0.7752249787143702} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6550064499641584, 'max_depth': 31, 'num_leaves': 1437, 'min_data_in_leaf': 41, 'lambda_l1': 0.5256235971191262, 'lambda_l2': 3.8580016680181766} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4400537463081926, 'max_depth': 48, 'num_leaves': 590, 'min_data_in_leaf': 35, 'lambda_l1': 0.09570184662285197, 'lambda_l2': 1.3568162039575602} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3590551505662725, 'max_depth': 45, 'num_leaves': 479, 'min_data_in_leaf': 12, 'lambda_l1': 0.06327164011352134, 'lambda_l2': 1.0820076949110427} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5717650599871489, 'max_depth': 35, 'num_leaves': 302, 'min_data_in_leaf': 43, 'lambda_l1': 0.027289738855639345, 'lambda_l2': 4.2169407345500565} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47643963024904623, 'max_depth': 38, 'num_leaves': 1820, 'min_data_in_leaf': 39, 'lambda_l1': 0.04849986484813859, 'lambda_l2': 1.217330367377757} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33150014010579026, 'max_depth': 53, 'num_leaves': 3896, 'min_data_in_leaf': 33, 'lambda_l1': 0.4435656451159322, 'lambda_l2': 0.14608690708148311} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7834951711946961, 'max_depth': 42, 'num_leaves': 397, 'min_data_in_leaf': 46, 'lambda_l1': 0.4935778952377985, 'lambda_l2': 0.8527420906707217} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.001703833566491349, 'max_depth': 40, 'num_leaves': 159, 'min_data_in_leaf': 37, 'lambda_l1': 0.07948405131543103, 'lambda_l2': 2.708716455195676} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6220265762758985, 'max_depth': 33, 'num_leaves': 535, 'min_data_in_leaf': 41, 'lambda_l1': 0.11011109955669099, 'lambda_l2': 3.7423862584071985} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4152762997137962, 'max_depth': 43, 'num_leaves': 234, 'min_data_in_leaf': 35, 'lambda_l1': 0.01952513056400418, 'lambda_l2': 2.8291577523084745} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5314280469018611, 'max_depth': 50, 'num_leaves': 624, 'min_data_in_leaf': 38, 'lambda_l1': 0.552420797885683, 'lambda_l2': 3.0110475396893346} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3799802148975925, 'max_depth': 37, 'num_leaves': 882, 'min_data_in_leaf': 32, 'lambda_l1': 0.09138559958224754, 'lambda_l2': 4.79383528585962} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.46712711042451704, 'max_depth': 46, 'num_leaves': 3577, 'min_data_in_leaf': 36, 'lambda_l1': 0.47539913551223567, 'lambda_l2': 4.509905922243882} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6187895185419647, 'max_depth': 44, 'num_leaves': 362, 'min_data_in_leaf': 63, 'lambda_l1': 0.6295373568768012, 'lambda_l2': 4.0044458064802795} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.541051532620906, 'max_depth': 47, 'num_leaves': 737, 'min_data_in_leaf': 42, 'lambda_l1': 0.06447145426925081, 'lambda_l2': 2.9409146607561834} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32387836096915257, 'max_depth': 39, 'num_leaves': 480, 'min_data_in_leaf': 24, 'lambda_l1': 0.03928251661259897, 'lambda_l2': 0.0014197643257553016} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6955022674093706, 'max_depth': 41, 'num_leaves': 579, 'min_data_in_leaf': 39, 'lambda_l1': 0.5896350913086811, 'lambda_l2': 0.9873033020561486} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.41535569698099445, 'max_depth': 49, 'num_leaves': 316, 'min_data_in_leaf': 31, 'lambda_l1': 8.856260838263673e-05, 'lambda_l2': 4.697159175349863} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24348220094664724, 'max_depth': 35, 'num_leaves': 449, 'min_data_in_leaf': 35, 'lambda_l1': 0.42915820659442044, 'lambda_l2': 4.353883435853117} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.8517254088261184, 'max_depth': 38, 'num_leaves': 1310, 'min_data_in_leaf': 40, 'lambda_l1': 0.3970733468383929, 'lambda_l2': 3.072642705685258} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.50233907137058, 'max_depth': 43, 'num_leaves': 54, 'min_data_in_leaf': 44, 'lambda_l1': 0.08267730974005148, 'lambda_l2': 2.550477485153322} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4452088744865564, 'max_depth': 48, 'num_leaves': 190, 'min_data_in_leaf': 33, 'lambda_l1': 0.10673828074405782, 'lambda_l2': 0.516856042771765} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.38283469561133177, 'max_depth': 52, 'num_leaves': 161, 'min_data_in_leaf': 33, 'lambda_l1': 0.12410875030925861, 'lambda_l2': 0.499370562424461} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31209135163930973, 'max_depth': 51, 'num_leaves': 214, 'min_data_in_leaf': 30, 'lambda_l1': 0.14136077825966695, 'lambda_l2': 0.4513034584648225} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4429872009093836, 'max_depth': 54, 'num_leaves': 140, 'min_data_in_leaf': 33, 'lambda_l1': 0.0907874283466771, 'lambda_l2': 0.6744131562600437} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3518323594377088, 'max_depth': 48, 'num_leaves': 236, 'min_data_in_leaf': 28, 'lambda_l1': 0.11369955190310581, 'lambda_l2': 0.5932103039605156} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4247684716651888, 'max_depth': 34, 'num_leaves': 130, 'min_data_in_leaf': 36, 'lambda_l1': 0.11429291401193098, 'lambda_l2': 0.33483591478257546} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4724143561316771, 'max_depth': 50, 'num_leaves': 261, 'min_data_in_leaf': 18, 'lambda_l1': 0.06768833877767343, 'lambda_l2': 0.5183376445366996} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2827957480789284, 'max_depth': 37, 'num_leaves': 352, 'min_data_in_leaf': 31, 'lambda_l1': 0.45671631286748277, 'lambda_l2': 0.7268254581042238} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5619631739961268, 'max_depth': 31, 'num_leaves': 183, 'min_data_in_leaf': 34, 'lambda_l1': 0.09972884566604545, 'lambda_l2': 0.6064654581967244} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3821621535571074, 'max_depth': 40, 'num_leaves': 104, 'min_data_in_leaf': 22, 'lambda_l1': 0.21938132358356124, 'lambda_l2': 0.848177816316364} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6365867932832612, 'max_depth': 48, 'num_leaves': 280, 'min_data_in_leaf': 29, 'lambda_l1': 0.16737810231519923, 'lambda_l2': 0.2188571311458516} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.20763150717413262, 'max_depth': 29, 'num_leaves': 371, 'min_data_in_leaf': 37, 'lambda_l1': 0.14367431774097153, 'lambda_l2': 1.4674290550545392} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.7662284934472248, 'max_depth': 92, 'num_leaves': 1099, 'min_data_in_leaf': 32, 'lambda_l1': 0.07151211634959173, 'lambda_l2': 3.8832121096764403} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.09192139140575999, 'max_depth': 45, 'num_leaves': 228, 'min_data_in_leaf': 26, 'lambda_l1': 0.3060796121400911, 'lambda_l2': 4.897680808725063} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.47923085052912445, 'max_depth': 41, 'num_leaves': 118, 'min_data_in_leaf': 34, 'lambda_l1': 0.10081241197812632, 'lambda_l2': 1.159136121308646} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4006420141519761, 'max_depth': 39, 'num_leaves': 327, 'min_data_in_leaf': 37, 'lambda_l1': 0.5239632686835997, 'lambda_l2': 0.9272652816245144} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5517102336467876, 'max_depth': 56, 'num_leaves': 2097, 'min_data_in_leaf': 39, 'lambda_l1': 0.12134103598808954, 'lambda_l2': 1.0330935726609625} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.34282133617234534, 'max_depth': 36, 'num_leaves': 428, 'min_data_in_leaf': 35, 'lambda_l1': 0.0833544002426607, 'lambda_l2': 0.4776753023875393} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.45044130904787577, 'max_depth': 43, 'num_leaves': 1388, 'min_data_in_leaf': 28, 'lambda_l1': 0.060540421512247186, 'lambda_l2': 3.6235937650116012} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6545018025426054, 'max_depth': 47, 'num_leaves': 54, 'min_data_in_leaf': 25, 'lambda_l1': 0.40919506379664494, 'lambda_l2': 2.7328941123750297} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.9075161161519436, 'max_depth': 51, 'num_leaves': 291, 'min_data_in_leaf': 32, 'lambda_l1': 0.3742417907684916, 'lambda_l2': 4.772514754081125} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5129336855104653, 'max_depth': 33, 'num_leaves': 200, 'min_data_in_leaf': 41, 'lambda_l1': 0.09576443365962317, 'lambda_l2': 0.37958199825629174} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5869468717910435, 'max_depth': 38, 'num_leaves': 502, 'min_data_in_leaf': 38, 'lambda_l1': 0.5689935843496218, 'lambda_l2': 4.5742327299674175} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.30611721817520265, 'max_depth': 45, 'num_leaves': 420, 'min_data_in_leaf': 36, 'lambda_l1': 0.053605695382527234, 'lambda_l2': 3.784296438829497} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.42029532735538644, 'max_depth': 41, 'num_leaves': 326, 'min_data_in_leaf': 34, 'lambda_l1': 0.12856164251035868, 'lambda_l2': 0.6977795295253235} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3846502637528058, 'max_depth': 42, 'num_leaves': 205, 'min_data_in_leaf': 30, 'lambda_l1': 0.1289427703043391, 'lambda_l2': 0.5532054538857634} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.7447635970188573, 'max_depth': 41, 'num_leaves': 979, 'min_data_in_leaf': 34, 'lambda_l1': 0.14843016723738472, 'lambda_l2': 0.6514677706880017} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4365918434752941, 'max_depth': 44, 'num_leaves': 307, 'min_data_in_leaf': 88, 'lambda_l1': 0.1531136478094075, 'lambda_l2': 0.729384366402284} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5040088284954236, 'max_depth': 49, 'num_leaves': 50, 'min_data_in_leaf': 31, 'lambda_l1': 0.12370206432843285, 'lambda_l2': 0.8225135741963692} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.34744100287290464, 'max_depth': 24, 'num_leaves': 1495, 'min_data_in_leaf': 27, 'lambda_l1': 0.11094675732950962, 'lambda_l2': 0.6783164490344112} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.012166775549079772, 'max_depth': 6, 'num_leaves': 1188, 'min_data_in_leaf': 23, 'lambda_l1': 0.48381288262975375, 'lambda_l2': 0.5757448434443468} : acc= 51.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6484009226746689, 'max_depth': 40, 'num_leaves': 145, 'min_data_in_leaf': 33, 'lambda_l1': 0.13322775966131922, 'lambda_l2': 0.40487070989992713} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.06468135916921822, 'max_depth': 46, 'num_leaves': 255, 'min_data_in_leaf': 39, 'lambda_l1': 0.18584780883792992, 'lambda_l2': 0.7661126523703947} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5751071825640289, 'max_depth': 43, 'num_leaves': 174, 'min_data_in_leaf': 42, 'lambda_l1': 0.4407710921344905, 'lambda_l2': 0.9222409662747124} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.43646794352606366, 'max_depth': 42, 'num_leaves': 373, 'min_data_in_leaf': 29, 'lambda_l1': 0.34530245194919906, 'lambda_l2': 4.116048267202528} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3762248567625715, 'max_depth': 47, 'num_leaves': 2214, 'min_data_in_leaf': 37, 'lambda_l1': 0.5043401569990811, 'lambda_l2': 0.49002078079422107} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.511565111347804, 'max_depth': 81, 'num_leaves': 334, 'min_data_in_leaf': 33, 'lambda_l1': 0.10243426967423744, 'lambda_l2': 2.2950257070926834} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.30617607034832456, 'max_depth': 53, 'num_leaves': 275, 'min_data_in_leaf': 40, 'lambda_l1': 0.5409506189872676, 'lambda_l2': 0.8285844105643676} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7787019281015951, 'max_depth': 11, 'num_leaves': 423, 'min_data_in_leaf': 35, 'lambda_l1': 0.25273133447283613, 'lambda_l2': 0.6414850259591025} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6658839694377572, 'max_depth': 39, 'num_leaves': 120, 'min_data_in_leaf': 26, 'lambda_l1': 0.5971978038746805, 'lambda_l2': 1.063010276657148} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.47590326159774504, 'max_depth': 45, 'num_leaves': 549, 'min_data_in_leaf': 30, 'lambda_l1': 0.4627050550591924, 'lambda_l2': 0.9536383813501971} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.24482598547244042, 'max_depth': 49, 'num_leaves': 353, 'min_data_in_leaf': 38, 'lambda_l1': 0.4243684943087364, 'lambda_l2': 0.7023745449203187} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5698525911863275, 'max_depth': 41, 'num_leaves': 3445, 'min_data_in_leaf': 1, 'lambda_l1': 0.16665553934126343, 'lambda_l2': 2.4158526742274775} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4180020138047023, 'max_depth': 44, 'num_leaves': 1040, 'min_data_in_leaf': 43, 'lambda_l1': 0.08318174993888904, 'lambda_l2': 1.3142501891694423} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.15087926624934603, 'max_depth': 38, 'num_leaves': 213, 'min_data_in_leaf': 32, 'lambda_l1': 0.11189864834379849, 'lambda_l2': 4.99893370024628} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.36728323972333565, 'max_depth': 51, 'num_leaves': 1906, 'min_data_in_leaf': 24, 'lambda_l1': 0.3882771813755721, 'lambda_l2': 0.2831425884412052} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.507214256418593, 'max_depth': 47, 'num_leaves': 50, 'min_data_in_leaf': 21, 'lambda_l1': 0.12788559177599002, 'lambda_l2': 4.667667254785983} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6876606595235234, 'max_depth': 40, 'num_leaves': 1689, 'min_data_in_leaf': 36, 'lambda_l1': 0.09132063938963274, 'lambda_l2': 1.182524006799645} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5928429323505862, 'max_depth': 44, 'num_leaves': 1272, 'min_data_in_leaf': 34, 'lambda_l1': 0.5626067427891941, 'lambda_l2': 2.799655529045272} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.9999166688886608, 'max_depth': 42, 'num_leaves': 491, 'min_data_in_leaf': 40, 'lambda_l1': 0.07352010134789412, 'lambda_l2': 1.6748732233700154} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.42324205073331367, 'max_depth': 15, 'num_leaves': 270, 'min_data_in_leaf': 29, 'lambda_l1': 0.1379276336015624, 'lambda_l2': 2.1174581604141522} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.8495029075680423, 'max_depth': 20, 'num_leaves': 650, 'min_data_in_leaf': 38, 'lambda_l1': 0.622450783997377, 'lambda_l2': 1.9678702246524595} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.33938631473636943, 'max_depth': 49, 'num_leaves': 868, 'min_data_in_leaf': 27, 'lambda_l1': 0.060326962111556526, 'lambda_l2': 2.602252139630729} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2848276753760726, 'max_depth': 38, 'num_leaves': 391, 'min_data_in_leaf': 45, 'lambda_l1': 0.04503486469713014, 'lambda_l2': 4.427391045345685} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5112156337219632, 'max_depth': 8, 'num_leaves': 133, 'min_data_in_leaf': 42, 'lambda_l1': 0.10902163643832816, 'lambda_l2': 4.803894293821688} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.39602043172599904, 'max_depth': 54, 'num_leaves': 2011, 'min_data_in_leaf': 35, 'lambda_l1': 0.08471924836745637, 'lambda_l2': 0.5139886058526476} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.46671430070196257, 'max_depth': 36, 'num_leaves': 773, 'min_data_in_leaf': 31, 'lambda_l1': 0.4107773374404157, 'lambda_l2': 0.8577184809328416} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5987145990979387, 'max_depth': 46, 'num_leaves': 2363, 'min_data_in_leaf': 40, 'lambda_l1': 0.5028522186653933, 'lambda_l2': 3.75716203026188} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5315294439204111, 'max_depth': 40, 'num_leaves': 576, 'min_data_in_leaf': 38, 'lambda_l1': 0.9951139406913656, 'lambda_l2': 3.9763428043893656} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.7106771137424983, 'max_depth': 43, 'num_leaves': 229, 'min_data_in_leaf': 36, 'lambda_l1': 0.6651234945656279, 'lambda_l2': 0.11515594693462264} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.33818752243890293, 'max_depth': 48, 'num_leaves': 457, 'min_data_in_leaf': 32, 'lambda_l1': 0.5371998405098968, 'lambda_l2': 0.410042771567926} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.45306870630114543, 'max_depth': 51, 'num_leaves': 168, 'min_data_in_leaf': 25, 'lambda_l1': 0.3658886128387539, 'lambda_l2': 2.8827867660167357} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6084257105294636, 'max_depth': 1, 'num_leaves': 329, 'min_data_in_leaf': 19, 'lambda_l1': 0.1047863500804731, 'lambda_l2': 3.6585670222766744} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40509189541786567, 'max_depth': 41, 'num_leaves': 1764, 'min_data_in_leaf': 34, 'lambda_l1': 0.4568487406731412, 'lambda_l2': 0.5999704270363084} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.765357928957453, 'max_depth': 37, 'num_leaves': 1601, 'min_data_in_leaf': 42, 'lambda_l1': 0.14814573800360928, 'lambda_l2': 4.898044544867963} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.01933409451405564, 'max_depth': 45, 'num_leaves': 519, 'min_data_in_leaf': 28, 'lambda_l1': 0.07456069816585993, 'lambda_l2': 0.7561464653778893} : acc= 55.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4837627641792764, 'max_depth': 42, 'num_leaves': 703, 'min_data_in_leaf': 37, 'lambda_l1': 0.046966370580857994, 'lambda_l2': 3.5370558232064386} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.541523933677564, 'max_depth': 27, 'num_leaves': 398, 'min_data_in_leaf': 44, 'lambda_l1': 0.4736652685363628, 'lambda_l2': 4.221823585992087} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.374982284481303, 'max_depth': 39, 'num_leaves': 1134, 'min_data_in_leaf': 39, 'lambda_l1': 0.12874687712739677, 'lambda_l2': 4.615734912910661} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6581854681583086, 'max_depth': 47, 'num_leaves': 280, 'min_data_in_leaf': 34, 'lambda_l1': 0.093280952484795, 'lambda_l2': 1.0518506997207533} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44250541443742575, 'max_depth': 44, 'num_leaves': 120, 'min_data_in_leaf': 31, 'lambda_l1': 0.4362205558619752, 'lambda_l2': 2.750068388201663} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2743943271772736, 'max_depth': 50, 'num_leaves': 558, 'min_data_in_leaf': 41, 'lambda_l1': 0.2798622726237773, 'lambda_l2': 4.725170893730874} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.310303193507426, 'max_depth': 39, 'num_leaves': 954, 'min_data_in_leaf': 36, 'lambda_l1': 0.1963052202792016, 'lambda_l2': 3.8672006592134487} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5563628752595546, 'max_depth': 48, 'num_leaves': 199, 'min_data_in_leaf': 27, 'lambda_l1': 0.3935034293840537, 'lambda_l2': 0.9184863053019017} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.8201274839948732, 'max_depth': 37, 'num_leaves': 630, 'min_data_in_leaf': 15, 'lambda_l1': 0.5202504309572596, 'lambda_l2': 0.5721039265397497} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3664694615196982, 'max_depth': 42, 'num_leaves': 2278, 'min_data_in_leaf': 24, 'lambda_l1': 0.06441776494581287, 'lambda_l2': 4.827547730302056} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4732558774519007, 'max_depth': 35, 'num_leaves': 368, 'min_data_in_leaf': 29, 'lambda_l1': 0.10818296990983636, 'lambda_l2': 0.7919003001754853} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6182282491209992, 'max_depth': 46, 'num_leaves': 425, 'min_data_in_leaf': 38, 'lambda_l1': 0.7290893654087467, 'lambda_l2': 4.515916116778727} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4164877726041094, 'max_depth': 52, 'num_leaves': 2502, 'min_data_in_leaf': 33, 'lambda_l1': 0.5838858827596771, 'lambda_l2': 1.0962045951200952} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6946347474027675, 'max_depth': 40, 'num_leaves': 300, 'min_data_in_leaf': 22, 'lambda_l1': 0.08142396987874621, 'lambda_l2': 2.928844237328805} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5119081573981336, 'max_depth': 44, 'num_leaves': 2158, 'min_data_in_leaf': 40, 'lambda_l1': 0.03935832498072911, 'lambda_l2': 0.6773831866506268} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3284149477269279, 'max_depth': 49, 'num_leaves': 832, 'min_data_in_leaf': 35, 'lambda_l1': 0.05808807375370381, 'lambda_l2': 3.7024796243009424} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42223984255454433, 'max_depth': 41, 'num_leaves': 52, 'min_data_in_leaf': 32, 'lambda_l1': 0.33553612412648937, 'lambda_l2': 2.6692578673747995} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5855477648609714, 'max_depth': 38, 'num_leaves': 489, 'min_data_in_leaf': 37, 'lambda_l1': 0.1213422716379101, 'lambda_l2': 0.3163862107042048} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4736915290165729, 'max_depth': 34, 'num_leaves': 231, 'min_data_in_leaf': 44, 'lambda_l1': 0.16839517821429978, 'lambda_l2': 0.45710113005014424} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.873830750431929, 'max_depth': 75, 'num_leaves': 621, 'min_data_in_leaf': 47, 'lambda_l1': 0.09457623702894433, 'lambda_l2': 3.5467183334259493} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.55890138883994, 'max_depth': 46, 'num_leaves': 1411, 'min_data_in_leaf': 41, 'lambda_l1': 0.4178190617634031, 'lambda_l2': 0.9851954576563624} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3629789819457195, 'max_depth': 43, 'num_leaves': 343, 'min_data_in_leaf': 39, 'lambda_l1': 0.48510162559647485, 'lambda_l2': 1.5665049061629237} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6877405270581337, 'max_depth': 53, 'num_leaves': 137, 'min_data_in_leaf': 30, 'lambda_l1': 0.0729309173997293, 'lambda_l2': 0.8361902653671218} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.49730464801908464, 'max_depth': 37, 'num_leaves': 1235, 'min_data_in_leaf': 25, 'lambda_l1': 0.5638266468928036, 'lambda_l2': 4.66102866809508} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.40121779109317957, 'max_depth': 50, 'num_leaves': 455, 'min_data_in_leaf': 34, 'lambda_l1': 0.03452254667760341, 'lambda_l2': 2.8314288554151466} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7564319275383649, 'max_depth': 32, 'num_leaves': 540, 'min_data_in_leaf': 36, 'lambda_l1': 0.1424995596182308, 'lambda_l2': 3.0053319896867117} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.23222960115124905, 'max_depth': 41, 'num_leaves': 757, 'min_data_in_leaf': 43, 'lambda_l1': 0.09262260013732077, 'lambda_l2': 4.012750727023193} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2966522290704835, 'max_depth': 45, 'num_leaves': 250, 'min_data_in_leaf': 27, 'lambda_l1': 0.44366223050122294, 'lambda_l2': 2.526530039439563} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.02824599334197745, 'max_depth': 48, 'num_leaves': 1040, 'min_data_in_leaf': 38, 'lambda_l1': 0.11546807074144758, 'lambda_l2': 0.6454775527523622} : acc= 58.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6136032042701492, 'max_depth': 39, 'num_leaves': 344, 'min_data_in_leaf': 31, 'lambda_l1': 0.6018364045261478, 'lambda_l2': 0.19626639564993523} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.04695401978818128, 'max_depth': 36, 'num_leaves': 673, 'min_data_in_leaf': 41, 'lambda_l1': 0.05578075955765553, 'lambda_l2': 1.1426815325258004} : acc= 62.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4431239636422446, 'max_depth': 43, 'num_leaves': 178, 'min_data_in_leaf': 34, 'lambda_l1': 0.38222301238124634, 'lambda_l2': 1.272246341772636} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.533362553965966, 'max_depth': 47, 'num_leaves': 446, 'min_data_in_leaf': 36, 'lambda_l1': 0.21948721697250256, 'lambda_l2': 3.781657073416838} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.036641374307704665, 'max_depth': 51, 'num_leaves': 110, 'min_data_in_leaf': 39, 'lambda_l1': 0.07807047967981037, 'lambda_l2': 4.753286751751534} : acc= 61.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3570740860347819, 'max_depth': 29, 'num_leaves': 266, 'min_data_in_leaf': 21, 'lambda_l1': 0.30837020928022235, 'lambda_l2': 4.319366683529085} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4632562156234364, 'max_depth': 40, 'num_leaves': 582, 'min_data_in_leaf': 29, 'lambda_l1': 0.35229150692312106, 'lambda_l2': 4.911038455183227} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40084079688002233, 'max_depth': 45, 'num_leaves': 2623, 'min_data_in_leaf': 32, 'lambda_l1': 0.10778738401629394, 'lambda_l2': 0.5341553002014674} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6428893363184665, 'max_depth': 43, 'num_leaves': 395, 'min_data_in_leaf': 23, 'lambda_l1': 0.05614488886093742, 'lambda_l2': 0.9136608541719471} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5392139001696684, 'max_depth': 49, 'num_leaves': 924, 'min_data_in_leaf': 37, 'lambda_l1': 0.030924861095480836, 'lambda_l2': 3.918735529510406} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.7221434191420156, 'max_depth': 35, 'num_leaves': 498, 'min_data_in_leaf': 34, 'lambda_l1': 0.5130821894883913, 'lambda_l2': 4.155642870368033} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.8850154451277149, 'max_depth': 55, 'num_leaves': 304, 'min_data_in_leaf': 46, 'lambda_l1': 0.07606195541595914, 'lambda_l2': 0.7220408719270328} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3225511551434974, 'max_depth': 39, 'num_leaves': 2037, 'min_data_in_leaf': 41, 'lambda_l1': 0.1318948615561643, 'lambda_l2': 2.8275459858263905} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4919160980152754, 'max_depth': 42, 'num_leaves': 200, 'min_data_in_leaf': 27, 'lambda_l1': 0.40607795070565017, 'lambda_l2': 0.4275795929233416} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.412656388917808, 'max_depth': 58, 'num_leaves': 706, 'min_data_in_leaf': 39, 'lambda_l1': 0.5463755451277431, 'lambda_l2': 3.5984202416911035} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5760341347392546, 'max_depth': 22, 'num_leaves': 51, 'min_data_in_leaf': 43, 'lambda_l1': 0.09587799996332148, 'lambda_l2': 1.055461445734545} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.36838609362754, 'max_depth': 4, 'num_leaves': 423, 'min_data_in_leaf': 36, 'lambda_l1': 0.06971140440047824, 'lambda_l2': 1.4227312559913672} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.45646108453541223, 'max_depth': 37, 'num_leaves': 1139, 'min_data_in_leaf': 32, 'lambda_l1': 0.11838660357409937, 'lambda_l2': 2.673942444673266} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6492930925862984, 'max_depth': 46, 'num_leaves': 593, 'min_data_in_leaf': 25, 'lambda_l1': 0.42626896749923493, 'lambda_l2': 4.61565259336388} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5283244038990679, 'max_depth': 40, 'num_leaves': 3755, 'min_data_in_leaf': 38, 'lambda_l1': 0.0433778705024534, 'lambda_l2': 4.786748497386678} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.7833274234822984, 'max_depth': 48, 'num_leaves': 340, 'min_data_in_leaf': 29, 'lambda_l1': 0.461573597089638, 'lambda_l2': 2.995556921469395} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2830651653142107, 'max_depth': 52, 'num_leaves': 811, 'min_data_in_leaf': 35, 'lambda_l1': 0.1575246673116066, 'lambda_l2': 0.8042792602126216} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.44044467447567986, 'max_depth': 44, 'num_leaves': 135, 'min_data_in_leaf': 40, 'lambda_l1': 0.17901808902258137, 'lambda_l2': 0.9636699069480412} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5960467261007643, 'max_depth': 41, 'num_leaves': 1310, 'min_data_in_leaf': 33, 'lambda_l1': 0.0785095450233717, 'lambda_l2': 0.10984970831606167} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.33313762656183793, 'max_depth': 32, 'num_leaves': 1556, 'min_data_in_leaf': 30, 'lambda_l1': 0.09521568240328881, 'lambda_l2': 3.4688804661422576} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.9898578937029909, 'max_depth': 38, 'num_leaves': 2431, 'min_data_in_leaf': 37, 'lambda_l1': 0.026938376650519215, 'lambda_l2': 0.3042222507192497} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.0035535209896430725, 'max_depth': 50, 'num_leaves': 517, 'min_data_in_leaf': 42, 'lambda_l1': 0.06101010924937015, 'lambda_l2': 3.6918476247134993} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.0025822795018378146, 'max_depth': 34, 'num_leaves': 240, 'min_data_in_leaf': 34, 'lambda_l1': 0.13546186128244703, 'lambda_l2': 0.5360308786281556} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3773933957700959, 'max_depth': 46, 'num_leaves': 648, 'min_data_in_leaf': 39, 'lambda_l1': 0.5000031851764887, 'lambda_l2': 1.1797741071386092} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.01024373493515494, 'max_depth': 66, 'num_leaves': 1842, 'min_data_in_leaf': 26, 'lambda_l1': 0.240919936774457, 'lambda_l2': 1.8379470796566413} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.10923051891857735, 'max_depth': 42, 'num_leaves': 338, 'min_data_in_leaf': 45, 'lambda_l1': 0.4516983569267407, 'lambda_l2': 2.460020391592434} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.48951136579664933, 'max_depth': 38, 'num_leaves': 183, 'min_data_in_leaf': 36, 'lambda_l1': 0.7892493134110963, 'lambda_l2': 4.401902291196646} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6525382400026871, 'max_depth': 44, 'num_leaves': 429, 'min_data_in_leaf': 31, 'lambda_l1': 0.62045648592861, 'lambda_l2': 2.8870371024948662} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.547969311123394, 'max_depth': 25, 'num_leaves': 286, 'min_data_in_leaf': 28, 'lambda_l1': 0.11194254737262949, 'lambda_l2': 3.851382802124255} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4108660314616708, 'max_depth': 36, 'num_leaves': 536, 'min_data_in_leaf': 42, 'lambda_l1': 0.5277175666597915, 'lambda_l2': 4.500493388193296} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7369337358454934, 'max_depth': 48, 'num_leaves': 116, 'min_data_in_leaf': 23, 'lambda_l1': 0.4799051725921841, 'lambda_l2': 2.7372330424149642} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2618141584408921, 'max_depth': 40, 'num_leaves': 746, 'min_data_in_leaf': 38, 'lambda_l1': 0.5725952975810408, 'lambda_l2': 4.852855942889687} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.47234561376561573, 'max_depth': 53, 'num_leaves': 375, 'min_data_in_leaf': 35, 'lambda_l1': 0.3652852142904435, 'lambda_l2': 0.6386396775499047} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33100388462722236, 'max_depth': 42, 'num_leaves': 209, 'min_data_in_leaf': 33, 'lambda_l1': 0.05099725470544089, 'lambda_l2': 4.057637141417697} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5818003774110883, 'max_depth': 46, 'num_leaves': 452, 'min_data_in_leaf': 41, 'lambda_l1': 0.08832005466183261, 'lambda_l2': 2.5982969323746428} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.40060899401094613, 'max_depth': 84, 'num_leaves': 650, 'min_data_in_leaf': 37, 'lambda_l1': 0.39746113826088136, 'lambda_l2': 3.1016431207367354} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5127909516578101, 'max_depth': 49, 'num_leaves': 872, 'min_data_in_leaf': 40, 'lambda_l1': 0.4278808948962588, 'lambda_l2': 4.741668061724448} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.01534441074609741, 'max_depth': 44, 'num_leaves': 1369, 'min_data_in_leaf': 25, 'lambda_l1': 0.10009151292712454, 'lambda_l2': 0.7214916832217357} : acc= 53.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4493398056358564, 'max_depth': 39, 'num_leaves': 1094, 'min_data_in_leaf': 31, 'lambda_l1': 0.06687455474894113, 'lambda_l2': 0.901166995235939} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.698706984514461, 'max_depth': 51, 'num_leaves': 2260, 'min_data_in_leaf': 44, 'lambda_l1': 0.1285451960449911, 'lambda_l2': 0.025324973401212883} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.34769620767915127, 'max_depth': 37, 'num_leaves': 1000, 'min_data_in_leaf': 20, 'lambda_l1': 0.15548372128246618, 'lambda_l2': 4.961941585996341} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.8317805818795906, 'max_depth': 47, 'num_leaves': 568, 'min_data_in_leaf': 28, 'lambda_l1': 0.02366156667110641, 'lambda_l2': 0.35638849383993837} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.07412448591987411, 'max_depth': 42, 'num_leaves': 261, 'min_data_in_leaf': 35, 'lambda_l1': 0.6470379656878764, 'lambda_l2': 4.5989012077932525} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.005422032374993063, 'max_depth': 35, 'num_leaves': 115, 'min_data_in_leaf': 39, 'lambda_l1': 0.08607948552768536, 'lambda_l2': 0.462361131586025} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5983659660574342, 'max_depth': 30, 'num_leaves': 1481, 'min_data_in_leaf': 33, 'lambda_l1': 0.04795683909150922, 'lambda_l2': 2.911676165854358} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5244665908817394, 'max_depth': 40, 'num_leaves': 368, 'min_data_in_leaf': 37, 'lambda_l1': 0.11995476727705087, 'lambda_l2': 0.9766144297341495} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.39015315887581037, 'max_depth': 45, 'num_leaves': 505, 'min_data_in_leaf': 30, 'lambda_l1': 0.07428282482221035, 'lambda_l2': 0.5657948529182764} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4510210705545389, 'max_depth': 50, 'num_leaves': 268, 'min_data_in_leaf': 43, 'lambda_l1': 0.09708644223843689, 'lambda_l2': 2.254080434980427} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6753655577102983, 'max_depth': 43, 'num_leaves': 2134, 'min_data_in_leaf': 35, 'lambda_l1': 0.32949310253558756, 'lambda_l2': 3.4837163405739036} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.8899624055512302, 'max_depth': 43, 'num_leaves': 2282, 'min_data_in_leaf': 40, 'lambda_l1': 0.36789986184036594, 'lambda_l2': 3.8127259870605386} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7991552489563474, 'max_depth': 45, 'num_leaves': 2098, 'min_data_in_leaf': 32, 'lambda_l1': 0.3482832345704789, 'lambda_l2': 3.6136349549098745} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.617417149166433, 'max_depth': 18, 'num_leaves': 2143, 'min_data_in_leaf': 27, 'lambda_l1': 0.3009050483643192, 'lambda_l2': 3.662259486117355} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.717853172465097, 'max_depth': 47, 'num_leaves': 2115, 'min_data_in_leaf': 23, 'lambda_l1': 0.29461167051580517, 'lambda_l2': 3.3325389902144535} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.29146970207842665, 'max_depth': 43, 'num_leaves': 2179, 'min_data_in_leaf': 36, 'lambda_l1': 0.31358192834071114, 'lambda_l2': 3.6029347943633034} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7032333741042465, 'max_depth': 47, 'num_leaves': 1961, 'min_data_in_leaf': 38, 'lambda_l1': 0.3683249714558505, 'lambda_l2': 3.458821239625029} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.20331355373336757, 'max_depth': 45, 'num_leaves': 2210, 'min_data_in_leaf': 34, 'lambda_l1': 0.39044245571466574, 'lambda_l2': 3.369916249977245} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6401145407574056, 'max_depth': 41, 'num_leaves': 2264, 'min_data_in_leaf': 25, 'lambda_l1': 0.34489641645742825, 'lambda_l2': 3.4894941311491543} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5169163793349876, 'max_depth': 43, 'num_leaves': 2368, 'min_data_in_leaf': 29, 'lambda_l1': 0.3357317572289436, 'lambda_l2': 3.590935723700211} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.37372210351574947, 'max_depth': 48, 'num_leaves': 2342, 'min_data_in_leaf': 29, 'lambda_l1': 0.3184459270455973, 'lambda_l2': 3.7522304563688404} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4279632539851622, 'max_depth': 44, 'num_leaves': 2205, 'min_data_in_leaf': 27, 'lambda_l1': 0.318930474290823, 'lambda_l2': 3.4431261290007598} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32094299184271874, 'max_depth': 45, 'num_leaves': 2365, 'min_data_in_leaf': 29, 'lambda_l1': 0.32635695486723154, 'lambda_l2': 3.690384406325273} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.504981555002427, 'max_depth': 55, 'num_leaves': 2038, 'min_data_in_leaf': 30, 'lambda_l1': 0.3657894847761502, 'lambda_l2': 3.534897539136264} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4664968522130904, 'max_depth': 49, 'num_leaves': 2388, 'min_data_in_leaf': 26, 'lambda_l1': 0.33120698315619646, 'lambda_l2': 3.668774217834032} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.37831126921573216, 'max_depth': 43, 'num_leaves': 2079, 'min_data_in_leaf': 22, 'lambda_l1': 0.2720231833851093, 'lambda_l2': 3.544311109088283} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.260130438250918, 'max_depth': 46, 'num_leaves': 2061, 'min_data_in_leaf': 19, 'lambda_l1': 0.2627326440046107, 'lambda_l2': 3.5755492402469997} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3202572263691227, 'max_depth': 43, 'num_leaves': 1996, 'min_data_in_leaf': 17, 'lambda_l1': 0.33170037849345785, 'lambda_l2': 3.5609658896798804} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3772981331773019, 'max_depth': 47, 'num_leaves': 2093, 'min_data_in_leaf': 21, 'lambda_l1': 0.2532207797359084, 'lambda_l2': 3.4983938362162763} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2963093337359804, 'max_depth': 44, 'num_leaves': 1987, 'min_data_in_leaf': 24, 'lambda_l1': 0.2268186692126679, 'lambda_l2': 3.4110558841080296} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.351683283291214, 'max_depth': 52, 'num_leaves': 2167, 'min_data_in_leaf': 23, 'lambda_l1': 0.2688021466800907, 'lambda_l2': 3.7233486105591034} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.41638997434945724, 'max_depth': 49, 'num_leaves': 2079, 'min_data_in_leaf': 21, 'lambda_l1': 0.33720532950531623, 'lambda_l2': 3.515641657737512} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5482940933781416, 'max_depth': 42, 'num_leaves': 1897, 'min_data_in_leaf': 21, 'lambda_l1': 0.3602609333028344, 'lambda_l2': 3.577962872802901} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.363236021778019, 'max_depth': 46, 'num_leaves': 2126, 'min_data_in_leaf': 18, 'lambda_l1': 0.3442308109131704, 'lambda_l2': 3.34674888107542} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4144643537363249, 'max_depth': 44, 'num_leaves': 2203, 'min_data_in_leaf': 24, 'lambda_l1': 0.2891461969488862, 'lambda_l2': 3.6902420032492276} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.7906421054207056, 'max_depth': 50, 'num_leaves': 1658, 'min_data_in_leaf': 25, 'lambda_l1': 0.3067709801756364, 'lambda_l2': 3.812151409936867} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5041385690231277, 'max_depth': 42, 'num_leaves': 1913, 'min_data_in_leaf': 28, 'lambda_l1': 0.2720388715574583, 'lambda_l2': 3.5661177090271114} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.22714312601044773, 'max_depth': 47, 'num_leaves': 1991, 'min_data_in_leaf': 26, 'lambda_l1': 0.35202501406081504, 'lambda_l2': 3.443202946502342} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.9341270964808076, 'max_depth': 44, 'num_leaves': 1830, 'min_data_in_leaf': 31, 'lambda_l1': 0.3791695362099979, 'lambda_l2': 3.3023653848741152} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6459586558513629, 'max_depth': 48, 'num_leaves': 2225, 'min_data_in_leaf': 22, 'lambda_l1': 0.20138219942055705, 'lambda_l2': 3.249062969195859} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.329248845927781, 'max_depth': 27, 'num_leaves': 3329, 'min_data_in_leaf': 27, 'lambda_l1': 0.3398022934199558, 'lambda_l2': 3.6472715627652503} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2569473422139007, 'max_depth': 28, 'num_leaves': 2146, 'min_data_in_leaf': 25, 'lambda_l1': 0.294350348466514, 'lambda_l2': 3.636182783394535} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2884411744450274, 'max_depth': 27, 'num_leaves': 2303, 'min_data_in_leaf': 28, 'lambda_l1': 0.349872491089247, 'lambda_l2': 3.756568045837542} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.328211251579906, 'max_depth': 32, 'num_leaves': 3568, 'min_data_in_leaf': 23, 'lambda_l1': 0.32464627832791126, 'lambda_l2': 3.4859624163775855} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3012484491232834, 'max_depth': 31, 'num_leaves': 3501, 'min_data_in_leaf': 26, 'lambda_l1': 0.2901832337353667, 'lambda_l2': 3.6598182825382173} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.26306300766536234, 'max_depth': 29, 'num_leaves': 3644, 'min_data_in_leaf': 73, 'lambda_l1': 0.34925651885492104, 'lambda_l2': 3.5585883983219553} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3313095946689199, 'max_depth': 25, 'num_leaves': 70, 'min_data_in_leaf': 22, 'lambda_l1': 0.32745392213077884, 'lambda_l2': 3.742141337398959} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.37290376877627057, 'max_depth': 23, 'num_leaves': 3154, 'min_data_in_leaf': 24, 'lambda_l1': 0.30703616794167116, 'lambda_l2': 3.9085294103036} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.34870124290485016, 'max_depth': 30, 'num_leaves': 3512, 'min_data_in_leaf': 19, 'lambda_l1': 0.32972915731526836, 'lambda_l2': 3.8458562101997398} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.39583265020362884, 'max_depth': 31, 'num_leaves': 3242, 'min_data_in_leaf': 27, 'lambda_l1': 0.3809328944310692, 'lambda_l2': 3.4151461509952354} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.289678453696174, 'max_depth': 27, 'num_leaves': 3376, 'min_data_in_leaf': 32, 'lambda_l1': 0.35388284584015584, 'lambda_l2': 3.6122386741181276} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4283504911959453, 'max_depth': 34, 'num_leaves': 3910, 'min_data_in_leaf': 29, 'lambda_l1': 0.2799799672622629, 'lambda_l2': 3.6930118438112447} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3204950683126919, 'max_depth': 10, 'num_leaves': 2048, 'min_data_in_leaf': 26, 'lambda_l1': 0.24477857812328102, 'lambda_l2': 3.527313368273658} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7943963551141008, 'max_depth': 16, 'num_leaves': 3296, 'min_data_in_leaf': 20, 'lambda_l1': 0.3127208249445137, 'lambda_l2': 3.413000835194204} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3535665452174436, 'max_depth': 29, 'num_leaves': 3435, 'min_data_in_leaf': 33, 'lambda_l1': 0.3677840768350168, 'lambda_l2': 3.7629565994451495} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4569312956425999, 'max_depth': 33, 'num_leaves': 3316, 'min_data_in_leaf': 81, 'lambda_l1': 0.38102885284151566, 'lambda_l2': 3.1575536049688493} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.577715792321692, 'max_depth': 54, 'num_leaves': 2854, 'min_data_in_leaf': 30, 'lambda_l1': 0.3320680156095069, 'lambda_l2': 3.9048405359256964} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.23333945465896183, 'max_depth': 20, 'num_leaves': 54, 'min_data_in_leaf': 23, 'lambda_l1': 0.34120514611519814, 'lambda_l2': 3.625451381966506} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.39026999175155896, 'max_depth': 41, 'num_leaves': 148, 'min_data_in_leaf': 37, 'lambda_l1': 0.3159404329667779, 'lambda_l2': 3.328319420619821} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6955723731956456, 'max_depth': 52, 'num_leaves': 2997, 'min_data_in_leaf': 35, 'lambda_l1': 0.39640108117994716, 'lambda_l2': 0.22533660493450824} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.486554813744262, 'max_depth': 32, 'num_leaves': 1730, 'min_data_in_leaf': 27, 'lambda_l1': 0.2895244884326112, 'lambda_l2': 3.078561536352837} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5807832048157228, 'max_depth': 14, 'num_leaves': 187, 'min_data_in_leaf': 40, 'lambda_l1': 0.35591579046926475, 'lambda_l2': 3.541044987144126} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.9916084629372439, 'max_depth': 40, 'num_leaves': 694, 'min_data_in_leaf': 32, 'lambda_l1': 0.3651706740608261, 'lambda_l2': 3.2702220949869374} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4195968707820727, 'max_depth': 51, 'num_leaves': 2111, 'min_data_in_leaf': 38, 'lambda_l1': 0.2997542346232645, 'lambda_l2': 3.438387354051041} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.302287224566854, 'max_depth': 42, 'num_leaves': 2251, 'min_data_in_leaf': 35, 'lambda_l1': 0.2125448331404448, 'lambda_l2': 3.7885367901505136} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5248760899912213, 'max_depth': 38, 'num_leaves': 621, 'min_data_in_leaf': 29, 'lambda_l1': 0.34426234461346433, 'lambda_l2': 3.638841102029109} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7297380404998917, 'max_depth': 35, 'num_leaves': 164, 'min_data_in_leaf': 25, 'lambda_l1': 0.27598593540640814, 'lambda_l2': 3.4697876949623456} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.1877184741944636, 'max_depth': 50, 'num_leaves': 2758, 'min_data_in_leaf': 31, 'lambda_l1': 0.3859722991330968, 'lambda_l2': 3.9920338876422075} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3536878773577153, 'max_depth': 41, 'num_leaves': 59, 'min_data_in_leaf': 41, 'lambda_l1': 0.328808757348229, 'lambda_l2': 3.0437476484496417} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4492474589863563, 'max_depth': 57, 'num_leaves': 1597, 'min_data_in_leaf': 37, 'lambda_l1': 0.3085957485238955, 'lambda_l2': 2.9678834186780954} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6562124013399353, 'max_depth': 26, 'num_leaves': 136, 'min_data_in_leaf': 34, 'lambda_l1': 0.40019752557584914, 'lambda_l2': 3.6969294158019754} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3799031092323315, 'max_depth': 45, 'num_leaves': 3623, 'min_data_in_leaf': 22, 'lambda_l1': 0.24579080597436084, 'lambda_l2': 0.4312817540466734} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.8588821168672582, 'max_depth': 39, 'num_leaves': 583, 'min_data_in_leaf': 28, 'lambda_l1': 0.37449181229805767, 'lambda_l2': 3.1822958377843227} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5310546227121712, 'max_depth': 53, 'num_leaves': 3099, 'min_data_in_leaf': 39, 'lambda_l1': 0.18180474275006928, 'lambda_l2': 2.788928738619805} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.45371728188097643, 'max_depth': 48, 'num_leaves': 2150, 'min_data_in_leaf': 33, 'lambda_l1': 0.07052417641536969, 'lambda_l2': 0.13863941665744847} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3917991534965525, 'max_depth': 12, 'num_leaves': 186, 'min_data_in_leaf': 24, 'lambda_l1': 0.10814852931330418, 'lambda_l2': 3.855192196843816} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2761769501049865, 'max_depth': 42, 'num_leaves': 3230, 'min_data_in_leaf': 42, 'lambda_l1': 0.1413820720856869, 'lambda_l2': 0.2863300430007439} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6111522698801893, 'max_depth': 33, 'num_leaves': 1889, 'min_data_in_leaf': 37, 'lambda_l1': 0.09040148985575147, 'lambda_l2': 3.548013908994331} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3299870436082258, 'max_depth': 36, 'num_leaves': 747, 'min_data_in_leaf': 89, 'lambda_l1': 0.34714995726872444, 'lambda_l2': 3.249626680281255} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47767364183007904, 'max_depth': 46, 'num_leaves': 2034, 'min_data_in_leaf': 35, 'lambda_l1': 0.061336061204280874, 'lambda_l2': 3.7508248868667406} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5547188284663394, 'max_depth': 40, 'num_leaves': 3855, 'min_data_in_leaf': 30, 'lambda_l1': 0.41093962640009696, 'lambda_l2': 3.3975567263826845} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7179911801271092, 'max_depth': 96, 'num_leaves': 274, 'min_data_in_leaf': 39, 'lambda_l1': 0.26482466283731054, 'lambda_l2': 3.591011220796745} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4130282014211956, 'max_depth': 43, 'num_leaves': 1488, 'min_data_in_leaf': 27, 'lambda_l1': 0.07984079031400323, 'lambda_l2': 2.89666684779744} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6446752683014839, 'max_depth': 50, 'num_leaves': 52, 'min_data_in_leaf': 32, 'lambda_l1': 0.12199466959965362, 'lambda_l2': 0.38175505773059315} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.47973021468624927, 'max_depth': 72, 'num_leaves': 657, 'min_data_in_leaf': 20, 'lambda_l1': 0.36056481350949365, 'lambda_l2': 3.6542776329387885} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.055523032479203906, 'max_depth': 60, 'num_leaves': 681, 'min_data_in_leaf': 18, 'lambda_l1': 0.3731693293796398, 'lambda_l2': 3.657515709059644} : acc= 63.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5180940745412054, 'max_depth': 63, 'num_leaves': 2542, 'min_data_in_leaf': 20, 'lambda_l1': 0.047679619988524984, 'lambda_l2': 3.8085858279213514} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5977321879677313, 'max_depth': 29, 'num_leaves': 776, 'min_data_in_leaf': 17, 'lambda_l1': 0.3589602250576348, 'lambda_l2': 3.5044836142049127} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4878964842331961, 'max_depth': 94, 'num_leaves': 638, 'min_data_in_leaf': 19, 'lambda_l1': 0.38605190623159336, 'lambda_l2': 3.9240779669507724} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.8042229057090715, 'max_depth': 37, 'num_leaves': 706, 'min_data_in_leaf': 21, 'lambda_l1': 0.327816926580517, 'lambda_l2': 3.7695737305370147} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5743616106376261, 'max_depth': 68, 'num_leaves': 552, 'min_data_in_leaf': 21, 'lambda_l1': 0.35215765381639647, 'lambda_l2': 3.6681799937459276} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4646192260936276, 'max_depth': 80, 'num_leaves': 616, 'min_data_in_leaf': 25, 'lambda_l1': 0.3372582132473021, 'lambda_l2': 3.617827236195211} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5275834606265748, 'max_depth': 38, 'num_leaves': 473, 'min_data_in_leaf': 8, 'lambda_l1': 0.3688260109582237, 'lambda_l2': 3.4966028660535686} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.682164796508873, 'max_depth': 72, 'num_leaves': 2667, 'min_data_in_leaf': 23, 'lambda_l1': 0.30810434319924784, 'lambda_l2': 3.6951537156701493} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4381234466733101, 'max_depth': 40, 'num_leaves': 515, 'min_data_in_leaf': 22, 'lambda_l1': 0.3328520283121533, 'lambda_l2': 3.5796736139381142} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.0011064413742295132, 'max_depth': 92, 'num_leaves': 609, 'min_data_in_leaf': 24, 'lambda_l1': 0.401764043829543, 'lambda_l2': 3.32516106061445} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6198597642287741, 'max_depth': 43, 'num_leaves': 3723, 'min_data_in_leaf': 18, 'lambda_l1': 0.37930106520955026, 'lambda_l2': 3.814382780911128} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5351611036145347, 'max_depth': 33, 'num_leaves': 837, 'min_data_in_leaf': 16, 'lambda_l1': 0.3535333328848223, 'lambda_l2': 4.1172558240747215} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.022368210477656664, 'max_depth': 78, 'num_leaves': 689, 'min_data_in_leaf': 20, 'lambda_l1': 0.3185552127481656, 'lambda_l2': 3.3620733761890302} : acc= 55.83%\n",
            "[HPO] metrics with {'learning_rate': 0.7556932513785295, 'max_depth': 36, 'num_leaves': 386, 'min_data_in_leaf': 26, 'lambda_l1': 0.39761963524294186, 'lambda_l2': 3.726458894569815} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.41236740531683164, 'max_depth': 76, 'num_leaves': 466, 'min_data_in_leaf': 28, 'lambda_l1': 0.36582863644129454, 'lambda_l2': 3.944048466083376} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8787719948157957, 'max_depth': 41, 'num_leaves': 315, 'min_data_in_leaf': 31, 'lambda_l1': 0.2942795202347891, 'lambda_l2': 3.484766189063096} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.48424035021709394, 'max_depth': 88, 'num_leaves': 216, 'min_data_in_leaf': 22, 'lambda_l1': 0.5175391383695749, 'lambda_l2': 3.608615823654645} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6479528354375929, 'max_depth': 39, 'num_leaves': 765, 'min_data_in_leaf': 34, 'lambda_l1': 0.41303349109219345, 'lambda_l2': 3.4322130732630525} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5700652062841368, 'max_depth': 31, 'num_leaves': 565, 'min_data_in_leaf': 24, 'lambda_l1': 0.33483924994916026, 'lambda_l2': 3.5398921602336064} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.40850921804223583, 'max_depth': 90, 'num_leaves': 130, 'min_data_in_leaf': 36, 'lambda_l1': 0.6808787144826205, 'lambda_l2': 0.02079734760639207} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4746234105936828, 'max_depth': 43, 'num_leaves': 162, 'min_data_in_leaf': 11, 'lambda_l1': 0.6824532757455885, 'lambda_l2': 0.1439501823129895} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4208022493955417, 'max_depth': 99, 'num_leaves': 110, 'min_data_in_leaf': 36, 'lambda_l1': 0.7832909423320068, 'lambda_l2': 0.10859214318095363} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5130699991965479, 'max_depth': 89, 'num_leaves': 119, 'min_data_in_leaf': 35, 'lambda_l1': 0.8455671352044423, 'lambda_l2': 0.17603173735502994} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3881700726588404, 'max_depth': 73, 'num_leaves': 228, 'min_data_in_leaf': 37, 'lambda_l1': 0.7658272009925773, 'lambda_l2': 0.026881902550426162} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.45333342488157663, 'max_depth': 56, 'num_leaves': 124, 'min_data_in_leaf': 33, 'lambda_l1': 0.04236171763366113, 'lambda_l2': 0.20847698045645802} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5755425029892325, 'max_depth': 84, 'num_leaves': 188, 'min_data_in_leaf': 38, 'lambda_l1': 0.497277561757837, 'lambda_l2': 0.12077159641055855} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.49839567254338335, 'max_depth': 45, 'num_leaves': 302, 'min_data_in_leaf': 35, 'lambda_l1': 0.6534820035086245, 'lambda_l2': 0.29518946820787617} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7343393176549514, 'max_depth': 96, 'num_leaves': 211, 'min_data_in_leaf': 34, 'lambda_l1': 0.7446778576055643, 'lambda_l2': 0.016029098802021545} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3983662973330194, 'max_depth': 63, 'num_leaves': 117, 'min_data_in_leaf': 36, 'lambda_l1': 0.060069420342825516, 'lambda_l2': 0.23614653144005837} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6361798883217483, 'max_depth': 74, 'num_leaves': 56, 'min_data_in_leaf': 39, 'lambda_l1': 0.7379815750957561, 'lambda_l2': 0.444490515154522} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5539603489655909, 'max_depth': 84, 'num_leaves': 276, 'min_data_in_leaf': 14, 'lambda_l1': 0.23682091493487228, 'lambda_l2': 0.1067592173858767} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4425314013556445, 'max_depth': 87, 'num_leaves': 408, 'min_data_in_leaf': 36, 'lambda_l1': 0.09101892242350249, 'lambda_l2': 0.09397550343607777} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.35765298972935533, 'max_depth': 69, 'num_leaves': 356, 'min_data_in_leaf': 33, 'lambda_l1': 0.923597315529853, 'lambda_l2': 0.358554287112157} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4919868559267514, 'max_depth': 66, 'num_leaves': 480, 'min_data_in_leaf': 38, 'lambda_l1': 0.7604065920466517, 'lambda_l2': 3.1151762492147275} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.8614525970161343, 'max_depth': 94, 'num_leaves': 2333, 'min_data_in_leaf': 32, 'lambda_l1': 0.5358822495939886, 'lambda_l2': 0.5435037752877088} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6834488909884833, 'max_depth': 78, 'num_leaves': 54, 'min_data_in_leaf': 40, 'lambda_l1': 0.4150838171224407, 'lambda_l2': 0.08255784034207203} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5584010377908887, 'max_depth': 41, 'num_leaves': 219, 'min_data_in_leaf': 35, 'lambda_l1': 0.15279493269171907, 'lambda_l2': 3.1571162179300067} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.42804861949594625, 'max_depth': 89, 'num_leaves': 642, 'min_data_in_leaf': 37, 'lambda_l1': 0.6712919303445455, 'lambda_l2': 4.249783806686917} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.36664934683474465, 'max_depth': 44, 'num_leaves': 312, 'min_data_in_leaf': 33, 'lambda_l1': 0.10663740467969332, 'lambda_l2': 0.28716031692968536} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6136297766389421, 'max_depth': 54, 'num_leaves': 556, 'min_data_in_leaf': 40, 'lambda_l1': 0.07264907525965755, 'lambda_l2': 3.2656377912919523} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.08386582782158374, 'max_depth': 39, 'num_leaves': 159, 'min_data_in_leaf': 37, 'lambda_l1': 0.025454977845211335, 'lambda_l2': 0.5376954310077644} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4864496372369028, 'max_depth': 47, 'num_leaves': 729, 'min_data_in_leaf': 20, 'lambda_l1': 0.6827358983659928, 'lambda_l2': 0.4458629145407482} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.764854391092101, 'max_depth': 58, 'num_leaves': 398, 'min_data_in_leaf': 15, 'lambda_l1': 0.388190576743459, 'lambda_l2': 0.05224047826201234} : acc= 50.42%\n",
            "[HPO] metrics with {'learning_rate': 0.42288960751032323, 'max_depth': 77, 'num_leaves': 2469, 'min_data_in_leaf': 31, 'lambda_l1': 0.4912269487533667, 'lambda_l2': 4.041431846022882} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5391040688186406, 'max_depth': 99, 'num_leaves': 2193, 'min_data_in_leaf': 35, 'lambda_l1': 0.20484152010112, 'lambda_l2': 4.998675246277916} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6581660064004506, 'max_depth': 52, 'num_leaves': 277, 'min_data_in_leaf': 38, 'lambda_l1': 0.05704201208772217, 'lambda_l2': 0.24936423361115997} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.36710838940369317, 'max_depth': 69, 'num_leaves': 51, 'min_data_in_leaf': 41, 'lambda_l1': 0.8672800258374248, 'lambda_l2': 0.6185567718994731} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.47188231040354883, 'max_depth': 41, 'num_leaves': 194, 'min_data_in_leaf': 30, 'lambda_l1': 0.7294861832642322, 'lambda_l2': 3.0535241276262544} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5896337443705766, 'max_depth': 91, 'num_leaves': 485, 'min_data_in_leaf': 33, 'lambda_l1': 0.16883261103070754, 'lambda_l2': 3.380713083494801} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4046952682851877, 'max_depth': 45, 'num_leaves': 644, 'min_data_in_leaf': 36, 'lambda_l1': 0.6897825615544284, 'lambda_l2': 3.2399006180007417} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.007045321158608508, 'max_depth': 43, 'num_leaves': 351, 'min_data_in_leaf': 39, 'lambda_l1': 0.4292635400674155, 'lambda_l2': 3.8976733727232364} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.9774051876665356, 'max_depth': 39, 'num_leaves': 538, 'min_data_in_leaf': 43, 'lambda_l1': 0.0822902954609785, 'lambda_l2': 0.023955771781443924} : acc= 39.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5244475387303826, 'max_depth': 49, 'num_leaves': 127, 'min_data_in_leaf': 34, 'lambda_l1': 0.7028418570451641, 'lambda_l2': 4.859299936875884} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.7481721414671594, 'max_depth': 46, 'num_leaves': 264, 'min_data_in_leaf': 37, 'lambda_l1': 0.10196306769555091, 'lambda_l2': 3.8306044857137618} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.421004420416507, 'max_depth': 42, 'num_leaves': 435, 'min_data_in_leaf': 31, 'lambda_l1': 0.12288825952796813, 'lambda_l2': 0.018257487493031514} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4860263054973116, 'max_depth': 37, 'num_leaves': 802, 'min_data_in_leaf': 94, 'lambda_l1': 0.8173143391131634, 'lambda_l2': 0.3817427419830417} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6339901044065843, 'max_depth': 51, 'num_leaves': 2245, 'min_data_in_leaf': 17, 'lambda_l1': 0.5148729523863272, 'lambda_l2': 0.20875005508943092} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3647802275669355, 'max_depth': 84, 'num_leaves': 1955, 'min_data_in_leaf': 39, 'lambda_l1': 0.0336224987780349, 'lambda_l2': 3.1640196491411285} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.45339156257739566, 'max_depth': 81, 'num_leaves': 2063, 'min_data_in_leaf': 29, 'lambda_l1': 0.06991692607969965, 'lambda_l2': 3.3293967174519787} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5521212943573228, 'max_depth': 48, 'num_leaves': 212, 'min_data_in_leaf': 42, 'lambda_l1': 0.05022559142851559, 'lambda_l2': 3.44737811674091} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.8357445456591146, 'max_depth': 41, 'num_leaves': 592, 'min_data_in_leaf': 35, 'lambda_l1': 0.22358382534304677, 'lambda_l2': 3.7338656675846944} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.31258947204212484, 'max_depth': 44, 'num_leaves': 700, 'min_data_in_leaf': 23, 'lambda_l1': 0.4716342140721017, 'lambda_l2': 2.9733342211567115} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6873716573137644, 'max_depth': 71, 'num_leaves': 358, 'min_data_in_leaf': 19, 'lambda_l1': 0.09661779435944737, 'lambda_l2': 0.6652651824994065} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5194059158667778, 'max_depth': 61, 'num_leaves': 128, 'min_data_in_leaf': 33, 'lambda_l1': 0.6998911080932769, 'lambda_l2': 2.379170533166629} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.38486043015216564, 'max_depth': 38, 'num_leaves': 422, 'min_data_in_leaf': 37, 'lambda_l1': 0.1874620292620115, 'lambda_l2': 0.5391893583775488} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.44908938603347465, 'max_depth': 86, 'num_leaves': 525, 'min_data_in_leaf': 40, 'lambda_l1': 0.13482342743496295, 'lambda_l2': 3.52652737334228} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6072462649496466, 'max_depth': 47, 'num_leaves': 262, 'min_data_in_leaf': 32, 'lambda_l1': 0.2795497249623122, 'lambda_l2': 2.016742185074783} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.34691296754187917, 'max_depth': 45, 'num_leaves': 186, 'min_data_in_leaf': 36, 'lambda_l1': 0.392368026689098, 'lambda_l2': 4.361997280495773} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.426821606075297, 'max_depth': 55, 'num_leaves': 665, 'min_data_in_leaf': 30, 'lambda_l1': 0.08173296604554287, 'lambda_l2': 1.5087095171441522} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5486844261220858, 'max_depth': 40, 'num_leaves': 339, 'min_data_in_leaf': 26, 'lambda_l1': 0.37519308799230316, 'lambda_l2': 0.009824718520074605} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7578870560310185, 'max_depth': 43, 'num_leaves': 126, 'min_data_in_leaf': 59, 'lambda_l1': 0.10952538274214263, 'lambda_l2': 4.681534915018997} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4820632810721312, 'max_depth': 49, 'num_leaves': 458, 'min_data_in_leaf': 38, 'lambda_l1': 0.060622591102636236, 'lambda_l2': 3.082931262489602} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6581976932123845, 'max_depth': 37, 'num_leaves': 2123, 'min_data_in_leaf': 46, 'lambda_l1': 0.4441354256627067, 'lambda_l2': 4.490970226562156} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3787814896480415, 'max_depth': 7, 'num_leaves': 236, 'min_data_in_leaf': 41, 'lambda_l1': 0.036948401694046895, 'lambda_l2': 3.6161191847784835} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5812374652027182, 'max_depth': 35, 'num_leaves': 825, 'min_data_in_leaf': 21, 'lambda_l1': 0.6390798213284732, 'lambda_l2': 0.35294005695996855} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44698219869201145, 'max_depth': 52, 'num_leaves': 542, 'min_data_in_leaf': 34, 'lambda_l1': 0.5488195141906256, 'lambda_l2': 0.20123896733026525} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31486931577616994, 'max_depth': 41, 'num_leaves': 719, 'min_data_in_leaf': 28, 'lambda_l1': 0.07902169669755735, 'lambda_l2': 4.179291593060867} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.8504983192324256, 'max_depth': 47, 'num_leaves': 2322, 'min_data_in_leaf': 24, 'lambda_l1': 0.7172094063537278, 'lambda_l2': 4.885000597697751} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5207626302345816, 'max_depth': 43, 'num_leaves': 340, 'min_data_in_leaf': 39, 'lambda_l1': 0.1444097808992953, 'lambda_l2': 4.0045799653900005} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.15669986825846396, 'max_depth': 39, 'num_leaves': 50, 'min_data_in_leaf': 36, 'lambda_l1': 0.4151154541627368, 'lambda_l2': 1.742994546765666} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3965924139969158, 'max_depth': 45, 'num_leaves': 607, 'min_data_in_leaf': 32, 'lambda_l1': 0.2593000944788294, 'lambda_l2': 3.3651867812843728} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.7170041005501658, 'max_depth': 50, 'num_leaves': 434, 'min_data_in_leaf': 43, 'lambda_l1': 0.10480979774641183, 'lambda_l2': 3.7421539749648063} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6103981078621566, 'max_depth': 42, 'num_leaves': 141, 'min_data_in_leaf': 4, 'lambda_l1': 0.3558168530621086, 'lambda_l2': 3.2370852265625443} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4741652829845887, 'max_depth': 39, 'num_leaves': 293, 'min_data_in_leaf': 34, 'lambda_l1': 0.8122162740666916, 'lambda_l2': 0.4667661551345503} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.343404714563198, 'max_depth': 46, 'num_leaves': 2177, 'min_data_in_leaf': 30, 'lambda_l1': 0.06976023691210223, 'lambda_l2': 1.3437819058303282} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.40751333094435416, 'max_depth': 36, 'num_leaves': 194, 'min_data_in_leaf': 22, 'lambda_l1': 0.4898187439038675, 'lambda_l2': 3.5258537208987186} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5347531803555505, 'max_depth': 48, 'num_leaves': 488, 'min_data_in_leaf': 67, 'lambda_l1': 0.048652147197550885, 'lambda_l2': 4.7496246814028895} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6351084344933792, 'max_depth': 43, 'num_leaves': 386, 'min_data_in_leaf': 38, 'lambda_l1': 0.08511180247668652, 'lambda_l2': 0.6492434444601325} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4637550843809149, 'max_depth': 41, 'num_leaves': 599, 'min_data_in_leaf': 41, 'lambda_l1': 0.012722689411733025, 'lambda_l2': 3.8578713459255116} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3516567664941213, 'max_depth': 53, 'num_leaves': 254, 'min_data_in_leaf': 26, 'lambda_l1': 0.3725055625769694, 'lambda_l2': 3.6282358334024423} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.12859569598000078, 'max_depth': 50, 'num_leaves': 2033, 'min_data_in_leaf': 36, 'lambda_l1': 0.12481272087919423, 'lambda_l2': 3.4707056097455475} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.7813511143055959, 'max_depth': 45, 'num_leaves': 749, 'min_data_in_leaf': 34, 'lambda_l1': 0.3926791277763802, 'lambda_l2': 3.0090553941577967} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.0023653135610624825, 'max_depth': 38, 'num_leaves': 908, 'min_data_in_leaf': 29, 'lambda_l1': 0.5290193577352164, 'lambda_l2': 3.716276757763226} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5359952575036276, 'max_depth': 40, 'num_leaves': 316, 'min_data_in_leaf': 39, 'lambda_l1': 0.1021220782323041, 'lambda_l2': 3.1273704902365957} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4086990831532499, 'max_depth': 34, 'num_leaves': 120, 'min_data_in_leaf': 32, 'lambda_l1': 0.307139040069836, 'lambda_l2': 2.5492244344890125} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2755215660616194, 'max_depth': 43, 'num_leaves': 2401, 'min_data_in_leaf': 44, 'lambda_l1': 0.05293928617633418, 'lambda_l2': 0.5857383397930475} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.684348790060903, 'max_depth': 47, 'num_leaves': 55, 'min_data_in_leaf': 37, 'lambda_l1': 0.46844180887203724, 'lambda_l2': 3.2942213212988434} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5781262689842395, 'max_depth': 51, 'num_leaves': 541, 'min_data_in_leaf': 25, 'lambda_l1': 0.16862593704620377, 'lambda_l2': 3.626198458874004} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4812760933143352, 'max_depth': 37, 'num_leaves': 666, 'min_data_in_leaf': 48, 'lambda_l1': 0.427096766442041, 'lambda_l2': 4.613284534737885} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.9223601256201754, 'max_depth': 41, 'num_leaves': 202, 'min_data_in_leaf': 41, 'lambda_l1': 0.03183775258808597, 'lambda_l2': 3.405342857762773} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.31896318602110313, 'max_depth': 45, 'num_leaves': 436, 'min_data_in_leaf': 35, 'lambda_l1': 0.0809640687946364, 'lambda_l2': 0.31176917051868325} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2935277737744305, 'max_depth': 48, 'num_leaves': 450, 'min_data_in_leaf': 35, 'lambda_l1': 0.08181314507629005, 'lambda_l2': 0.19498863239937236} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23529597454243933, 'max_depth': 46, 'num_leaves': 393, 'min_data_in_leaf': 33, 'lambda_l1': 0.06873849035235523, 'lambda_l2': 0.36228608209923163} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3196934891301701, 'max_depth': 45, 'num_leaves': 496, 'min_data_in_leaf': 34, 'lambda_l1': 0.11387477876833697, 'lambda_l2': 0.3019812939272497} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.30997497908490335, 'max_depth': 50, 'num_leaves': 494, 'min_data_in_leaf': 36, 'lambda_l1': 0.1246273492892001, 'lambda_l2': 0.3344396710560891} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3059861511234857, 'max_depth': 65, 'num_leaves': 535, 'min_data_in_leaf': 38, 'lambda_l1': 0.11554428560480973, 'lambda_l2': 0.21899472362040806} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.214115348876011, 'max_depth': 48, 'num_leaves': 430, 'min_data_in_leaf': 36, 'lambda_l1': 0.14407956799800678, 'lambda_l2': 0.35163222053853793} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3331809202153407, 'max_depth': 46, 'num_leaves': 479, 'min_data_in_leaf': 38, 'lambda_l1': 0.09110871188722379, 'lambda_l2': 0.2150274119523709} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.25282782816954386, 'max_depth': 49, 'num_leaves': 485, 'min_data_in_leaf': 40, 'lambda_l1': 0.09756446538051156, 'lambda_l2': 0.12552133351171613} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3637986332640396, 'max_depth': 47, 'num_leaves': 589, 'min_data_in_leaf': 39, 'lambda_l1': 0.11507073848081967, 'lambda_l2': 0.1330564312941333} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2934617596121651, 'max_depth': 46, 'num_leaves': 416, 'min_data_in_leaf': 41, 'lambda_l1': 0.09364652407722958, 'lambda_l2': 0.22660482116123232} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2525712196264409, 'max_depth': 48, 'num_leaves': 546, 'min_data_in_leaf': 38, 'lambda_l1': 0.09639916145555294, 'lambda_l2': 0.2309005031218182} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.258987982003509, 'max_depth': 51, 'num_leaves': 496, 'min_data_in_leaf': 37, 'lambda_l1': 0.14126964829759975, 'lambda_l2': 0.3143254584641721} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2750352842777875, 'max_depth': 49, 'num_leaves': 404, 'min_data_in_leaf': 43, 'lambda_l1': 0.07887322606883315, 'lambda_l2': 0.2931467493728392} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.32043076275238874, 'max_depth': 45, 'num_leaves': 626, 'min_data_in_leaf': 39, 'lambda_l1': 0.11905259014223434, 'lambda_l2': 0.445284328621307} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3233672812963005, 'max_depth': 47, 'num_leaves': 354, 'min_data_in_leaf': 35, 'lambda_l1': 0.06627045315660418, 'lambda_l2': 0.14201728064761712} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.23999441926027562, 'max_depth': 3, 'num_leaves': 461, 'min_data_in_leaf': 37, 'lambda_l1': 0.05825118813065694, 'lambda_l2': 0.2931951475009791} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27140109801995543, 'max_depth': 46, 'num_leaves': 372, 'min_data_in_leaf': 40, 'lambda_l1': 0.05698174677830285, 'lambda_l2': 0.15375388643737062} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28212558351073286, 'max_depth': 45, 'num_leaves': 512, 'min_data_in_leaf': 35, 'lambda_l1': 0.033661375026683094, 'lambda_l2': 0.09915373943869417} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.24183407397169437, 'max_depth': 47, 'num_leaves': 584, 'min_data_in_leaf': 42, 'lambda_l1': 0.06769107214713582, 'lambda_l2': 0.15368327323742836} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20247544914846666, 'max_depth': 79, 'num_leaves': 369, 'min_data_in_leaf': 38, 'lambda_l1': 0.01584495982817391, 'lambda_l2': 0.07381687546938132} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3122649457488819, 'max_depth': 50, 'num_leaves': 439, 'min_data_in_leaf': 36, 'lambda_l1': 0.08603567833411571, 'lambda_l2': 0.0061307587730422} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3373517130474182, 'max_depth': 45, 'num_leaves': 499, 'min_data_in_leaf': 45, 'lambda_l1': 0.049516562450449976, 'lambda_l2': 0.2219495231564215} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.28783868056155176, 'max_depth': 53, 'num_leaves': 330, 'min_data_in_leaf': 40, 'lambda_l1': 0.07003103887641227, 'lambda_l2': 0.17635027230649844} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3448082396423543, 'max_depth': 48, 'num_leaves': 585, 'min_data_in_leaf': 38, 'lambda_l1': 0.08696192592917126, 'lambda_l2': 0.25622351322488285} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.33201061496458245, 'max_depth': 49, 'num_leaves': 645, 'min_data_in_leaf': 34, 'lambda_l1': 0.0911961021758021, 'lambda_l2': 0.23184206680449265} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2607595061254261, 'max_depth': 51, 'num_leaves': 598, 'min_data_in_leaf': 37, 'lambda_l1': 0.07690683024921868, 'lambda_l2': 0.0037601994945958284} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.30647705320236446, 'max_depth': 49, 'num_leaves': 695, 'min_data_in_leaf': 35, 'lambda_l1': 0.048763321951490884, 'lambda_l2': 0.12517817369604264} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.22374003914650287, 'max_depth': 53, 'num_leaves': 559, 'min_data_in_leaf': 38, 'lambda_l1': 0.10133786173578536, 'lambda_l2': 0.301356865426992} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.326479731761258, 'max_depth': 48, 'num_leaves': 580, 'min_data_in_leaf': 35, 'lambda_l1': 0.06940327516764379, 'lambda_l2': 0.2722843733512903} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3420996350718952, 'max_depth': 51, 'num_leaves': 504, 'min_data_in_leaf': 37, 'lambda_l1': 0.03796065347750804, 'lambda_l2': 0.16188823106899408} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2958592067542592, 'max_depth': 55, 'num_leaves': 654, 'min_data_in_leaf': 37, 'lambda_l1': 0.011839794623902077, 'lambda_l2': 0.0960795613918929} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.26949466460565663, 'max_depth': 55, 'num_leaves': 751, 'min_data_in_leaf': 37, 'lambda_l1': 0.011456201577440157, 'lambda_l2': 0.09813432269523126} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.23223320680189835, 'max_depth': 70, 'num_leaves': 650, 'min_data_in_leaf': 39, 'lambda_l1': 0.004365907535836339, 'lambda_l2': 0.10708526640087393} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.18865639439692736, 'max_depth': 58, 'num_leaves': 677, 'min_data_in_leaf': 37, 'lambda_l1': 0.011002424584236795, 'lambda_l2': 0.012500594662824771} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2836328929802718, 'max_depth': 55, 'num_leaves': 602, 'min_data_in_leaf': 36, 'lambda_l1': 0.02827907078643894, 'lambda_l2': 0.21339253790084578} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2867998533549985, 'max_depth': 51, 'num_leaves': 715, 'min_data_in_leaf': 39, 'lambda_l1': 0.02239765248610366, 'lambda_l2': 0.00029774675776512993} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3250536379029263, 'max_depth': 64, 'num_leaves': 818, 'min_data_in_leaf': 35, 'lambda_l1': 0.0340688767694574, 'lambda_l2': 0.12633040425442776} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.0013591239001759527, 'max_depth': 53, 'num_leaves': 527, 'min_data_in_leaf': 38, 'lambda_l1': 0.02712941265234758, 'lambda_l2': 0.19347601714130347} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24594909663580788, 'max_depth': 52, 'num_leaves': 652, 'min_data_in_leaf': 40, 'lambda_l1': 0.03338619732856768, 'lambda_l2': 0.14411183016291013} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2941462821753645, 'max_depth': 61, 'num_leaves': 568, 'min_data_in_leaf': 36, 'lambda_l1': 0.054969005373436484, 'lambda_l2': 0.23484336546230009} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3309108329775474, 'max_depth': 59, 'num_leaves': 771, 'min_data_in_leaf': 34, 'lambda_l1': 0.012147101197582123, 'lambda_l2': 0.07166524890361882} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.34334222375919066, 'max_depth': 50, 'num_leaves': 531, 'min_data_in_leaf': 38, 'lambda_l1': 0.041997096689195115, 'lambda_l2': 0.11660253663052265} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33928984077364993, 'max_depth': 74, 'num_leaves': 641, 'min_data_in_leaf': 37, 'lambda_l1': 0.04236867355346374, 'lambda_l2': 0.2816498333028772} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2536140568865185, 'max_depth': 72, 'num_leaves': 665, 'min_data_in_leaf': 41, 'lambda_l1': 0.0072715426169504965, 'lambda_l2': 0.306209418370705} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3023096254269006, 'max_depth': 68, 'num_leaves': 780, 'min_data_in_leaf': 39, 'lambda_l1': 0.0034308631511267146, 'lambda_l2': 0.26923575554637985} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3437867790304595, 'max_depth': 56, 'num_leaves': 612, 'min_data_in_leaf': 37, 'lambda_l1': 0.037041184814016054, 'lambda_l2': 0.2047265768792121} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27600779604061165, 'max_depth': 81, 'num_leaves': 710, 'min_data_in_leaf': 41, 'lambda_l1': 0.04440332673950503, 'lambda_l2': 0.3096104604486962} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.33610285978188176, 'max_depth': 82, 'num_leaves': 495, 'min_data_in_leaf': 38, 'lambda_l1': 0.019954063695068844, 'lambda_l2': 0.15306798632457544} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.22462711169118313, 'max_depth': 85, 'num_leaves': 598, 'min_data_in_leaf': 36, 'lambda_l1': 0.04695193058962574, 'lambda_l2': 0.09915184636794652} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.35369643695733954, 'max_depth': 89, 'num_leaves': 670, 'min_data_in_leaf': 40, 'lambda_l1': 0.06122909210308282, 'lambda_l2': 0.004666662855811986} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.29558771507172116, 'max_depth': 91, 'num_leaves': 486, 'min_data_in_leaf': 42, 'lambda_l1': 0.02500690985616371, 'lambda_l2': 0.02619890482651016} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2546876758859348, 'max_depth': 91, 'num_leaves': 657, 'min_data_in_leaf': 40, 'lambda_l1': 0.04861013507491889, 'lambda_l2': 0.09806375171661699} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3454434753305297, 'max_depth': 89, 'num_leaves': 863, 'min_data_in_leaf': 40, 'lambda_l1': 0.026693295475799975, 'lambda_l2': 0.1721711762784331} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3118277005725147, 'max_depth': 89, 'num_leaves': 555, 'min_data_in_leaf': 42, 'lambda_l1': 0.00017083035659444523, 'lambda_l2': 0.06962187846500698} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.36413349148224605, 'max_depth': 94, 'num_leaves': 473, 'min_data_in_leaf': 34, 'lambda_l1': 0.06103388536069476, 'lambda_l2': 0.0036062849975047606} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2066950667512691, 'max_depth': 92, 'num_leaves': 734, 'min_data_in_leaf': 44, 'lambda_l1': 0.0606019332354248, 'lambda_l2': 0.0025315131967471594} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.26527612363774533, 'max_depth': 75, 'num_leaves': 646, 'min_data_in_leaf': 38, 'lambda_l1': 0.04322627171034005, 'lambda_l2': 0.3615597854150918} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.36439028378404564, 'max_depth': 89, 'num_leaves': 555, 'min_data_in_leaf': 36, 'lambda_l1': 0.0726449054951783, 'lambda_l2': 0.25161958108654486} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3072032744253235, 'max_depth': 93, 'num_leaves': 453, 'min_data_in_leaf': 39, 'lambda_l1': 0.033674579558591745, 'lambda_l2': 0.20432908096104385} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3517171171808585, 'max_depth': 85, 'num_leaves': 743, 'min_data_in_leaf': 34, 'lambda_l1': 0.06603851714486339, 'lambda_l2': 0.3501735546285449} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2940502464830347, 'max_depth': 55, 'num_leaves': 609, 'min_data_in_leaf': 37, 'lambda_l1': 0.08523192681542463, 'lambda_l2': 0.16996398550765346} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2538623183711114, 'max_depth': 57, 'num_leaves': 549, 'min_data_in_leaf': 33, 'lambda_l1': 0.08335631763454875, 'lambda_l2': 0.15036193939866677} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2718616037526404, 'max_depth': 56, 'num_leaves': 589, 'min_data_in_leaf': 36, 'lambda_l1': 0.08015687085502951, 'lambda_l2': 0.13651560926341633} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20618416780791285, 'max_depth': 63, 'num_leaves': 518, 'min_data_in_leaf': 33, 'lambda_l1': 0.09137147083255219, 'lambda_l2': 0.1962845329170747} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2308898887026447, 'max_depth': 58, 'num_leaves': 595, 'min_data_in_leaf': 38, 'lambda_l1': 0.05290151492374566, 'lambda_l2': 0.2788708665167438} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.23278797716154145, 'max_depth': 58, 'num_leaves': 633, 'min_data_in_leaf': 37, 'lambda_l1': 0.052952930182518704, 'lambda_l2': 0.26563887420432397} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.19324390739491745, 'max_depth': 59, 'num_leaves': 551, 'min_data_in_leaf': 34, 'lambda_l1': 0.021952729014743287, 'lambda_l2': 0.11905078695929308} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.22414391481938833, 'max_depth': 60, 'num_leaves': 678, 'min_data_in_leaf': 36, 'lambda_l1': 0.038534650159895024, 'lambda_l2': 0.19539154887864804} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2392077608243794, 'max_depth': 56, 'num_leaves': 461, 'min_data_in_leaf': 39, 'lambda_l1': 0.0007039205324536613, 'lambda_l2': 0.007053063589247538} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.17499371373954853, 'max_depth': 62, 'num_leaves': 792, 'min_data_in_leaf': 34, 'lambda_l1': 0.06297768253742823, 'lambda_l2': 0.2920310556660059} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.25923178447128414, 'max_depth': 59, 'num_leaves': 602, 'min_data_in_leaf': 37, 'lambda_l1': 0.08273837513791825, 'lambda_l2': 0.12892563043305086} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2322616898104968, 'max_depth': 57, 'num_leaves': 451, 'min_data_in_leaf': 41, 'lambda_l1': 0.04793783264472441, 'lambda_l2': 0.3841592447946919} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.17215569864350913, 'max_depth': 57, 'num_leaves': 537, 'min_data_in_leaf': 33, 'lambda_l1': 0.02234277204040944, 'lambda_l2': 0.10281287264569094} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.20607107721681578, 'max_depth': 54, 'num_leaves': 684, 'min_data_in_leaf': 35, 'lambda_l1': 0.06685078104033948, 'lambda_l2': 0.2644674916009582} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2660280933003879, 'max_depth': 61, 'num_leaves': 509, 'min_data_in_leaf': 38, 'lambda_l1': 0.0888785929400894, 'lambda_l2': 0.0011912987206326212} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.28889347645150404, 'max_depth': 54, 'num_leaves': 627, 'min_data_in_leaf': 40, 'lambda_l1': 0.04880235352421719, 'lambda_l2': 0.19419962532033866} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2875984762892756, 'max_depth': 55, 'num_leaves': 412, 'min_data_in_leaf': 36, 'lambda_l1': 0.885177622503133, 'lambda_l2': 0.17474665988853424} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.24707951769698905, 'max_depth': 56, 'num_leaves': 731, 'min_data_in_leaf': 32, 'lambda_l1': 0.10087148409813128, 'lambda_l2': 0.293954279543658} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3022113637280691, 'max_depth': 59, 'num_leaves': 568, 'min_data_in_leaf': 38, 'lambda_l1': 0.07825361871587683, 'lambda_l2': 0.32239618796448183} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.21965547811500788, 'max_depth': 57, 'num_leaves': 439, 'min_data_in_leaf': 43, 'lambda_l1': 0.03554665456706644, 'lambda_l2': 0.08246425115120193} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.257760585902578, 'max_depth': 87, 'num_leaves': 508, 'min_data_in_leaf': 13, 'lambda_l1': 0.9555532589986308, 'lambda_l2': 0.36526311251238636} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3019893210864077, 'max_depth': 97, 'num_leaves': 807, 'min_data_in_leaf': 34, 'lambda_l1': 0.11707179567549743, 'lambda_l2': 0.09720890103118987} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31263128068692214, 'max_depth': 57, 'num_leaves': 610, 'min_data_in_leaf': 40, 'lambda_l1': 0.05962227921664825, 'lambda_l2': 0.00010686883566751737} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2809447830899657, 'max_depth': 67, 'num_leaves': 699, 'min_data_in_leaf': 37, 'lambda_l1': 0.022243802342536846, 'lambda_l2': 0.21481202998959856} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2545655870157451, 'max_depth': 54, 'num_leaves': 438, 'min_data_in_leaf': 35, 'lambda_l1': 0.0845735558967977, 'lambda_l2': 0.40607471703185716} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3217306027332475, 'max_depth': 61, 'num_leaves': 528, 'min_data_in_leaf': 32, 'lambda_l1': 0.10522265204911165, 'lambda_l2': 0.18542715605659305} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32747545481094975, 'max_depth': 58, 'num_leaves': 884, 'min_data_in_leaf': 39, 'lambda_l1': 0.06093538723893887, 'lambda_l2': 0.09196070731411954} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2883303508660427, 'max_depth': 60, 'num_leaves': 611, 'min_data_in_leaf': 42, 'lambda_l1': 0.07317429523053803, 'lambda_l2': 0.26855969787625034} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34446983839076456, 'max_depth': 73, 'num_leaves': 397, 'min_data_in_leaf': 45, 'lambda_l1': 0.1294445855039758, 'lambda_l2': 0.1681047207489768} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.28987636784593307, 'max_depth': 77, 'num_leaves': 703, 'min_data_in_leaf': 43, 'lambda_l1': 0.10200676819224738, 'lambda_l2': 0.39071598724470036} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33759477982166614, 'max_depth': 53, 'num_leaves': 504, 'min_data_in_leaf': 47, 'lambda_l1': 0.08235482522095752, 'lambda_l2': 0.26809920313468205} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.27703932952684157, 'max_depth': 55, 'num_leaves': 638, 'min_data_in_leaf': 43, 'lambda_l1': 0.07543273885046048, 'lambda_l2': 0.0906146892251156} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3655301675312243, 'max_depth': 91, 'num_leaves': 809, 'min_data_in_leaf': 41, 'lambda_l1': 0.11061662010041155, 'lambda_l2': 0.16437154405029245} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31660075925369613, 'max_depth': 55, 'num_leaves': 403, 'min_data_in_leaf': 41, 'lambda_l1': 0.09469498456454246, 'lambda_l2': 0.08703019104316825} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.36476468975042325, 'max_depth': 66, 'num_leaves': 575, 'min_data_in_leaf': 45, 'lambda_l1': 0.12618671215021524, 'lambda_l2': 0.2804171321164092} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2695038059392162, 'max_depth': 71, 'num_leaves': 488, 'min_data_in_leaf': 50, 'lambda_l1': 0.0676260756724709, 'lambda_l2': 0.4087464463650989} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.31463109050953636, 'max_depth': 53, 'num_leaves': 671, 'min_data_in_leaf': 42, 'lambda_l1': 0.039088159350387605, 'lambda_l2': 2.20400556334577} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.36001789164722436, 'max_depth': 65, 'num_leaves': 736, 'min_data_in_leaf': 100, 'lambda_l1': 0.0918653249811906, 'lambda_l2': 0.1953728503074726} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.302147163957281, 'max_depth': 60, 'num_leaves': 572, 'min_data_in_leaf': 40, 'lambda_l1': 0.07065677949752759, 'lambda_l2': 0.08501760652184873} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.009233029659699821, 'max_depth': 56, 'num_leaves': 374, 'min_data_in_leaf': 36, 'lambda_l1': 0.04105135523518519, 'lambda_l2': 0.24188681348481564} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2583851682635536, 'max_depth': 63, 'num_leaves': 486, 'min_data_in_leaf': 32, 'lambda_l1': 0.11117815941231005, 'lambda_l2': 0.32679491188907767} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3684639433923583, 'max_depth': 75, 'num_leaves': 641, 'min_data_in_leaf': 39, 'lambda_l1': 0.02002674573737824, 'lambda_l2': 0.07643405487590119} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.322046693530677, 'max_depth': 87, 'num_leaves': 418, 'min_data_in_leaf': 43, 'lambda_l1': 0.08865696759356959, 'lambda_l2': 0.1916071560996855} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.28172474538614456, 'max_depth': 53, 'num_leaves': 776, 'min_data_in_leaf': 35, 'lambda_l1': 0.05800489742368839, 'lambda_l2': 0.0011476316799870754} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.21934063271221776, 'max_depth': 53, 'num_leaves': 811, 'min_data_in_leaf': 34, 'lambda_l1': 0.1283782840422646, 'lambda_l2': 0.0022793101696407525} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.18989587331084135, 'max_depth': 55, 'num_leaves': 901, 'min_data_in_leaf': 76, 'lambda_l1': 0.049497274180137975, 'lambda_l2': 0.3395094519790533} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.27639514943043697, 'max_depth': 54, 'num_leaves': 537, 'min_data_in_leaf': 33, 'lambda_l1': 0.15087911077385313, 'lambda_l2': 0.15327640018012706} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.23263476821538176, 'max_depth': 53, 'num_leaves': 589, 'min_data_in_leaf': 35, 'lambda_l1': 0.020412353070565437, 'lambda_l2': 0.42748286156259474} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.25958038277075035, 'max_depth': 57, 'num_leaves': 471, 'min_data_in_leaf': 32, 'lambda_l1': 0.07234640300150788, 'lambda_l2': 0.2556196904175982} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31095507734308847, 'max_depth': 51, 'num_leaves': 716, 'min_data_in_leaf': 35, 'lambda_l1': 0.10816540756504531, 'lambda_l2': 0.16325982836548975} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28000040634203566, 'max_depth': 52, 'num_leaves': 347, 'min_data_in_leaf': 33, 'lambda_l1': 0.08738474400446453, 'lambda_l2': 0.2564153194958132} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.26217763838509944, 'max_depth': 55, 'num_leaves': 562, 'min_data_in_leaf': 62, 'lambda_l1': 0.038916712002304774, 'lambda_l2': 0.09976719806192053} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3680530764670756, 'max_depth': 58, 'num_leaves': 764, 'min_data_in_leaf': 36, 'lambda_l1': 0.06680006639348189, 'lambda_l2': 0.4056443696272765} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29881382370429377, 'max_depth': 52, 'num_leaves': 389, 'min_data_in_leaf': 37, 'lambda_l1': 0.0006158360654640368, 'lambda_l2': 0.15655436069047257} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.22892186780837379, 'max_depth': 54, 'num_leaves': 475, 'min_data_in_leaf': 57, 'lambda_l1': 0.052349191621923835, 'lambda_l2': 2.330199905170058} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.32747655322540853, 'max_depth': 56, 'num_leaves': 625, 'min_data_in_leaf': 32, 'lambda_l1': 0.10495113887672296, 'lambda_l2': 0.29777006163204023} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.20224997031217376, 'max_depth': 54, 'num_leaves': 534, 'min_data_in_leaf': 34, 'lambda_l1': 0.07865690132704589, 'lambda_l2': 0.06776427723129844} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3910067083552072, 'max_depth': 50, 'num_leaves': 449, 'min_data_in_leaf': 37, 'lambda_l1': 0.1270385434923451, 'lambda_l2': 0.004495300593394286} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2546323691542352, 'max_depth': 59, 'num_leaves': 617, 'min_data_in_leaf': 36, 'lambda_l1': 0.09005343107939175, 'lambda_l2': 0.1891073352068331} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2950025160733034, 'max_depth': 53, 'num_leaves': 349, 'min_data_in_leaf': 34, 'lambda_l1': 0.03381245436653284, 'lambda_l2': 0.3623403247685293} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.04266607526686515, 'max_depth': 52, 'num_leaves': 744, 'min_data_in_leaf': 53, 'lambda_l1': 0.05649192281676822, 'lambda_l2': 0.26689768203269093} : acc= 60.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3672484782797028, 'max_depth': 55, 'num_leaves': 424, 'min_data_in_leaf': 37, 'lambda_l1': 0.14021092651077385, 'lambda_l2': 0.1308765678071901} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3243910627880949, 'max_depth': 79, 'num_leaves': 686, 'min_data_in_leaf': 31, 'lambda_l1': 0.11173704389963561, 'lambda_l2': 0.006415814371314249} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3784262575007439, 'max_depth': 51, 'num_leaves': 528, 'min_data_in_leaf': 35, 'lambda_l1': 0.07300758224053018, 'lambda_l2': 0.22079390307852076} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2808956684809505, 'max_depth': 70, 'num_leaves': 839, 'min_data_in_leaf': 32, 'lambda_l1': 0.04260794059524665, 'lambda_l2': 0.43217717424430324} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2463033354854171, 'max_depth': 61, 'num_leaves': 956, 'min_data_in_leaf': 38, 'lambda_l1': 0.08624969258423913, 'lambda_l2': 2.088590866512163} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.32727929164282693, 'max_depth': 82, 'num_leaves': 580, 'min_data_in_leaf': 34, 'lambda_l1': 0.021056183616126233, 'lambda_l2': 0.09477461894770509} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3529231041981409, 'max_depth': 57, 'num_leaves': 478, 'min_data_in_leaf': 38, 'lambda_l1': 0.0651671177504696, 'lambda_l2': 0.20960645471634665} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.38995069301144936, 'max_depth': 58, 'num_leaves': 347, 'min_data_in_leaf': 39, 'lambda_l1': 0.1013452278543822, 'lambda_l2': 0.40550538298068567} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.38842824149459476, 'max_depth': 60, 'num_leaves': 339, 'min_data_in_leaf': 42, 'lambda_l1': 0.1214637233206097, 'lambda_l2': 0.4122284118359315} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.403917576640216, 'max_depth': 60, 'num_leaves': 312, 'min_data_in_leaf': 43, 'lambda_l1': 0.1543321982095365, 'lambda_l2': 0.4575277979105432} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40525585770889394, 'max_depth': 60, 'num_leaves': 334, 'min_data_in_leaf': 47, 'lambda_l1': 0.16784268884364947, 'lambda_l2': 0.47862413670755366} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.03117074756849569, 'max_depth': 63, 'num_leaves': 403, 'min_data_in_leaf': 44, 'lambda_l1': 0.15493938025428172, 'lambda_l2': 0.40638729807346174} : acc= 60.00%\n",
            "[HPO] metrics with {'learning_rate': 0.40478104649568203, 'max_depth': 59, 'num_leaves': 302, 'min_data_in_leaf': 48, 'lambda_l1': 0.14380949782009222, 'lambda_l2': 0.4976204208381851} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.37211330008112165, 'max_depth': 62, 'num_leaves': 351, 'min_data_in_leaf': 46, 'lambda_l1': 0.1727059039715086, 'lambda_l2': 0.5183290626372683} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.40156128516952294, 'max_depth': 60, 'num_leaves': 316, 'min_data_in_leaf': 44, 'lambda_l1': 0.16248592405666634, 'lambda_l2': 0.46112910719482486} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4068735488604271, 'max_depth': 62, 'num_leaves': 346, 'min_data_in_leaf': 45, 'lambda_l1': 0.13482091166224155, 'lambda_l2': 0.3838428007974935} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3960107779450553, 'max_depth': 76, 'num_leaves': 298, 'min_data_in_leaf': 43, 'lambda_l1': 0.13771638967377767, 'lambda_l2': 0.4199096210757701} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3744406865710779, 'max_depth': 60, 'num_leaves': 388, 'min_data_in_leaf': 42, 'lambda_l1': 0.1489675544980101, 'lambda_l2': 0.34487596616509153} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4234445318086588, 'max_depth': 64, 'num_leaves': 416, 'min_data_in_leaf': 45, 'lambda_l1': 0.11816923923492775, 'lambda_l2': 0.5086724140840849} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3541415101083196, 'max_depth': 58, 'num_leaves': 323, 'min_data_in_leaf': 42, 'lambda_l1': 0.1228410674634255, 'lambda_l2': 0.37767216303557877} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.423426286924441, 'max_depth': 61, 'num_leaves': 383, 'min_data_in_leaf': 44, 'lambda_l1': 0.15744290623966078, 'lambda_l2': 0.45241904550496476} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35859092957583366, 'max_depth': 58, 'num_leaves': 446, 'min_data_in_leaf': 42, 'lambda_l1': 0.13056494837217597, 'lambda_l2': 0.34591457345951937} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.41807075665491605, 'max_depth': 59, 'num_leaves': 298, 'min_data_in_leaf': 41, 'lambda_l1': 0.18733360526782994, 'lambda_l2': 0.504274030127057} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3346440982011404, 'max_depth': 73, 'num_leaves': 464, 'min_data_in_leaf': 46, 'lambda_l1': 0.10904114017857737, 'lambda_l2': 0.31397759433064715} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3839015042894017, 'max_depth': 57, 'num_leaves': 390, 'min_data_in_leaf': 49, 'lambda_l1': 0.1133696088372837, 'lambda_l2': 0.31134249042691736} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4356852144284319, 'max_depth': 61, 'num_leaves': 269, 'min_data_in_leaf': 42, 'lambda_l1': 0.14145805935087657, 'lambda_l2': 0.28759285035156723} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3368675946992579, 'max_depth': 58, 'num_leaves': 452, 'min_data_in_leaf': 41, 'lambda_l1': 0.10588224230183302, 'lambda_l2': 0.40550067858961636} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3620936351545172, 'max_depth': 60, 'num_leaves': 351, 'min_data_in_leaf': 44, 'lambda_l1': 0.09874634579824416, 'lambda_l2': 0.26384461821644506} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2977720565191131, 'max_depth': 56, 'num_leaves': 493, 'min_data_in_leaf': 41, 'lambda_l1': 0.12965982764479955, 'lambda_l2': 0.4692174771209725} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.42994952676620174, 'max_depth': 62, 'num_leaves': 281, 'min_data_in_leaf': 40, 'lambda_l1': 0.10832198576245144, 'lambda_l2': 0.2654877167839308} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.40024299923226603, 'max_depth': 58, 'num_leaves': 537, 'min_data_in_leaf': 42, 'lambda_l1': 0.17509762913000454, 'lambda_l2': 1.9112992629531798} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.09863351389987216, 'max_depth': 65, 'num_leaves': 400, 'min_data_in_leaf': 40, 'lambda_l1': 0.15703827247802524, 'lambda_l2': 2.4613930128762807} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3334229909499822, 'max_depth': 64, 'num_leaves': 494, 'min_data_in_leaf': 43, 'lambda_l1': 0.09641699676463664, 'lambda_l2': 0.36997751825005165} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3006128518629952, 'max_depth': 57, 'num_leaves': 344, 'min_data_in_leaf': 46, 'lambda_l1': 0.11879907779932103, 'lambda_l2': 0.5294900805532884} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.43920560513665424, 'max_depth': 60, 'num_leaves': 573, 'min_data_in_leaf': 39, 'lambda_l1': 0.09765002051283006, 'lambda_l2': 0.23744225429406599} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3569585456535652, 'max_depth': 63, 'num_leaves': 275, 'min_data_in_leaf': 40, 'lambda_l1': 0.13534572454244978, 'lambda_l2': 0.3317415454286279} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.017107026641392742, 'max_depth': 57, 'num_leaves': 431, 'min_data_in_leaf': 42, 'lambda_l1': 0.08503523901897622, 'lambda_l2': 0.45412084112423673} : acc= 52.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3840112170845758, 'max_depth': 59, 'num_leaves': 511, 'min_data_in_leaf': 44, 'lambda_l1': 0.11912603831391545, 'lambda_l2': 0.2099514164790485} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.28140433312184715, 'max_depth': 61, 'num_leaves': 398, 'min_data_in_leaf': 39, 'lambda_l1': 0.09392319206263573, 'lambda_l2': 0.3707568180430028} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.44650195970927203, 'max_depth': 74, 'num_leaves': 611, 'min_data_in_leaf': 40, 'lambda_l1': 0.07505817633711581, 'lambda_l2': 0.23382164865444954} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32276102526582173, 'max_depth': 67, 'num_leaves': 300, 'min_data_in_leaf': 65, 'lambda_l1': 0.1384264370223994, 'lambda_l2': 0.5867931011723873} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.24162903070118047, 'max_depth': 62, 'num_leaves': 482, 'min_data_in_leaf': 15, 'lambda_l1': 0.1567176344133671, 'lambda_l2': 0.4487875020563914} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.13729289934418176, 'max_depth': 57, 'num_leaves': 366, 'min_data_in_leaf': 39, 'lambda_l1': 0.10026580605863478, 'lambda_l2': 0.25236625674756463} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.38725150983802514, 'max_depth': 59, 'num_leaves': 580, 'min_data_in_leaf': 42, 'lambda_l1': 0.12263164859403891, 'lambda_l2': 0.3948831116001806} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.45123027280361283, 'max_depth': 56, 'num_leaves': 260, 'min_data_in_leaf': 47, 'lambda_l1': 0.07070392129063846, 'lambda_l2': 0.30836705698270983} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3355121006398069, 'max_depth': 75, 'num_leaves': 461, 'min_data_in_leaf': 44, 'lambda_l1': 0.0845067364738376, 'lambda_l2': 0.1738039876963107} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.26753225990682344, 'max_depth': 58, 'num_leaves': 688, 'min_data_in_leaf': 39, 'lambda_l1': 0.06485590000215137, 'lambda_l2': 0.22906217513774169} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3875852721290366, 'max_depth': 60, 'num_leaves': 535, 'min_data_in_leaf': 41, 'lambda_l1': 0.11440500112988575, 'lambda_l2': 0.32751359347948406} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3110912650920996, 'max_depth': 55, 'num_leaves': 383, 'min_data_in_leaf': 38, 'lambda_l1': 0.09448337069994782, 'lambda_l2': 2.2941707469106087} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.44982429314885286, 'max_depth': 69, 'num_leaves': 660, 'min_data_in_leaf': 40, 'lambda_l1': 0.07332436623574995, 'lambda_l2': 0.17248884712251855} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.012798290309293464, 'max_depth': 71, 'num_leaves': 331, 'min_data_in_leaf': 42, 'lambda_l1': 0.14454164480642748, 'lambda_l2': 0.5316215419233439} : acc= 51.67%\n",
            "[HPO] metrics with {'learning_rate': 0.21562402416346282, 'max_depth': 57, 'num_leaves': 552, 'min_data_in_leaf': 51, 'lambda_l1': 0.11073105045864984, 'lambda_l2': 2.1931548331013224} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.35135995641910917, 'max_depth': 61, 'num_leaves': 761, 'min_data_in_leaf': 38, 'lambda_l1': 0.06412185599700568, 'lambda_l2': 0.4315946045503456} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28667826792916595, 'max_depth': 64, 'num_leaves': 444, 'min_data_in_leaf': 45, 'lambda_l1': 0.0904002228712068, 'lambda_l2': 0.1913200690445527} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4089023847566828, 'max_depth': 59, 'num_leaves': 246, 'min_data_in_leaf': 40, 'lambda_l1': 0.12418548604198101, 'lambda_l2': 0.3215500593057338} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3531451293460664, 'max_depth': 57, 'num_leaves': 625, 'min_data_in_leaf': 43, 'lambda_l1': 0.06232653055119381, 'lambda_l2': 0.2323445587727064} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44159517260988784, 'max_depth': 77, 'num_leaves': 468, 'min_data_in_leaf': 38, 'lambda_l1': 0.08866794439004545, 'lambda_l2': 0.5507317473178643} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.06784170467963628, 'max_depth': 55, 'num_leaves': 875, 'min_data_in_leaf': 39, 'lambda_l1': 0.1816574971810076, 'lambda_l2': 0.3726525545780375} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.16894779075590552, 'max_depth': 63, 'num_leaves': 1026, 'min_data_in_leaf': 42, 'lambda_l1': 0.1042642735509252, 'lambda_l2': 0.11911127737162959} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.29926232851405626, 'max_depth': 73, 'num_leaves': 328, 'min_data_in_leaf': 38, 'lambda_l1': 0.16352212827638202, 'lambda_l2': 0.4408810782791108} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.004398733177883962, 'max_depth': 56, 'num_leaves': 557, 'min_data_in_leaf': 41, 'lambda_l1': 0.056759955216443836, 'lambda_l2': 0.26938353901119777} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2513158413406155, 'max_depth': 54, 'num_leaves': 1195, 'min_data_in_leaf': 17, 'lambda_l1': 0.08304334836574187, 'lambda_l2': 0.14397593200279923} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3762263782654467, 'max_depth': 60, 'num_leaves': 765, 'min_data_in_leaf': 37, 'lambda_l1': 0.13416641665357157, 'lambda_l2': 2.4347370785651847} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4708355816829757, 'max_depth': 53, 'num_leaves': 395, 'min_data_in_leaf': 44, 'lambda_l1': 0.10883897318765416, 'lambda_l2': 0.35922620053210397} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.31607478562644736, 'max_depth': 65, 'num_leaves': 504, 'min_data_in_leaf': 40, 'lambda_l1': 0.076237879814454, 'lambda_l2': 0.11229257118801364} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2540080751323256, 'max_depth': 67, 'num_leaves': 636, 'min_data_in_leaf': 41, 'lambda_l1': 0.06035693956129297, 'lambda_l2': 0.09432716431404374} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2983834802806062, 'max_depth': 69, 'num_leaves': 577, 'min_data_in_leaf': 44, 'lambda_l1': 0.07708495350707215, 'lambda_l2': 0.1099066988291905} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2319997122098621, 'max_depth': 64, 'num_leaves': 497, 'min_data_in_leaf': 40, 'lambda_l1': 0.054254905319815944, 'lambda_l2': 0.06753431621704825} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.20548216455022636, 'max_depth': 66, 'num_leaves': 664, 'min_data_in_leaf': 42, 'lambda_l1': 0.07487376185049646, 'lambda_l2': 0.16198556345020293} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.27245962798884293, 'max_depth': 63, 'num_leaves': 537, 'min_data_in_leaf': 46, 'lambda_l1': 0.05315760658215607, 'lambda_l2': 0.005661590018849173} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.32610913500329103, 'max_depth': 66, 'num_leaves': 710, 'min_data_in_leaf': 39, 'lambda_l1': 0.0902076328666938, 'lambda_l2': 0.20414843261707002} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2898320796723422, 'max_depth': 60, 'num_leaves': 515, 'min_data_in_leaf': 43, 'lambda_l1': 0.06979243141364219, 'lambda_l2': 0.17539599101846004} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32382983174740976, 'max_depth': 58, 'num_leaves': 604, 'min_data_in_leaf': 40, 'lambda_l1': 0.050179385957341935, 'lambda_l2': 0.25817032191011} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2589826628513382, 'max_depth': 71, 'num_leaves': 476, 'min_data_in_leaf': 41, 'lambda_l1': 0.09321332566490044, 'lambda_l2': 0.09181744454633041} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.346184251098676, 'max_depth': 62, 'num_leaves': 635, 'min_data_in_leaf': 49, 'lambda_l1': 0.08077067329232046, 'lambda_l2': 0.25352014936584344} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2884488313128807, 'max_depth': 74, 'num_leaves': 421, 'min_data_in_leaf': 86, 'lambda_l1': 0.06358933148837165, 'lambda_l2': 0.08664839105435318} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.34237673666975244, 'max_depth': 65, 'num_leaves': 799, 'min_data_in_leaf': 39, 'lambda_l1': 0.10055046897703561, 'lambda_l2': 0.17349193128321844} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.22939345528875818, 'max_depth': 61, 'num_leaves': 545, 'min_data_in_leaf': 43, 'lambda_l1': 0.04472476184547001, 'lambda_l2': 1.6491756376630224} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.005892564588287044, 'max_depth': 69, 'num_leaves': 671, 'min_data_in_leaf': 38, 'lambda_l1': 0.07467444704629406, 'lambda_l2': 0.2780710925166232} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.37278863017558855, 'max_depth': 62, 'num_leaves': 463, 'min_data_in_leaf': 47, 'lambda_l1': 0.09649571746140705, 'lambda_l2': 0.00862160622906119} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.024852135144566034, 'max_depth': 57, 'num_leaves': 588, 'min_data_in_leaf': 41, 'lambda_l1': 0.055448783580458946, 'lambda_l2': 0.20689289488195775} : acc= 57.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3141931103452273, 'max_depth': 76, 'num_leaves': 740, 'min_data_in_leaf': 38, 'lambda_l1': 0.07443196161835111, 'lambda_l2': 1.9919510255747603} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.28000216253644195, 'max_depth': 59, 'num_leaves': 419, 'min_data_in_leaf': 44, 'lambda_l1': 0.10827993525922483, 'lambda_l2': 0.12573908736006395} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.38916519764367286, 'max_depth': 56, 'num_leaves': 561, 'min_data_in_leaf': 40, 'lambda_l1': 0.03897665315458302, 'lambda_l2': 0.34742961682900675} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3191202552906996, 'max_depth': 58, 'num_leaves': 519, 'min_data_in_leaf': 37, 'lambda_l1': 0.08219200810604467, 'lambda_l2': 2.5975029323572816} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.23581278428520355, 'max_depth': 59, 'num_leaves': 482, 'min_data_in_leaf': 36, 'lambda_l1': 0.09164385911837765, 'lambda_l2': 2.5490700440788228} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.29803751320743166, 'max_depth': 62, 'num_leaves': 620, 'min_data_in_leaf': 37, 'lambda_l1': 0.07736453401771164, 'lambda_l2': 2.683079594691486} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2577684939861416, 'max_depth': 60, 'num_leaves': 502, 'min_data_in_leaf': 39, 'lambda_l1': 0.05923843303789027, 'lambda_l2': 0.2943490604219786} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3157993946360524, 'max_depth': 57, 'num_leaves': 712, 'min_data_in_leaf': 36, 'lambda_l1': 0.12114294959359362, 'lambda_l2': 2.576900397701892} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.20237261763754302, 'max_depth': 59, 'num_leaves': 545, 'min_data_in_leaf': 42, 'lambda_l1': 0.10253709763312142, 'lambda_l2': 2.61244352693545} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.27901418953798063, 'max_depth': 64, 'num_leaves': 403, 'min_data_in_leaf': 46, 'lambda_l1': 0.08294927512468031, 'lambda_l2': 2.607509736574859} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.329408581234503, 'max_depth': 57, 'num_leaves': 621, 'min_data_in_leaf': 38, 'lambda_l1': 0.04319123378868637, 'lambda_l2': 0.09511833601113684} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2521264224593245, 'max_depth': 57, 'num_leaves': 671, 'min_data_in_leaf': 36, 'lambda_l1': 0.03807844733914728, 'lambda_l2': 0.015181968068549767} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2740194747061897, 'max_depth': 57, 'num_leaves': 646, 'min_data_in_leaf': 36, 'lambda_l1': 0.03545875182537415, 'lambda_l2': 0.08654072691576124} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2215602755181966, 'max_depth': 55, 'num_leaves': 813, 'min_data_in_leaf': 38, 'lambda_l1': 0.04913875968707526, 'lambda_l2': 2.678484563040826} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.18030518214937863, 'max_depth': 54, 'num_leaves': 745, 'min_data_in_leaf': 37, 'lambda_l1': 0.05742541062332859, 'lambda_l2': 2.3767265166708613} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32018751453683425, 'max_depth': 56, 'num_leaves': 584, 'min_data_in_leaf': 35, 'lambda_l1': 0.03670449709102268, 'lambda_l2': 2.5451502106322286} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2607903856820861, 'max_depth': 58, 'num_leaves': 700, 'min_data_in_leaf': 38, 'lambda_l1': 0.06544560607836312, 'lambda_l2': 0.0012865753614836328} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3269257682857838, 'max_depth': 72, 'num_leaves': 884, 'min_data_in_leaf': 71, 'lambda_l1': 0.05336229777528898, 'lambda_l2': 0.1316662987513756} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.31255177997901323, 'max_depth': 55, 'num_leaves': 611, 'min_data_in_leaf': 19, 'lambda_l1': 0.021627945371312518, 'lambda_l2': 2.7643951152001707} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.24309154706181715, 'max_depth': 56, 'num_leaves': 593, 'min_data_in_leaf': 34, 'lambda_l1': 0.06758842300433353, 'lambda_l2': 2.4282065701896047} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28868811110998255, 'max_depth': 58, 'num_leaves': 527, 'min_data_in_leaf': 9, 'lambda_l1': 0.03312603453117798, 'lambda_l2': 0.10913267822489352} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35388470787672294, 'max_depth': 54, 'num_leaves': 718, 'min_data_in_leaf': 38, 'lambda_l1': 0.07659782015900862, 'lambda_l2': 0.17752012845048742} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3344630100420763, 'max_depth': 61, 'num_leaves': 652, 'min_data_in_leaf': 40, 'lambda_l1': 0.05231593475084918, 'lambda_l2': 0.0021257329817345877} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.21490794500669505, 'max_depth': 61, 'num_leaves': 785, 'min_data_in_leaf': 41, 'lambda_l1': 0.02653133160444074, 'lambda_l2': 0.07419838435661288} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2739565969117502, 'max_depth': 62, 'num_leaves': 856, 'min_data_in_leaf': 31, 'lambda_l1': 0.04441680438980905, 'lambda_l2': 0.04972388626154081} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.30771075116627505, 'max_depth': 65, 'num_leaves': 761, 'min_data_in_leaf': 39, 'lambda_l1': 0.04998235011415885, 'lambda_l2': 0.07006752879226621} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.24444742970057357, 'max_depth': 59, 'num_leaves': 683, 'min_data_in_leaf': 40, 'lambda_l1': 0.08163787961577251, 'lambda_l2': 0.015707568138385794} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3423487298916102, 'max_depth': 67, 'num_leaves': 635, 'min_data_in_leaf': 36, 'lambda_l1': 0.023031908583103035, 'lambda_l2': 0.10941853241066747} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3079095092660106, 'max_depth': 61, 'num_leaves': 654, 'min_data_in_leaf': 40, 'lambda_l1': 0.047415966712127555, 'lambda_l2': 0.013367974558011657} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2814980808257202, 'max_depth': 63, 'num_leaves': 804, 'min_data_in_leaf': 33, 'lambda_l1': 0.06143296179779319, 'lambda_l2': 2.4881655591509233} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.05055381308261526, 'max_depth': 9, 'num_leaves': 944, 'min_data_in_leaf': 40, 'lambda_l1': 0.0887686338567725, 'lambda_l2': 0.173125957065561} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3569008634516437, 'max_depth': 61, 'num_leaves': 704, 'min_data_in_leaf': 36, 'lambda_l1': 0.07161148387335954, 'lambda_l2': 0.08897826591593866} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2485894830994575, 'max_depth': 64, 'num_leaves': 592, 'min_data_in_leaf': 38, 'lambda_l1': 0.03181044320352237, 'lambda_l2': 0.19209031536346097} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3240538128185185, 'max_depth': 74, 'num_leaves': 613, 'min_data_in_leaf': 31, 'lambda_l1': 0.09177542616754969, 'lambda_l2': 0.009005719227506204} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2789255850318822, 'max_depth': 62, 'num_leaves': 704, 'min_data_in_leaf': 35, 'lambda_l1': 0.04629673324216449, 'lambda_l2': 4.280271174580326} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3955481790525087, 'max_depth': 59, 'num_leaves': 1322, 'min_data_in_leaf': 43, 'lambda_l1': 0.06254136716254577, 'lambda_l2': 0.13987597808365534} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20703599915698956, 'max_depth': 59, 'num_leaves': 552, 'min_data_in_leaf': 39, 'lambda_l1': 0.021038708100337845, 'lambda_l2': 0.007795085477198836} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.36015465672891733, 'max_depth': 70, 'num_leaves': 775, 'min_data_in_leaf': 41, 'lambda_l1': 0.08107297661204918, 'lambda_l2': 0.003847910548889985} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.30359745931372845, 'max_depth': 52, 'num_leaves': 534, 'min_data_in_leaf': 33, 'lambda_l1': 0.09960773292330845, 'lambda_l2': 2.6700748008779973} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3852437973868837, 'max_depth': 72, 'num_leaves': 682, 'min_data_in_leaf': 37, 'lambda_l1': 0.05280677790622052, 'lambda_l2': 0.22483697036154535} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.326130432646335, 'max_depth': 18, 'num_leaves': 616, 'min_data_in_leaf': 92, 'lambda_l1': 0.07702439054229145, 'lambda_l2': 0.17689922729249402} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2335508479227339, 'max_depth': 61, 'num_leaves': 833, 'min_data_in_leaf': 35, 'lambda_l1': 0.10585029831581523, 'lambda_l2': 0.09732683912645458} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2773807783081154, 'max_depth': 65, 'num_leaves': 513, 'min_data_in_leaf': 40, 'lambda_l1': 0.04445163048922108, 'lambda_l2': 0.24274649296907194} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40494914630119183, 'max_depth': 68, 'num_leaves': 611, 'min_data_in_leaf': 37, 'lambda_l1': 0.06350525293462596, 'lambda_l2': 0.14544997853806071} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3492535278852901, 'max_depth': 76, 'num_leaves': 523, 'min_data_in_leaf': 42, 'lambda_l1': 0.017845653665076677, 'lambda_l2': 0.2838729689052561} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29470980689459936, 'max_depth': 57, 'num_leaves': 734, 'min_data_in_leaf': 33, 'lambda_l1': 0.08704650723186157, 'lambda_l2': 0.1607531714331343} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40991161786404834, 'max_depth': 53, 'num_leaves': 980, 'min_data_in_leaf': 33, 'lambda_l1': 0.1076111498438343, 'lambda_l2': 0.0947894899165886} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.33323849105262127, 'max_depth': 56, 'num_leaves': 794, 'min_data_in_leaf': 31, 'lambda_l1': 0.08927148474560316, 'lambda_l2': 0.11626525502800439} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.002687441673999686, 'max_depth': 54, 'num_leaves': 821, 'min_data_in_leaf': 31, 'lambda_l1': 0.11199121218656369, 'lambda_l2': 0.09546831803996937} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.46220191190813026, 'max_depth': 57, 'num_leaves': 863, 'min_data_in_leaf': 32, 'lambda_l1': 0.0952176183438063, 'lambda_l2': 0.009062904663519222} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2546551855550292, 'max_depth': 52, 'num_leaves': 948, 'min_data_in_leaf': 30, 'lambda_l1': 0.08097148761139564, 'lambda_l2': 0.13520272998934135} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.36185970937436207, 'max_depth': 21, 'num_leaves': 753, 'min_data_in_leaf': 32, 'lambda_l1': 0.0389555598323465, 'lambda_l2': 2.48290204842111} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3129375457450648, 'max_depth': 56, 'num_leaves': 694, 'min_data_in_leaf': 34, 'lambda_l1': 0.06738160291628022, 'lambda_l2': 2.79306144617979} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.41512177126969485, 'max_depth': 58, 'num_leaves': 1071, 'min_data_in_leaf': 34, 'lambda_l1': 0.11926308736664233, 'lambda_l2': 0.09709527334391745} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.365339594801695, 'max_depth': 54, 'num_leaves': 883, 'min_data_in_leaf': 30, 'lambda_l1': 0.10112786149868946, 'lambda_l2': 0.2216369412997022} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29280374904596995, 'max_depth': 6, 'num_leaves': 742, 'min_data_in_leaf': 35, 'lambda_l1': 0.19658272615093886, 'lambda_l2': 0.19512939160260628} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.43264501255160215, 'max_depth': 55, 'num_leaves': 681, 'min_data_in_leaf': 33, 'lambda_l1': 0.0004351659400364874, 'lambda_l2': 0.1974208867851334} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22367838141871108, 'max_depth': 78, 'num_leaves': 468, 'min_data_in_leaf': 34, 'lambda_l1': 0.05570906439213868, 'lambda_l2': 0.30392476706320015} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4746836014877351, 'max_depth': 51, 'num_leaves': 643, 'min_data_in_leaf': 35, 'lambda_l1': 0.08300929242674393, 'lambda_l2': 2.321365557685177} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2683575672943186, 'max_depth': 59, 'num_leaves': 752, 'min_data_in_leaf': 36, 'lambda_l1': 0.03363100013059041, 'lambda_l2': 0.0008833227372953709} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37964362645574656, 'max_depth': 16, 'num_leaves': 453, 'min_data_in_leaf': 30, 'lambda_l1': 0.06129165784035821, 'lambda_l2': 0.003809188296342754} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.08001204898313746, 'max_depth': 52, 'num_leaves': 1408, 'min_data_in_leaf': 16, 'lambda_l1': 0.12638238912531774, 'lambda_l2': 0.13501970981698636} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.1554134739601396, 'max_depth': 58, 'num_leaves': 561, 'min_data_in_leaf': 19, 'lambda_l1': 0.09241911158121292, 'lambda_l2': 4.405276511716839} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.31593337971814794, 'max_depth': 49, 'num_leaves': 544, 'min_data_in_leaf': 36, 'lambda_l1': 0.0699497027175848, 'lambda_l2': 0.0022846365969148804} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.19176631997803817, 'max_depth': 56, 'num_leaves': 687, 'min_data_in_leaf': 33, 'lambda_l1': 0.11182179909443293, 'lambda_l2': 0.27543840332248065} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33982381473028944, 'max_depth': 54, 'num_leaves': 401, 'min_data_in_leaf': 37, 'lambda_l1': 0.043353008568970466, 'lambda_l2': 2.714715402491664} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.49224440830346483, 'max_depth': 49, 'num_leaves': 460, 'min_data_in_leaf': 38, 'lambda_l1': 0.08321771596275437, 'lambda_l2': 0.1701268066296075} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.24519381215593564, 'max_depth': 57, 'num_leaves': 609, 'min_data_in_leaf': 32, 'lambda_l1': 0.01698360437527517, 'lambda_l2': 0.1286731547185139} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3976652715882141, 'max_depth': 74, 'num_leaves': 736, 'min_data_in_leaf': 35, 'lambda_l1': 0.09630371742397338, 'lambda_l2': 2.613726791426383} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.30013488730888066, 'max_depth': 51, 'num_leaves': 917, 'min_data_in_leaf': 29, 'lambda_l1': 0.05898955682891498, 'lambda_l2': 0.2928747400363024} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3583455509277934, 'max_depth': 53, 'num_leaves': 502, 'min_data_in_leaf': 37, 'lambda_l1': 0.13075539889251847, 'lambda_l2': 0.0903185116921737} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4526946670962579, 'max_depth': 59, 'num_leaves': 840, 'min_data_in_leaf': 33, 'lambda_l1': 0.07815717942489696, 'lambda_l2': 0.20334367572713713} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.26585490782270027, 'max_depth': 47, 'num_leaves': 1247, 'min_data_in_leaf': 38, 'lambda_l1': 0.04581880570439843, 'lambda_l2': 0.32611827291041484} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3161604296630275, 'max_depth': 55, 'num_leaves': 578, 'min_data_in_leaf': 35, 'lambda_l1': 0.02915000960716664, 'lambda_l2': 0.2084932437961461} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4042150226192442, 'max_depth': 49, 'num_leaves': 654, 'min_data_in_leaf': 39, 'lambda_l1': 0.10992427116206921, 'lambda_l2': 0.09685097728294832} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.49203041870604214, 'max_depth': 57, 'num_leaves': 443, 'min_data_in_leaf': 31, 'lambda_l1': 0.14393853790496702, 'lambda_l2': 4.121697827410142} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3649069952889673, 'max_depth': 71, 'num_leaves': 524, 'min_data_in_leaf': 36, 'lambda_l1': 0.06587462541983616, 'lambda_l2': 0.00673594924802462} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2812961741842752, 'max_depth': 62, 'num_leaves': 384, 'min_data_in_leaf': 39, 'lambda_l1': 0.09035382985836603, 'lambda_l2': 0.21349151542897332} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3130737797350983, 'max_depth': 60, 'num_leaves': 736, 'min_data_in_leaf': 34, 'lambda_l1': 0.05438513361336234, 'lambda_l2': 0.36113688427892543} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.42652088830648777, 'max_depth': 63, 'num_leaves': 914, 'min_data_in_leaf': 37, 'lambda_l1': 0.01745923255353738, 'lambda_l2': 0.32805195094228784} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3356036189931436, 'max_depth': 67, 'num_leaves': 782, 'min_data_in_leaf': 36, 'lambda_l1': 0.03998111441034539, 'lambda_l2': 0.39317550192728823} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3737204943412367, 'max_depth': 60, 'num_leaves': 813, 'min_data_in_leaf': 39, 'lambda_l1': 0.032628313758963544, 'lambda_l2': 0.46731564559614175} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4946035545825827, 'max_depth': 63, 'num_leaves': 995, 'min_data_in_leaf': 34, 'lambda_l1': 2.691487318231406e-05, 'lambda_l2': 0.35050894266908317} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32257692444556235, 'max_depth': 62, 'num_leaves': 733, 'min_data_in_leaf': 37, 'lambda_l1': 0.05269143131234528, 'lambda_l2': 0.37596751521824245} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.38706668342942424, 'max_depth': 64, 'num_leaves': 872, 'min_data_in_leaf': 39, 'lambda_l1': 0.03310706546823426, 'lambda_l2': 0.47548468405536826} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4392291929966487, 'max_depth': 65, 'num_leaves': 805, 'min_data_in_leaf': 35, 'lambda_l1': 0.016506221846690414, 'lambda_l2': 0.5509632325089507} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3472689126167023, 'max_depth': 62, 'num_leaves': 853, 'min_data_in_leaf': 37, 'lambda_l1': 0.04965529202824742, 'lambda_l2': 0.4171039204237402} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.43325523203298694, 'max_depth': 61, 'num_leaves': 721, 'min_data_in_leaf': 20, 'lambda_l1': 0.053091394572206976, 'lambda_l2': 2.509958097713942} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.03949867627558701, 'max_depth': 1, 'num_leaves': 769, 'min_data_in_leaf': 40, 'lambda_l1': 0.027009749616561895, 'lambda_l2': 2.8389832904072803} : acc= 57.08%\n",
            "[HPO] metrics with {'learning_rate': 0.33071767516170325, 'max_depth': 63, 'num_leaves': 926, 'min_data_in_leaf': 34, 'lambda_l1': 0.05444468756307704, 'lambda_l2': 0.48356497761435335} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5042886456210595, 'max_depth': 63, 'num_leaves': 731, 'min_data_in_leaf': 31, 'lambda_l1': 0.03477946080810629, 'lambda_l2': 0.4881087853352301} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3812870789423749, 'max_depth': 61, 'num_leaves': 821, 'min_data_in_leaf': 38, 'lambda_l1': 0.05701945665220768, 'lambda_l2': 0.3793579774329315} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3257044955137187, 'max_depth': 61, 'num_leaves': 716, 'min_data_in_leaf': 41, 'lambda_l1': 0.0193373672001319, 'lambda_l2': 4.899721730600149} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.008375961016121447, 'max_depth': 60, 'num_leaves': 1057, 'min_data_in_leaf': 36, 'lambda_l1': 0.04436171449282921, 'lambda_l2': 0.364608817832357} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4184511095955842, 'max_depth': 64, 'num_leaves': 737, 'min_data_in_leaf': 29, 'lambda_l1': 0.06864141714859219, 'lambda_l2': 0.31597696965997224} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.013984386105996218, 'max_depth': 64, 'num_leaves': 862, 'min_data_in_leaf': 33, 'lambda_l1': 0.2111048943671554, 'lambda_l2': 0.5926416819877545} : acc= 52.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5080328706369123, 'max_depth': 47, 'num_leaves': 722, 'min_data_in_leaf': 38, 'lambda_l1': 0.06636137860843613, 'lambda_l2': 2.699259596204387} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.34264752501264306, 'max_depth': 65, 'num_leaves': 666, 'min_data_in_leaf': 40, 'lambda_l1': 0.04620472137291947, 'lambda_l2': 4.227890605776249} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4572395953008961, 'max_depth': 66, 'num_leaves': 912, 'min_data_in_leaf': 21, 'lambda_l1': 0.02530228216344645, 'lambda_l2': 0.4084867215771059} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.29932647471360924, 'max_depth': 68, 'num_leaves': 765, 'min_data_in_leaf': 36, 'lambda_l1': 0.06789153568183005, 'lambda_l2': 0.3000438098194289} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.38636482912177683, 'max_depth': 14, 'num_leaves': 676, 'min_data_in_leaf': 34, 'lambda_l1': 0.04404569848298222, 'lambda_l2': 0.2540141362399978} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31039678494487627, 'max_depth': 60, 'num_leaves': 800, 'min_data_in_leaf': 38, 'lambda_l1': 0.013380668211802817, 'lambda_l2': 0.3858854418531045} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3898227497791109, 'max_depth': 62, 'num_leaves': 674, 'min_data_in_leaf': 41, 'lambda_l1': 0.06696988756630927, 'lambda_l2': 2.174249451058338} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.544473640815367, 'max_depth': 68, 'num_leaves': 622, 'min_data_in_leaf': 35, 'lambda_l1': 0.07542721041432182, 'lambda_l2': 0.47701420660180305} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.45014983810833475, 'max_depth': 66, 'num_leaves': 365, 'min_data_in_leaf': 32, 'lambda_l1': 0.03638900672988005, 'lambda_l2': 4.532502308935445} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3516289930666068, 'max_depth': 12, 'num_leaves': 835, 'min_data_in_leaf': 39, 'lambda_l1': 0.1006226242258972, 'lambda_l2': 0.2916394861196512} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28447382492740475, 'max_depth': 59, 'num_leaves': 635, 'min_data_in_leaf': 28, 'lambda_l1': 0.0525184112887401, 'lambda_l2': 2.368676562847} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.329975586580361, 'max_depth': 48, 'num_leaves': 1145, 'min_data_in_leaf': 37, 'lambda_l1': 0.09302887107912293, 'lambda_l2': 0.28592802269590645} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.0017831046457269782, 'max_depth': 61, 'num_leaves': 1182, 'min_data_in_leaf': 31, 'lambda_l1': 0.1107637101467947, 'lambda_l2': 0.5273700713577105} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2689848299839286, 'max_depth': 72, 'num_leaves': 871, 'min_data_in_leaf': 34, 'lambda_l1': 0.1484563623092058, 'lambda_l2': 0.38722194393470794} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3097226423363724, 'max_depth': 47, 'num_leaves': 1166, 'min_data_in_leaf': 36, 'lambda_l1': 0.0008777605451358098, 'lambda_l2': 2.8297285006450785} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.39278508898844366, 'max_depth': 76, 'num_leaves': 1378, 'min_data_in_leaf': 33, 'lambda_l1': 0.07374384393427424, 'lambda_l2': 2.604721850966819} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4764221753356243, 'max_depth': 63, 'num_leaves': 1269, 'min_data_in_leaf': 23, 'lambda_l1': 0.056670689630235895, 'lambda_l2': 4.812833171006787} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2394444124607662, 'max_depth': 59, 'num_leaves': 1142, 'min_data_in_leaf': 37, 'lambda_l1': 0.12186687993636426, 'lambda_l2': 0.5886109364814505} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3374714491544398, 'max_depth': 70, 'num_leaves': 1100, 'min_data_in_leaf': 17, 'lambda_l1': 0.18491812557586754, 'lambda_l2': 0.0003676462625098187} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5523595677301181, 'max_depth': 49, 'num_leaves': 1152, 'min_data_in_leaf': 97, 'lambda_l1': 0.0953645469131692, 'lambda_l2': 0.27148269141811915} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.060175941086904626, 'max_depth': 47, 'num_leaves': 1026, 'min_data_in_leaf': 30, 'lambda_l1': 0.0321961455808335, 'lambda_l2': 4.991785601264742} : acc= 63.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4289926319944755, 'max_depth': 78, 'num_leaves': 341, 'min_data_in_leaf': 35, 'lambda_l1': 0.07857055771598344, 'lambda_l2': 0.36289775350819803} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28579355732613754, 'max_depth': 62, 'num_leaves': 1247, 'min_data_in_leaf': 40, 'lambda_l1': 0.054976732788525474, 'lambda_l2': 2.522210765873859} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.35866776860167343, 'max_depth': 59, 'num_leaves': 1081, 'min_data_in_leaf': 32, 'lambda_l1': 0.5008012175167693, 'lambda_l2': 4.009776199022349} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.020033920500985656, 'max_depth': 46, 'num_leaves': 964, 'min_data_in_leaf': 36, 'lambda_l1': 0.09591625858018746, 'lambda_l2': 0.23575831362279387} : acc= 54.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3174933410471062, 'max_depth': 50, 'num_leaves': 1055, 'min_data_in_leaf': 43, 'lambda_l1': 0.12104419696379101, 'lambda_l2': 0.4578004519599812} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.40564344066438524, 'max_depth': 59, 'num_leaves': 1275, 'min_data_in_leaf': 38, 'lambda_l1': 0.024008833777889697, 'lambda_l2': 0.0956619372568647} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5269937054787478, 'max_depth': 66, 'num_leaves': 1335, 'min_data_in_leaf': 41, 'lambda_l1': 0.06873415101274816, 'lambda_l2': 0.3619259157769892} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.26116677796211923, 'max_depth': 23, 'num_leaves': 1128, 'min_data_in_leaf': 34, 'lambda_l1': 0.0492410392671835, 'lambda_l2': 0.20946022203166983} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.47207828863224555, 'max_depth': 61, 'num_leaves': 1202, 'min_data_in_leaf': 37, 'lambda_l1': 0.08841137773064302, 'lambda_l2': 2.7757480990336325} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.22035402540124857, 'max_depth': 47, 'num_leaves': 1102, 'min_data_in_leaf': 39, 'lambda_l1': 0.135235088188352, 'lambda_l2': 0.10827630125268607} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.35798127085656634, 'max_depth': 49, 'num_leaves': 927, 'min_data_in_leaf': 13, 'lambda_l1': 0.10798689738593278, 'lambda_l2': 0.3074912998103888} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3077561900355135, 'max_depth': 73, 'num_leaves': 279, 'min_data_in_leaf': 28, 'lambda_l1': 0.035504496854080005, 'lambda_l2': 0.18063678021250112} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.42847727615881365, 'max_depth': 45, 'num_leaves': 1014, 'min_data_in_leaf': 35, 'lambda_l1': 0.08101007607279846, 'lambda_l2': 4.7175846989061245} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.11464760281992514, 'max_depth': 64, 'num_leaves': 1519, 'min_data_in_leaf': 32, 'lambda_l1': 0.16371205825958354, 'lambda_l2': 0.5989786430115237} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.38728958453705703, 'max_depth': 62, 'num_leaves': 1007, 'min_data_in_leaf': 18, 'lambda_l1': 0.06356293798053606, 'lambda_l2': 0.47324683148235314} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2752190640436228, 'max_depth': 58, 'num_leaves': 1199, 'min_data_in_leaf': 41, 'lambda_l1': 0.015637040165724543, 'lambda_l2': 0.24527930810756302} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3333740118947146, 'max_depth': 75, 'num_leaves': 397, 'min_data_in_leaf': 21, 'lambda_l1': 0.049051164069450995, 'lambda_l2': 0.10212789572289326} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5797909003449127, 'max_depth': 60, 'num_leaves': 428, 'min_data_in_leaf': 37, 'lambda_l1': 0.10726900353667893, 'lambda_l2': 2.9376433220407367} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4822934802212046, 'max_depth': 49, 'num_leaves': 785, 'min_data_in_leaf': 34, 'lambda_l1': 0.07696350817761918, 'lambda_l2': 4.338931181472021} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2938211500050567, 'max_depth': 45, 'num_leaves': 293, 'min_data_in_leaf': 44, 'lambda_l1': 0.0944275648465775, 'lambda_l2': 0.0030276951459831517} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3726722643095058, 'max_depth': 51, 'num_leaves': 746, 'min_data_in_leaf': 30, 'lambda_l1': 0.06103184295026903, 'lambda_l2': 0.3549233997792508} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.24446312656277197, 'max_depth': 58, 'num_leaves': 467, 'min_data_in_leaf': 39, 'lambda_l1': 0.03635341673913622, 'lambda_l2': 0.15786804970548435} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.43518421643526045, 'max_depth': 47, 'num_leaves': 943, 'min_data_in_leaf': 23, 'lambda_l1': 0.13024367178007204, 'lambda_l2': 1.8001530564341197} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5807904647859464, 'max_depth': 61, 'num_leaves': 672, 'min_data_in_leaf': 36, 'lambda_l1': 0.07637928135144889, 'lambda_l2': 0.4414735737245359} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.33931055285107403, 'max_depth': 65, 'num_leaves': 343, 'min_data_in_leaf': 40, 'lambda_l1': 0.09977024240913669, 'lambda_l2': 0.24154855034049336} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.38726161403024467, 'max_depth': 50, 'num_leaves': 499, 'min_data_in_leaf': 33, 'lambda_l1': 0.05590176435564296, 'lambda_l2': 2.4398864394072404} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.31388199248062554, 'max_depth': 51, 'num_leaves': 369, 'min_data_in_leaf': 32, 'lambda_l1': 0.03478378766530625, 'lambda_l2': 1.702767236314378} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.26905477019123303, 'max_depth': 49, 'num_leaves': 442, 'min_data_in_leaf': 30, 'lambda_l1': 0.05284315180643291, 'lambda_l2': 1.5158249682713638} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.36548367210183674, 'max_depth': 51, 'num_leaves': 509, 'min_data_in_leaf': 32, 'lambda_l1': 0.014527945708116698, 'lambda_l2': 1.9210561742536874} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.299553103801286, 'max_depth': 49, 'num_leaves': 275, 'min_data_in_leaf': 34, 'lambda_l1': 0.0599010646013099, 'lambda_l2': 2.2129061041558864} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.34142874186132505, 'max_depth': 52, 'num_leaves': 402, 'min_data_in_leaf': 33, 'lambda_l1': 0.034888581605466186, 'lambda_l2': 2.6303620250654243} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3852300681956821, 'max_depth': 51, 'num_leaves': 476, 'min_data_in_leaf': 30, 'lambda_l1': 0.07374744642653394, 'lambda_l2': 2.2843133352098786} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3026639175111393, 'max_depth': 48, 'num_leaves': 329, 'min_data_in_leaf': 35, 'lambda_l1': 0.046549212340350435, 'lambda_l2': 4.803361051544514} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4066927572385649, 'max_depth': 47, 'num_leaves': 426, 'min_data_in_leaf': 32, 'lambda_l1': 0.013519349904958254, 'lambda_l2': 2.4385055084861063} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2436763926651477, 'max_depth': 4, 'num_leaves': 538, 'min_data_in_leaf': 35, 'lambda_l1': 0.08457411670198592, 'lambda_l2': 2.903252348839555} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3417026783425907, 'max_depth': 46, 'num_leaves': 1318, 'min_data_in_leaf': 28, 'lambda_l1': 0.06534787319190499, 'lambda_l2': 2.6671302453660486} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2727526425180655, 'max_depth': 53, 'num_leaves': 264, 'min_data_in_leaf': 37, 'lambda_l1': 0.03211999906303108, 'lambda_l2': 1.3950723651893695} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3169634673622291, 'max_depth': 51, 'num_leaves': 1466, 'min_data_in_leaf': 34, 'lambda_l1': 0.05545064961202186, 'lambda_l2': 2.761008303519156} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.39465081876532265, 'max_depth': 50, 'num_leaves': 487, 'min_data_in_leaf': 32, 'lambda_l1': 0.09074021758720907, 'lambda_l2': 4.622424843608994} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.34837866376694643, 'max_depth': 48, 'num_leaves': 349, 'min_data_in_leaf': 37, 'lambda_l1': 0.07078616580361015, 'lambda_l2': 2.068580725314046} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.0010100740197871037, 'max_depth': 53, 'num_leaves': 565, 'min_data_in_leaf': 35, 'lambda_l1': 0.0005182328929065269, 'lambda_l2': 0.3204343322141604} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2059809883128345, 'max_depth': 46, 'num_leaves': 409, 'min_data_in_leaf': 30, 'lambda_l1': 0.11357785540384992, 'lambda_l2': 2.108947845028481} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2674585605774027, 'max_depth': 48, 'num_leaves': 488, 'min_data_in_leaf': 33, 'lambda_l1': 0.0434865351722441, 'lambda_l2': 1.5992282088715855} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.42084194426712307, 'max_depth': 45, 'num_leaves': 260, 'min_data_in_leaf': 38, 'lambda_l1': 0.0978927924941333, 'lambda_l2': 0.09652035005934954} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2908279665133544, 'max_depth': 56, 'num_leaves': 571, 'min_data_in_leaf': 36, 'lambda_l1': 0.027218361463417988, 'lambda_l2': 2.4035422258174184} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2279620526878991, 'max_depth': 44, 'num_leaves': 400, 'min_data_in_leaf': 42, 'lambda_l1': 0.07619320916145352, 'lambda_l2': 0.5424086511203315} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3543063699965785, 'max_depth': 50, 'num_leaves': 542, 'min_data_in_leaf': 39, 'lambda_l1': 0.055972320525881816, 'lambda_l2': 2.5068394525088427} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4205521514183803, 'max_depth': 58, 'num_leaves': 618, 'min_data_in_leaf': 33, 'lambda_l1': 0.12647168234942663, 'lambda_l2': 4.185775740490332} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.31784771118360294, 'max_depth': 53, 'num_leaves': 456, 'min_data_in_leaf': 27, 'lambda_l1': 0.0893883626042118, 'lambda_l2': 0.24231104481793364} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.48071125113308416, 'max_depth': 49, 'num_leaves': 334, 'min_data_in_leaf': 37, 'lambda_l1': 0.06551410673305749, 'lambda_l2': 0.41952218037327016} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3917624297994901, 'max_depth': 60, 'num_leaves': 1006, 'min_data_in_leaf': 31, 'lambda_l1': 0.15391015716251144, 'lambda_l2': 4.456116275576535} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.26621180477131845, 'max_depth': 55, 'num_leaves': 1113, 'min_data_in_leaf': 40, 'lambda_l1': 0.10577456595460383, 'lambda_l2': 0.10511397740283712} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3286785480533829, 'max_depth': 47, 'num_leaves': 1231, 'min_data_in_leaf': 35, 'lambda_l1': 0.04420166036539596, 'lambda_l2': 0.16884151462424604} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.0015105108138097631, 'max_depth': 57, 'num_leaves': 248, 'min_data_in_leaf': 42, 'lambda_l1': 0.01660947982360369, 'lambda_l2': 0.0026028784773524938} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3672097050071293, 'max_depth': 44, 'num_leaves': 504, 'min_data_in_leaf': 38, 'lambda_l1': 0.08197185998538666, 'lambda_l2': 0.35690495793844246} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3036562311733797, 'max_depth': 51, 'num_leaves': 400, 'min_data_in_leaf': 45, 'lambda_l1': 0.11311372343471005, 'lambda_l2': 0.2682462734664838} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.43658724589491893, 'max_depth': 62, 'num_leaves': 596, 'min_data_in_leaf': 29, 'lambda_l1': 0.05643302728335813, 'lambda_l2': 4.880095476116365} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4982552615285094, 'max_depth': 46, 'num_leaves': 658, 'min_data_in_leaf': 36, 'lambda_l1': 0.03495243485572966, 'lambda_l2': 0.1026132125352589} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23558735297437014, 'max_depth': 54, 'num_leaves': 515, 'min_data_in_leaf': 34, 'lambda_l1': 0.13938231638534235, 'lambda_l2': 0.194267748361298} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.37127795666145585, 'max_depth': 49, 'num_leaves': 724, 'min_data_in_leaf': 40, 'lambda_l1': 0.07665349667311493, 'lambda_l2': 0.002087239707447508} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27715398225969423, 'max_depth': 59, 'num_leaves': 327, 'min_data_in_leaf': 37, 'lambda_l1': 0.09418200526576671, 'lambda_l2': 0.6529692457134196} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.32629287027017534, 'max_depth': 57, 'num_leaves': 428, 'min_data_in_leaf': 43, 'lambda_l1': 0.06116039655674236, 'lambda_l2': 0.3987568214520055} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.43821771665291315, 'max_depth': 52, 'num_leaves': 570, 'min_data_in_leaf': 31, 'lambda_l1': 0.024944394134167297, 'lambda_l2': 0.2936189964246702} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.18565989313068787, 'max_depth': 19, 'num_leaves': 771, 'min_data_in_leaf': 39, 'lambda_l1': 0.11367680246019266, 'lambda_l2': 0.5247587195139414} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5227418385687164, 'max_depth': 44, 'num_leaves': 233, 'min_data_in_leaf': 55, 'lambda_l1': 0.04778219110819004, 'lambda_l2': 0.18014596213309914} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3781745658080065, 'max_depth': 63, 'num_leaves': 869, 'min_data_in_leaf': 33, 'lambda_l1': 0.08525287412889977, 'lambda_l2': 0.10103482296526442} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.30159393608488755, 'max_depth': 47, 'num_leaves': 467, 'min_data_in_leaf': 35, 'lambda_l1': 0.06622223319882786, 'lambda_l2': 0.30108258136152055} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2630076385700714, 'max_depth': 50, 'num_leaves': 655, 'min_data_in_leaf': 38, 'lambda_l1': 0.12688611812073608, 'lambda_l2': 0.43967419097628535} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3527430199752469, 'max_depth': 59, 'num_leaves': 374, 'min_data_in_leaf': 41, 'lambda_l1': 0.04167353156427094, 'lambda_l2': 2.851326434242629} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5933683414048697, 'max_depth': 55, 'num_leaves': 577, 'min_data_in_leaf': 36, 'lambda_l1': 0.10172011905077179, 'lambda_l2': 0.1981072341518193} : acc= 73.75%\n",
            "[HPO] metrics with {'learning_rate': 0.53377835311328, 'max_depth': 53, 'num_leaves': 599, 'min_data_in_leaf': 36, 'lambda_l1': 0.14363436277122707, 'lambda_l2': 0.22978708552416283} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4272327656891948, 'max_depth': 55, 'num_leaves': 568, 'min_data_in_leaf': 37, 'lambda_l1': 0.1053612940036267, 'lambda_l2': 0.11040071888552594} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.46768355095193914, 'max_depth': 55, 'num_leaves': 497, 'min_data_in_leaf': 39, 'lambda_l1': 0.07598832562426984, 'lambda_l2': 0.1980185741860543} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5387185342917077, 'max_depth': 57, 'num_leaves': 689, 'min_data_in_leaf': 35, 'lambda_l1': 0.0007356326479198219, 'lambda_l2': 0.3184361267249269} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3879117564403702, 'max_depth': 54, 'num_leaves': 620, 'min_data_in_leaf': 37, 'lambda_l1': 0.055434560436237124, 'lambda_l2': 0.19734128235503057} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6071342249681262, 'max_depth': 56, 'num_leaves': 531, 'min_data_in_leaf': 34, 'lambda_l1': 0.025511343030625782, 'lambda_l2': 0.12008711816384468} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4711586837553236, 'max_depth': 53, 'num_leaves': 715, 'min_data_in_leaf': 41, 'lambda_l1': 0.17609408848331726, 'lambda_l2': 4.117303122014771} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.32492905386821774, 'max_depth': 56, 'num_leaves': 449, 'min_data_in_leaf': 39, 'lambda_l1': 0.09350216061342445, 'lambda_l2': 4.290738725091039} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.41225027159851674, 'max_depth': 52, 'num_leaves': 595, 'min_data_in_leaf': 43, 'lambda_l1': 0.07369214572751161, 'lambda_l2': 4.55717735229492} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24899202186692496, 'max_depth': 57, 'num_leaves': 680, 'min_data_in_leaf': 34, 'lambda_l1': 0.11713798291101041, 'lambda_l2': 0.28767514046122794} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.29702152699820566, 'max_depth': 54, 'num_leaves': 525, 'min_data_in_leaf': 36, 'lambda_l1': 0.04362315844416021, 'lambda_l2': 0.08477342223932469} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.37245138276781176, 'max_depth': 60, 'num_leaves': 778, 'min_data_in_leaf': 38, 'lambda_l1': 0.0870794061433207, 'lambda_l2': 0.3419789899355906} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4536658083780592, 'max_depth': 58, 'num_leaves': 422, 'min_data_in_leaf': 45, 'lambda_l1': 0.06813048943759614, 'lambda_l2': 4.742037016988059} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.21530280792817658, 'max_depth': 55, 'num_leaves': 344, 'min_data_in_leaf': 40, 'lambda_l1': 0.02120398782862925, 'lambda_l2': 0.20091156559792367} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5877754052484649, 'max_depth': 52, 'num_leaves': 626, 'min_data_in_leaf': 52, 'lambda_l1': 0.09980823988829418, 'lambda_l2': 0.1649532264761515} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33641457663017993, 'max_depth': 50, 'num_leaves': 516, 'min_data_in_leaf': 33, 'lambda_l1': 0.048047992350567253, 'lambda_l2': 0.37019572623593194} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5091166952913364, 'max_depth': 60, 'num_leaves': 448, 'min_data_in_leaf': 36, 'lambda_l1': 0.1525054582110305, 'lambda_l2': 0.0006250847132477171} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.30544666532017367, 'max_depth': 58, 'num_leaves': 581, 'min_data_in_leaf': 42, 'lambda_l1': 0.05665588929002367, 'lambda_l2': 0.21838328991603934} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.38398995949534004, 'max_depth': 56, 'num_leaves': 798, 'min_data_in_leaf': 38, 'lambda_l1': 0.1253111900976324, 'lambda_l2': 0.0838324295705408} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2737266862881532, 'max_depth': 52, 'num_leaves': 300, 'min_data_in_leaf': 36, 'lambda_l1': 0.08216983278920112, 'lambda_l2': 0.27339796638573943} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42760528107374135, 'max_depth': 62, 'num_leaves': 382, 'min_data_in_leaf': 40, 'lambda_l1': 0.10389175042366902, 'lambda_l2': 3.030360372483559} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3539168183851501, 'max_depth': 54, 'num_leaves': 674, 'min_data_in_leaf': 33, 'lambda_l1': 0.9629685293810757, 'lambda_l2': 0.08980794840491013} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4836158668205706, 'max_depth': 49, 'num_leaves': 490, 'min_data_in_leaf': 38, 'lambda_l1': 0.03493100697121229, 'lambda_l2': 0.46056502125931464} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24468137681670174, 'max_depth': 58, 'num_leaves': 713, 'min_data_in_leaf': 35, 'lambda_l1': 0.06831457239536509, 'lambda_l2': 4.916355938708669} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32452049509118713, 'max_depth': 61, 'num_leaves': 565, 'min_data_in_leaf': 48, 'lambda_l1': 0.0854442148059759, 'lambda_l2': 0.004980035374399533} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3969567889511832, 'max_depth': 48, 'num_leaves': 229, 'min_data_in_leaf': 42, 'lambda_l1': 0.018622794885372197, 'lambda_l2': 2.5582328611969807} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2950517247860784, 'max_depth': 51, 'num_leaves': 618, 'min_data_in_leaf': 39, 'lambda_l1': 0.13418348256571844, 'lambda_l2': 0.27627398918018053} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6081595741409428, 'max_depth': 56, 'num_leaves': 460, 'min_data_in_leaf': 34, 'lambda_l1': 0.05961577266497384, 'lambda_l2': 0.16869776077864934} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3368306347394568, 'max_depth': 60, 'num_leaves': 318, 'min_data_in_leaf': 37, 'lambda_l1': 0.11447038643705362, 'lambda_l2': 2.723549638703803} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5232074534249113, 'max_depth': 46, 'num_leaves': 537, 'min_data_in_leaf': 44, 'lambda_l1': 0.038862398245880926, 'lambda_l2': 4.433787904112374} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43441317026562803, 'max_depth': 10, 'num_leaves': 805, 'min_data_in_leaf': 32, 'lambda_l1': 0.09429432491455132, 'lambda_l2': 0.3741457266401204} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.002130914444609983, 'max_depth': 53, 'num_leaves': 385, 'min_data_in_leaf': 41, 'lambda_l1': 0.19802795776470183, 'lambda_l2': 0.2536545978978809} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27573081195951493, 'max_depth': 50, 'num_leaves': 706, 'min_data_in_leaf': 36, 'lambda_l1': 0.0702603404547332, 'lambda_l2': 0.09546723142422318} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3746000012357218, 'max_depth': 64, 'num_leaves': 619, 'min_data_in_leaf': 40, 'lambda_l1': 0.053790853231119054, 'lambda_l2': 0.17075766815029492} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.030660370705087592, 'max_depth': 58, 'num_leaves': 495, 'min_data_in_leaf': 38, 'lambda_l1': 0.08039406180352293, 'lambda_l2': 0.3287917607742479} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.21689242114416754, 'max_depth': 54, 'num_leaves': 415, 'min_data_in_leaf': 34, 'lambda_l1': 0.11262324694239306, 'lambda_l2': 0.16648831577549056} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.330012903133011, 'max_depth': 48, 'num_leaves': 237, 'min_data_in_leaf': 32, 'lambda_l1': 0.03278091810579012, 'lambda_l2': 4.670596863618927} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.45099436182544317, 'max_depth': 60, 'num_leaves': 742, 'min_data_in_leaf': 35, 'lambda_l1': 0.09699681177648384, 'lambda_l2': 0.4857508901448879} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.27846308015001653, 'max_depth': 46, 'num_leaves': 1659, 'min_data_in_leaf': 37, 'lambda_l1': 0.061428566641563535, 'lambda_l2': 0.37174088315060494} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6333841209657969, 'max_depth': 56, 'num_leaves': 855, 'min_data_in_leaf': 39, 'lambda_l1': 0.1428973207147245, 'lambda_l2': 0.0005386383036235672} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3958036069771996, 'max_depth': 51, 'num_leaves': 547, 'min_data_in_leaf': 43, 'lambda_l1': 0.046367154503349085, 'lambda_l2': 0.08835629091591737} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5372800903387727, 'max_depth': 58, 'num_leaves': 658, 'min_data_in_leaf': 41, 'lambda_l1': 0.01768612432534459, 'lambda_l2': 0.4304110532964305} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.0038023312637952287, 'max_depth': 62, 'num_leaves': 314, 'min_data_in_leaf': 36, 'lambda_l1': 0.0802774808891213, 'lambda_l2': 0.21964106078390644} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24288448878869967, 'max_depth': 48, 'num_leaves': 445, 'min_data_in_leaf': 33, 'lambda_l1': 0.16100239595975774, 'lambda_l2': 0.28414412727683636} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.30945108565334023, 'max_depth': 52, 'num_leaves': 602, 'min_data_in_leaf': 38, 'lambda_l1': 0.12892108108745823, 'lambda_l2': 0.08977723520894648} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.354443323938722, 'max_depth': 55, 'num_leaves': 375, 'min_data_in_leaf': 31, 'lambda_l1': 0.5103270349146403, 'lambda_l2': 4.9969802988149485} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4482548877810056, 'max_depth': 63, 'num_leaves': 555, 'min_data_in_leaf': 45, 'lambda_l1': 0.9226968068796998, 'lambda_l2': 0.0005321518585534868} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3919229827400523, 'max_depth': 45, 'num_leaves': 735, 'min_data_in_leaf': 6, 'lambda_l1': 0.10154439788940539, 'lambda_l2': 2.9547992733246033} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2941806352291949, 'max_depth': 59, 'num_leaves': 492, 'min_data_in_leaf': 40, 'lambda_l1': 0.05270375216158146, 'lambda_l2': 0.17355072717950365} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5718938086338804, 'max_depth': 48, 'num_leaves': 646, 'min_data_in_leaf': 36, 'lambda_l1': 0.0009332715156352284, 'lambda_l2': 2.589004629979275} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.48486172584665865, 'max_depth': 61, 'num_leaves': 292, 'min_data_in_leaf': 34, 'lambda_l1': 0.07174557263280434, 'lambda_l2': 0.28776720441199566} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3405797775929989, 'max_depth': 53, 'num_leaves': 3994, 'min_data_in_leaf': 38, 'lambda_l1': 0.0329348761708816, 'lambda_l2': 4.812518628997963} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2692431283393658, 'max_depth': 65, 'num_leaves': 831, 'min_data_in_leaf': 42, 'lambda_l1': 0.0895711703977219, 'lambda_l2': 0.41354865524848905} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4024912000508632, 'max_depth': 50, 'num_leaves': 445, 'min_data_in_leaf': 35, 'lambda_l1': 0.1171836664258687, 'lambda_l2': 0.09341136856233037} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6566961664762373, 'max_depth': 57, 'num_leaves': 551, 'min_data_in_leaf': 32, 'lambda_l1': 0.05838850622158566, 'lambda_l2': 0.5692727069050032} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3490186886262987, 'max_depth': 45, 'num_leaves': 371, 'min_data_in_leaf': 79, 'lambda_l1': 0.07663541759600462, 'lambda_l2': 0.23582002168319938} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.24490953841787835, 'max_depth': 50, 'num_leaves': 668, 'min_data_in_leaf': 39, 'lambda_l1': 0.04473558675466157, 'lambda_l2': 2.7294453978886604} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3010944146207355, 'max_depth': 47, 'num_leaves': 229, 'min_data_in_leaf': 37, 'lambda_l1': 0.10484915900325995, 'lambda_l2': 4.066229573381197} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.49821319527874103, 'max_depth': 55, 'num_leaves': 453, 'min_data_in_leaf': 41, 'lambda_l1': 0.02159258941273437, 'lambda_l2': 0.3523657737420586} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.09247373893171926, 'max_depth': 57, 'num_leaves': 335, 'min_data_in_leaf': 41, 'lambda_l1': 0.0010357178156061853, 'lambda_l2': 0.5140424493882123} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6883820235045397, 'max_depth': 55, 'num_leaves': 385, 'min_data_in_leaf': 46, 'lambda_l1': 0.015621136123214502, 'lambda_l2': 0.41737619617566163} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5848957638459883, 'max_depth': 55, 'num_leaves': 458, 'min_data_in_leaf': 43, 'lambda_l1': 0.027880172902757832, 'lambda_l2': 0.35196905994411276} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5190416354833469, 'max_depth': 58, 'num_leaves': 282, 'min_data_in_leaf': 44, 'lambda_l1': 0.023067681852777768, 'lambda_l2': 0.5245386220075652} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.604834335650904, 'max_depth': 55, 'num_leaves': 413, 'min_data_in_leaf': 44, 'lambda_l1': 0.021127995889321814, 'lambda_l2': 0.3497872475028899} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4922689026918342, 'max_depth': 56, 'num_leaves': 483, 'min_data_in_leaf': 42, 'lambda_l1': 0.014635474534297484, 'lambda_l2': 0.4522985237164028} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22005042528456153, 'max_depth': 60, 'num_leaves': 339, 'min_data_in_leaf': 59, 'lambda_l1': 0.03934279592006061, 'lambda_l2': 0.5990175307278035} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42576760896333565, 'max_depth': 54, 'num_leaves': 402, 'min_data_in_leaf': 48, 'lambda_l1': 0.03484628280706454, 'lambda_l2': 0.2843406910632491} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5149214937238006, 'max_depth': 59, 'num_leaves': 213, 'min_data_in_leaf': 41, 'lambda_l1': 0.0005316846751332038, 'lambda_l2': 0.32577354858642427} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.30913619872495723, 'max_depth': 56, 'num_leaves': 478, 'min_data_in_leaf': 40, 'lambda_l1': 0.04784346218063577, 'lambda_l2': 0.19138424527573528} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3670156692439034, 'max_depth': 53, 'num_leaves': 331, 'min_data_in_leaf': 43, 'lambda_l1': 0.061851532515397885, 'lambda_l2': 0.4399521954011053} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.197099231942691, 'max_depth': 59, 'num_leaves': 506, 'min_data_in_leaf': 41, 'lambda_l1': 0.028310968358568868, 'lambda_l2': 0.22273033772295264} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.26239098600902777, 'max_depth': 55, 'num_leaves': 408, 'min_data_in_leaf': 40, 'lambda_l1': 0.045449749057125954, 'lambda_l2': 0.2845862183074222} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7241165400575255, 'max_depth': 57, 'num_leaves': 244, 'min_data_in_leaf': 45, 'lambda_l1': 0.06619035421876188, 'lambda_l2': 0.3620665372398} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.43215648929323175, 'max_depth': 62, 'num_leaves': 556, 'min_data_in_leaf': 50, 'lambda_l1': 0.021859442435843146, 'lambda_l2': 0.13783040300366764} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5796627688697519, 'max_depth': 53, 'num_leaves': 445, 'min_data_in_leaf': 43, 'lambda_l1': 0.07614596975043626, 'lambda_l2': 0.1648305003609013} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3406970865842211, 'max_depth': 58, 'num_leaves': 1581, 'min_data_in_leaf': 39, 'lambda_l1': 0.046583800069886445, 'lambda_l2': 0.48685926531769663} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3684100085479199, 'max_depth': 59, 'num_leaves': 941, 'min_data_in_leaf': 39, 'lambda_l1': 0.012285269115210731, 'lambda_l2': 0.5376120842292391} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.49749112990964056, 'max_depth': 57, 'num_leaves': 1559, 'min_data_in_leaf': 41, 'lambda_l1': 0.03898119513485977, 'lambda_l2': 0.5417708243944237} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4212524959093367, 'max_depth': 60, 'num_leaves': 1746, 'min_data_in_leaf': 40, 'lambda_l1': 0.044321409056875115, 'lambda_l2': 0.39802406092776} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3343710080143356, 'max_depth': 58, 'num_leaves': 1632, 'min_data_in_leaf': 42, 'lambda_l1': 0.013803219930203059, 'lambda_l2': 0.6433392703653477} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.6484454573505675, 'max_depth': 58, 'num_leaves': 553, 'min_data_in_leaf': 39, 'lambda_l1': 0.05938919872868814, 'lambda_l2': 0.6345335408594982} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29597491874486165, 'max_depth': 56, 'num_leaves': 1605, 'min_data_in_leaf': 38, 'lambda_l1': 0.023602522355678297, 'lambda_l2': 0.5182335354922978} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4642317409161269, 'max_depth': 61, 'num_leaves': 1412, 'min_data_in_leaf': 43, 'lambda_l1': 0.04408711585371424, 'lambda_l2': 0.4199955597547999} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.16839569748810201, 'max_depth': 63, 'num_leaves': 1431, 'min_data_in_leaf': 47, 'lambda_l1': 0.05916903464699005, 'lambda_l2': 0.6360231345547167} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.39650131038454667, 'max_depth': 60, 'num_leaves': 1717, 'min_data_in_leaf': 39, 'lambda_l1': 0.0340845733849668, 'lambda_l2': 0.49283620764903313} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5529417272061942, 'max_depth': 57, 'num_leaves': 612, 'min_data_in_leaf': 41, 'lambda_l1': 0.0016312558747937425, 'lambda_l2': 0.5126355656222442} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3554104443505833, 'max_depth': 54, 'num_leaves': 1495, 'min_data_in_leaf': 38, 'lambda_l1': 0.06963302692118045, 'lambda_l2': 0.44147192261797713} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.26813870821597213, 'max_depth': 61, 'num_leaves': 525, 'min_data_in_leaf': 45, 'lambda_l1': 0.052925118349751464, 'lambda_l2': 0.69820043044883} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.30936068047008325, 'max_depth': 58, 'num_leaves': 1578, 'min_data_in_leaf': 37, 'lambda_l1': 0.03263082058897736, 'lambda_l2': 0.4410310826770974} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.46105476249577404, 'max_depth': 56, 'num_leaves': 782, 'min_data_in_leaf': 40, 'lambda_l1': 0.08352747664598922, 'lambda_l2': 0.3608818115368156} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3847671600050378, 'max_depth': 64, 'num_leaves': 606, 'min_data_in_leaf': 42, 'lambda_l1': 0.06540374042233835, 'lambda_l2': 0.5797771917000456} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.33197913526638073, 'max_depth': 60, 'num_leaves': 1437, 'min_data_in_leaf': 38, 'lambda_l1': 0.05055189786005061, 'lambda_l2': 0.37743618596693196} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.24095880493206473, 'max_depth': 54, 'num_leaves': 876, 'min_data_in_leaf': 37, 'lambda_l1': 0.08493183917066371, 'lambda_l2': 0.3279077091233731} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5168276175867679, 'max_depth': 58, 'num_leaves': 721, 'min_data_in_leaf': 40, 'lambda_l1': 0.028079063854619255, 'lambda_l2': 0.5287328005687129} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6617986353620207, 'max_depth': 62, 'num_leaves': 1787, 'min_data_in_leaf': 44, 'lambda_l1': 0.06839348642259915, 'lambda_l2': 0.4576192197883088} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4037620842701951, 'max_depth': 56, 'num_leaves': 539, 'min_data_in_leaf': 42, 'lambda_l1': 0.049100157414394954, 'lambda_l2': 0.2882188904202701} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3003958607466222, 'max_depth': 52, 'num_leaves': 648, 'min_data_in_leaf': 39, 'lambda_l1': 0.08479841704824836, 'lambda_l2': 0.35889648569452914} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34851115033470575, 'max_depth': 66, 'num_leaves': 487, 'min_data_in_leaf': 36, 'lambda_l1': 0.0008949254832987634, 'lambda_l2': 2.3490342425255744} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.45166650461881375, 'max_depth': 59, 'num_leaves': 1380, 'min_data_in_leaf': 38, 'lambda_l1': 0.03280634054765196, 'lambda_l2': 0.2701338112704386} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2596328281390369, 'max_depth': 54, 'num_leaves': 576, 'min_data_in_leaf': 41, 'lambda_l1': 0.06229566683532945, 'lambda_l2': 0.4435344921009041} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5574981428046887, 'max_depth': 61, 'num_leaves': 897, 'min_data_in_leaf': 46, 'lambda_l1': 0.0922589747476297, 'lambda_l2': 0.26899953316833136} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.37954024327327657, 'max_depth': 57, 'num_leaves': 1502, 'min_data_in_leaf': 36, 'lambda_l1': 0.02229335191262652, 'lambda_l2': 4.336581297493737} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.28503184184257085, 'max_depth': 55, 'num_leaves': 1357, 'min_data_in_leaf': 39, 'lambda_l1': 0.06840273028657659, 'lambda_l2': 4.528230991528977} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3309173718101458, 'max_depth': 52, 'num_leaves': 696, 'min_data_in_leaf': 43, 'lambda_l1': 0.048341058131590176, 'lambda_l2': 0.3397812001402056} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.737764876829321, 'max_depth': 63, 'num_leaves': 467, 'min_data_in_leaf': 37, 'lambda_l1': 0.09457182075816388, 'lambda_l2': 0.23835881495801492} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4310303181776166, 'max_depth': 59, 'num_leaves': 796, 'min_data_in_leaf': 35, 'lambda_l1': 0.07186094034353523, 'lambda_l2': 0.6277684917885225} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6122736301444833, 'max_depth': 56, 'num_leaves': 616, 'min_data_in_leaf': 40, 'lambda_l1': 0.04265962532100403, 'lambda_l2': 4.682245619142788} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.22784830165033135, 'max_depth': 58, 'num_leaves': 1318, 'min_data_in_leaf': 38, 'lambda_l1': 0.08301851387201971, 'lambda_l2': 0.4250903885089582} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3664711074079004, 'max_depth': 53, 'num_leaves': 519, 'min_data_in_leaf': 36, 'lambda_l1': 0.017081486041307242, 'lambda_l2': 0.21650831425723363} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.006007501436676737, 'max_depth': 61, 'num_leaves': 421, 'min_data_in_leaf': 42, 'lambda_l1': 0.05449967578450309, 'lambda_l2': 0.4985680721024494} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5084008967556289, 'max_depth': 52, 'num_leaves': 691, 'min_data_in_leaf': 40, 'lambda_l1': 0.09916977267144635, 'lambda_l2': 0.3124319757568672} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3062481996124513, 'max_depth': 35, 'num_leaves': 597, 'min_data_in_leaf': 35, 'lambda_l1': 0.03697094756060776, 'lambda_l2': 4.8390152727824} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.41183748883037596, 'max_depth': 55, 'num_leaves': 1806, 'min_data_in_leaf': 37, 'lambda_l1': 0.07427629339723038, 'lambda_l2': 0.3860108033303302} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.14166414687667134, 'max_depth': 65, 'num_leaves': 504, 'min_data_in_leaf': 45, 'lambda_l1': 0.10480635767134698, 'lambda_l2': 2.2661663044591194} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2675786277331506, 'max_depth': 59, 'num_leaves': 406, 'min_data_in_leaf': 41, 'lambda_l1': 0.05481201704958185, 'lambda_l2': 4.222661831453249} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.34098008265230556, 'max_depth': 57, 'num_leaves': 740, 'min_data_in_leaf': 38, 'lambda_l1': 0.015782592967898905, 'lambda_l2': 0.21319263253327336} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.47833057446416666, 'max_depth': 62, 'num_leaves': 577, 'min_data_in_leaf': 86, 'lambda_l1': 0.08490261061936812, 'lambda_l2': 2.434093187700969} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3206956958999282, 'max_depth': 54, 'num_leaves': 825, 'min_data_in_leaf': 34, 'lambda_l1': 0.0667402028418021, 'lambda_l2': 0.14676925388275874} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.38896887396899693, 'max_depth': 51, 'num_leaves': 481, 'min_data_in_leaf': 39, 'lambda_l1': 0.03602392363499694, 'lambda_l2': 0.557827912765858} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28289479303594867, 'max_depth': 59, 'num_leaves': 956, 'min_data_in_leaf': 43, 'lambda_l1': 0.09077031203177652, 'lambda_l2': 0.31914882393247734} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5500309136696787, 'max_depth': 64, 'num_leaves': 668, 'min_data_in_leaf': 37, 'lambda_l1': 0.05790644670335363, 'lambda_l2': 0.41556144342039236} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43637779230455176, 'max_depth': 56, 'num_leaves': 371, 'min_data_in_leaf': 35, 'lambda_l1': 0.11273499091167972, 'lambda_l2': 0.2597322312870589} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3557472489658814, 'max_depth': 60, 'num_leaves': 543, 'min_data_in_leaf': 40, 'lambda_l1': 0.0348477824289575, 'lambda_l2': 0.7066424758457425} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2382302261697476, 'max_depth': 67, 'num_leaves': 443, 'min_data_in_leaf': 37, 'lambda_l1': 0.0750812560480738, 'lambda_l2': 0.09771945998752517} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6312422513716668, 'max_depth': 57, 'num_leaves': 1673, 'min_data_in_leaf': 33, 'lambda_l1': 0.015578520171083604, 'lambda_l2': 0.21515898822007484} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.48267798606156304, 'max_depth': 51, 'num_leaves': 767, 'min_data_in_leaf': 41, 'lambda_l1': 0.051316339180277455, 'lambda_l2': 0.34586403799335164} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3049042737130192, 'max_depth': 54, 'num_leaves': 608, 'min_data_in_leaf': 39, 'lambda_l1': 0.10216981784582696, 'lambda_l2': 0.4778477602950942} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3857753945862867, 'max_depth': 62, 'num_leaves': 666, 'min_data_in_leaf': 35, 'lambda_l1': 0.08150121283006753, 'lambda_l2': 0.16620096391813105} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.19856440932788222, 'max_depth': 43, 'num_leaves': 354, 'min_data_in_leaf': 44, 'lambda_l1': 0.06348673899902077, 'lambda_l2': 0.0853293423433941} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3337864503865651, 'max_depth': 80, 'num_leaves': 478, 'min_data_in_leaf': 37, 'lambda_l1': 0.03937982098123208, 'lambda_l2': 0.2654937961260241} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2639285495062454, 'max_depth': 34, 'num_leaves': 531, 'min_data_in_leaf': 42, 'lambda_l1': 0.11742736241084707, 'lambda_l2': 0.5883652418207432} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42451339409970723, 'max_depth': 58, 'num_leaves': 306, 'min_data_in_leaf': 34, 'lambda_l1': 0.0005932528124006076, 'lambda_l2': 0.3759789925189534} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.709020593879793, 'max_depth': 53, 'num_leaves': 621, 'min_data_in_leaf': 39, 'lambda_l1': 0.09537864017301712, 'lambda_l2': 2.491527569825868} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.29482230549044175, 'max_depth': 60, 'num_leaves': 879, 'min_data_in_leaf': 37, 'lambda_l1': 0.07052724837295482, 'lambda_l2': 0.1728188251387247} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5302720206631614, 'max_depth': 49, 'num_leaves': 740, 'min_data_in_leaf': 35, 'lambda_l1': 0.04881002883344153, 'lambda_l2': 0.0857088795704713} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3564757862099537, 'max_depth': 56, 'num_leaves': 437, 'min_data_in_leaf': 41, 'lambda_l1': 0.0263813859507498, 'lambda_l2': 0.4552243536678721} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47194869376901516, 'max_depth': 63, 'num_leaves': 564, 'min_data_in_leaf': 39, 'lambda_l1': 0.08297490797090405, 'lambda_l2': 0.28508261718679057} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.38206395431375806, 'max_depth': 44, 'num_leaves': 416, 'min_data_in_leaf': 33, 'lambda_l1': 0.05936402714168745, 'lambda_l2': 4.7274866326690566} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.0032459672296732494, 'max_depth': 36, 'num_leaves': 672, 'min_data_in_leaf': 46, 'lambda_l1': 0.10216098284471893, 'lambda_l2': 0.16511823396327652} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5993680835820959, 'max_depth': 52, 'num_leaves': 528, 'min_data_in_leaf': 36, 'lambda_l1': 0.03613733976590798, 'lambda_l2': 1.8580542407809073} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3305505047248483, 'max_depth': 50, 'num_leaves': 359, 'min_data_in_leaf': 43, 'lambda_l1': 0.07526401568295413, 'lambda_l2': 4.891680033519972} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2518766677981184, 'max_depth': 60, 'num_leaves': 1555, 'min_data_in_leaf': 39, 'lambda_l1': 0.12257387991174953, 'lambda_l2': 2.0254635799897036} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4357929725316511, 'max_depth': 57, 'num_leaves': 808, 'min_data_in_leaf': 37, 'lambda_l1': 0.018754816504771045, 'lambda_l2': 0.3261579302190222} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.29593982016142867, 'max_depth': 55, 'num_leaves': 626, 'min_data_in_leaf': 33, 'lambda_l1': 0.04768807440304909, 'lambda_l2': 0.08552891150278362} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.38881790911962877, 'max_depth': 61, 'num_leaves': 484, 'min_data_in_leaf': 31, 'lambda_l1': 0.08883802907303204, 'lambda_l2': 0.004491778096299246} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.33405250195844605, 'max_depth': 58, 'num_leaves': 296, 'min_data_in_leaf': 41, 'lambda_l1': 0.06269852712124833, 'lambda_l2': 0.4896381280969184} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.024497617357274366, 'max_depth': 46, 'num_leaves': 729, 'min_data_in_leaf': 35, 'lambda_l1': 0.10817593485607267, 'lambda_l2': 2.6025771060226033} : acc= 55.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5429618830184001, 'max_depth': 54, 'num_leaves': 406, 'min_data_in_leaf': 39, 'lambda_l1': 0.07634974810311698, 'lambda_l2': 4.617885744978771} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.22151462829165952, 'max_depth': 50, 'num_leaves': 569, 'min_data_in_leaf': 44, 'lambda_l1': 0.053306296030027824, 'lambda_l2': 0.23825142113900694} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.7838390386940803, 'max_depth': 64, 'num_leaves': 203, 'min_data_in_leaf': 37, 'lambda_l1': 0.028687925813779713, 'lambda_l2': 0.35942507649443267} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.28449890334499656, 'max_depth': 52, 'num_leaves': 481, 'min_data_in_leaf': 41, 'lambda_l1': 0.09242027953543488, 'lambda_l2': 0.18974582398690565} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.47909257841096825, 'max_depth': 44, 'num_leaves': 676, 'min_data_in_leaf': 35, 'lambda_l1': 0.0642533662827124, 'lambda_l2': 0.26827207313799867} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6578152145606407, 'max_depth': 58, 'num_leaves': 591, 'min_data_in_leaf': 38, 'lambda_l1': 0.11180278841580628, 'lambda_l2': 0.08817375224645818} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.40889199276064325, 'max_depth': 48, 'num_leaves': 1009, 'min_data_in_leaf': 33, 'lambda_l1': 0.036251913894221006, 'lambda_l2': 0.5932467620854442} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35229880286364035, 'max_depth': 62, 'num_leaves': 348, 'min_data_in_leaf': 42, 'lambda_l1': 0.016730148447456773, 'lambda_l2': 3.9940855182871133} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2666103960437076, 'max_depth': 56, 'num_leaves': 767, 'min_data_in_leaf': 36, 'lambda_l1': 0.07632345104680172, 'lambda_l2': 0.47842455164637043} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32146784127054656, 'max_depth': 60, 'num_leaves': 510, 'min_data_in_leaf': 39, 'lambda_l1': 0.046814659980276, 'lambda_l2': 0.17895198290794403} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44212247871675214, 'max_depth': 42, 'num_leaves': 850, 'min_data_in_leaf': 40, 'lambda_l1': 0.08983644928342718, 'lambda_l2': 0.3899666248054863} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5551243845067595, 'max_depth': 54, 'num_leaves': 1264, 'min_data_in_leaf': 31, 'lambda_l1': 0.12807969688224616, 'lambda_l2': 0.3576687393562473} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3692564378548551, 'max_depth': 50, 'num_leaves': 287, 'min_data_in_leaf': 37, 'lambda_l1': 0.061231793774266144, 'lambda_l2': 0.00821853757110394} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3029570123258148, 'max_depth': 46, 'num_leaves': 425, 'min_data_in_leaf': 34, 'lambda_l1': 0.10004249128619697, 'lambda_l2': 0.0015026519275356254} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2393423424817048, 'max_depth': 66, 'num_leaves': 634, 'min_data_in_leaf': 47, 'lambda_l1': 0.04815165312455758, 'lambda_l2': 4.141905966928883} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4044372606350907, 'max_depth': 59, 'num_leaves': 541, 'min_data_in_leaf': 44, 'lambda_l1': 0.07589261979517825, 'lambda_l2': 0.27765744502598877} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.034298930360914595, 'max_depth': 56, 'num_leaves': 689, 'min_data_in_leaf': 38, 'lambda_l1': 0.01756249011745993, 'lambda_l2': 0.15720668121463371} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.465586733764182, 'max_depth': 37, 'num_leaves': 380, 'min_data_in_leaf': 32, 'lambda_l1': 0.03456667441399143, 'lambda_l2': 2.644282673310115} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.33374388367755325, 'max_depth': 52, 'num_leaves': 456, 'min_data_in_leaf': 36, 'lambda_l1': 0.11277263575383562, 'lambda_l2': 4.40143059335513} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6139214283593776, 'max_depth': 47, 'num_leaves': 595, 'min_data_in_leaf': 41, 'lambda_l1': 0.0653709327295212, 'lambda_l2': 0.24168265610020062} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.27488637792908954, 'max_depth': 62, 'num_leaves': 929, 'min_data_in_leaf': 39, 'lambda_l1': 0.08924970083805109, 'lambda_l2': 0.4339410623785582} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.517411736632371, 'max_depth': 44, 'num_leaves': 750, 'min_data_in_leaf': 10, 'lambda_l1': 0.04719949416302898, 'lambda_l2': 0.12732292807107617} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3665254911321454, 'max_depth': 54, 'num_leaves': 204, 'min_data_in_leaf': 34, 'lambda_l1': 0.0722170840981378, 'lambda_l2': 0.5823148642010733} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.42153172663872895, 'max_depth': 58, 'num_leaves': 552, 'min_data_in_leaf': 43, 'lambda_l1': 0.48774734605639686, 'lambda_l2': 0.2576241579543745} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.30792045555905245, 'max_depth': 49, 'num_leaves': 278, 'min_data_in_leaf': 36, 'lambda_l1': 0.09490958586057216, 'lambda_l2': 0.710038124470355} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.6911560094600824, 'max_depth': 34, 'num_leaves': 456, 'min_data_in_leaf': 40, 'lambda_l1': 0.12290034846382489, 'lambda_l2': 0.3820348328558351} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.21844909896971215, 'max_depth': 60, 'num_leaves': 659, 'min_data_in_leaf': 38, 'lambda_l1': 0.026617756395490254, 'lambda_l2': 4.760649163126017} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3684125396802052, 'max_depth': 57, 'num_leaves': 370, 'min_data_in_leaf': 31, 'lambda_l1': 0.056301067449938604, 'lambda_l2': 2.1640755997403223} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4858287899278725, 'max_depth': 82, 'num_leaves': 506, 'min_data_in_leaf': 35, 'lambda_l1': 0.01266134956937024, 'lambda_l2': 0.08878969907191331} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27637149987943754, 'max_depth': 51, 'num_leaves': 614, 'min_data_in_leaf': 42, 'lambda_l1': 0.0024446486486314964, 'lambda_l2': 0.18943461295694175} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5640631318499486, 'max_depth': 64, 'num_leaves': 769, 'min_data_in_leaf': 37, 'lambda_l1': 0.08196571634817726, 'lambda_l2': 2.8428972573619546} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33769019560730884, 'max_depth': 55, 'num_leaves': 415, 'min_data_in_leaf': 34, 'lambda_l1': 0.04188496613167036, 'lambda_l2': 0.3212479916848734} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.42607980200888684, 'max_depth': 38, 'num_leaves': 525, 'min_data_in_leaf': 40, 'lambda_l1': 0.06242907271666795, 'lambda_l2': 0.45881337811546735} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.25685432431971944, 'max_depth': 42, 'num_leaves': 869, 'min_data_in_leaf': 45, 'lambda_l1': 0.10526734802290708, 'lambda_l2': 0.1312305487053828} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.31051815869873167, 'max_depth': 68, 'num_leaves': 309, 'min_data_in_leaf': 38, 'lambda_l1': 0.00022602401553303841, 'lambda_l2': 0.3082094245701813} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3924775110408641, 'max_depth': 48, 'num_leaves': 667, 'min_data_in_leaf': 33, 'lambda_l1': 0.0792334674587922, 'lambda_l2': 2.513347677410335} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.780447249224745, 'max_depth': 53, 'num_leaves': 1457, 'min_data_in_leaf': 36, 'lambda_l1': 0.03641923193588629, 'lambda_l2': 0.08549933082162164} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4577792119461735, 'max_depth': 45, 'num_leaves': 583, 'min_data_in_leaf': 42, 'lambda_l1': 0.11987595896230964, 'lambda_l2': 0.2500981804216256} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.350980219943131, 'max_depth': 62, 'num_leaves': 718, 'min_data_in_leaf': 76, 'lambda_l1': 0.06218784058311407, 'lambda_l2': 4.981294928112333} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.007987695605658656, 'max_depth': 59, 'num_leaves': 469, 'min_data_in_leaf': 39, 'lambda_l1': 0.09804538497525653, 'lambda_l2': 4.474070646541134} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.04736112806356162, 'max_depth': 57, 'num_leaves': 356, 'min_data_in_leaf': 32, 'lambda_l1': 0.5238068899512165, 'lambda_l2': 0.5552382862046517} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5189633410894336, 'max_depth': 39, 'num_leaves': 207, 'min_data_in_leaf': 36, 'lambda_l1': 0.1333455275871422, 'lambda_l2': 0.3694108518401835} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.30414739267117824, 'max_depth': 61, 'num_leaves': 823, 'min_data_in_leaf': 41, 'lambda_l1': 0.05375071525359224, 'lambda_l2': 0.1807559793428874} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.198347763814156, 'max_depth': 50, 'num_leaves': 536, 'min_data_in_leaf': 38, 'lambda_l1': 0.07509719113453744, 'lambda_l2': 2.7583509449605934} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2533129407550245, 'max_depth': 36, 'num_leaves': 437, 'min_data_in_leaf': 54, 'lambda_l1': 0.03523026981153682, 'lambda_l2': 0.5162261865865834} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5963080764848631, 'max_depth': 55, 'num_leaves': 634, 'min_data_in_leaf': 35, 'lambda_l1': 0.0979974601757897, 'lambda_l2': 0.09206363661009452} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3829519510616972, 'max_depth': 43, 'num_leaves': 1841, 'min_data_in_leaf': 30, 'lambda_l1': 0.0800588588583004, 'lambda_l2': 0.23667415423546145} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2882073553152891, 'max_depth': 47, 'num_leaves': 730, 'min_data_in_leaf': 43, 'lambda_l1': 0.05075861228387602, 'lambda_l2': 0.0020921285378395216} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4249050418541442, 'max_depth': 52, 'num_leaves': 265, 'min_data_in_leaf': 40, 'lambda_l1': 0.02896257862018696, 'lambda_l2': 0.41336604956542866} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.34885757828478775, 'max_depth': 58, 'num_leaves': 555, 'min_data_in_leaf': 33, 'lambda_l1': 0.10615356268938225, 'lambda_l2': 0.3051607049903925} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.45466708168290393, 'max_depth': 59, 'num_leaves': 973, 'min_data_in_leaf': 37, 'lambda_l1': 0.14274379991723268, 'lambda_l2': 0.34177819263889275} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35787060645360247, 'max_depth': 58, 'num_leaves': 584, 'min_data_in_leaf': 33, 'lambda_l1': 0.12176609713157602, 'lambda_l2': 0.4651577079074682} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3423365704446538, 'max_depth': 58, 'num_leaves': 567, 'min_data_in_leaf': 32, 'lambda_l1': 0.1384375047523848, 'lambda_l2': 0.5070346807190609} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3539226990436741, 'max_depth': 60, 'num_leaves': 400, 'min_data_in_leaf': 32, 'lambda_l1': 0.1491812041935974, 'lambda_l2': 0.5463157778692572} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3229089279340923, 'max_depth': 57, 'num_leaves': 497, 'min_data_in_leaf': 30, 'lambda_l1': 0.12478556514481833, 'lambda_l2': 0.582460174519866} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.388197527613426, 'max_depth': 58, 'num_leaves': 654, 'min_data_in_leaf': 69, 'lambda_l1': 0.1417446893311864, 'lambda_l2': 0.44861290296471945} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.29433013348744724, 'max_depth': 60, 'num_leaves': 812, 'min_data_in_leaf': 31, 'lambda_l1': 0.12658142108771875, 'lambda_l2': 0.7054926643268715} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3709816214033795, 'max_depth': 56, 'num_leaves': 326, 'min_data_in_leaf': 33, 'lambda_l1': 0.14155754292774822, 'lambda_l2': 0.6561813172100956} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3295931818143954, 'max_depth': 62, 'num_leaves': 1322, 'min_data_in_leaf': 29, 'lambda_l1': 0.12102674325497798, 'lambda_l2': 0.6480942182585673} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4044582812785262, 'max_depth': 58, 'num_leaves': 1689, 'min_data_in_leaf': 33, 'lambda_l1': 0.12158286051112546, 'lambda_l2': 0.4676453997808859} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24688072235707811, 'max_depth': 60, 'num_leaves': 581, 'min_data_in_leaf': 34, 'lambda_l1': 0.1132093487297213, 'lambda_l2': 0.401606142204786} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.30233111534188356, 'max_depth': 56, 'num_leaves': 714, 'min_data_in_leaf': 34, 'lambda_l1': 0.154023063975918, 'lambda_l2': 1.7555229728982482} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3617875046385387, 'max_depth': 63, 'num_leaves': 460, 'min_data_in_leaf': 32, 'lambda_l1': 0.11360046455990536, 'lambda_l2': 0.5029756288127906} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2705862842743884, 'max_depth': 58, 'num_leaves': 383, 'min_data_in_leaf': 30, 'lambda_l1': 0.13924238220292012, 'lambda_l2': 0.3303211051995164} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.32463960637201633, 'max_depth': 61, 'num_leaves': 1064, 'min_data_in_leaf': 34, 'lambda_l1': 0.11109315572844958, 'lambda_l2': 0.40680790849488707} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3460683841702589, 'max_depth': 56, 'num_leaves': 1199, 'min_data_in_leaf': 31, 'lambda_l1': 0.1333647297447802, 'lambda_l2': 0.5868567902716909} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4171452531016749, 'max_depth': 59, 'num_leaves': 516, 'min_data_in_leaf': 49, 'lambda_l1': 0.10572726331919827, 'lambda_l2': 0.32477346100341853} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.28811600613313787, 'max_depth': 56, 'num_leaves': 620, 'min_data_in_leaf': 35, 'lambda_l1': 0.12472345684094827, 'lambda_l2': 0.4094290371309214} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3945992211265798, 'max_depth': 64, 'num_leaves': 692, 'min_data_in_leaf': 33, 'lambda_l1': 0.10415733545982456, 'lambda_l2': 0.7816318765303921} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2333746612048747, 'max_depth': 61, 'num_leaves': 271, 'min_data_in_leaf': 30, 'lambda_l1': 0.1601249005519307, 'lambda_l2': 0.2860531895242673} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.36661463196984306, 'max_depth': 58, 'num_leaves': 456, 'min_data_in_leaf': 35, 'lambda_l1': 0.0995911350121326, 'lambda_l2': 0.4844285881642316} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.31884966626860733, 'max_depth': 54, 'num_leaves': 582, 'min_data_in_leaf': 36, 'lambda_l1': 0.11751083710968324, 'lambda_l2': 0.2897777099961713} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4299747680198741, 'max_depth': 60, 'num_leaves': 184, 'min_data_in_leaf': 32, 'lambda_l1': 0.09408964005312566, 'lambda_l2': 0.6374009474536524} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.28206862368901503, 'max_depth': 57, 'num_leaves': 900, 'min_data_in_leaf': 35, 'lambda_l1': 0.13103926572603164, 'lambda_l2': 0.3942320536347777} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.39284857189637507, 'max_depth': 55, 'num_leaves': 791, 'min_data_in_leaf': 37, 'lambda_l1': 0.09718882794235656, 'lambda_l2': 0.22419371971550134} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.18287472994347995, 'max_depth': 63, 'num_leaves': 366, 'min_data_in_leaf': 33, 'lambda_l1': 0.1095921748420749, 'lambda_l2': 0.5141198859986166} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3189880354510329, 'max_depth': 59, 'num_leaves': 508, 'min_data_in_leaf': 29, 'lambda_l1': 0.13308768242046448, 'lambda_l2': 1.4434502726676528} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.24103492210427668, 'max_depth': 65, 'num_leaves': 650, 'min_data_in_leaf': 91, 'lambda_l1': 0.09139714947524476, 'lambda_l2': 0.19983849396518716} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.46984879481157793, 'max_depth': 57, 'num_leaves': 569, 'min_data_in_leaf': 36, 'lambda_l1': 0.1109657393188604, 'lambda_l2': 0.3446567743888349} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.35610169664517355, 'max_depth': 62, 'num_leaves': 424, 'min_data_in_leaf': 38, 'lambda_l1': 0.09387736326632817, 'lambda_l2': 0.4347828768138313} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.27357814732088137, 'max_depth': 55, 'num_leaves': 720, 'min_data_in_leaf': 34, 'lambda_l1': 0.14463543017007666, 'lambda_l2': 0.2361481257069227} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4281864163689755, 'max_depth': 61, 'num_leaves': 513, 'min_data_in_leaf': 36, 'lambda_l1': 0.08892636443046939, 'lambda_l2': 0.3252065044590563} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3446127663914455, 'max_depth': 59, 'num_leaves': 344, 'min_data_in_leaf': 32, 'lambda_l1': 0.10803936102715618, 'lambda_l2': 0.1615285976999723} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.21608609429348774, 'max_depth': 57, 'num_leaves': 644, 'min_data_in_leaf': 38, 'lambda_l1': 0.08235366629003099, 'lambda_l2': 0.5841794390498405} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.30541291706496543, 'max_depth': 54, 'num_leaves': 268, 'min_data_in_leaf': 31, 'lambda_l1': 0.12605073126043218, 'lambda_l2': 0.27567772327205975} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.39312563402081113, 'max_depth': 59, 'num_leaves': 423, 'min_data_in_leaf': 34, 'lambda_l1': 0.07604527849273984, 'lambda_l2': 0.4185210488341163} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.46569566885861446, 'max_depth': 55, 'num_leaves': 1523, 'min_data_in_leaf': 40, 'lambda_l1': 0.15471248196048537, 'lambda_l2': 0.1616482023831038} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2743233958311159, 'max_depth': 61, 'num_leaves': 766, 'min_data_in_leaf': 37, 'lambda_l1': 0.10875128914157313, 'lambda_l2': 0.5021185720401813} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33187994885195643, 'max_depth': 57, 'num_leaves': 581, 'min_data_in_leaf': 35, 'lambda_l1': 0.08875475927697145, 'lambda_l2': 0.7170917353264984} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3793175728857381, 'max_depth': 63, 'num_leaves': 494, 'min_data_in_leaf': 65, 'lambda_l1': 0.1234640231646141, 'lambda_l2': 0.07779782460819631} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.47109607232891104, 'max_depth': 54, 'num_leaves': 844, 'min_data_in_leaf': 45, 'lambda_l1': 0.5004705788938147, 'lambda_l2': 0.3160926754786365} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2518535386756833, 'max_depth': 59, 'num_leaves': 314, 'min_data_in_leaf': 39, 'lambda_l1': 0.0776314827055094, 'lambda_l2': 0.18769703071638874} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.31987322194197265, 'max_depth': 56, 'num_leaves': 680, 'min_data_in_leaf': 42, 'lambda_l1': 0.0967354388651575, 'lambda_l2': 0.41079026191711804} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.40370775621535276, 'max_depth': 60, 'num_leaves': 199, 'min_data_in_leaf': 37, 'lambda_l1': 0.0685149356242918, 'lambda_l2': 1.5821388595523602} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2846249800155757, 'max_depth': 58, 'num_leaves': 410, 'min_data_in_leaf': 1, 'lambda_l1': 0.16574083935916212, 'lambda_l2': 0.2886015894498093} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3683917059450392, 'max_depth': 64, 'num_leaves': 539, 'min_data_in_leaf': 30, 'lambda_l1': 0.1018770678723323, 'lambda_l2': 0.10791367481353553} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.49449209530198523, 'max_depth': 66, 'num_leaves': 615, 'min_data_in_leaf': 33, 'lambda_l1': 0.12012723833559298, 'lambda_l2': 0.23241999817574577} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4304681460268477, 'max_depth': 53, 'num_leaves': 476, 'min_data_in_leaf': 39, 'lambda_l1': 0.0816545302908612, 'lambda_l2': 0.00017454444529940716} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3221735675529965, 'max_depth': 56, 'num_leaves': 745, 'min_data_in_leaf': 35, 'lambda_l1': 0.06896135557492661, 'lambda_l2': 0.5021192128179515} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3494611027604677, 'max_depth': 62, 'num_leaves': 353, 'min_data_in_leaf': 41, 'lambda_l1': 0.09715554441023089, 'lambda_l2': 0.3460119659926635} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2932827870724484, 'max_depth': 66, 'num_leaves': 334, 'min_data_in_leaf': 44, 'lambda_l1': 0.8370551105272083, 'lambda_l2': 0.4119016825177546} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.10714274368111602, 'max_depth': 64, 'num_leaves': 363, 'min_data_in_leaf': 47, 'lambda_l1': 0.13993426980586074, 'lambda_l2': 0.5795191065962496} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.33810149665948896, 'max_depth': 62, 'num_leaves': 381, 'min_data_in_leaf': 45, 'lambda_l1': 0.11715060386547772, 'lambda_l2': 0.3556229709518181} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2552747030934058, 'max_depth': 61, 'num_leaves': 299, 'min_data_in_leaf': 43, 'lambda_l1': 0.10566614660850689, 'lambda_l2': 0.49065727346512755} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.29229310627333605, 'max_depth': 68, 'num_leaves': 413, 'min_data_in_leaf': 42, 'lambda_l1': 0.08003752796921164, 'lambda_l2': 0.3543742752963073} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.22895932796394466, 'max_depth': 63, 'num_leaves': 441, 'min_data_in_leaf': 46, 'lambda_l1': 0.13381632011260183, 'lambda_l2': 0.2691384331498752} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31810071081419455, 'max_depth': 64, 'num_leaves': 325, 'min_data_in_leaf': 41, 'lambda_l1': 0.09761786085871707, 'lambda_l2': 0.417756644900505} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.011030019396373058, 'max_depth': 61, 'num_leaves': 448, 'min_data_in_leaf': 41, 'lambda_l1': 0.06302930769154046, 'lambda_l2': 0.6352359171736305} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.36373078500386347, 'max_depth': 62, 'num_leaves': 366, 'min_data_in_leaf': 43, 'lambda_l1': 0.15321104374250355, 'lambda_l2': 0.2374840598946269} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.27455439049940683, 'max_depth': 66, 'num_leaves': 519, 'min_data_in_leaf': 52, 'lambda_l1': 0.47561946028028557, 'lambda_l2': 0.34196950777888674} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.016048859181085878, 'max_depth': 60, 'num_leaves': 452, 'min_data_in_leaf': 32, 'lambda_l1': 0.12116595506122538, 'lambda_l2': 0.5133129620165064} : acc= 52.92%\n",
            "[HPO] metrics with {'learning_rate': 0.35638239606920286, 'max_depth': 63, 'num_leaves': 1405, 'min_data_in_leaf': 40, 'lambda_l1': 0.08601531461915927, 'lambda_l2': 0.16289375332890926} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32103121743645935, 'max_depth': 65, 'num_leaves': 278, 'min_data_in_leaf': 38, 'lambda_l1': 0.05970288850541432, 'lambda_l2': 0.2801712093314728} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2158942979866564, 'max_depth': 69, 'num_leaves': 245, 'min_data_in_leaf': 36, 'lambda_l1': 0.05212642428207104, 'lambda_l2': 0.3530508181783894} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2537920786660954, 'max_depth': 65, 'num_leaves': 261, 'min_data_in_leaf': 34, 'lambda_l1': 0.06650788012471727, 'lambda_l2': 0.2404763463482192} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3022007454944191, 'max_depth': 64, 'num_leaves': 262, 'min_data_in_leaf': 38, 'lambda_l1': 0.09735181411904201, 'lambda_l2': 0.4169860563724974} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2667183109767471, 'max_depth': 69, 'num_leaves': 324, 'min_data_in_leaf': 36, 'lambda_l1': 0.023042663196450985, 'lambda_l2': 0.280979498414765} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3171293622947943, 'max_depth': 65, 'num_leaves': 313, 'min_data_in_leaf': 34, 'lambda_l1': 0.07895746483981977, 'lambda_l2': 0.16771831863471548} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.33469740421886857, 'max_depth': 62, 'num_leaves': 201, 'min_data_in_leaf': 38, 'lambda_l1': 0.13596773638250226, 'lambda_l2': 0.468672404876599} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2833197686432765, 'max_depth': 67, 'num_leaves': 229, 'min_data_in_leaf': 39, 'lambda_l1': 0.053031138740968375, 'lambda_l2': 0.31702532498544045} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.24489643586510265, 'max_depth': 66, 'num_leaves': 308, 'min_data_in_leaf': 36, 'lambda_l1': 0.10835390319908442, 'lambda_l2': 0.1584450509105519} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33230880425152354, 'max_depth': 64, 'num_leaves': 339, 'min_data_in_leaf': 34, 'lambda_l1': 0.09227060902555351, 'lambda_l2': 0.3784179164125596} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3685172654758208, 'max_depth': 67, 'num_leaves': 378, 'min_data_in_leaf': 37, 'lambda_l1': 0.03850231921205088, 'lambda_l2': 0.24118430558409934} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.29505951599302804, 'max_depth': 67, 'num_leaves': 240, 'min_data_in_leaf': 40, 'lambda_l1': 0.07169771463232824, 'lambda_l2': 0.5565749261435666} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.20849337621388292, 'max_depth': 68, 'num_leaves': 399, 'min_data_in_leaf': 32, 'lambda_l1': 0.11645077478142425, 'lambda_l2': 0.12380684118390536} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3496089825796489, 'max_depth': 63, 'num_leaves': 295, 'min_data_in_leaf': 37, 'lambda_l1': 0.05957131367845082, 'lambda_l2': 0.264116445757133} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2753546091132043, 'max_depth': 61, 'num_leaves': 399, 'min_data_in_leaf': 41, 'lambda_l1': 0.17267300994436158, 'lambda_l2': 0.4287760607726082} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3049259666188744, 'max_depth': 66, 'num_leaves': 456, 'min_data_in_leaf': 35, 'lambda_l1': 0.5205094353103735, 'lambda_l2': 0.34120159428150093} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3696675270330304, 'max_depth': 65, 'num_leaves': 367, 'min_data_in_leaf': 39, 'lambda_l1': 0.09068385394520335, 'lambda_l2': 0.08290691033768383} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.23598902127316707, 'max_depth': 62, 'num_leaves': 262, 'min_data_in_leaf': 34, 'lambda_l1': 0.01992203479518461, 'lambda_l2': 0.21096708450118892} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3213361285536319, 'max_depth': 60, 'num_leaves': 489, 'min_data_in_leaf': 38, 'lambda_l1': 0.04079405642745428, 'lambda_l2': 0.5131581699956377} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.37926514077315016, 'max_depth': 59, 'num_leaves': 394, 'min_data_in_leaf': 32, 'lambda_l1': 0.0687189740589127, 'lambda_l2': 0.31136400233013733} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.26832753010224053, 'max_depth': 63, 'num_leaves': 539, 'min_data_in_leaf': 43, 'lambda_l1': 0.13709125427139301, 'lambda_l2': 0.18878971559031799} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33886842147776647, 'max_depth': 58, 'num_leaves': 311, 'min_data_in_leaf': 36, 'lambda_l1': 0.001139422935853368, 'lambda_l2': 0.43359022462149865} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.1672421071096676, 'max_depth': 65, 'num_leaves': 204, 'min_data_in_leaf': 40, 'lambda_l1': 0.08888734865623835, 'lambda_l2': 0.0807415869072568} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29340879930585084, 'max_depth': 61, 'num_leaves': 447, 'min_data_in_leaf': 38, 'lambda_l1': 0.11041049526426044, 'lambda_l2': 0.6459053184842998} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3903834660662659, 'max_depth': 60, 'num_leaves': 587, 'min_data_in_leaf': 33, 'lambda_l1': 0.04313067318304788, 'lambda_l2': 0.30681113266251414} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2351493910926963, 'max_depth': 63, 'num_leaves': 490, 'min_data_in_leaf': 41, 'lambda_l1': 0.057823992560230415, 'lambda_l2': 0.17786271632202294} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.32949603281801687, 'max_depth': 59, 'num_leaves': 353, 'min_data_in_leaf': 36, 'lambda_l1': 0.0769282611051135, 'lambda_l2': 0.0008734779207042465} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.37457632366157506, 'max_depth': 68, 'num_leaves': 562, 'min_data_in_leaf': 35, 'lambda_l1': 0.12134296485779764, 'lambda_l2': 0.38690248124794324} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.26333233250624644, 'max_depth': 57, 'num_leaves': 432, 'min_data_in_leaf': 39, 'lambda_l1': 0.022867172088589894, 'lambda_l2': 0.25201644932113965} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.396585145235062, 'max_depth': 61, 'num_leaves': 646, 'min_data_in_leaf': 31, 'lambda_l1': 0.10243194963726657, 'lambda_l2': 0.5027040675900285} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3113807754070404, 'max_depth': 58, 'num_leaves': 254, 'min_data_in_leaf': 42, 'lambda_l1': 0.06432407680558604, 'lambda_l2': 0.1324970124690288} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.19417116766180573, 'max_depth': 63, 'num_leaves': 532, 'min_data_in_leaf': 37, 'lambda_l1': 0.047975991638659045, 'lambda_l2': 0.35063977176306443} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3484120075398075, 'max_depth': 70, 'num_leaves': 378, 'min_data_in_leaf': 33, 'lambda_l1': 0.09041051454061383, 'lambda_l2': 0.2478547675295042} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2890806938295592, 'max_depth': 59, 'num_leaves': 477, 'min_data_in_leaf': 44, 'lambda_l1': 0.07582080647015935, 'lambda_l2': 0.09423396547637419} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.40126503838611405, 'max_depth': 57, 'num_leaves': 610, 'min_data_in_leaf': 39, 'lambda_l1': 0.1373489871622963, 'lambda_l2': 0.7681060630423664} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24597612931761498, 'max_depth': 62, 'num_leaves': 191, 'min_data_in_leaf': 35, 'lambda_l1': 0.03528855564256388, 'lambda_l2': 0.43644938367681896} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31438706261290406, 'max_depth': 60, 'num_leaves': 716, 'min_data_in_leaf': 37, 'lambda_l1': 0.1566694248392865, 'lambda_l2': 0.18451095139374557} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35453752702269875, 'max_depth': 67, 'num_leaves': 311, 'min_data_in_leaf': 41, 'lambda_l1': 0.10779694056034403, 'lambda_l2': 0.31897762975014027} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4028015401011986, 'max_depth': 56, 'num_leaves': 419, 'min_data_in_leaf': 31, 'lambda_l1': 0.057959795086996224, 'lambda_l2': 0.5458400251749416} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2795569506828879, 'max_depth': 65, 'num_leaves': 528, 'min_data_in_leaf': 38, 'lambda_l1': 0.08385215442803928, 'lambda_l2': 0.09001546878839779} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.339457837650852, 'max_depth': 58, 'num_leaves': 623, 'min_data_in_leaf': 34, 'lambda_l1': 0.017805716866552038, 'lambda_l2': 0.2492263080901423} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.07578284517208152, 'max_depth': 61, 'num_leaves': 369, 'min_data_in_leaf': 40, 'lambda_l1': 0.04490280569401947, 'lambda_l2': 0.412405763274138} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4108788446472235, 'max_depth': 65, 'num_leaves': 680, 'min_data_in_leaf': 48, 'lambda_l1': 0.1194179993207053, 'lambda_l2': 0.5887772363025237} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2940570491582409, 'max_depth': 55, 'num_leaves': 468, 'min_data_in_leaf': 36, 'lambda_l1': 0.06871419501352093, 'lambda_l2': 0.16255746327519188} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.21505230904028044, 'max_depth': 59, 'num_leaves': 299, 'min_data_in_leaf': 43, 'lambda_l1': 0.0976860092484791, 'lambda_l2': 0.0008509198792557729} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3565998816036535, 'max_depth': 63, 'num_leaves': 565, 'min_data_in_leaf': 33, 'lambda_l1': 0.08635169547737342, 'lambda_l2': 0.309237721662851} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.26082834370151703, 'max_depth': 57, 'num_leaves': 786, 'min_data_in_leaf': 38, 'lambda_l1': 0.03343700216526045, 'lambda_l2': 0.4771263148677147} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.33890832557439343, 'max_depth': 60, 'num_leaves': 474, 'min_data_in_leaf': 41, 'lambda_l1': 0.058264407643690404, 'lambda_l2': 0.09524894032951114} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4267121209995859, 'max_depth': 55, 'num_leaves': 645, 'min_data_in_leaf': 35, 'lambda_l1': 0.12862064692384317, 'lambda_l2': 0.3681908533571679} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.30686488179421495, 'max_depth': 62, 'num_leaves': 180, 'min_data_in_leaf': 45, 'lambda_l1': 0.10176921450089818, 'lambda_l2': 0.20680038041009005} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3880522104598282, 'max_depth': 58, 'num_leaves': 426, 'min_data_in_leaf': 31, 'lambda_l1': 0.5034705338506822, 'lambda_l2': 0.27351996042218385} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2406659258809667, 'max_depth': 56, 'num_leaves': 540, 'min_data_in_leaf': 39, 'lambda_l1': 0.01679680257266316, 'lambda_l2': 0.42808496993372663} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3085513262076468, 'max_depth': 60, 'num_leaves': 271, 'min_data_in_leaf': 37, 'lambda_l1': 0.07249714993328586, 'lambda_l2': 0.1641730504006503} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4205341301332231, 'max_depth': 65, 'num_leaves': 360, 'min_data_in_leaf': 33, 'lambda_l1': 0.04888787276682318, 'lambda_l2': 0.6420116776389807} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3675603561237467, 'max_depth': 54, 'num_leaves': 696, 'min_data_in_leaf': 42, 'lambda_l1': 0.5453449864548177, 'lambda_l2': 0.08092178213640455} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2692929335061027, 'max_depth': 58, 'num_leaves': 587, 'min_data_in_leaf': 35, 'lambda_l1': 0.0010827622542617932, 'lambda_l2': 0.3323482526132282} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32564310318892864, 'max_depth': 62, 'num_leaves': 503, 'min_data_in_leaf': 40, 'lambda_l1': 0.0828867795471345, 'lambda_l2': 0.23924607162291703} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.35840428406124186, 'max_depth': 69, 'num_leaves': 800, 'min_data_in_leaf': 37, 'lambda_l1': 0.03436538286178983, 'lambda_l2': 0.522615878494421} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.420680250031674, 'max_depth': 56, 'num_leaves': 393, 'min_data_in_leaf': 30, 'lambda_l1': 0.8698832992905926, 'lambda_l2': 0.39887930910850794} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28477237768860897, 'max_depth': 60, 'num_leaves': 717, 'min_data_in_leaf': 39, 'lambda_l1': 0.1521989856608285, 'lambda_l2': 0.0799537131976514} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.05797560672952697, 'max_depth': 63, 'num_leaves': 578, 'min_data_in_leaf': 35, 'lambda_l1': 0.10898351369156004, 'lambda_l2': 0.1786466562731821} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.22535209508439147, 'max_depth': 54, 'num_leaves': 259, 'min_data_in_leaf': 43, 'lambda_l1': 0.06296635984640755, 'lambda_l2': 0.2745155210423969} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31315193455901214, 'max_depth': 59, 'num_leaves': 465, 'min_data_in_leaf': 33, 'lambda_l1': 0.12313557346690787, 'lambda_l2': 0.4480143101091175} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.38162445607728357, 'max_depth': 57, 'num_leaves': 341, 'min_data_in_leaf': 37, 'lambda_l1': 0.08947677817548268, 'lambda_l2': 0.3400765353646617} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.43048386051990506, 'max_depth': 67, 'num_leaves': 650, 'min_data_in_leaf': 40, 'lambda_l1': 0.05109713859429646, 'lambda_l2': 0.09159958393075868} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.0028895187785470586, 'max_depth': 61, 'num_leaves': 527, 'min_data_in_leaf': 38, 'lambda_l1': 0.07638555678270319, 'lambda_l2': 0.0008094265403555011} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.25419519118392425, 'max_depth': 64, 'num_leaves': 856, 'min_data_in_leaf': 35, 'lambda_l1': 0.028369183315842116, 'lambda_l2': 0.23206797798853798} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.34338664299388594, 'max_depth': 58, 'num_leaves': 422, 'min_data_in_leaf': 42, 'lambda_l1': 0.10702236272440598, 'lambda_l2': 0.5724236974455681} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.004798222615329769, 'max_depth': 54, 'num_leaves': 598, 'min_data_in_leaf': 32, 'lambda_l1': 0.06382030368713498, 'lambda_l2': 0.354403883521052} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.28296161905544315, 'max_depth': 56, 'num_leaves': 186, 'min_data_in_leaf': 46, 'lambda_l1': 0.13126520558235344, 'lambda_l2': 0.1641792771108862} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.36484845619890915, 'max_depth': 61, 'num_leaves': 735, 'min_data_in_leaf': 36, 'lambda_l1': 0.04642772036053222, 'lambda_l2': 0.0006864582788355666} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3064086546794876, 'max_depth': 59, 'num_leaves': 332, 'min_data_in_leaf': 39, 'lambda_l1': 0.0885218380338521, 'lambda_l2': 0.47149265908184834} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4187400898315191, 'max_depth': 53, 'num_leaves': 498, 'min_data_in_leaf': 41, 'lambda_l1': 0.015916242659884977, 'lambda_l2': 0.26610410964799036} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3249526884800891, 'max_depth': 64, 'num_leaves': 651, 'min_data_in_leaf': 30, 'lambda_l1': 0.06850420159589293, 'lambda_l2': 0.1672226036198918} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.26612614443596955, 'max_depth': 57, 'num_leaves': 414, 'min_data_in_leaf': 34, 'lambda_l1': 0.17560363165688742, 'lambda_l2': 0.33052005785046595} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4472354446830483, 'max_depth': 55, 'num_leaves': 536, 'min_data_in_leaf': 44, 'lambda_l1': 0.10480402204956943, 'lambda_l2': 0.7251673218894505} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.37719292319538794, 'max_depth': 62, 'num_leaves': 325, 'min_data_in_leaf': 37, 'lambda_l1': 0.043694324567725394, 'lambda_l2': 1.2568365294339165} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.19265033503539114, 'max_depth': 59, 'num_leaves': 252, 'min_data_in_leaf': 33, 'lambda_l1': 0.9786852396988686, 'lambda_l2': 0.43940306951060804} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.33118571818325754, 'max_depth': 53, 'num_leaves': 787, 'min_data_in_leaf': 40, 'lambda_l1': 0.14468568251544817, 'lambda_l2': 0.08768038230947815} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.22506637225916434, 'max_depth': 65, 'num_leaves': 439, 'min_data_in_leaf': 38, 'lambda_l1': 0.08022954617033212, 'lambda_l2': 0.2521327471563915} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29256775813767805, 'max_depth': 61, 'num_leaves': 603, 'min_data_in_leaf': 35, 'lambda_l1': 0.028704238974799862, 'lambda_l2': 0.5758026626689947} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.38417063833942205, 'max_depth': 57, 'num_leaves': 679, 'min_data_in_leaf': 36, 'lambda_l1': 0.4832378821652408, 'lambda_l2': 0.37018197267380243} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4441224570893985, 'max_depth': 59, 'num_leaves': 480, 'min_data_in_leaf': 42, 'lambda_l1': 0.09731234802502127, 'lambda_l2': 0.15353917196667577} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.25519348046168056, 'max_depth': 56, 'num_leaves': 915, 'min_data_in_leaf': 4, 'lambda_l1': 0.062254920882410844, 'lambda_l2': 0.2523140785226621} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.33527731350960605, 'max_depth': 61, 'num_leaves': 363, 'min_data_in_leaf': 38, 'lambda_l1': 0.11081631840337106, 'lambda_l2': 0.4977788304570874} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.28880521503586587, 'max_depth': 63, 'num_leaves': 564, 'min_data_in_leaf': 31, 'lambda_l1': 0.07950950171323584, 'lambda_l2': 1.9551571105168202} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.38090029560168603, 'max_depth': 67, 'num_leaves': 741, 'min_data_in_leaf': 57, 'lambda_l1': 0.04992112727040964, 'lambda_l2': 0.157634548815418} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.44051784188674437, 'max_depth': 53, 'num_leaves': 501, 'min_data_in_leaf': 40, 'lambda_l1': 0.12655057647952422, 'lambda_l2': 0.33509373124744246} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.33755956733073744, 'max_depth': 58, 'num_leaves': 409, 'min_data_in_leaf': 36, 'lambda_l1': 0.02993374071115737, 'lambda_l2': 0.075513297469323} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2510795092675951, 'max_depth': 55, 'num_leaves': 260, 'min_data_in_leaf': 33, 'lambda_l1': 0.08940904917126209, 'lambda_l2': 0.2326055059377799} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.30453516228115923, 'max_depth': 60, 'num_leaves': 669, 'min_data_in_leaf': 44, 'lambda_l1': 0.06369117707039006, 'lambda_l2': 0.3614038071045115} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3640240543936572, 'max_depth': 58, 'num_leaves': 609, 'min_data_in_leaf': 38, 'lambda_l1': 0.0011520979402239867, 'lambda_l2': 0.6450916012482886} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.40490921738003516, 'max_depth': 63, 'num_leaves': 843, 'min_data_in_leaf': 34, 'lambda_l1': 0.11250321571142652, 'lambda_l2': 0.4723719326335093} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47090774513405614, 'max_depth': 55, 'num_leaves': 322, 'min_data_in_leaf': 41, 'lambda_l1': 0.0433918201394919, 'lambda_l2': 0.1893048415778985} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.30798952984313566, 'max_depth': 70, 'num_leaves': 184, 'min_data_in_leaf': 36, 'lambda_l1': 0.07349348271527692, 'lambda_l2': 0.3050805493672155} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2691734249417667, 'max_depth': 66, 'num_leaves': 479, 'min_data_in_leaf': 39, 'lambda_l1': 0.09861271297174289, 'lambda_l2': 0.08589396463785723} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3558772064433621, 'max_depth': 52, 'num_leaves': 582, 'min_data_in_leaf': 29, 'lambda_l1': 0.05564729700801352, 'lambda_l2': 0.4122926181564713} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.41360062843118495, 'max_depth': 57, 'num_leaves': 399, 'min_data_in_leaf': 32, 'lambda_l1': 0.15064987091298565, 'lambda_l2': 0.24049842349889025} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32251060491455663, 'max_depth': 60, 'num_leaves': 722, 'min_data_in_leaf': 42, 'lambda_l1': 0.030674233785801128, 'lambda_l2': 0.15257633300312734} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2649518917319112, 'max_depth': 60, 'num_leaves': 823, 'min_data_in_leaf': 49, 'lambda_l1': 0.01735941422672055, 'lambda_l2': 2.771834521891603} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.29065019391646457, 'max_depth': 62, 'num_leaves': 787, 'min_data_in_leaf': 45, 'lambda_l1': 0.017453685430341623, 'lambda_l2': 0.08644842393041943} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32051144980952334, 'max_depth': 61, 'num_leaves': 898, 'min_data_in_leaf': 45, 'lambda_l1': 0.012536109353792499, 'lambda_l2': 0.14009681996156864} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24251360195458743, 'max_depth': 59, 'num_leaves': 761, 'min_data_in_leaf': 43, 'lambda_l1': 0.03145684556340783, 'lambda_l2': 2.713659765946232} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.23275286966680653, 'max_depth': 64, 'num_leaves': 706, 'min_data_in_leaf': 46, 'lambda_l1': 0.030814671853070272, 'lambda_l2': 0.0828763728513584} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3231554165452413, 'max_depth': 60, 'num_leaves': 857, 'min_data_in_leaf': 42, 'lambda_l1': 0.022992752979272946, 'lambda_l2': 0.1781591062411821} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.19209333280756224, 'max_depth': 59, 'num_leaves': 981, 'min_data_in_leaf': 44, 'lambda_l1': 0.010373518278511351, 'lambda_l2': 0.07836676404288742} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.28096409721473176, 'max_depth': 57, 'num_leaves': 855, 'min_data_in_leaf': 43, 'lambda_l1': 0.011258602841550062, 'lambda_l2': 0.16156845814892692} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.21513892096038242, 'max_depth': 58, 'num_leaves': 925, 'min_data_in_leaf': 48, 'lambda_l1': 0.02176849106341762, 'lambda_l2': 2.6339719058814643} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3034419767720256, 'max_depth': 60, 'num_leaves': 899, 'min_data_in_leaf': 47, 'lambda_l1': 0.016925648259709096, 'lambda_l2': 0.08842418223265847} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.24480651016666816, 'max_depth': 56, 'num_leaves': 790, 'min_data_in_leaf': 43, 'lambda_l1': 0.007579907886207632, 'lambda_l2': 0.019477827484822297} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2996021771797983, 'max_depth': 58, 'num_leaves': 873, 'min_data_in_leaf': 42, 'lambda_l1': 0.0004189447611575442, 'lambda_l2': 0.1573033880033709} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3344544741962137, 'max_depth': 60, 'num_leaves': 811, 'min_data_in_leaf': 46, 'lambda_l1': 0.0001360147533782316, 'lambda_l2': 0.18787696337061457} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2670326758498168, 'max_depth': 56, 'num_leaves': 961, 'min_data_in_leaf': 31, 'lambda_l1': 0.026499501927163098, 'lambda_l2': 0.07091172783133541} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.22360811377925086, 'max_depth': 54, 'num_leaves': 753, 'min_data_in_leaf': 33, 'lambda_l1': 0.03447962472106796, 'lambda_l2': 0.2043968317410752} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3308403416126417, 'max_depth': 58, 'num_leaves': 820, 'min_data_in_leaf': 34, 'lambda_l1': 0.03616006550347239, 'lambda_l2': 0.008422857363274694} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2790539173722227, 'max_depth': 61, 'num_leaves': 752, 'min_data_in_leaf': 29, 'lambda_l1': 0.039615473901310025, 'lambda_l2': 0.22934602717601685} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.352156883768361, 'max_depth': 56, 'num_leaves': 885, 'min_data_in_leaf': 41, 'lambda_l1': 0.023547994853984035, 'lambda_l2': 0.14744313750635518} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3107076405565742, 'max_depth': 59, 'num_leaves': 708, 'min_data_in_leaf': 73, 'lambda_l1': 0.043265913795337924, 'lambda_l2': 0.23586812698070966} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2626057498997966, 'max_depth': 55, 'num_leaves': 787, 'min_data_in_leaf': 44, 'lambda_l1': 0.020351411851087173, 'lambda_l2': 0.09900067014261354} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.359706965880037, 'max_depth': 62, 'num_leaves': 704, 'min_data_in_leaf': 36, 'lambda_l1': 0.043218319412742304, 'lambda_l2': 0.16778947441972336} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3067127455901123, 'max_depth': 60, 'num_leaves': 841, 'min_data_in_leaf': 39, 'lambda_l1': 0.0299360096961245, 'lambda_l2': 0.25314931745831215} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3825578925898927, 'max_depth': 57, 'num_leaves': 966, 'min_data_in_leaf': 50, 'lambda_l1': 0.04985196771398316, 'lambda_l2': 0.07226177862042699} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.20444803402654504, 'max_depth': 53, 'num_leaves': 715, 'min_data_in_leaf': 37, 'lambda_l1': 0.020726873204021362, 'lambda_l2': 0.008982883058136557} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.25386379227060984, 'max_depth': 59, 'num_leaves': 755, 'min_data_in_leaf': 95, 'lambda_l1': 0.0038680847456761085, 'lambda_l2': 0.2715295784371614} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.34740667194870717, 'max_depth': 62, 'num_leaves': 684, 'min_data_in_leaf': 84, 'lambda_l1': 0.04407390816354534, 'lambda_l2': 2.671812190741672} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2876115101624297, 'max_depth': 57, 'num_leaves': 862, 'min_data_in_leaf': 34, 'lambda_l1': 0.05249762284348636, 'lambda_l2': 0.1621807161407287} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3676033362243611, 'max_depth': 60, 'num_leaves': 736, 'min_data_in_leaf': 41, 'lambda_l1': 0.0015376857716828847, 'lambda_l2': 0.2976996791434037} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31789830623381954, 'max_depth': 54, 'num_leaves': 810, 'min_data_in_leaf': 31, 'lambda_l1': 0.025478487763230834, 'lambda_l2': 0.1445567986292065} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23492399741348483, 'max_depth': 63, 'num_leaves': 651, 'min_data_in_leaf': 39, 'lambda_l1': 0.048258745794457325, 'lambda_l2': 0.2778013886005579} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3997342499424113, 'max_depth': 58, 'num_leaves': 926, 'min_data_in_leaf': 36, 'lambda_l1': 0.05808077381865576, 'lambda_l2': 0.006951935286722288} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.021284744176977944, 'max_depth': 52, 'num_leaves': 692, 'min_data_in_leaf': 42, 'lambda_l1': 0.03569917439724517, 'lambda_l2': 0.18063631682956882} : acc= 55.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31638328858124787, 'max_depth': 55, 'num_leaves': 788, 'min_data_in_leaf': 46, 'lambda_l1': 0.052567020370449156, 'lambda_l2': 0.2616614037224507} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.27432649794312924, 'max_depth': 61, 'num_leaves': 659, 'min_data_in_leaf': 34, 'lambda_l1': 0.026987718192199025, 'lambda_l2': 0.33480580806879223} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3870011704934591, 'max_depth': 64, 'num_leaves': 705, 'min_data_in_leaf': 38, 'lambda_l1': 0.06611958569259949, 'lambda_l2': 0.09052771579179501} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3375838638857954, 'max_depth': 57, 'num_leaves': 639, 'min_data_in_leaf': 40, 'lambda_l1': 0.06011307691866412, 'lambda_l2': 0.38613595142617846} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2931956669155801, 'max_depth': 59, 'num_leaves': 857, 'min_data_in_leaf': 32, 'lambda_l1': 0.035358319261122956, 'lambda_l2': 0.145349385030973} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.009561772904954862, 'max_depth': 56, 'num_leaves': 755, 'min_data_in_leaf': 37, 'lambda_l1': 0.019984603517800383, 'lambda_l2': 0.22558245254986592} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.40836811852833954, 'max_depth': 52, 'num_leaves': 643, 'min_data_in_leaf': 35, 'lambda_l1': 0.0006145801891163614, 'lambda_l2': 0.07964935303657163} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.25055872254509487, 'max_depth': 61, 'num_leaves': 781, 'min_data_in_leaf': 43, 'lambda_l1': 0.065895847572887, 'lambda_l2': 2.5594453749076007} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.17706299211746815, 'max_depth': 55, 'num_leaves': 639, 'min_data_in_leaf': 40, 'lambda_l1': 0.00011799061167120858, 'lambda_l2': 0.3178637667199715} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3565468558309475, 'max_depth': 59, 'num_leaves': 1032, 'min_data_in_leaf': 29, 'lambda_l1': 0.04302141465097469, 'lambda_l2': 0.2064405129028743} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31888593661851955, 'max_depth': 65, 'num_leaves': 717, 'min_data_in_leaf': 37, 'lambda_l1': 0.06476441438855707, 'lambda_l2': 0.3876990124931104} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4004075374062242, 'max_depth': 79, 'num_leaves': 612, 'min_data_in_leaf': 33, 'lambda_l1': 0.04218827504754933, 'lambda_l2': 0.07734310828529206} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.27572272786790236, 'max_depth': 57, 'num_leaves': 838, 'min_data_in_leaf': 44, 'lambda_l1': 0.06338052242063556, 'lambda_l2': 0.00776556150551605} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2127771976023492, 'max_depth': 62, 'num_leaves': 942, 'min_data_in_leaf': 35, 'lambda_l1': 0.025017349208509163, 'lambda_l2': 0.001152101580867454} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.1427081542008458, 'max_depth': 54, 'num_leaves': 649, 'min_data_in_leaf': 39, 'lambda_l1': 0.076904607306146, 'lambda_l2': 0.3021351152955855} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3513274795947987, 'max_depth': 58, 'num_leaves': 743, 'min_data_in_leaf': 42, 'lambda_l1': 0.9069169665896778, 'lambda_l2': 0.4744892947310589} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43996523374604063, 'max_depth': 60, 'num_leaves': 593, 'min_data_in_leaf': 38, 'lambda_l1': 0.042629124185349206, 'lambda_l2': 0.17554655260615032} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2969603874705542, 'max_depth': 52, 'num_leaves': 696, 'min_data_in_leaf': 32, 'lambda_l1': 0.07530885644522367, 'lambda_l2': 0.28738088808801765} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.37518268713710023, 'max_depth': 63, 'num_leaves': 875, 'min_data_in_leaf': 35, 'lambda_l1': 0.05196388889678995, 'lambda_l2': 0.0031183703864059165} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.323425516536938, 'max_depth': 56, 'num_leaves': 575, 'min_data_in_leaf': 40, 'lambda_l1': 0.02888851364615274, 'lambda_l2': 0.41696221913123155} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.23891557259832205, 'max_depth': 59, 'num_leaves': 795, 'min_data_in_leaf': 37, 'lambda_l1': 0.07168213692044278, 'lambda_l2': 0.1466989791135082} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.44203407111387893, 'max_depth': 54, 'num_leaves': 651, 'min_data_in_leaf': 47, 'lambda_l1': 0.052549348029834575, 'lambda_l2': 0.0004662847934544473} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.039235975638373326, 'max_depth': 61, 'num_leaves': 577, 'min_data_in_leaf': 30, 'lambda_l1': 0.025647468765381702, 'lambda_l2': 0.2303967985110002} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.283934687253354, 'max_depth': 65, 'num_leaves': 752, 'min_data_in_leaf': 33, 'lambda_l1': 0.08151596207022417, 'lambda_l2': 0.34752174910434064} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.37609934426083536, 'max_depth': 51, 'num_leaves': 632, 'min_data_in_leaf': 42, 'lambda_l1': 0.05143106700071418, 'lambda_l2': 0.15537722659238387} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.32557282427674145, 'max_depth': 58, 'num_leaves': 705, 'min_data_in_leaf': 36, 'lambda_l1': 0.08295606376177342, 'lambda_l2': 0.5290242460102881} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.25792900371484523, 'max_depth': 57, 'num_leaves': 565, 'min_data_in_leaf': 39, 'lambda_l1': 0.06115454305244758, 'lambda_l2': 2.6802012395278076} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.40653362861722103, 'max_depth': 63, 'num_leaves': 921, 'min_data_in_leaf': 34, 'lambda_l1': 0.033218080012076295, 'lambda_l2': 0.26837936694763903} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33591929651436925, 'max_depth': 68, 'num_leaves': 789, 'min_data_in_leaf': 38, 'lambda_l1': 0.013965401387070432, 'lambda_l2': 0.4181212457796145} : acc= 73.75%\n",
            "[HPO] metrics with {'learning_rate': 0.22650353780633783, 'max_depth': 70, 'num_leaves': 986, 'min_data_in_leaf': 41, 'lambda_l1': 0.012986863107197717, 'lambda_l2': 0.21098555869179503} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2822536246664668, 'max_depth': 72, 'num_leaves': 894, 'min_data_in_leaf': 40, 'lambda_l1': 0.01074461152729753, 'lambda_l2': 0.3670199427090345} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3069236969389752, 'max_depth': 65, 'num_leaves': 866, 'min_data_in_leaf': 44, 'lambda_l1': 0.002324047578210975, 'lambda_l2': 0.12904840932529305} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2716534173107854, 'max_depth': 73, 'num_leaves': 1003, 'min_data_in_leaf': 39, 'lambda_l1': 0.0014065464066957741, 'lambda_l2': 0.28831973661416344} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.34287984157117735, 'max_depth': 69, 'num_leaves': 830, 'min_data_in_leaf': 42, 'lambda_l1': 0.01958970690581748, 'lambda_l2': 0.3893448939390067} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3163143726342591, 'max_depth': 67, 'num_leaves': 835, 'min_data_in_leaf': 38, 'lambda_l1': 0.020683257839727305, 'lambda_l2': 0.2114425249745584} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.21646644221156916, 'max_depth': 68, 'num_leaves': 774, 'min_data_in_leaf': 41, 'lambda_l1': 0.026028630149935627, 'lambda_l2': 0.10625758206312372} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.24877435045746335, 'max_depth': 68, 'num_leaves': 882, 'min_data_in_leaf': 38, 'lambda_l1': 0.0375935996241336, 'lambda_l2': 0.33461230456670565} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4020017012357414, 'max_depth': 71, 'num_leaves': 819, 'min_data_in_leaf': 39, 'lambda_l1': 0.021287158666090128, 'lambda_l2': 0.2379786385907555} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2918168228765686, 'max_depth': 67, 'num_leaves': 818, 'min_data_in_leaf': 43, 'lambda_l1': 0.016016638409344156, 'lambda_l2': 0.11475954621124043} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3656341165118424, 'max_depth': 69, 'num_leaves': 710, 'min_data_in_leaf': 45, 'lambda_l1': 0.03660706652696299, 'lambda_l2': 0.39526150608372274} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.443467746303881, 'max_depth': 70, 'num_leaves': 968, 'min_data_in_leaf': 40, 'lambda_l1': 0.012677831909644152, 'lambda_l2': 0.0005961257329584191} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33426716365429493, 'max_depth': 67, 'num_leaves': 781, 'min_data_in_leaf': 37, 'lambda_l1': 0.03834159018475568, 'lambda_l2': 0.2923549270575128} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2602879056023139, 'max_depth': 66, 'num_leaves': 816, 'min_data_in_leaf': 37, 'lambda_l1': 0.003507182353544542, 'lambda_l2': 0.17480173428339116} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29762681970412647, 'max_depth': 69, 'num_leaves': 770, 'min_data_in_leaf': 37, 'lambda_l1': 0.03428784714517663, 'lambda_l2': 0.223846615321214} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.32317705756441706, 'max_depth': 68, 'num_leaves': 932, 'min_data_in_leaf': 36, 'lambda_l1': 0.0006343390289078529, 'lambda_l2': 0.10700082122026056} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.23519007498000574, 'max_depth': 70, 'num_leaves': 887, 'min_data_in_leaf': 37, 'lambda_l1': 0.026947432788718702, 'lambda_l2': 0.26927435476100714} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.37873535334166336, 'max_depth': 70, 'num_leaves': 759, 'min_data_in_leaf': 36, 'lambda_l1': 0.04226594341755047, 'lambda_l2': 0.10209182336757289} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.45396485027068423, 'max_depth': 67, 'num_leaves': 785, 'min_data_in_leaf': 35, 'lambda_l1': 0.018801093926984005, 'lambda_l2': 0.20299414077218436} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3390446426756013, 'max_depth': 68, 'num_leaves': 822, 'min_data_in_leaf': 35, 'lambda_l1': 0.046150549429074116, 'lambda_l2': 0.09503958036119743} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2693634318203597, 'max_depth': 67, 'num_leaves': 838, 'min_data_in_leaf': 34, 'lambda_l1': 0.017572363618249653, 'lambda_l2': 0.16976481663771067} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3954212988885125, 'max_depth': 67, 'num_leaves': 864, 'min_data_in_leaf': 35, 'lambda_l1': 0.050437393235915395, 'lambda_l2': 0.1641769203451705} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31471601191038034, 'max_depth': 73, 'num_leaves': 976, 'min_data_in_leaf': 35, 'lambda_l1': 0.034262496354801025, 'lambda_l2': 0.09040137797072084} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.1844770137173968, 'max_depth': 70, 'num_leaves': 772, 'min_data_in_leaf': 34, 'lambda_l1': 0.05665379946008991, 'lambda_l2': 0.08619978233379963} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35018879868930747, 'max_depth': 71, 'num_leaves': 943, 'min_data_in_leaf': 36, 'lambda_l1': 0.01486943226885476, 'lambda_l2': 0.0031777182145645566} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.41611663666971627, 'max_depth': 66, 'num_leaves': 869, 'min_data_in_leaf': 32, 'lambda_l1': 0.04120925161062672, 'lambda_l2': 0.23566724745415712} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.28598141949167166, 'max_depth': 66, 'num_leaves': 917, 'min_data_in_leaf': 35, 'lambda_l1': 0.7671584641138197, 'lambda_l2': 0.19426191816611404} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37069540921986055, 'max_depth': 68, 'num_leaves': 764, 'min_data_in_leaf': 37, 'lambda_l1': 0.058878092105812, 'lambda_l2': 0.27600325689281036} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.0012374718591416142, 'max_depth': 72, 'num_leaves': 777, 'min_data_in_leaf': 33, 'lambda_l1': 0.030546042463975305, 'lambda_l2': 0.16917079294714443} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.31463524261528014, 'max_depth': 66, 'num_leaves': 891, 'min_data_in_leaf': 36, 'lambda_l1': 0.0015024035011760445, 'lambda_l2': 0.26359344918104666} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.06693032532085054, 'max_depth': 69, 'num_leaves': 738, 'min_data_in_leaf': 34, 'lambda_l1': 0.06357560224497734, 'lambda_l2': 0.08447009315480003} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43134275142591216, 'max_depth': 68, 'num_leaves': 826, 'min_data_in_leaf': 37, 'lambda_l1': 0.03690505472362861, 'lambda_l2': 0.18788238103366942} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.24738268743203976, 'max_depth': 66, 'num_leaves': 722, 'min_data_in_leaf': 32, 'lambda_l1': 0.06606399131525184, 'lambda_l2': 0.08872208531526624} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.34327868980529097, 'max_depth': 69, 'num_leaves': 821, 'min_data_in_leaf': 35, 'lambda_l1': 0.002204675607821227, 'lambda_l2': 0.294636016322279} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2827366629144778, 'max_depth': 66, 'num_leaves': 742, 'min_data_in_leaf': 38, 'lambda_l1': 0.050234955559706335, 'lambda_l2': 0.0005933255719290931} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4501400639005593, 'max_depth': 67, 'num_leaves': 727, 'min_data_in_leaf': 61, 'lambda_l1': 0.02673370574914028, 'lambda_l2': 2.614763076007055} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.20363484250448388, 'max_depth': 65, 'num_leaves': 1021, 'min_data_in_leaf': 36, 'lambda_l1': 0.06752497626095877, 'lambda_l2': 2.740831112842453} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3568212323932005, 'max_depth': 70, 'num_leaves': 891, 'min_data_in_leaf': 33, 'lambda_l1': 0.02057048704422819, 'lambda_l2': 0.0008479589070544968} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2976152055785399, 'max_depth': 67, 'num_leaves': 708, 'min_data_in_leaf': 38, 'lambda_l1': 0.04604613509042319, 'lambda_l2': 0.1703793667467797} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.40217726256667097, 'max_depth': 71, 'num_leaves': 784, 'min_data_in_leaf': 31, 'lambda_l1': 0.0763872598686687, 'lambda_l2': 0.2833238954914234} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2631819209647753, 'max_depth': 65, 'num_leaves': 815, 'min_data_in_leaf': 35, 'lambda_l1': 0.05281097691872679, 'lambda_l2': 0.1715156082134165} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3247918732981811, 'max_depth': 71, 'num_leaves': 933, 'min_data_in_leaf': 37, 'lambda_l1': 0.0008736208986372257, 'lambda_l2': 0.2848807343322107} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.24039829591643633, 'max_depth': 75, 'num_leaves': 982, 'min_data_in_leaf': 38, 'lambda_l1': 0.017701145442093613, 'lambda_l2': 0.2511377115005985} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.017971415533970272, 'max_depth': 71, 'num_leaves': 897, 'min_data_in_leaf': 38, 'lambda_l1': 0.0018667775082694266, 'lambda_l2': 0.332753502499724} : acc= 53.33%\n",
            "[HPO] metrics with {'learning_rate': 0.21823635397620872, 'max_depth': 74, 'num_leaves': 1085, 'min_data_in_leaf': 39, 'lambda_l1': 0.010331418634873593, 'lambda_l2': 0.340483097539442} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2760829371734548, 'max_depth': 69, 'num_leaves': 929, 'min_data_in_leaf': 38, 'lambda_l1': 0.003924582043038992, 'lambda_l2': 0.2461276901235732} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3090042527347663, 'max_depth': 70, 'num_leaves': 834, 'min_data_in_leaf': 37, 'lambda_l1': 0.0015066148395729145, 'lambda_l2': 0.3296142276604191} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2485112193650368, 'max_depth': 69, 'num_leaves': 875, 'min_data_in_leaf': 39, 'lambda_l1': 0.016675894384539675, 'lambda_l2': 0.16451670153340064} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3128823750697378, 'max_depth': 72, 'num_leaves': 977, 'min_data_in_leaf': 37, 'lambda_l1': 0.01631554596551422, 'lambda_l2': 0.2811722286120396} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.013792934718157132, 'max_depth': 72, 'num_leaves': 837, 'min_data_in_leaf': 40, 'lambda_l1': 0.004047326019521418, 'lambda_l2': 0.3950758636303571} : acc= 52.08%\n",
            "[HPO] metrics with {'learning_rate': 0.002057320535399672, 'max_depth': 73, 'num_leaves': 974, 'min_data_in_leaf': 36, 'lambda_l1': 0.022000467324417086, 'lambda_l2': 0.10479737982421208} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27652308524628666, 'max_depth': 76, 'num_leaves': 843, 'min_data_in_leaf': 37, 'lambda_l1': 7.440401353100978e-05, 'lambda_l2': 0.21404003198539812} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.30349454813463644, 'max_depth': 75, 'num_leaves': 948, 'min_data_in_leaf': 40, 'lambda_l1': 0.000625408356778677, 'lambda_l2': 0.34310406383445025} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3398084259421839, 'max_depth': 70, 'num_leaves': 938, 'min_data_in_leaf': 38, 'lambda_l1': 0.0005521067752686792, 'lambda_l2': 0.1191387507016491} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2472431580980773, 'max_depth': 73, 'num_leaves': 916, 'min_data_in_leaf': 36, 'lambda_l1': 0.029243871180831243, 'lambda_l2': 0.19815157574092987} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2109079814792891, 'max_depth': 73, 'num_leaves': 1005, 'min_data_in_leaf': 40, 'lambda_l1': 0.030426446964538126, 'lambda_l2': 0.26622869823812595} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.324894341400023, 'max_depth': 68, 'num_leaves': 779, 'min_data_in_leaf': 35, 'lambda_l1': 0.02716589941924623, 'lambda_l2': 0.0013768832709166456} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2662190908518787, 'max_depth': 71, 'num_leaves': 1085, 'min_data_in_leaf': 38, 'lambda_l1': 0.03302665233820172, 'lambda_l2': 0.3727217682442186} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.35921053915665535, 'max_depth': 71, 'num_leaves': 897, 'min_data_in_leaf': 36, 'lambda_l1': 0.033290835982628525, 'lambda_l2': 0.10125665777385252} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.29838512551899904, 'max_depth': 73, 'num_leaves': 776, 'min_data_in_leaf': 40, 'lambda_l1': 0.00010912807464415891, 'lambda_l2': 0.20977990658897183} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3412003715964656, 'max_depth': 68, 'num_leaves': 833, 'min_data_in_leaf': 35, 'lambda_l1': 0.038252757286119744, 'lambda_l2': 0.3014836726711072} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2740220677426312, 'max_depth': 69, 'num_leaves': 742, 'min_data_in_leaf': 38, 'lambda_l1': 0.022485406280007943, 'lambda_l2': 0.10239233305721718} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.23870095635827335, 'max_depth': 75, 'num_leaves': 906, 'min_data_in_leaf': 41, 'lambda_l1': 0.03727392205857996, 'lambda_l2': 0.4111551085412527} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3210562039150016, 'max_depth': 71, 'num_leaves': 733, 'min_data_in_leaf': 37, 'lambda_l1': 0.054509984187670696, 'lambda_l2': 0.19616173323648384} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3831390066278367, 'max_depth': 74, 'num_leaves': 821, 'min_data_in_leaf': 39, 'lambda_l1': 0.07719950392061482, 'lambda_l2': 0.09772105467983587} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.34509760830835584, 'max_depth': 71, 'num_leaves': 696, 'min_data_in_leaf': 40, 'lambda_l1': 0.01938462275889072, 'lambda_l2': 0.15790194192407392} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3965787040659866, 'max_depth': 72, 'num_leaves': 790, 'min_data_in_leaf': 42, 'lambda_l1': 0.05366169250366275, 'lambda_l2': 0.06906438327322442} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2999060374173522, 'max_depth': 76, 'num_leaves': 1043, 'min_data_in_leaf': 38, 'lambda_l1': 0.04487838749752984, 'lambda_l2': 0.19081385176502363} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.34309796103441825, 'max_depth': 71, 'num_leaves': 1034, 'min_data_in_leaf': 37, 'lambda_l1': 0.017136773411109946, 'lambda_l2': 0.0837855529036676} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4456584157594145, 'max_depth': 77, 'num_leaves': 888, 'min_data_in_leaf': 40, 'lambda_l1': 0.07716450399849098, 'lambda_l2': 0.18183402810728416} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.28332159051428224, 'max_depth': 74, 'num_leaves': 704, 'min_data_in_leaf': 39, 'lambda_l1': 0.04350521648443611, 'lambda_l2': 0.2396159406207322} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.15644069042338796, 'max_depth': 72, 'num_leaves': 771, 'min_data_in_leaf': 42, 'lambda_l1': 0.06797948044682005, 'lambda_l2': 0.10821775922891752} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3693061779855927, 'max_depth': 68, 'num_leaves': 692, 'min_data_in_leaf': 37, 'lambda_l1': 6.441841945017371e-05, 'lambda_l2': 0.0004808521855251269} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.31820280479082275, 'max_depth': 74, 'num_leaves': 849, 'min_data_in_leaf': 39, 'lambda_l1': 0.08643490366404943, 'lambda_l2': 0.22582068946007705} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.22574264784969464, 'max_depth': 71, 'num_leaves': 942, 'min_data_in_leaf': 41, 'lambda_l1': 0.00021422811791370344, 'lambda_l2': 0.15379124265055616} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42787851792593307, 'max_depth': 70, 'num_leaves': 688, 'min_data_in_leaf': 36, 'lambda_l1': 0.03393028248090743, 'lambda_l2': 0.001636200007451627} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4779016049852651, 'max_depth': 70, 'num_leaves': 662, 'min_data_in_leaf': 38, 'lambda_l1': 0.0344171015551584, 'lambda_l2': 0.06068213723945409} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4640676590626236, 'max_depth': 72, 'num_leaves': 686, 'min_data_in_leaf': 37, 'lambda_l1': 0.021813911583233436, 'lambda_l2': 0.05883292242030861} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4886036390311256, 'max_depth': 70, 'num_leaves': 786, 'min_data_in_leaf': 40, 'lambda_l1': 0.01644157299671606, 'lambda_l2': 0.058221908364297054} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.08447685389584479, 'max_depth': 72, 'num_leaves': 665, 'min_data_in_leaf': 37, 'lambda_l1': 0.023752545718813425, 'lambda_l2': 0.03392752988892474} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.42160759052051117, 'max_depth': 69, 'num_leaves': 714, 'min_data_in_leaf': 51, 'lambda_l1': 0.019790469382821432, 'lambda_l2': 0.09496073077330194} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4526948291763558, 'max_depth': 68, 'num_leaves': 1029, 'min_data_in_leaf': 39, 'lambda_l1': 0.00037685571525099943, 'lambda_l2': 0.07597881137052961} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4353757688915981, 'max_depth': 74, 'num_leaves': 760, 'min_data_in_leaf': 41, 'lambda_l1': 0.038856090260931446, 'lambda_l2': 0.022358918066149036} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.400045018765583, 'max_depth': 71, 'num_leaves': 857, 'min_data_in_leaf': 36, 'lambda_l1': 0.038303031438559634, 'lambda_l2': 0.012421388899494096} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4663493747991964, 'max_depth': 69, 'num_leaves': 666, 'min_data_in_leaf': 38, 'lambda_l1': 0.022080846074157827, 'lambda_l2': 0.15223560082479368} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3964118219912189, 'max_depth': 67, 'num_leaves': 767, 'min_data_in_leaf': 42, 'lambda_l1': 0.03560262280155678, 'lambda_l2': 0.23986628820851702} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.12578400946391088, 'max_depth': 74, 'num_leaves': 662, 'min_data_in_leaf': 36, 'lambda_l1': 0.00026972735914848264, 'lambda_l2': 0.17299626813490077} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4094491835986355, 'max_depth': 70, 'num_leaves': 822, 'min_data_in_leaf': 39, 'lambda_l1': 0.05124205640862151, 'lambda_l2': 0.013095678235882952} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4638666437731889, 'max_depth': 72, 'num_leaves': 908, 'min_data_in_leaf': 41, 'lambda_l1': 0.042647652895385205, 'lambda_l2': 0.27619631844824993} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3788126286291785, 'max_depth': 68, 'num_leaves': 902, 'min_data_in_leaf': 36, 'lambda_l1': 0.056012139436885225, 'lambda_l2': 0.1558034346243894} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3793999562956917, 'max_depth': 76, 'num_leaves': 791, 'min_data_in_leaf': 44, 'lambda_l1': 0.023330249520735653, 'lambda_l2': 0.01040096192295055} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4889333398892564, 'max_depth': 67, 'num_leaves': 709, 'min_data_in_leaf': 38, 'lambda_l1': 0.05514928567940793, 'lambda_l2': 0.29307915993987804} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4203723523108416, 'max_depth': 70, 'num_leaves': 690, 'min_data_in_leaf': 40, 'lambda_l1': 0.02123255656866091, 'lambda_l2': 0.1556913919803097} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.359512401961921, 'max_depth': 74, 'num_leaves': 654, 'min_data_in_leaf': 36, 'lambda_l1': 0.03870798743209949, 'lambda_l2': 0.22976596501256397} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3483888255867403, 'max_depth': 67, 'num_leaves': 737, 'min_data_in_leaf': 43, 'lambda_l1': 0.05182814811844465, 'lambda_l2': 0.13498606643271088} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4348495302135231, 'max_depth': 71, 'num_leaves': 650, 'min_data_in_leaf': 38, 'lambda_l1': 0.021161882079411533, 'lambda_l2': 0.31049930917733365} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3648916937015543, 'max_depth': 68, 'num_leaves': 985, 'min_data_in_leaf': 35, 'lambda_l1': 0.06340814642962597, 'lambda_l2': 0.0013615917042455693} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.40528483613670724, 'max_depth': 72, 'num_leaves': 819, 'min_data_in_leaf': 40, 'lambda_l1': 0.04408945603529954, 'lambda_l2': 0.24837023167089858} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47446642192432104, 'max_depth': 66, 'num_leaves': 632, 'min_data_in_leaf': 37, 'lambda_l1': 0.018210919411395826, 'lambda_l2': 0.1285375568440869} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3294927604920424, 'max_depth': 69, 'num_leaves': 762, 'min_data_in_leaf': 42, 'lambda_l1': 0.06481702375313393, 'lambda_l2': 0.37039293310275} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33591282631278996, 'max_depth': 69, 'num_leaves': 852, 'min_data_in_leaf': 39, 'lambda_l1': 0.035295367970528846, 'lambda_l2': 0.09954121294953584} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.39769654750854655, 'max_depth': 78, 'num_leaves': 659, 'min_data_in_leaf': 35, 'lambda_l1': 0.06433255161526001, 'lambda_l2': 2.809857846331617} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4899810073454222, 'max_depth': 66, 'num_leaves': 753, 'min_data_in_leaf': 37, 'lambda_l1': 0.01697767986366519, 'lambda_l2': 0.21460432957040165} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3623376563623706, 'max_depth': 73, 'num_leaves': 1043, 'min_data_in_leaf': 41, 'lambda_l1': 0.04177473822876358, 'lambda_l2': 0.3083218102464336} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.325691209823278, 'max_depth': 72, 'num_leaves': 631, 'min_data_in_leaf': 39, 'lambda_l1': 0.00038627229175140776, 'lambda_l2': 0.0899876506647104} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.43771555288245884, 'max_depth': 67, 'num_leaves': 928, 'min_data_in_leaf': 35, 'lambda_l1': 0.07017614270224273, 'lambda_l2': 0.004799166101688707} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3851350587838363, 'max_depth': 69, 'num_leaves': 844, 'min_data_in_leaf': 37, 'lambda_l1': 0.0546458003352536, 'lambda_l2': 0.43015758900733503} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3068816129863631, 'max_depth': 66, 'num_leaves': 693, 'min_data_in_leaf': 44, 'lambda_l1': 0.031074160625661658, 'lambda_l2': 0.20999261856862173} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.02717796389477441, 'max_depth': 75, 'num_leaves': 622, 'min_data_in_leaf': 39, 'lambda_l1': 1.9968038293670734e-05, 'lambda_l2': 0.004790813294771974} : acc= 58.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3367142348659987, 'max_depth': 77, 'num_leaves': 765, 'min_data_in_leaf': 42, 'lambda_l1': 0.07731524525127573, 'lambda_l2': 0.3383692487757975} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.40276375316906926, 'max_depth': 70, 'num_leaves': 704, 'min_data_in_leaf': 35, 'lambda_l1': 0.04846395152911818, 'lambda_l2': 0.17403465602362367} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4838746247670181, 'max_depth': 66, 'num_leaves': 608, 'min_data_in_leaf': 37, 'lambda_l1': 0.0271963692843247, 'lambda_l2': 0.4261108485586741} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.28066475902963367, 'max_depth': 71, 'num_leaves': 816, 'min_data_in_leaf': 48, 'lambda_l1': 0.07021835082452335, 'lambda_l2': 0.29175957950251247} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3550732607419891, 'max_depth': 65, 'num_leaves': 767, 'min_data_in_leaf': 40, 'lambda_l1': 0.053250802376131556, 'lambda_l2': 0.12751268743615185} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.303096233743026, 'max_depth': 69, 'num_leaves': 960, 'min_data_in_leaf': 35, 'lambda_l1': 0.08588207681154261, 'lambda_l2': 0.00035585140231936263} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.434566352212214, 'max_depth': 73, 'num_leaves': 872, 'min_data_in_leaf': 38, 'lambda_l1': 0.03676241167102366, 'lambda_l2': 0.2496462908636442} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.370829377185292, 'max_depth': 68, 'num_leaves': 599, 'min_data_in_leaf': 46, 'lambda_l1': 0.021967989933577618, 'lambda_l2': 0.3947837276978897} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2685697350429372, 'max_depth': 65, 'num_leaves': 720, 'min_data_in_leaf': 42, 'lambda_l1': 0.06240680384443104, 'lambda_l2': 0.15195897653425658} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3185729423854246, 'max_depth': 67, 'num_leaves': 684, 'min_data_in_leaf': 36, 'lambda_l1': 0.08236703275165243, 'lambda_l2': 2.52034886819221} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.006738222882832249, 'max_depth': 70, 'num_leaves': 632, 'min_data_in_leaf': 39, 'lambda_l1': 0.038785674331891486, 'lambda_l2': 0.30612035305511015} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4875581353907795, 'max_depth': 72, 'num_leaves': 808, 'min_data_in_leaf': 34, 'lambda_l1': 0.02170166797790784, 'lambda_l2': 0.216522692703295} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3945870947088181, 'max_depth': 67, 'num_leaves': 589, 'min_data_in_leaf': 40, 'lambda_l1': 0.05571780259375825, 'lambda_l2': 0.09651670732034677} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3223050337407882, 'max_depth': 75, 'num_leaves': 910, 'min_data_in_leaf': 37, 'lambda_l1': 0.09143228666758221, 'lambda_l2': 0.423496085055549} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.26474239326836996, 'max_depth': 65, 'num_leaves': 1069, 'min_data_in_leaf': 43, 'lambda_l1': 0.06561530161604315, 'lambda_l2': 0.0035245017764745645} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.42601608049541995, 'max_depth': 70, 'num_leaves': 694, 'min_data_in_leaf': 34, 'lambda_l1': 0.04167720454494659, 'lambda_l2': 0.22720112016220712} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3603584953687748, 'max_depth': 65, 'num_leaves': 757, 'min_data_in_leaf': 38, 'lambda_l1': 0.014298966645503276, 'lambda_l2': 0.3362600406962155} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5007588737587314, 'max_depth': 67, 'num_leaves': 969, 'min_data_in_leaf': 35, 'lambda_l1': 0.01850629128377846, 'lambda_l2': 0.48730939636230186} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.40340118257685126, 'max_depth': 68, 'num_leaves': 839, 'min_data_in_leaf': 37, 'lambda_l1': 0.0152814959285788, 'lambda_l2': 0.417165890245937} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.44908801615824273, 'max_depth': 65, 'num_leaves': 874, 'min_data_in_leaf': 34, 'lambda_l1': 0.0005869835011804991, 'lambda_l2': 0.4809525617915015} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3648071434182982, 'max_depth': 68, 'num_leaves': 916, 'min_data_in_leaf': 36, 'lambda_l1': 0.0022868581100698657, 'lambda_l2': 0.364940700799329} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.36710036080667086, 'max_depth': 71, 'num_leaves': 789, 'min_data_in_leaf': 38, 'lambda_l1': 0.019495951985824267, 'lambda_l2': 0.45942244024530754} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44346088157871877, 'max_depth': 66, 'num_leaves': 849, 'min_data_in_leaf': 36, 'lambda_l1': 0.01684517127265857, 'lambda_l2': 0.37962411326654955} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3062935283771098, 'max_depth': 65, 'num_leaves': 787, 'min_data_in_leaf': 34, 'lambda_l1': 0.019230005003156588, 'lambda_l2': 0.30996544270819115} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5152011486273629, 'max_depth': 68, 'num_leaves': 1007, 'min_data_in_leaf': 38, 'lambda_l1': 0.033912076851812335, 'lambda_l2': 0.553046725472677} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.36168262598251577, 'max_depth': 69, 'num_leaves': 761, 'min_data_in_leaf': 36, 'lambda_l1': 0.0170294380840085, 'lambda_l2': 0.4129057843190774} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4037423311274175, 'max_depth': 65, 'num_leaves': 902, 'min_data_in_leaf': 38, 'lambda_l1': 0.03477607322627689, 'lambda_l2': 0.35296444409633493} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.1019745852223991, 'max_depth': 67, 'num_leaves': 714, 'min_data_in_leaf': 34, 'lambda_l1': 0.022418190041043545, 'lambda_l2': 0.3140974903110617} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3304376271523907, 'max_depth': 73, 'num_leaves': 830, 'min_data_in_leaf': 39, 'lambda_l1': 0.003488293625147621, 'lambda_l2': 0.311884629167626} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.503084828975777, 'max_depth': 74, 'num_leaves': 760, 'min_data_in_leaf': 36, 'lambda_l1': 0.002864402261193866, 'lambda_l2': 0.48452028902015204} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2820306253893359, 'max_depth': 71, 'num_leaves': 934, 'min_data_in_leaf': 34, 'lambda_l1': 0.04232589537668579, 'lambda_l2': 0.28876310917636416} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4203145850402729, 'max_depth': 69, 'num_leaves': 732, 'min_data_in_leaf': 41, 'lambda_l1': 0.0009462196187279143, 'lambda_l2': 0.4021176134335173} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3386131642327565, 'max_depth': 65, 'num_leaves': 838, 'min_data_in_leaf': 37, 'lambda_l1': 0.000868718229100153, 'lambda_l2': 0.2494849678562039} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.28653729650918214, 'max_depth': 65, 'num_leaves': 1124, 'min_data_in_leaf': 39, 'lambda_l1': 0.03806009537175516, 'lambda_l2': 0.48657631606698953} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37876077691114896, 'max_depth': 67, 'num_leaves': 1005, 'min_data_in_leaf': 34, 'lambda_l1': 0.028750352235678702, 'lambda_l2': 2.657566846303106} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4559600703274261, 'max_depth': 71, 'num_leaves': 698, 'min_data_in_leaf': 37, 'lambda_l1': 0.00018589116903552916, 'lambda_l2': 0.33593207592701674} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.25305113325438144, 'max_depth': 76, 'num_leaves': 614, 'min_data_in_leaf': 40, 'lambda_l1': 0.04758816608661866, 'lambda_l2': 0.25421819604858004} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3194583895046558, 'max_depth': 70, 'num_leaves': 813, 'min_data_in_leaf': 36, 'lambda_l1': 0.06929151572775702, 'lambda_l2': 0.5483643824231758} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.37311171712645863, 'max_depth': 68, 'num_leaves': 737, 'min_data_in_leaf': 33, 'lambda_l1': 0.02132933163299242, 'lambda_l2': 0.3185747350360382} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2985359328756908, 'max_depth': 64, 'num_leaves': 888, 'min_data_in_leaf': 55, 'lambda_l1': 0.09697755501922017, 'lambda_l2': 0.42474681526189095} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.42406510212117177, 'max_depth': 64, 'num_leaves': 581, 'min_data_in_leaf': 38, 'lambda_l1': 0.055055450324127765, 'lambda_l2': 0.24383056963493666} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33794182392842576, 'max_depth': 73, 'num_leaves': 665, 'min_data_in_leaf': 40, 'lambda_l1': 0.03145569333114595, 'lambda_l2': 0.3611871968398941} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5123975981319767, 'max_depth': 66, 'num_leaves': 2931, 'min_data_in_leaf': 35, 'lambda_l1': 0.08046821830957145, 'lambda_l2': 0.2139656959233244} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24888349589356829, 'max_depth': 69, 'num_leaves': 773, 'min_data_in_leaf': 42, 'lambda_l1': 0.05347861845896486, 'lambda_l2': 0.4535850391305368} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3879753125767118, 'max_depth': 64, 'num_leaves': 555, 'min_data_in_leaf': 38, 'lambda_l1': 0.8171024576219043, 'lambda_l2': 0.24408163720816917} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29095829806792795, 'max_depth': 71, 'num_leaves': 678, 'min_data_in_leaf': 35, 'lambda_l1': 0.0935500255564479, 'lambda_l2': 0.1860478330986065} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3445362888003889, 'max_depth': 64, 'num_leaves': 897, 'min_data_in_leaf': 33, 'lambda_l1': 0.03441965785846646, 'lambda_l2': 0.35588374871118234} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.43419229698577405, 'max_depth': 67, 'num_leaves': 774, 'min_data_in_leaf': 41, 'lambda_l1': 0.06974513716276338, 'lambda_l2': 0.5379779721587905} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.05413619166509597, 'max_depth': 73, 'num_leaves': 595, 'min_data_in_leaf': 37, 'lambda_l1': 0.01942114966180475, 'lambda_l2': 2.778610401373478} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2669470342905124, 'max_depth': 77, 'num_leaves': 991, 'min_data_in_leaf': 39, 'lambda_l1': 0.04879110593431642, 'lambda_l2': 0.31590547507776956} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3187643319628693, 'max_depth': 69, 'num_leaves': 652, 'min_data_in_leaf': 36, 'lambda_l1': 0.07713034366454752, 'lambda_l2': 0.2181893430349543} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3664798199757796, 'max_depth': 67, 'num_leaves': 813, 'min_data_in_leaf': 39, 'lambda_l1': 0.09731650296868621, 'lambda_l2': 0.1614500507953137} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22678138280487448, 'max_depth': 64, 'num_leaves': 570, 'min_data_in_leaf': 44, 'lambda_l1': 0.02018994942488277, 'lambda_l2': 0.4106774388294685} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4885437435209195, 'max_depth': 71, 'num_leaves': 741, 'min_data_in_leaf': 80, 'lambda_l1': 0.05862558092531356, 'lambda_l2': 0.2925804446272775} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3991368409536994, 'max_depth': 66, 'num_leaves': 880, 'min_data_in_leaf': 41, 'lambda_l1': 0.039419805380441104, 'lambda_l2': 0.1956217089543961} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.30128471952112756, 'max_depth': 75, 'num_leaves': 1075, 'min_data_in_leaf': 34, 'lambda_l1': 0.076034961891045, 'lambda_l2': 0.4654967087960924} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3481795307088394, 'max_depth': 69, 'num_leaves': 666, 'min_data_in_leaf': 37, 'lambda_l1': 0.04420046172590584, 'lambda_l2': 0.3423533975102085} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4374754483860468, 'max_depth': 66, 'num_leaves': 729, 'min_data_in_leaf': 32, 'lambda_l1': 0.018997610611033108, 'lambda_l2': 0.173933315019108} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.26725553627005005, 'max_depth': 72, 'num_leaves': 603, 'min_data_in_leaf': 36, 'lambda_l1': 0.09889856055163622, 'lambda_l2': 2.587135264327369} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.31984343147427396, 'max_depth': 64, 'num_leaves': 544, 'min_data_in_leaf': 38, 'lambda_l1': 0.06517581394545646, 'lambda_l2': 0.5936134153849725} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.19589724783328374, 'max_depth': 68, 'num_leaves': 840, 'min_data_in_leaf': 42, 'lambda_l1': 0.03677590372564913, 'lambda_l2': 0.26613462477808564} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3841507523830084, 'max_depth': 74, 'num_leaves': 690, 'min_data_in_leaf': 40, 'lambda_l1': 0.08509762752774044, 'lambda_l2': 0.14342207966027948} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47387591721875105, 'max_depth': 70, 'num_leaves': 932, 'min_data_in_leaf': 34, 'lambda_l1': 0.017450324215956603, 'lambda_l2': 0.4041633262955814} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3437590765602958, 'max_depth': 64, 'num_leaves': 541, 'min_data_in_leaf': 45, 'lambda_l1': 0.05942408731321766, 'lambda_l2': 0.2863713948875901} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.24747000613791273, 'max_depth': 67, 'num_leaves': 790, 'min_data_in_leaf': 36, 'lambda_l1': 0.0012722191346779196, 'lambda_l2': 0.1583819533325401} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.28998011871708995, 'max_depth': 64, 'num_leaves': 647, 'min_data_in_leaf': 38, 'lambda_l1': 0.03660158130823625, 'lambda_l2': 2.8517489160998473} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5317814636167295, 'max_depth': 72, 'num_leaves': 712, 'min_data_in_leaf': 40, 'lambda_l1': 0.10798216911751618, 'lambda_l2': 0.5023797518734233} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3961795933008817, 'max_depth': 70, 'num_leaves': 545, 'min_data_in_leaf': 33, 'lambda_l1': 0.07208821803020408, 'lambda_l2': 0.3562597109233875} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.31194516344278395, 'max_depth': 67, 'num_leaves': 824, 'min_data_in_leaf': 35, 'lambda_l1': 0.05546008502644823, 'lambda_l2': 0.11856878373080998} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3578463072316406, 'max_depth': 64, 'num_leaves': 754, 'min_data_in_leaf': 43, 'lambda_l1': 0.08799414566731706, 'lambda_l2': 0.2520400724826303} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.43323222502007513, 'max_depth': 66, 'num_leaves': 612, 'min_data_in_leaf': 38, 'lambda_l1': 0.019889859967761322, 'lambda_l2': 0.4370706392112379} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2668552932889313, 'max_depth': 69, 'num_leaves': 937, 'min_data_in_leaf': 36, 'lambda_l1': 0.10719201570724982, 'lambda_l2': 0.22107537954989043} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.29524725003970376, 'max_depth': 73, 'num_leaves': 524, 'min_data_in_leaf': 41, 'lambda_l1': 0.04542611334091352, 'lambda_l2': 0.13023315453208656} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.22869107741522907, 'max_depth': 64, 'num_leaves': 640, 'min_data_in_leaf': 32, 'lambda_l1': 0.06963463877416454, 'lambda_l2': 0.3393606999661552} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.36486882319151137, 'max_depth': 77, 'num_leaves': 2826, 'min_data_in_leaf': 39, 'lambda_l1': 0.031018160373657316, 'lambda_l2': 0.578910941232752} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.46463575965929454, 'max_depth': 68, 'num_leaves': 863, 'min_data_in_leaf': 35, 'lambda_l1': 0.08931862963788435, 'lambda_l2': 0.27821352096300217} : acc= 73.75%\n",
            "[HPO] metrics with {'learning_rate': 0.536394143407589, 'max_depth': 69, 'num_leaves': 958, 'min_data_in_leaf': 32, 'lambda_l1': 0.11965212623498786, 'lambda_l2': 0.4841876880138116} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5297070267920806, 'max_depth': 67, 'num_leaves': 982, 'min_data_in_leaf': 32, 'lambda_l1': 0.11497432048600131, 'lambda_l2': 0.42436150540898954} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5338340077081971, 'max_depth': 71, 'num_leaves': 1077, 'min_data_in_leaf': 34, 'lambda_l1': 0.12835091979578905, 'lambda_l2': 0.3852332383249016} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4816416655733632, 'max_depth': 68, 'num_leaves': 989, 'min_data_in_leaf': 33, 'lambda_l1': 0.09655025564496417, 'lambda_l2': 0.5755966125708958} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5210644070487425, 'max_depth': 69, 'num_leaves': 922, 'min_data_in_leaf': 35, 'lambda_l1': 0.09993345000542248, 'lambda_l2': 0.35714102195682057} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.46582845468117196, 'max_depth': 66, 'num_leaves': 882, 'min_data_in_leaf': 31, 'lambda_l1': 0.10907380928533611, 'lambda_l2': 0.433323580453168} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5287705912644207, 'max_depth': 71, 'num_leaves': 1089, 'min_data_in_leaf': 34, 'lambda_l1': 0.12946589865268898, 'lambda_l2': 0.29289280471070345} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.44452803806945573, 'max_depth': 68, 'num_leaves': 873, 'min_data_in_leaf': 35, 'lambda_l1': 0.09271847998282871, 'lambda_l2': 0.3124689118486129} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.48174565672409153, 'max_depth': 70, 'num_leaves': 1049, 'min_data_in_leaf': 33, 'lambda_l1': 0.08690616642227127, 'lambda_l2': 0.5138904533299029} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.44811138405705264, 'max_depth': 66, 'num_leaves': 856, 'min_data_in_leaf': 36, 'lambda_l1': 0.10737062684059306, 'lambda_l2': 0.40340827049699624} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5202416300332812, 'max_depth': 72, 'num_leaves': 925, 'min_data_in_leaf': 32, 'lambda_l1': 0.09081015478362794, 'lambda_l2': 2.481613680410329} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4005205026128121, 'max_depth': 75, 'num_leaves': 998, 'min_data_in_leaf': 35, 'lambda_l1': 0.1304004578771491, 'lambda_l2': 0.30506659012528814} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.43973059245909957, 'max_depth': 68, 'num_leaves': 841, 'min_data_in_leaf': 37, 'lambda_l1': 0.0771870274645364, 'lambda_l2': 2.670002101243761} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4759536385740368, 'max_depth': 66, 'num_leaves': 872, 'min_data_in_leaf': 34, 'lambda_l1': 0.11542781261424431, 'lambda_l2': 0.2527873058857757} : acc= 75.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5630053708482794, 'max_depth': 66, 'num_leaves': 1010, 'min_data_in_leaf': 31, 'lambda_l1': 0.14257226840723985, 'lambda_l2': 0.2518581643170275} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.573967335381299, 'max_depth': 67, 'num_leaves': 907, 'min_data_in_leaf': 31, 'lambda_l1': 0.13644828518658822, 'lambda_l2': 0.3574817263231812} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.544983495624363, 'max_depth': 69, 'num_leaves': 1022, 'min_data_in_leaf': 31, 'lambda_l1': 0.15393670870412116, 'lambda_l2': 0.25532480219664005} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.49795151979446595, 'max_depth': 65, 'num_leaves': 944, 'min_data_in_leaf': 32, 'lambda_l1': 0.12669071205066273, 'lambda_l2': 0.49583645266176396} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5241791743689602, 'max_depth': 67, 'num_leaves': 935, 'min_data_in_leaf': 30, 'lambda_l1': 0.1507085243823019, 'lambda_l2': 0.40563647752397275} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.46962533321662325, 'max_depth': 66, 'num_leaves': 850, 'min_data_in_leaf': 33, 'lambda_l1': 0.15751824860384095, 'lambda_l2': 0.23276904287074643} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5689893597741429, 'max_depth': 68, 'num_leaves': 967, 'min_data_in_leaf': 33, 'lambda_l1': 0.1322279494401458, 'lambda_l2': 0.295781069298138} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4971140002408004, 'max_depth': 65, 'num_leaves': 870, 'min_data_in_leaf': 34, 'lambda_l1': 0.11691925411947174, 'lambda_l2': 0.46041850934674133} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5613726874325755, 'max_depth': 70, 'num_leaves': 863, 'min_data_in_leaf': 34, 'lambda_l1': 0.1747540074996146, 'lambda_l2': 0.35263192570493496} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4573044933051386, 'max_depth': 70, 'num_leaves': 970, 'min_data_in_leaf': 30, 'lambda_l1': 0.11738576519598426, 'lambda_l2': 0.25098410552155315} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4835893183578057, 'max_depth': 68, 'num_leaves': 1120, 'min_data_in_leaf': 34, 'lambda_l1': 0.10740916471473866, 'lambda_l2': 0.20207292268699978} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5816725690680652, 'max_depth': 73, 'num_leaves': 825, 'min_data_in_leaf': 35, 'lambda_l1': 0.13786990671310412, 'lambda_l2': 0.6656610162948413} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4529067617824806, 'max_depth': 65, 'num_leaves': 1046, 'min_data_in_leaf': 32, 'lambda_l1': 0.11478992847945521, 'lambda_l2': 0.5520020131907026} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.43235499433331037, 'max_depth': 71, 'num_leaves': 908, 'min_data_in_leaf': 36, 'lambda_l1': 0.17305598031020725, 'lambda_l2': 0.34613225318163454} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.41856329731589825, 'max_depth': 64, 'num_leaves': 858, 'min_data_in_leaf': 33, 'lambda_l1': 0.10500784650150173, 'lambda_l2': 0.20178738879914473} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5078326240923665, 'max_depth': 67, 'num_leaves': 1155, 'min_data_in_leaf': 36, 'lambda_l1': 0.15010258305578053, 'lambda_l2': 0.43315874289892775} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4213739261316729, 'max_depth': 66, 'num_leaves': 775, 'min_data_in_leaf': 34, 'lambda_l1': 0.10214374137551607, 'lambda_l2': 0.3063799987193114} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.483796654988553, 'max_depth': 69, 'num_leaves': 817, 'min_data_in_leaf': 36, 'lambda_l1': 0.12097721105456391, 'lambda_l2': 0.1627834058564761} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4158385556316958, 'max_depth': 64, 'num_leaves': 899, 'min_data_in_leaf': 29, 'lambda_l1': 0.0869857668081804, 'lambda_l2': 0.38185118231285237} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5540475522132358, 'max_depth': 71, 'num_leaves': 1011, 'min_data_in_leaf': 99, 'lambda_l1': 0.00046804357241493275, 'lambda_l2': 0.20251005675099226} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.39649524021541, 'max_depth': 73, 'num_leaves': 807, 'min_data_in_leaf': 37, 'lambda_l1': 0.19110147491635374, 'lambda_l2': 0.5022737488185904} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.45831460527242573, 'max_depth': 68, 'num_leaves': 931, 'min_data_in_leaf': 31, 'lambda_l1': 0.09031043858918963, 'lambda_l2': 0.29951585505594136} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.04521285669549912, 'max_depth': 65, 'num_leaves': 784, 'min_data_in_leaf': 48, 'lambda_l1': 0.13473420506419168, 'lambda_l2': 0.1607369580787527} : acc= 61.25%\n",
            "[HPO] metrics with {'learning_rate': 0.004045824022734427, 'max_depth': 70, 'num_leaves': 822, 'min_data_in_leaf': 35, 'lambda_l1': 0.07408858392366632, 'lambda_l2': 0.25554014663264896} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5922470401721762, 'max_depth': 64, 'num_leaves': 901, 'min_data_in_leaf': 38, 'lambda_l1': 0.11387442486634466, 'lambda_l2': 0.4016847593081049} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.42044016833189485, 'max_depth': 68, 'num_leaves': 1043, 'min_data_in_leaf': 33, 'lambda_l1': 0.08633268872206068, 'lambda_l2': 0.1323151065744834} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.38728072551061055, 'max_depth': 66, 'num_leaves': 811, 'min_data_in_leaf': 35, 'lambda_l1': 0.06396161053624293, 'lambda_l2': 0.5896956380622027} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.49792450379898007, 'max_depth': 71, 'num_leaves': 787, 'min_data_in_leaf': 37, 'lambda_l1': 0.09258647474131199, 'lambda_l2': 0.28331375548878407} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3991150962936155, 'max_depth': 74, 'num_leaves': 931, 'min_data_in_leaf': 39, 'lambda_l1': 0.06621140278499042, 'lambda_l2': 0.43855140881121046} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.47812473412133966, 'max_depth': 67, 'num_leaves': 786, 'min_data_in_leaf': 45, 'lambda_l1': 0.16012713752392893, 'lambda_l2': 0.14885747128360055} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3883644414862268, 'max_depth': 64, 'num_leaves': 884, 'min_data_in_leaf': 32, 'lambda_l1': 0.1104735769005754, 'lambda_l2': 0.33444441566913413} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5355879117821436, 'max_depth': 69, 'num_leaves': 762, 'min_data_in_leaf': 34, 'lambda_l1': 0.05885925971079457, 'lambda_l2': 0.2259064937672825} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4526800414625093, 'max_depth': 72, 'num_leaves': 978, 'min_data_in_leaf': 37, 'lambda_l1': 0.0008190984487865383, 'lambda_l2': 0.11113008842066567} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3671195253738875, 'max_depth': 66, 'num_leaves': 1098, 'min_data_in_leaf': 43, 'lambda_l1': 0.13472118286542856, 'lambda_l2': 0.49935272114607054} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.41617388601337063, 'max_depth': 63, 'num_leaves': 743, 'min_data_in_leaf': 39, 'lambda_l1': 0.00030810469511334537, 'lambda_l2': 0.3414354726877865} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3676576679978817, 'max_depth': 69, 'num_leaves': 835, 'min_data_in_leaf': 35, 'lambda_l1': 0.09884901747564068, 'lambda_l2': 0.22442329138716482} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5725521380815995, 'max_depth': 75, 'num_leaves': 884, 'min_data_in_leaf': 37, 'lambda_l1': 0.08054369238321432, 'lambda_l2': 0.10393220453472865} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4567196101411972, 'max_depth': 64, 'num_leaves': 746, 'min_data_in_leaf': 41, 'lambda_l1': 0.052956518167632874, 'lambda_l2': 0.3969657967075676} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3835225291467713, 'max_depth': 67, 'num_leaves': 867, 'min_data_in_leaf': 30, 'lambda_l1': 0.021087053295924543, 'lambda_l2': 0.267998039564252} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35708449935171116, 'max_depth': 66, 'num_leaves': 979, 'min_data_in_leaf': 39, 'lambda_l1': 0.07723508975231576, 'lambda_l2': 0.19915679735194075} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5063254641309977, 'max_depth': 78, 'num_leaves': 726, 'min_data_in_leaf': 33, 'lambda_l1': 0.11216150010289626, 'lambda_l2': 0.47509287754736373} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.42194778773170205, 'max_depth': 72, 'num_leaves': 2698, 'min_data_in_leaf': 50, 'lambda_l1': 0.03476792064059524, 'lambda_l2': 0.319393451498204} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.34865574164954755, 'max_depth': 70, 'num_leaves': 797, 'min_data_in_leaf': 36, 'lambda_l1': 0.05436487361375112, 'lambda_l2': 0.09464714212006684} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.42208874854804, 'max_depth': 64, 'num_leaves': 135, 'min_data_in_leaf': 46, 'lambda_l1': 0.7165170163034565, 'lambda_l2': 0.6150314234597208} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3506945564918299, 'max_depth': 68, 'num_leaves': 2566, 'min_data_in_leaf': 41, 'lambda_l1': 0.10142308549097968, 'lambda_l2': 0.1810916600573978} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5851128606729303, 'max_depth': 63, 'num_leaves': 748, 'min_data_in_leaf': 38, 'lambda_l1': 0.07287369510546197, 'lambda_l2': 0.36018817802884695} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4803690611095362, 'max_depth': 73, 'num_leaves': 850, 'min_data_in_leaf': 34, 'lambda_l1': 0.018851636846756906, 'lambda_l2': 0.2563881113883186} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3933270389148271, 'max_depth': 66, 'num_leaves': 942, 'min_data_in_leaf': 36, 'lambda_l1': 0.039823840860869285, 'lambda_l2': 0.11493601267040837} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3299626950594093, 'max_depth': 70, 'num_leaves': 756, 'min_data_in_leaf': 40, 'lambda_l1': 0.11766376577495875, 'lambda_l2': 0.4586715887456468} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.03550876838369907, 'max_depth': 63, 'num_leaves': 1052, 'min_data_in_leaf': 32, 'lambda_l1': 0.08657950869290852, 'lambda_l2': 0.29634230845385134} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4261572332370157, 'max_depth': 68, 'num_leaves': 718, 'min_data_in_leaf': 43, 'lambda_l1': 0.00018044516061805336, 'lambda_l2': 0.1979771770586689} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3716254554656214, 'max_depth': 67, 'num_leaves': 859, 'min_data_in_leaf': 38, 'lambda_l1': 0.05843319491727317, 'lambda_l2': 0.09493396517910424} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6271161789853371, 'max_depth': 75, 'num_leaves': 961, 'min_data_in_leaf': 35, 'lambda_l1': 0.13198064166538714, 'lambda_l2': 0.39771785464469916} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5115997778610805, 'max_depth': 65, 'num_leaves': 807, 'min_data_in_leaf': 37, 'lambda_l1': 0.0330478349024494, 'lambda_l2': 0.546687062963314} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.33591951869615994, 'max_depth': 71, 'num_leaves': 176, 'min_data_in_leaf': 90, 'lambda_l1': 0.06870774147134837, 'lambda_l2': 0.25402599908730283} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.44873342186677234, 'max_depth': 68, 'num_leaves': 718, 'min_data_in_leaf': 33, 'lambda_l1': 0.048421392709564165, 'lambda_l2': 0.10921705348503728} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3681716848875748, 'max_depth': 65, 'num_leaves': 879, 'min_data_in_leaf': 41, 'lambda_l1': 0.09252313087864343, 'lambda_l2': 0.3381627183774264} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3174307497743694, 'max_depth': 70, 'num_leaves': 694, 'min_data_in_leaf': 29, 'lambda_l1': 0.021132698472236613, 'lambda_l2': 0.1855740633055634} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.40437151469007226, 'max_depth': 64, 'num_leaves': 800, 'min_data_in_leaf': 39, 'lambda_l1': 0.14438238066760922, 'lambda_l2': 0.42920413194413065} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.46944712104553404, 'max_depth': 72, 'num_leaves': 1128, 'min_data_in_leaf': 36, 'lambda_l1': 0.07212175411876638, 'lambda_l2': 0.30272116094614226} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2970092866548784, 'max_depth': 63, 'num_leaves': 942, 'min_data_in_leaf': 31, 'lambda_l1': 0.09798089367456103, 'lambda_l2': 0.19839583976309982} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5474609325039648, 'max_depth': 66, 'num_leaves': 744, 'min_data_in_leaf': 44, 'lambda_l1': 0.03619600552059012, 'lambda_l2': 0.6706149044867062} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.35709187478364185, 'max_depth': 69, 'num_leaves': 822, 'min_data_in_leaf': 34, 'lambda_l1': 0.1191183143866982, 'lambda_l2': 0.0885358303425505} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40464284667504713, 'max_depth': 66, 'num_leaves': 685, 'min_data_in_leaf': 38, 'lambda_l1': 0.056421567708516154, 'lambda_l2': 0.5099973850971752} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3206106148331692, 'max_depth': 74, 'num_leaves': 1021, 'min_data_in_leaf': 42, 'lambda_l1': 0.16766363914535304, 'lambda_l2': 0.3812755787232961} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2827022305351472, 'max_depth': 70, 'num_leaves': 894, 'min_data_in_leaf': 35, 'lambda_l1': 0.015832455885525076, 'lambda_l2': 0.2406030872140031} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37858936317659386, 'max_depth': 63, 'num_leaves': 230, 'min_data_in_leaf': 40, 'lambda_l1': 0.0906142160277535, 'lambda_l2': 0.09466596130422392} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.45700662194905123, 'max_depth': 67, 'num_leaves': 792, 'min_data_in_leaf': 53, 'lambda_l1': 0.9988403089226454, 'lambda_l2': 0.3116009222881587} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3330650561875058, 'max_depth': 63, 'num_leaves': 699, 'min_data_in_leaf': 37, 'lambda_l1': 0.0441039597371392, 'lambda_l2': 0.20165411471015232} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.16744236698908657, 'max_depth': 68, 'num_leaves': 712, 'min_data_in_leaf': 33, 'lambda_l1': 0.07405180662520726, 'lambda_l2': 0.4162073491282335} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.41727739029064737, 'max_depth': 79, 'num_leaves': 824, 'min_data_in_leaf': 38, 'lambda_l1': 0.020761843657367773, 'lambda_l2': 0.15304505788711215} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6355933037273076, 'max_depth': 72, 'num_leaves': 865, 'min_data_in_leaf': 35, 'lambda_l1': 0.05371945646874116, 'lambda_l2': 0.30474650273152093} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29640628790663043, 'max_depth': 65, 'num_leaves': 153, 'min_data_in_leaf': 40, 'lambda_l1': 0.11372409874185031, 'lambda_l2': 0.5528147880924297} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.505236042133811, 'max_depth': 69, 'num_leaves': 936, 'min_data_in_leaf': 47, 'lambda_l1': 0.07499954588908722, 'lambda_l2': 0.12089753313135138} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.34415015670741395, 'max_depth': 71, 'num_leaves': 686, 'min_data_in_leaf': 32, 'lambda_l1': 0.03333890376317052, 'lambda_l2': 0.3756966033270568} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2551598202234503, 'max_depth': 76, 'num_leaves': 780, 'min_data_in_leaf': 42, 'lambda_l1': 0.00028397450526096435, 'lambda_l2': 0.24043533550858637} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3851435890607509, 'max_depth': 66, 'num_leaves': 1003, 'min_data_in_leaf': 36, 'lambda_l1': 0.0947747700445368, 'lambda_l2': 0.08189548756366719} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.11834401179284824, 'max_depth': 73, 'num_leaves': 686, 'min_data_in_leaf': 39, 'lambda_l1': 0.1447219112228055, 'lambda_l2': 0.4715669918976085} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4491892245067056, 'max_depth': 63, 'num_leaves': 778, 'min_data_in_leaf': 37, 'lambda_l1': 0.060178696423822516, 'lambda_l2': 0.2769056277341425} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.30360865008746585, 'max_depth': 45, 'num_leaves': 858, 'min_data_in_leaf': 34, 'lambda_l1': 0.020821619667751992, 'lambda_l2': 0.1951376833631151} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5297409106448984, 'max_depth': 63, 'num_leaves': 236, 'min_data_in_leaf': 30, 'lambda_l1': 0.04298616309216706, 'lambda_l2': 0.3668538395160521} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.35021512595807874, 'max_depth': 69, 'num_leaves': 663, 'min_data_in_leaf': 45, 'lambda_l1': 0.1259274864544586, 'lambda_l2': 0.08983664412402137} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2833721174391227, 'max_depth': 67, 'num_leaves': 912, 'min_data_in_leaf': 40, 'lambda_l1': 0.07653088192381254, 'lambda_l2': 0.0026249716454921318} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.39675018462038963, 'max_depth': 65, 'num_leaves': 730, 'min_data_in_leaf': 43, 'lambda_l1': 0.0981198539184892, 'lambda_l2': 0.18250952926306216} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3260656071915578, 'max_depth': 68, 'num_leaves': 651, 'min_data_in_leaf': 36, 'lambda_l1': 0.03378174680469106, 'lambda_l2': 0.4527444475267276} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.46022186130484777, 'max_depth': 63, 'num_leaves': 785, 'min_data_in_leaf': 39, 'lambda_l1': 0.061059028854561326, 'lambda_l2': 0.29460263932061526} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.26155003936195154, 'max_depth': 74, 'num_leaves': 860, 'min_data_in_leaf': 33, 'lambda_l1': 0.021779792251633723, 'lambda_l2': 0.36277484230712664} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2032510778742764, 'max_depth': 71, 'num_leaves': 276, 'min_data_in_leaf': 37, 'lambda_l1': 0.10667580814392003, 'lambda_l2': 0.17735511198717296} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37634537512994515, 'max_depth': 65, 'num_leaves': 1050, 'min_data_in_leaf': 35, 'lambda_l1': 0.07432895341953623, 'lambda_l2': 0.6016883022564281} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.011928468740903713, 'max_depth': 69, 'num_leaves': 745, 'min_data_in_leaf': 41, 'lambda_l1': 4.3958812081405785e-05, 'lambda_l2': 0.08507323349933654} : acc= 50.00%\n",
            "[HPO] metrics with {'learning_rate': 0.001633206936298519, 'max_depth': 46, 'num_leaves': 626, 'min_data_in_leaf': 37, 'lambda_l1': 0.04769277981762011, 'lambda_l2': 0.2939467593597663} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5558869350234401, 'max_depth': 67, 'num_leaves': 1162, 'min_data_in_leaf': 31, 'lambda_l1': 0.22427908639100125, 'lambda_l2': 0.512268121679625} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31708393636792176, 'max_depth': 63, 'num_leaves': 927, 'min_data_in_leaf': 39, 'lambda_l1': 0.08550147979459247, 'lambda_l2': 0.22631833499927606} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.03035120493412856, 'max_depth': 72, 'num_leaves': 166, 'min_data_in_leaf': 34, 'lambda_l1': 0.12403920248128608, 'lambda_l2': 0.4038422480586882} : acc= 61.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4252144489286651, 'max_depth': 65, 'num_leaves': 636, 'min_data_in_leaf': 43, 'lambda_l1': 0.05638247092275637, 'lambda_l2': 0.07701925416108112} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.236524701406913, 'max_depth': 76, 'num_leaves': 791, 'min_data_in_leaf': 38, 'lambda_l1': 0.03230515186838204, 'lambda_l2': 0.28433835915527494} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3707463886219163, 'max_depth': 70, 'num_leaves': 732, 'min_data_in_leaf': 35, 'lambda_l1': 0.018428088155499255, 'lambda_l2': 0.1820783790094633} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28220879651246444, 'max_depth': 67, 'num_leaves': 985, 'min_data_in_leaf': 41, 'lambda_l1': 0.10528887020783227, 'lambda_l2': 0.7489291104885161} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4793106492245601, 'max_depth': 63, 'num_leaves': 860, 'min_data_in_leaf': 32, 'lambda_l1': 0.08063442300508586, 'lambda_l2': 0.3656413194234469} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.33840766221779955, 'max_depth': 44, 'num_leaves': 606, 'min_data_in_leaf': 36, 'lambda_l1': 0.04832337983021632, 'lambda_l2': 0.0014084500573578324} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.38991927614967226, 'max_depth': 68, 'num_leaves': 270, 'min_data_in_leaf': 38, 'lambda_l1': 0.14037686459083037, 'lambda_l2': 0.17575649250562786} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3072581141805567, 'max_depth': 65, 'num_leaves': 721, 'min_data_in_leaf': 34, 'lambda_l1': 0.06426766274011687, 'lambda_l2': 0.482221639794967} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5864125966630979, 'max_depth': 73, 'num_leaves': 808, 'min_data_in_leaf': 69, 'lambda_l1': 0.019234819569499642, 'lambda_l2': 0.2677102302212693} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.489810094815665, 'max_depth': 71, 'num_leaves': 647, 'min_data_in_leaf': 40, 'lambda_l1': 0.09886101339250179, 'lambda_l2': 0.10262913871733693} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.424946800549094, 'max_depth': 63, 'num_leaves': 543, 'min_data_in_leaf': 42, 'lambda_l1': 0.16227206084181747, 'lambda_l2': 0.38559608995455624} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2558306444218903, 'max_depth': 44, 'num_leaves': 899, 'min_data_in_leaf': 36, 'lambda_l1': 0.037800594361508004, 'lambda_l2': 0.22971831488447714} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3356234343665264, 'max_depth': 69, 'num_leaves': 701, 'min_data_in_leaf': 45, 'lambda_l1': 0.06727980722467938, 'lambda_l2': 0.3181083379629207} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.368251303429479, 'max_depth': 66, 'num_leaves': 808, 'min_data_in_leaf': 38, 'lambda_l1': 0.11885941927246305, 'lambda_l2': 0.09724290104265548} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29227510364799214, 'max_depth': 63, 'num_leaves': 585, 'min_data_in_leaf': 32, 'lambda_l1': 0.04616576951358578, 'lambda_l2': 0.6396503942934533} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.22892212797654185, 'max_depth': 67, 'num_leaves': 957, 'min_data_in_leaf': 34, 'lambda_l1': 0.07843154215586742, 'lambda_l2': 0.0016017295775155038} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.41512817855384904, 'max_depth': 74, 'num_leaves': 304, 'min_data_in_leaf': 39, 'lambda_l1': 0.09130414943123308, 'lambda_l2': 0.44704961620184214} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.33689738652965084, 'max_depth': 69, 'num_leaves': 206, 'min_data_in_leaf': 29, 'lambda_l1': 0.01722543376274526, 'lambda_l2': 0.1871079112763153} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.488311509470989, 'max_depth': 46, 'num_leaves': 512, 'min_data_in_leaf': 36, 'lambda_l1': 0.035004794728908266, 'lambda_l2': 0.2919807967190342} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2743523245242528, 'max_depth': 65, 'num_leaves': 670, 'min_data_in_leaf': 42, 'lambda_l1': 0.05480663090763802, 'lambda_l2': 0.1670804841540218} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.614284248356634, 'max_depth': 62, 'num_leaves': 774, 'min_data_in_leaf': 40, 'lambda_l1': 0.10370836889323182, 'lambda_l2': 0.39406686571113453} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3761904284728069, 'max_depth': 71, 'num_leaves': 875, 'min_data_in_leaf': 37, 'lambda_l1': 0.00022204145447938042, 'lambda_l2': 0.5152541985107214} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.43922856504236035, 'max_depth': 66, 'num_leaves': 1046, 'min_data_in_leaf': 31, 'lambda_l1': 0.1899448884028912, 'lambda_l2': 0.25468856272957463} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32577802376716797, 'max_depth': 77, 'num_leaves': 3779, 'min_data_in_leaf': 34, 'lambda_l1': 0.06817658189562828, 'lambda_l2': 0.0003106024518806927} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5315039187937279, 'max_depth': 68, 'num_leaves': 620, 'min_data_in_leaf': 44, 'lambda_l1': 0.1281575146527159, 'lambda_l2': 0.11668632415846325} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.29727694157920476, 'max_depth': 70, 'num_leaves': 751, 'min_data_in_leaf': 38, 'lambda_l1': 0.019746719780829668, 'lambda_l2': 0.3297819182646142} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.37552874099935774, 'max_depth': 62, 'num_leaves': 499, 'min_data_in_leaf': 35, 'lambda_l1': 0.08455682142569712, 'lambda_l2': 0.2277550065573917} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.005561259122197721, 'max_depth': 46, 'num_leaves': 330, 'min_data_in_leaf': 41, 'lambda_l1': 0.041500425513116446, 'lambda_l2': 0.5678221006560777} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.25551385366920826, 'max_depth': 73, 'num_leaves': 859, 'min_data_in_leaf': 37, 'lambda_l1': 0.788278118998548, 'lambda_l2': 0.43078335599979745} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4257839351250908, 'max_depth': 43, 'num_leaves': 412, 'min_data_in_leaf': 33, 'lambda_l1': 0.06059870348654619, 'lambda_l2': 0.10172788026170823} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3328312129219735, 'max_depth': 65, 'num_leaves': 690, 'min_data_in_leaf': 39, 'lambda_l1': 0.03447981054770327, 'lambda_l2': 0.32403157835094054} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.21813396424870085, 'max_depth': 63, 'num_leaves': 572, 'min_data_in_leaf': 47, 'lambda_l1': 0.10885058176898844, 'lambda_l2': 0.1984568856275683} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3609375214220884, 'max_depth': 67, 'num_leaves': 945, 'min_data_in_leaf': 36, 'lambda_l1': 0.08248859458979012, 'lambda_l2': 0.12387902183259024} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29123965485235964, 'max_depth': 71, 'num_leaves': 766, 'min_data_in_leaf': 40, 'lambda_l1': 0.017890506800599417, 'lambda_l2': 0.36480480254626535} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4551111483415961, 'max_depth': 68, 'num_leaves': 674, 'min_data_in_leaf': 33, 'lambda_l1': 0.059539894316747666, 'lambda_l2': 0.2603705154719196} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.39826259732070696, 'max_depth': 65, 'num_leaves': 295, 'min_data_in_leaf': 43, 'lambda_l1': 0.13119786138164138, 'lambda_l2': 0.4774881453438441} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.32365476122816034, 'max_depth': 75, 'num_leaves': 819, 'min_data_in_leaf': 38, 'lambda_l1': 0.09631363959597933, 'lambda_l2': 0.08741362966232274} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5279705982240138, 'max_depth': 47, 'num_leaves': 467, 'min_data_in_leaf': 31, 'lambda_l1': 0.04530801979740415, 'lambda_l2': 0.1837947181284718} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2678577274541764, 'max_depth': 44, 'num_leaves': 590, 'min_data_in_leaf': 35, 'lambda_l1': 0.0726358228940635, 'lambda_l2': 0.3167999231533794} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3675241662311222, 'max_depth': 70, 'num_leaves': 724, 'min_data_in_leaf': 77, 'lambda_l1': 0.1485672079140442, 'lambda_l2': 0.21772636155596023} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4207508720510447, 'max_depth': 62, 'num_leaves': 195, 'min_data_in_leaf': 29, 'lambda_l1': 0.02142337334277521, 'lambda_l2': 0.400967446661047} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6136352072734644, 'max_depth': 64, 'num_leaves': 883, 'min_data_in_leaf': 41, 'lambda_l1': 0.00043778133483932113, 'lambda_l2': 0.5377957255123509} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3082314004899577, 'max_depth': 72, 'num_leaves': 371, 'min_data_in_leaf': 37, 'lambda_l1': 0.054194453873850204, 'lambda_l2': 0.15176758253304923} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.24544535246737514, 'max_depth': 68, 'num_leaves': 514, 'min_data_in_leaf': 35, 'lambda_l1': 0.10961748608289362, 'lambda_l2': 0.0019090023504084478} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4809178964045707, 'max_depth': 67, 'num_leaves': 1010, 'min_data_in_leaf': 39, 'lambda_l1': 0.08177703552897282, 'lambda_l2': 0.26565971406095307} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.35157018981376137, 'max_depth': 65, 'num_leaves': 637, 'min_data_in_leaf': 33, 'lambda_l1': 0.037413087682929, 'lambda_l2': 0.3747258722812058} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2892340506433909, 'max_depth': 62, 'num_leaves': 802, 'min_data_in_leaf': 37, 'lambda_l1': 0.0172359077428827, 'lambda_l2': 0.07615746345716629} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.40476289200984605, 'max_depth': 70, 'num_leaves': 1125, 'min_data_in_leaf': 42, 'lambda_l1': 0.06016540814738099, 'lambda_l2': 0.2760184250206246} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.1795556921931658, 'max_depth': 63, 'num_leaves': 562, 'min_data_in_leaf': 39, 'lambda_l1': 0.12205426032007685, 'lambda_l2': 0.17132402189671947} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.33355335231002065, 'max_depth': 48, 'num_leaves': 249, 'min_data_in_leaf': 35, 'lambda_l1': 0.08937273818218998, 'lambda_l2': 0.4508800723094635} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4518396371657938, 'max_depth': 45, 'num_leaves': 726, 'min_data_in_leaf': 45, 'lambda_l1': 0.03503673002056429, 'lambda_l2': 0.646335633316008} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5357360096962023, 'max_depth': 73, 'num_leaves': 911, 'min_data_in_leaf': 32, 'lambda_l1': 0.07199087075455352, 'lambda_l2': 0.3285801657247587} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3892628411247161, 'max_depth': 67, 'num_leaves': 432, 'min_data_in_leaf': 37, 'lambda_l1': 0.04957695614877901, 'lambda_l2': 0.10728264678035393} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2863209780159372, 'max_depth': 69, 'num_leaves': 825, 'min_data_in_leaf': 41, 'lambda_l1': 0.10762496438463276, 'lambda_l2': 0.24757290229060808} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3400349747326673, 'max_depth': 65, 'num_leaves': 636, 'min_data_in_leaf': 35, 'lambda_l1': 0.019703714685380267, 'lambda_l2': 0.4370825067198968} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6663310517444789, 'max_depth': 80, 'num_leaves': 719, 'min_data_in_leaf': 39, 'lambda_l1': 0.08762507925867717, 'lambda_l2': 0.16968893789580186} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.24384493556705944, 'max_depth': 62, 'num_leaves': 325, 'min_data_in_leaf': 36, 'lambda_l1': 0.1459262374990401, 'lambda_l2': 0.5575142753855862} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.45649956179892637, 'max_depth': 75, 'num_leaves': 509, 'min_data_in_leaf': 44, 'lambda_l1': 0.03279763753361359, 'lambda_l2': 0.3323222685165525} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3068140204178147, 'max_depth': 66, 'num_leaves': 932, 'min_data_in_leaf': 33, 'lambda_l1': 0.05986155732520897, 'lambda_l2': 0.07891238918241313} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3838310701175929, 'max_depth': 70, 'num_leaves': 781, 'min_data_in_leaf': 38, 'lambda_l1': 0.06953746638481162, 'lambda_l2': 0.23709881198307486} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.0031760132929204606, 'max_depth': 64, 'num_leaves': 395, 'min_data_in_leaf': 40, 'lambda_l1': 0.09758973873074636, 'lambda_l2': 0.0016685810552027058} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2059388883608817, 'max_depth': 72, 'num_leaves': 612, 'min_data_in_leaf': 30, 'lambda_l1': 0.04161496675979097, 'lambda_l2': 0.36923139112424136} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.34206988842383895, 'max_depth': 43, 'num_leaves': 691, 'min_data_in_leaf': 50, 'lambda_l1': 0.017237795123345473, 'lambda_l2': 0.18816557525094385} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.007709581912900659, 'max_depth': 62, 'num_leaves': 542, 'min_data_in_leaf': 34, 'lambda_l1': 0.1186610997827381, 'lambda_l2': 0.4682786035186647} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2613926738496653, 'max_depth': 68, 'num_leaves': 849, 'min_data_in_leaf': 37, 'lambda_l1': 0.07785781991520263, 'lambda_l2': 0.29791305777124816} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.02218211773742676, 'max_depth': 47, 'num_leaves': 1014, 'min_data_in_leaf': 42, 'lambda_l1': 0.05317236362473933, 'lambda_l2': 0.0972549649220503} : acc= 57.92%\n",
            "[HPO] metrics with {'learning_rate': 0.41631353371258306, 'max_depth': 66, 'num_leaves': 126, 'min_data_in_leaf': 40, 'lambda_l1': 0.17007573278529836, 'lambda_l2': 0.2353245178707163} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5088506943800335, 'max_depth': 69, 'num_leaves': 444, 'min_data_in_leaf': 36, 'lambda_l1': 0.03767257235501707, 'lambda_l2': 0.3980268334201806} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.31899163091421656, 'max_depth': 64, 'num_leaves': 267, 'min_data_in_leaf': 32, 'lambda_l1': 0.016680666291786446, 'lambda_l2': 0.09952207049322158} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.28561738774160644, 'max_depth': 77, 'num_leaves': 766, 'min_data_in_leaf': 38, 'lambda_l1': 0.09914076762795737, 'lambda_l2': 0.0005212665935351857} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3685819669586157, 'max_depth': 72, 'num_leaves': 655, 'min_data_in_leaf': 43, 'lambda_l1': 0.00047211698176598087, 'lambda_l2': 0.5246346017654653} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.458074944167, 'max_depth': 62, 'num_leaves': 571, 'min_data_in_leaf': 34, 'lambda_l1': 0.0005433163657005621, 'lambda_l2': 0.18880609012407334} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5484293563827456, 'max_depth': 45, 'num_leaves': 846, 'min_data_in_leaf': 28, 'lambda_l1': 0.06547473335386153, 'lambda_l2': 0.2805139765783954} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3881649413282206, 'max_depth': 66, 'num_leaves': 364, 'min_data_in_leaf': 36, 'lambda_l1': 0.12507033601676884, 'lambda_l2': 0.3649455289496194} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3266244674143795, 'max_depth': 48, 'num_leaves': 495, 'min_data_in_leaf': 39, 'lambda_l1': 0.08143285655500607, 'lambda_l2': 0.16875387087601323} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.26392309406920583, 'max_depth': 42, 'num_leaves': 959, 'min_data_in_leaf': 41, 'lambda_l1': 0.033856076355300295, 'lambda_l2': 0.31095762029149243} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.42421666688602283, 'max_depth': 69, 'num_leaves': 714, 'min_data_in_leaf': 31, 'lambda_l1': 0.05618290617929195, 'lambda_l2': 0.7537275236480047} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3561604464041945, 'max_depth': 64, 'num_leaves': 624, 'min_data_in_leaf': 83, 'lambda_l1': 0.6607578368382393, 'lambda_l2': 0.4852981193274917} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.07110904029183222, 'max_depth': 74, 'num_leaves': 794, 'min_data_in_leaf': 57, 'lambda_l1': 0.9400112784251398, 'lambda_l2': 0.1676697333341398} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29110060681955957, 'max_depth': 67, 'num_leaves': 907, 'min_data_in_leaf': 35, 'lambda_l1': 0.14126264895739502, 'lambda_l2': 0.2594922883174017} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.22129265720679941, 'max_depth': 71, 'num_leaves': 412, 'min_data_in_leaf': 38, 'lambda_l1': 0.0978641540414473, 'lambda_l2': 0.08197015493054421} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4824050692109992, 'max_depth': 68, 'num_leaves': 712, 'min_data_in_leaf': 33, 'lambda_l1': 0.03408807880725795, 'lambda_l2': 0.4329300040420441} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3784732406683445, 'max_depth': 46, 'num_leaves': 1087, 'min_data_in_leaf': 47, 'lambda_l1': 0.08026295532246398, 'lambda_l2': 0.642309409312013} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.31811306504910075, 'max_depth': 62, 'num_leaves': 207, 'min_data_in_leaf': 37, 'lambda_l1': 0.05261942705261351, 'lambda_l2': 0.34433075772313515} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6352205941602286, 'max_depth': 65, 'num_leaves': 300, 'min_data_in_leaf': 40, 'lambda_l1': 0.1033454692754589, 'lambda_l2': 0.23134542225425336} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.42036467231997043, 'max_depth': 70, 'num_leaves': 556, 'min_data_in_leaf': 43, 'lambda_l1': 0.019246337098985548, 'lambda_l2': 0.10310267866154542} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24175115470175176, 'max_depth': 62, 'num_leaves': 773, 'min_data_in_leaf': 35, 'lambda_l1': 0.06851249683423628, 'lambda_l2': 1.3159303742849016e-05} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35307442762008423, 'max_depth': 67, 'num_leaves': 467, 'min_data_in_leaf': 38, 'lambda_l1': 0.12204401875521473, 'lambda_l2': 0.38720379955418116} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2935468577002688, 'max_depth': 73, 'num_leaves': 669, 'min_data_in_leaf': 33, 'lambda_l1': 0.043237365444984945, 'lambda_l2': 0.16823484241707665} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.49469182938470535, 'max_depth': 64, 'num_leaves': 866, 'min_data_in_leaf': 36, 'lambda_l1': 0.020588318576735706, 'lambda_l2': 0.2864068598603896} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.40360626729661053, 'max_depth': 48, 'num_leaves': 583, 'min_data_in_leaf': 41, 'lambda_l1': 0.08565309618629652, 'lambda_l2': 0.5099580871532555} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.598935224879241, 'max_depth': 43, 'num_leaves': 347, 'min_data_in_leaf': 39, 'lambda_l1': 0.06423130787635524, 'lambda_l2': 0.0976175400488225} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.32728842775520417, 'max_depth': 70, 'num_leaves': 822, 'min_data_in_leaf': 34, 'lambda_l1': 0.10689604122101062, 'lambda_l2': 0.256602072435986} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2679522197983309, 'max_depth': 67, 'num_leaves': 736, 'min_data_in_leaf': 37, 'lambda_l1': 0.04350964329282528, 'lambda_l2': 0.3857619526058339} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.43621481018260594, 'max_depth': 62, 'num_leaves': 973, 'min_data_in_leaf': 45, 'lambda_l1': 0.0011181948253399907, 'lambda_l2': 0.17248690490824478} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.35108944730285696, 'max_depth': 65, 'num_leaves': 487, 'min_data_in_leaf': 31, 'lambda_l1': 0.15697676163292149, 'lambda_l2': 0.5637330785475414} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5397780899509229, 'max_depth': 76, 'num_leaves': 656, 'min_data_in_leaf': 41, 'lambda_l1': 0.0817832985617585, 'lambda_l2': 0.3123581122371196} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.31499785277385167, 'max_depth': 45, 'num_leaves': 144, 'min_data_in_leaf': 36, 'lambda_l1': 0.03233274040936498, 'lambda_l2': 0.08773045042992433} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.37690403668656036, 'max_depth': 72, 'num_leaves': 858, 'min_data_in_leaf': 39, 'lambda_l1': 0.05301999953914959, 'lambda_l2': 0.22140575547517372} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2688289660928627, 'max_depth': 68, 'num_leaves': 584, 'min_data_in_leaf': 34, 'lambda_l1': 0.13181782427057515, 'lambda_l2': 0.45298760162541063} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4843569906848919, 'max_depth': 49, 'num_leaves': 377, 'min_data_in_leaf': 43, 'lambda_l1': 0.018463772549060082, 'lambda_l2': 0.3100116225294744} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2261287652169838, 'max_depth': 62, 'num_leaves': 243, 'min_data_in_leaf': 38, 'lambda_l1': 0.06852848698587298, 'lambda_l2': 0.1629074835961818} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4061153050863977, 'max_depth': 66, 'num_leaves': 774, 'min_data_in_leaf': 36, 'lambda_l1': 0.1084842077232591, 'lambda_l2': 0.38834506401810315} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3084567542181941, 'max_depth': 64, 'num_leaves': 448, 'min_data_in_leaf': 32, 'lambda_l1': 0.09158740860109602, 'lambda_l2': 0.2604755311340672} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3555356002974314, 'max_depth': 70, 'num_leaves': 674, 'min_data_in_leaf': 29, 'lambda_l1': 0.050975171511937714, 'lambda_l2': 0.09274955899327852} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4468873982023274, 'max_depth': 69, 'num_leaves': 942, 'min_data_in_leaf': 40, 'lambda_l1': 0.03393516621850289, 'lambda_l2': 0.4323649139030884} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.29039529556715404, 'max_depth': 74, 'num_leaves': 1180, 'min_data_in_leaf': 35, 'lambda_l1': 0.07074381616736405, 'lambda_l2': 0.19318134030583553} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3619422249712842, 'max_depth': 47, 'num_leaves': 512, 'min_data_in_leaf': 38, 'lambda_l1': 0.020088905872553648, 'lambda_l2': 0.6052058595313698} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.25404501954673053, 'max_depth': 66, 'num_leaves': 723, 'min_data_in_leaf': 6, 'lambda_l1': 0.0006224251967411939, 'lambda_l2': 0.0026732367532834034} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4163349089706253, 'max_depth': 62, 'num_leaves': 849, 'min_data_in_leaf': 42, 'lambda_l1': 0.11607641210743624, 'lambda_l2': 0.31791814845524474} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5707168856476758, 'max_depth': 71, 'num_leaves': 606, 'min_data_in_leaf': 33, 'lambda_l1': 0.08880635765426358, 'lambda_l2': 0.1417698169547137} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.32387415919314494, 'max_depth': 64, 'num_leaves': 780, 'min_data_in_leaf': 37, 'lambda_l1': 0.05489211389984973, 'lambda_l2': 0.23814821572272432} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.46475912291049876, 'max_depth': 63, 'num_leaves': 882, 'min_data_in_leaf': 34, 'lambda_l1': 0.03153118434580789, 'lambda_l2': 0.4750381306002125} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3742249710548534, 'max_depth': 61, 'num_leaves': 801, 'min_data_in_leaf': 31, 'lambda_l1': 0.0002209018529910553, 'lambda_l2': 0.3907916930962789} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.32772634151432606, 'max_depth': 61, 'num_leaves': 900, 'min_data_in_leaf': 35, 'lambda_l1': 0.04412037571995066, 'lambda_l2': 0.5187981543565057} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5072076791210344, 'max_depth': 43, 'num_leaves': 1005, 'min_data_in_leaf': 63, 'lambda_l1': 0.023253314016352427, 'lambda_l2': 0.37872481785014983} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4134415867453206, 'max_depth': 63, 'num_leaves': 838, 'min_data_in_leaf': 36, 'lambda_l1': 0.05010334099831691, 'lambda_l2': 0.3448436439424618} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2924529059021207, 'max_depth': 46, 'num_leaves': 816, 'min_data_in_leaf': 32, 'lambda_l1': 0.032613998954481443, 'lambda_l2': 0.4469839342391463} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3513421424645858, 'max_depth': 64, 'num_leaves': 928, 'min_data_in_leaf': 34, 'lambda_l1': 0.04585777374308073, 'lambda_l2': 0.30942248459430743} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6585747918050179, 'max_depth': 49, 'num_leaves': 773, 'min_data_in_leaf': 36, 'lambda_l1': 0.05921521224342171, 'lambda_l2': 0.2600163650901141} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.444629363574208, 'max_depth': 68, 'num_leaves': 775, 'min_data_in_leaf': 37, 'lambda_l1': 0.02362788357703531, 'lambda_l2': 0.6755150374797322} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3799021839874086, 'max_depth': 61, 'num_leaves': 1005, 'min_data_in_leaf': 30, 'lambda_l1': 0.01707563097001285, 'lambda_l2': 0.5575408129163213} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.32526120343443793, 'max_depth': 72, 'num_leaves': 920, 'min_data_in_leaf': 33, 'lambda_l1': 0.0563082498905696, 'lambda_l2': 0.4401256722526682} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.18439957227530185, 'max_depth': 73, 'num_leaves': 1095, 'min_data_in_leaf': 28, 'lambda_l1': 0.047607575049815554, 'lambda_l2': 0.2636625254990713} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.22952610695240871, 'max_depth': 78, 'num_leaves': 914, 'min_data_in_leaf': 31, 'lambda_l1': 0.03570979537545938, 'lambda_l2': 0.3707638680995772} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27511213373614385, 'max_depth': 75, 'num_leaves': 977, 'min_data_in_leaf': 31, 'lambda_l1': 0.05240573883415982, 'lambda_l2': 0.25709142177044947} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2482826726112377, 'max_depth': 75, 'num_leaves': 1089, 'min_data_in_leaf': 30, 'lambda_l1': 0.03372943281933965, 'lambda_l2': 0.4064663420409593} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2800169530739632, 'max_depth': 78, 'num_leaves': 1058, 'min_data_in_leaf': 29, 'lambda_l1': 0.06300139605023101, 'lambda_l2': 0.49543557160078544} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2020117996458852, 'max_depth': 73, 'num_leaves': 959, 'min_data_in_leaf': 33, 'lambda_l1': 0.019238145047867656, 'lambda_l2': 0.318279510440021} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2510977132242075, 'max_depth': 75, 'num_leaves': 1044, 'min_data_in_leaf': 28, 'lambda_l1': 0.053609319450706405, 'lambda_l2': 0.212620262449821} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29127843953382954, 'max_depth': 72, 'num_leaves': 926, 'min_data_in_leaf': 31, 'lambda_l1': 0.03498535966000563, 'lambda_l2': 0.33206219488448496} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3091766434130912, 'max_depth': 76, 'num_leaves': 959, 'min_data_in_leaf': 32, 'lambda_l1': 0.014711600489685082, 'lambda_l2': 0.2143878377191426} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3081206283919654, 'max_depth': 73, 'num_leaves': 1024, 'min_data_in_leaf': 33, 'lambda_l1': 0.062477250415403134, 'lambda_l2': 0.4319235555303682} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.22721533924771004, 'max_depth': 71, 'num_leaves': 914, 'min_data_in_leaf': 33, 'lambda_l1': 0.04409950954974473, 'lambda_l2': 0.6032548197249651} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.26542491127413015, 'max_depth': 73, 'num_leaves': 872, 'min_data_in_leaf': 29, 'lambda_l1': 0.016316846185431444, 'lambda_l2': 0.20043489637895873} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33360898242304793, 'max_depth': 71, 'num_leaves': 859, 'min_data_in_leaf': 33, 'lambda_l1': 0.057075975046251316, 'lambda_l2': 0.3448949055711332} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.323143888939506, 'max_depth': 74, 'num_leaves': 1124, 'min_data_in_leaf': 34, 'lambda_l1': 0.06811362326932421, 'lambda_l2': 0.2616583309704718} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2674126748209157, 'max_depth': 77, 'num_leaves': 838, 'min_data_in_leaf': 31, 'lambda_l1': 0.03173794709071723, 'lambda_l2': 0.4482704815855413} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3071582453004478, 'max_depth': 70, 'num_leaves': 1207, 'min_data_in_leaf': 34, 'lambda_l1': 0.03689868915629045, 'lambda_l2': 0.5284450482466851} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.34248695514526584, 'max_depth': 71, 'num_leaves': 953, 'min_data_in_leaf': 32, 'lambda_l1': 0.016379441503307716, 'lambda_l2': 0.14635638800004186} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2321454165333767, 'max_depth': 74, 'num_leaves': 852, 'min_data_in_leaf': 35, 'lambda_l1': 0.06862091758245645, 'lambda_l2': 0.31889781395549316} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28351471171031795, 'max_depth': 72, 'num_leaves': 1022, 'min_data_in_leaf': 28, 'lambda_l1': 0.0469070656640808, 'lambda_l2': 0.1860856682454066} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.34507127449627417, 'max_depth': 70, 'num_leaves': 799, 'min_data_in_leaf': 35, 'lambda_l1': 0.06840847908993561, 'lambda_l2': 0.400643978286557} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.0023274356729266234, 'max_depth': 69, 'num_leaves': 899, 'min_data_in_leaf': 30, 'lambda_l1': 0.01798599403409811, 'lambda_l2': 0.2545742143237648} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2633587054480875, 'max_depth': 72, 'num_leaves': 976, 'min_data_in_leaf': 33, 'lambda_l1': 0.0007917252839158978, 'lambda_l2': 0.08766252094998402} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3235046144579932, 'max_depth': 68, 'num_leaves': 780, 'min_data_in_leaf': 35, 'lambda_l1': 0.04709824228100953, 'lambda_l2': 0.22455045651410052} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.35916637496944553, 'max_depth': 70, 'num_leaves': 874, 'min_data_in_leaf': 34, 'lambda_l1': 0.7483961707023323, 'lambda_l2': 0.34477172569189174} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3140844940938939, 'max_depth': 75, 'num_leaves': 730, 'min_data_in_leaf': 36, 'lambda_l1': 0.03552479001492429, 'lambda_l2': 0.15530815434158} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.28606793342415426, 'max_depth': 79, 'num_leaves': 802, 'min_data_in_leaf': 32, 'lambda_l1': 0.07242679784075874, 'lambda_l2': 0.4799882832228653} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.38069604930414674, 'max_depth': 72, 'num_leaves': 1077, 'min_data_in_leaf': 35, 'lambda_l1': 0.03545163347620244, 'lambda_l2': 0.3100641093997969} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.08643658217415126, 'max_depth': 68, 'num_leaves': 744, 'min_data_in_leaf': 32, 'lambda_l1': 0.061934029017053804, 'lambda_l2': 0.713501180022128} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.1538599096034466, 'max_depth': 69, 'num_leaves': 930, 'min_data_in_leaf': 36, 'lambda_l1': 0.000550949381337637, 'lambda_l2': 0.0862967321029337} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.23672518740265014, 'max_depth': 74, 'num_leaves': 839, 'min_data_in_leaf': 30, 'lambda_l1': 0.00033712521220191985, 'lambda_l2': 0.5641020225776794} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20637703866758478, 'max_depth': 76, 'num_leaves': 739, 'min_data_in_leaf': 34, 'lambda_l1': 0.05238011353378728, 'lambda_l2': 0.39967433935078844} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.356365158296949, 'max_depth': 71, 'num_leaves': 898, 'min_data_in_leaf': 60, 'lambda_l1': 0.07317146491139498, 'lambda_l2': 0.2566215817267513} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2972287359183676, 'max_depth': 67, 'num_leaves': 1030, 'min_data_in_leaf': 37, 'lambda_l1': 0.029746895102995937, 'lambda_l2': 0.15345653551692245} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3850723925145279, 'max_depth': 41, 'num_leaves': 813, 'min_data_in_leaf': 33, 'lambda_l1': 0.05144243136634351, 'lambda_l2': 0.30759501406310125} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.26094515143982744, 'max_depth': 69, 'num_leaves': 737, 'min_data_in_leaf': 36, 'lambda_l1': 0.8632069463013203, 'lambda_l2': 0.186520644512336} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3288990204045358, 'max_depth': 73, 'num_leaves': 968, 'min_data_in_leaf': 37, 'lambda_l1': 0.017605439130963147, 'lambda_l2': 0.42274015744048044} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.23194087057165966, 'max_depth': 77, 'num_leaves': 1161, 'min_data_in_leaf': 34, 'lambda_l1': 0.016509510915526944, 'lambda_l2': 0.5427657376065518} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.25651402256614636, 'max_depth': 75, 'num_leaves': 1036, 'min_data_in_leaf': 32, 'lambda_l1': 0.013357333131591643, 'lambda_l2': 0.0830226918794859} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2835956558110908, 'max_depth': 73, 'num_leaves': 928, 'min_data_in_leaf': 87, 'lambda_l1': 0.016898047229885697, 'lambda_l2': 0.4011546512347266} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2986148028672773, 'max_depth': 75, 'num_leaves': 1103, 'min_data_in_leaf': 35, 'lambda_l1': 0.016913741182266323, 'lambda_l2': 0.24937550489790494} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.20277728806692907, 'max_depth': 76, 'num_leaves': 1012, 'min_data_in_leaf': 30, 'lambda_l1': 0.02729700039221386, 'lambda_l2': 0.4702651266977156} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2527795810651368, 'max_depth': 72, 'num_leaves': 1099, 'min_data_in_leaf': 33, 'lambda_l1': 0.001996076515386358, 'lambda_l2': 0.07865588509032673} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.31605612176876463, 'max_depth': 81, 'num_leaves': 1015, 'min_data_in_leaf': 36, 'lambda_l1': 0.00014066599332727622, 'lambda_l2': 0.3477895589093378} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.28540573189776314, 'max_depth': 78, 'num_leaves': 980, 'min_data_in_leaf': 34, 'lambda_l1': 0.029290417079366672, 'lambda_l2': 0.6312435037339853} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3289481370944868, 'max_depth': 74, 'num_leaves': 976, 'min_data_in_leaf': 37, 'lambda_l1': 0.019794712877246323, 'lambda_l2': 0.8088667096349531} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.23190395001448927, 'max_depth': 73, 'num_leaves': 1056, 'min_data_in_leaf': 32, 'lambda_l1': 0.0005546598584366194, 'lambda_l2': 0.17847692169913243} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32574470066393374, 'max_depth': 76, 'num_leaves': 1157, 'min_data_in_leaf': 35, 'lambda_l1': 0.03319659266345629, 'lambda_l2': 0.2534630115575782} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2688788669754269, 'max_depth': 73, 'num_leaves': 1002, 'min_data_in_leaf': 37, 'lambda_l1': 0.036487630408127275, 'lambda_l2': 0.4594581025141597} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.32752026459376243, 'max_depth': 71, 'num_leaves': 933, 'min_data_in_leaf': 31, 'lambda_l1': 0.022177800620151976, 'lambda_l2': 0.33021750950493195} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.28239124548297, 'max_depth': 72, 'num_leaves': 897, 'min_data_in_leaf': 35, 'lambda_l1': 0.03694664966779257, 'lambda_l2': 0.0025457210144960163} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.36012402605343097, 'max_depth': 78, 'num_leaves': 960, 'min_data_in_leaf': 33, 'lambda_l1': 0.00046079920677248934, 'lambda_l2': 0.15967790559884587} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.30350318302502544, 'max_depth': 73, 'num_leaves': 865, 'min_data_in_leaf': 37, 'lambda_l1': 0.04101581912285473, 'lambda_l2': 1.6250014562457782e-05} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20798327814343223, 'max_depth': 75, 'num_leaves': 1071, 'min_data_in_leaf': 28, 'lambda_l1': 0.021936263756483176, 'lambda_l2': 0.24261035269751463} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3610026078998887, 'max_depth': 71, 'num_leaves': 956, 'min_data_in_leaf': 35, 'lambda_l1': 0.04826209295787019, 'lambda_l2': 0.39111114536963687} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.25274521044529347, 'max_depth': 76, 'num_leaves': 870, 'min_data_in_leaf': 37, 'lambda_l1': 0.021802744939053077, 'lambda_l2': 0.14747963373706116} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3189603427664951, 'max_depth': 70, 'num_leaves': 900, 'min_data_in_leaf': 34, 'lambda_l1': 0.0451669317354431, 'lambda_l2': 0.28666917031524425} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.33275128899104656, 'max_depth': 70, 'num_leaves': 1019, 'min_data_in_leaf': 30, 'lambda_l1': 0.0006029267908199722, 'lambda_l2': 0.5434964386985648} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3861839777515971, 'max_depth': 72, 'num_leaves': 1162, 'min_data_in_leaf': 31, 'lambda_l1': 0.021602605706315267, 'lambda_l2': 0.4698686933960109} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.010146999958203251, 'max_depth': 71, 'num_leaves': 1048, 'min_data_in_leaf': 33, 'lambda_l1': 0.03907672820658632, 'lambda_l2': 0.3999838185742878} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3062648815377393, 'max_depth': 73, 'num_leaves': 973, 'min_data_in_leaf': 32, 'lambda_l1': 0.01867431457138309, 'lambda_l2': 0.6502248685605015} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3445203187482305, 'max_depth': 70, 'num_leaves': 965, 'min_data_in_leaf': 30, 'lambda_l1': 0.03446248031200397, 'lambda_l2': 0.4891251720417058} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.25038285600319193, 'max_depth': 69, 'num_leaves': 1035, 'min_data_in_leaf': 34, 'lambda_l1': 0.044647024860403374, 'lambda_l2': 0.3481061156364917} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.28233996164393727, 'max_depth': 74, 'num_leaves': 1122, 'min_data_in_leaf': 37, 'lambda_l1': 0.026400944286580408, 'lambda_l2': 0.34613632017968043} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.41463423370826985, 'max_depth': 71, 'num_leaves': 920, 'min_data_in_leaf': 28, 'lambda_l1': 0.01627296991069562, 'lambda_l2': 0.41181877837340686} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.351729914349098, 'max_depth': 74, 'num_leaves': 919, 'min_data_in_leaf': 34, 'lambda_l1': 0.04789188714082844, 'lambda_l2': 0.5312108991697031} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3136325565360245, 'max_depth': 69, 'num_leaves': 1104, 'min_data_in_leaf': 36, 'lambda_l1': 0.049802605228989494, 'lambda_l2': 0.29702704983961303} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2275169072863659, 'max_depth': 69, 'num_leaves': 1194, 'min_data_in_leaf': 32, 'lambda_l1': 0.053382918731431285, 'lambda_l2': 0.4506982927433214} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2563459370116177, 'max_depth': 68, 'num_leaves': 1266, 'min_data_in_leaf': 33, 'lambda_l1': 0.05606041293218138, 'lambda_l2': 0.30620140304715787} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2871162552976391, 'max_depth': 68, 'num_leaves': 1120, 'min_data_in_leaf': 35, 'lambda_l1': 0.01672752845153304, 'lambda_l2': 0.3734976775995319} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22578894376062306, 'max_depth': 69, 'num_leaves': 1175, 'min_data_in_leaf': 30, 'lambda_l1': 0.03399171573235561, 'lambda_l2': 0.6069889745319592} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.06106942921280622, 'max_depth': 68, 'num_leaves': 1119, 'min_data_in_leaf': 35, 'lambda_l1': 0.0010515227798746918, 'lambda_l2': 0.29816853680293043} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.1768186926876031, 'max_depth': 70, 'num_leaves': 1159, 'min_data_in_leaf': 32, 'lambda_l1': 0.05491992247975451, 'lambda_l2': 0.4193046503745319} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3060694523380441, 'max_depth': 67, 'num_leaves': 1048, 'min_data_in_leaf': 37, 'lambda_l1': 0.6252582078234433, 'lambda_l2': 0.506808997953868} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.25637442685469575, 'max_depth': 67, 'num_leaves': 1198, 'min_data_in_leaf': 28, 'lambda_l1': 0.040783624628769215, 'lambda_l2': 0.3185975369862079} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3116980275568524, 'max_depth': 69, 'num_leaves': 1129, 'min_data_in_leaf': 34, 'lambda_l1': 0.05970205484122582, 'lambda_l2': 0.27993123468811043} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3830891579891226, 'max_depth': 70, 'num_leaves': 1236, 'min_data_in_leaf': 36, 'lambda_l1': 0.020841001876597712, 'lambda_l2': 0.41284576672324397} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2669173068801759, 'max_depth': 67, 'num_leaves': 1220, 'min_data_in_leaf': 35, 'lambda_l1': 0.03210818887737308, 'lambda_l2': 0.5816309270372195} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3341877595014133, 'max_depth': 70, 'num_leaves': 1064, 'min_data_in_leaf': 32, 'lambda_l1': 0.06505631314058427, 'lambda_l2': 0.26937699871527315} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4032412708865755, 'max_depth': 67, 'num_leaves': 992, 'min_data_in_leaf': 37, 'lambda_l1': 0.04362902507889351, 'lambda_l2': 0.35395908938022513} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2947131608766295, 'max_depth': 71, 'num_leaves': 1077, 'min_data_in_leaf': 33, 'lambda_l1': 0.01899132374193867, 'lambda_l2': 0.7134264406065421} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.001380831285285404, 'max_depth': 71, 'num_leaves': 1095, 'min_data_in_leaf': 31, 'lambda_l1': 0.021871344877027316, 'lambda_l2': 1.3393927116712245} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3001615114125483, 'max_depth': 71, 'num_leaves': 1157, 'min_data_in_leaf': 28, 'lambda_l1': 0.0016366390128203616, 'lambda_l2': 0.729501550964446} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.24217989007049895, 'max_depth': 72, 'num_leaves': 1239, 'min_data_in_leaf': 32, 'lambda_l1': 0.017219197265602226, 'lambda_l2': 0.5804634899040488} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2189514119175082, 'max_depth': 69, 'num_leaves': 1116, 'min_data_in_leaf': 30, 'lambda_l1': 0.016092840865230506, 'lambda_l2': 0.5628426450630097} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2837567663524615, 'max_depth': 72, 'num_leaves': 1055, 'min_data_in_leaf': 30, 'lambda_l1': 0.0017734143358509244, 'lambda_l2': 0.81455553802947} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3490081521072769, 'max_depth': 70, 'num_leaves': 1099, 'min_data_in_leaf': 33, 'lambda_l1': 0.013615573159050324, 'lambda_l2': 0.5837544061945956} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.1941676920021505, 'max_depth': 69, 'num_leaves': 1108, 'min_data_in_leaf': 29, 'lambda_l1': 0.015302893182113891, 'lambda_l2': 0.4722077804647519} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2777706902687734, 'max_depth': 71, 'num_leaves': 1223, 'min_data_in_leaf': 31, 'lambda_l1': 0.02003010207074442, 'lambda_l2': 0.513054407936318} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4299455078944103, 'max_depth': 72, 'num_leaves': 1074, 'min_data_in_leaf': 33, 'lambda_l1': 0.032762636898973296, 'lambda_l2': 0.6776316408931026} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.360553120855625, 'max_depth': 68, 'num_leaves': 1035, 'min_data_in_leaf': 27, 'lambda_l1': 0.0005696970811179397, 'lambda_l2': 0.6264711291764706} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31495387985765655, 'max_depth': 70, 'num_leaves': 1220, 'min_data_in_leaf': 34, 'lambda_l1': 0.8881882637774418, 'lambda_l2': 0.4986096359270351} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2576790970027304, 'max_depth': 67, 'num_leaves': 1280, 'min_data_in_leaf': 30, 'lambda_l1': 0.030852428660599004, 'lambda_l2': 0.717592665041891} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6813185212470744, 'max_depth': 69, 'num_leaves': 1025, 'min_data_in_leaf': 33, 'lambda_l1': 0.014497006528924154, 'lambda_l2': 0.8822778641625683} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4040800539333727, 'max_depth': 72, 'num_leaves': 1121, 'min_data_in_leaf': 36, 'lambda_l1': 0.03170383952405563, 'lambda_l2': 0.7465018860427708} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3177662325870808, 'max_depth': 66, 'num_leaves': 1076, 'min_data_in_leaf': 34, 'lambda_l1': 0.03920729012222982, 'lambda_l2': 0.681848955432598} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.36623264985448983, 'max_depth': 71, 'num_leaves': 996, 'min_data_in_leaf': 38, 'lambda_l1': 0.03197769928093236, 'lambda_l2': 0.835131220558735} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.48113783397564536, 'max_depth': 68, 'num_leaves': 1167, 'min_data_in_leaf': 31, 'lambda_l1': 0.01885586321057235, 'lambda_l2': 0.45221802487156415} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.22286655078423068, 'max_depth': 66, 'num_leaves': 1317, 'min_data_in_leaf': 36, 'lambda_l1': 0.0001905754263425881, 'lambda_l2': 0.4386261926738393} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.282556187076562, 'max_depth': 73, 'num_leaves': 1017, 'min_data_in_leaf': 73, 'lambda_l1': 0.04459121362511297, 'lambda_l2': 0.5180348563541961} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.01395269458097044, 'max_depth': 69, 'num_leaves': 1305, 'min_data_in_leaf': 33, 'lambda_l1': 0.001607618876554251, 'lambda_l2': 0.40568154108188637} : acc= 51.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3413886721448115, 'max_depth': 70, 'num_leaves': 1173, 'min_data_in_leaf': 38, 'lambda_l1': 0.03296966485689951, 'lambda_l2': 0.368340537993348} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4380229441206184, 'max_depth': 66, 'num_leaves': 1002, 'min_data_in_leaf': 27, 'lambda_l1': 0.01564814618497292, 'lambda_l2': 0.4331108941661813} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5632091647210891, 'max_depth': 73, 'num_leaves': 1051, 'min_data_in_leaf': 35, 'lambda_l1': 0.048602470603383206, 'lambda_l2': 0.5405056658537857} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.38454784316912405, 'max_depth': 68, 'num_leaves': 1098, 'min_data_in_leaf': 38, 'lambda_l1': 0.04877993707900998, 'lambda_l2': 0.3441547791803641} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29016910390991785, 'max_depth': 71, 'num_leaves': 958, 'min_data_in_leaf': 29, 'lambda_l1': 0.030483163825665606, 'lambda_l2': 0.6117563280106184} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32543665585570375, 'max_depth': 67, 'num_leaves': 1181, 'min_data_in_leaf': 35, 'lambda_l1': 0.013821170652205679, 'lambda_l2': 0.34092646450239716} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.049664028015746035, 'max_depth': 73, 'num_leaves': 987, 'min_data_in_leaf': 32, 'lambda_l1': 0.0011802722717579456, 'lambda_l2': 0.4638725732096072} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.24488488876984185, 'max_depth': 69, 'num_leaves': 1086, 'min_data_in_leaf': 37, 'lambda_l1': 0.05310146419401351, 'lambda_l2': 0.2886163943069143} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.45257582492251736, 'max_depth': 71, 'num_leaves': 986, 'min_data_in_leaf': 34, 'lambda_l1': 0.034978638619043746, 'lambda_l2': 0.38956642397127894} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.04158201747582057, 'max_depth': 66, 'num_leaves': 958, 'min_data_in_leaf': 36, 'lambda_l1': 0.061317020592663224, 'lambda_l2': 0.6404392614474417} : acc= 61.67%\n",
            "[HPO] metrics with {'learning_rate': 0.13411134877643943, 'max_depth': 68, 'num_leaves': 1133, 'min_data_in_leaf': 32, 'lambda_l1': 0.018929288915114573, 'lambda_l2': 0.24666792018337813} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3778018086079556, 'max_depth': 66, 'num_leaves': 1057, 'min_data_in_leaf': 38, 'lambda_l1': 0.04617238579242457, 'lambda_l2': 0.33772775913929387} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3109585849729782, 'max_depth': 70, 'num_leaves': 960, 'min_data_in_leaf': 34, 'lambda_l1': 0.019647236841125168, 'lambda_l2': 0.4430242754212348} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2016530374632907, 'max_depth': 74, 'num_leaves': 925, 'min_data_in_leaf': 36, 'lambda_l1': 0.0013126180336736348, 'lambda_l2': 0.49757325879013875} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5189186701483606, 'max_depth': 72, 'num_leaves': 1239, 'min_data_in_leaf': 31, 'lambda_l1': 1.4981462628183007e-05, 'lambda_l2': 0.2811746498377925} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2681570390489357, 'max_depth': 66, 'num_leaves': 1040, 'min_data_in_leaf': 93, 'lambda_l1': 0.036288707119498415, 'lambda_l2': 0.2497738923200207} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3894192921646684, 'max_depth': 69, 'num_leaves': 913, 'min_data_in_leaf': 38, 'lambda_l1': 0.06364712127291307, 'lambda_l2': 0.3738882497542082} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3443623515484082, 'max_depth': 68, 'num_leaves': 1005, 'min_data_in_leaf': 34, 'lambda_l1': 0.05143629361685339, 'lambda_l2': 0.549749390224668} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.44519363433006615, 'max_depth': 72, 'num_leaves': 908, 'min_data_in_leaf': 38, 'lambda_l1': 0.031103680780559702, 'lambda_l2': 0.2805093445619027} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3094543555634078, 'max_depth': 65, 'num_leaves': 1172, 'min_data_in_leaf': 36, 'lambda_l1': 0.06875297818175324, 'lambda_l2': 0.4054628997637599} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.41099387796069614, 'max_depth': 70, 'num_leaves': 1079, 'min_data_in_leaf': 33, 'lambda_l1': 0.03138585596144812, 'lambda_l2': 0.23749109423643766} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24673372446469238, 'max_depth': 74, 'num_leaves': 936, 'min_data_in_leaf': 29, 'lambda_l1': 0.04744762221834446, 'lambda_l2': 0.368470575728733} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3501503586742133, 'max_depth': 67, 'num_leaves': 986, 'min_data_in_leaf': 38, 'lambda_l1': 0.06847519571795377, 'lambda_l2': 0.4890049346410308} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5876115596700581, 'max_depth': 71, 'num_leaves': 912, 'min_data_in_leaf': 36, 'lambda_l1': 0.01930760164671638, 'lambda_l2': 0.71698916820878} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2827959144421296, 'max_depth': 65, 'num_leaves': 899, 'min_data_in_leaf': 32, 'lambda_l1': 0.000729772029548735, 'lambda_l2': 0.23419915323950083} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5028107632529148, 'max_depth': 69, 'num_leaves': 1079, 'min_data_in_leaf': 35, 'lambda_l1': 0.05377452619558262, 'lambda_l2': 0.32978358607962077} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.7423513959532534, 'max_depth': 67, 'num_leaves': 887, 'min_data_in_leaf': 39, 'lambda_l1': 0.03366534628331913, 'lambda_l2': 0.23735801933868453} : acc= 62.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3569279518644986, 'max_depth': 72, 'num_leaves': 995, 'min_data_in_leaf': 34, 'lambda_l1': 0.0749805941767664, 'lambda_l2': 0.58360643555878} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4202097030309165, 'max_depth': 69, 'num_leaves': 870, 'min_data_in_leaf': 37, 'lambda_l1': 0.017531449836218328, 'lambda_l2': 0.42793878468408864} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3024934823268135, 'max_depth': 65, 'num_leaves': 1005, 'min_data_in_leaf': 31, 'lambda_l1': 0.04735881661719446, 'lambda_l2': 0.2913237756132815} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2620368378208623, 'max_depth': 74, 'num_leaves': 1276, 'min_data_in_leaf': 39, 'lambda_l1': 0.00030900977225105375, 'lambda_l2': 2.9170495388191} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.34240587672115663, 'max_depth': 67, 'num_leaves': 1171, 'min_data_in_leaf': 36, 'lambda_l1': 0.07430465989091818, 'lambda_l2': 0.3445993620643491} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.46278889640130766, 'max_depth': 71, 'num_leaves': 881, 'min_data_in_leaf': 33, 'lambda_l1': 0.032010650353626616, 'lambda_l2': 0.22158425319798614} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.38474512010511064, 'max_depth': 69, 'num_leaves': 966, 'min_data_in_leaf': 35, 'lambda_l1': 0.053750905617945426, 'lambda_l2': 0.4817936852984617} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.22395773109017275, 'max_depth': 66, 'num_leaves': 1047, 'min_data_in_leaf': 38, 'lambda_l1': 0.07290084089171522, 'lambda_l2': 0.20462173968649375} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3109266412467048, 'max_depth': 73, 'num_leaves': 854, 'min_data_in_leaf': 30, 'lambda_l1': 0.020586767533716185, 'lambda_l2': 0.374767332551094} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2783395176122958, 'max_depth': 71, 'num_leaves': 1137, 'min_data_in_leaf': 39, 'lambda_l1': 0.04796263768555944, 'lambda_l2': 0.33922463679241904} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.39051147078953774, 'max_depth': 65, 'num_leaves': 954, 'min_data_in_leaf': 36, 'lambda_l1': 0.03459159165682864, 'lambda_l2': 0.4790614991814299} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.515684547258309, 'max_depth': 69, 'num_leaves': 865, 'min_data_in_leaf': 33, 'lambda_l1': 0.07900777187869693, 'lambda_l2': 0.2145909124663702} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.33752636904533556, 'max_depth': 68, 'num_leaves': 1064, 'min_data_in_leaf': 67, 'lambda_l1': 0.059788022415421, 'lambda_l2': 0.3006562937448296} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4387391687756692, 'max_depth': 65, 'num_leaves': 926, 'min_data_in_leaf': 37, 'lambda_l1': 0.01774912513309617, 'lambda_l2': 0.6031492838173184} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6354936522292571, 'max_depth': 71, 'num_leaves': 846, 'min_data_in_leaf': 34, 'lambda_l1': 0.03343103186089723, 'lambda_l2': 0.19825214749338363} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3121452235412793, 'max_depth': 75, 'num_leaves': 850, 'min_data_in_leaf': 39, 'lambda_l1': 0.06278357170536225, 'lambda_l2': 0.4155077951085274} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.25669204281110547, 'max_depth': 67, 'num_leaves': 995, 'min_data_in_leaf': 31, 'lambda_l1': 0.017073635073964998, 'lambda_l2': 0.2989091290013556} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.36214705673683906, 'max_depth': 70, 'num_leaves': 928, 'min_data_in_leaf': 36, 'lambda_l1': 0.08175865467767783, 'lambda_l2': 0.19084884364309165} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.017774576336587897, 'max_depth': 73, 'num_leaves': 827, 'min_data_in_leaf': 34, 'lambda_l1': 0.04855186855215111, 'lambda_l2': 0.4170576450984105} : acc= 52.92%\n",
            "[HPO] metrics with {'learning_rate': 0.41570303990167434, 'max_depth': 65, 'num_leaves': 1023, 'min_data_in_leaf': 38, 'lambda_l1': 0.030297594991929813, 'lambda_l2': 0.5418985742063385} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.17642002364565146, 'max_depth': 68, 'num_leaves': 1237, 'min_data_in_leaf': 35, 'lambda_l1': 0.06328209431734452, 'lambda_l2': 0.2931115996537861} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.30760520592401663, 'max_depth': 67, 'num_leaves': 912, 'min_data_in_leaf': 32, 'lambda_l1': 0.001256457560264197, 'lambda_l2': 0.18405187942083184} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4842903289554306, 'max_depth': 70, 'num_leaves': 1116, 'min_data_in_leaf': 27, 'lambda_l1': 0.044255602867603196, 'lambda_l2': 0.37878748366877707} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.23703400002234795, 'max_depth': 72, 'num_leaves': 835, 'min_data_in_leaf': 39, 'lambda_l1': 0.0751857608215204, 'lambda_l2': 0.26623462080802285} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3546888027108977, 'max_depth': 64, 'num_leaves': 961, 'min_data_in_leaf': 37, 'lambda_l1': 0.019060423020013147, 'lambda_l2': 0.5235449896888491} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27397467906840683, 'max_depth': 66, 'num_leaves': 847, 'min_data_in_leaf': 35, 'lambda_l1': 0.04761585398527003, 'lambda_l2': 0.6786921742814838} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5843091038365709, 'max_depth': 74, 'num_leaves': 1059, 'min_data_in_leaf': 33, 'lambda_l1': 0.032601639023149165, 'lambda_l2': 0.1778217187219734} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.39406163866840416, 'max_depth': 68, 'num_leaves': 914, 'min_data_in_leaf': 29, 'lambda_l1': 0.08274970432519356, 'lambda_l2': 0.4299262731177106} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32984013566784354, 'max_depth': 70, 'num_leaves': 818, 'min_data_in_leaf': 37, 'lambda_l1': 0.059298721049968736, 'lambda_l2': 0.31772406949122556} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2099139376707171, 'max_depth': 64, 'num_leaves': 975, 'min_data_in_leaf': 39, 'lambda_l1': 0.01815337570921266, 'lambda_l2': 0.2119723163968029} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4600745931133914, 'max_depth': 72, 'num_leaves': 1129, 'min_data_in_leaf': 36, 'lambda_l1': 0.08394500031234087, 'lambda_l2': 0.3229316982362331} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.29888598224164975, 'max_depth': 76, 'num_leaves': 788, 'min_data_in_leaf': 32, 'lambda_l1': 7.925252194939151e-05, 'lambda_l2': 0.15549244870631213} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3801600505244502, 'max_depth': 68, 'num_leaves': 881, 'min_data_in_leaf': 39, 'lambda_l1': 0.043553008741145365, 'lambda_l2': 0.7751816858954819} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.26900772396788886, 'max_depth': 66, 'num_leaves': 1006, 'min_data_in_leaf': 34, 'lambda_l1': 0.06220380279146409, 'lambda_l2': 1.8279704046093954} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5293834686834158, 'max_depth': 70, 'num_leaves': 810, 'min_data_in_leaf': 37, 'lambda_l1': 0.035086296490119975, 'lambda_l2': 0.4595902188710401} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.42618895496218445, 'max_depth': 73, 'num_leaves': 924, 'min_data_in_leaf': 35, 'lambda_l1': 0.02094408864130815, 'lambda_l2': 0.36686312220726075} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.33673341585049965, 'max_depth': 64, 'num_leaves': 868, 'min_data_in_leaf': 31, 'lambda_l1': 0.08265004653523872, 'lambda_l2': 0.24884851136313357} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.379292370219085, 'max_depth': 68, 'num_leaves': 1174, 'min_data_in_leaf': 40, 'lambda_l1': 0.00012904703849481863, 'lambda_l2': 0.6030978162349936} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2981670406567505, 'max_depth': 66, 'num_leaves': 1072, 'min_data_in_leaf': 37, 'lambda_l1': 0.055610888978678226, 'lambda_l2': 0.18630146798842925} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2533734510979771, 'max_depth': 70, 'num_leaves': 816, 'min_data_in_leaf': 33, 'lambda_l1': 0.03686502718233913, 'lambda_l2': 0.45543747487221425} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.34144002834101006, 'max_depth': 75, 'num_leaves': 957, 'min_data_in_leaf': 39, 'lambda_l1': 0.00040247078815679876, 'lambda_l2': 0.2661611784785417} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.44951327361438276, 'max_depth': 72, 'num_leaves': 793, 'min_data_in_leaf': 35, 'lambda_l1': 0.06941518124366508, 'lambda_l2': 0.32883948265827123} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7135615226166939, 'max_depth': 68, 'num_leaves': 891, 'min_data_in_leaf': 29, 'lambda_l1': 0.01965856080458197, 'lambda_l2': 1.6357464435735904} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3864545156053491, 'max_depth': 66, 'num_leaves': 1051, 'min_data_in_leaf': 37, 'lambda_l1': 0.04305568674172888, 'lambda_l2': 0.15363531024958593} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2828759326161314, 'max_depth': 64, 'num_leaves': 972, 'min_data_in_leaf': 33, 'lambda_l1': 0.08108774162956181, 'lambda_l2': 0.3941653525136847} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5291808257827584, 'max_depth': 70, 'num_leaves': 802, 'min_data_in_leaf': 40, 'lambda_l1': 0.06419806479323692, 'lambda_l2': 0.24274798598040054} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.32317946734437736, 'max_depth': 74, 'num_leaves': 891, 'min_data_in_leaf': 36, 'lambda_l1': 0.0311735165067828, 'lambda_l2': 0.4916078637196075} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22328676451078125, 'max_depth': 69, 'num_leaves': 779, 'min_data_in_leaf': 31, 'lambda_l1': 0.049400088901796285, 'lambda_l2': 0.16191158042023346} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.10469772598004341, 'max_depth': 65, 'num_leaves': 1200, 'min_data_in_leaf': 38, 'lambda_l1': 0.08460605729388093, 'lambda_l2': 0.3614292750648151} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4037742484245144, 'max_depth': 64, 'num_leaves': 1098, 'min_data_in_leaf': 35, 'lambda_l1': 0.018448235544624436, 'lambda_l2': 0.27069131124615303} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3468277990451725, 'max_depth': 72, 'num_leaves': 986, 'min_data_in_leaf': 34, 'lambda_l1': 0.08811283617622365, 'lambda_l2': 0.5462683158261448} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29584502333496615, 'max_depth': 68, 'num_leaves': 828, 'min_data_in_leaf': 40, 'lambda_l1': 0.05723036773589659, 'lambda_l2': 0.13129870298116447} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4791903241194109, 'max_depth': 71, 'num_leaves': 944, 'min_data_in_leaf': 38, 'lambda_l1': 0.018780543681401585, 'lambda_l2': 0.40477410559718374} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2486443041325102, 'max_depth': 68, 'num_leaves': 879, 'min_data_in_leaf': 33, 'lambda_l1': 0.036328792167467816, 'lambda_l2': 1.1812547053728772} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4173433112569002, 'max_depth': 66, 'num_leaves': 760, 'min_data_in_leaf': 36, 'lambda_l1': 0.06450452536901186, 'lambda_l2': 1.4585867091298} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3502521106837523, 'max_depth': 70, 'num_leaves': 860, 'min_data_in_leaf': 31, 'lambda_l1': 0.038522346216849544, 'lambda_l2': 0.3020951758189474} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6078204924524849, 'max_depth': 76, 'num_leaves': 1048, 'min_data_in_leaf': 38, 'lambda_l1': 0.01763584148394238, 'lambda_l2': 0.14833209637131997} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.30355238664863005, 'max_depth': 64, 'num_leaves': 769, 'min_data_in_leaf': 35, 'lambda_l1': 0.09333866654824698, 'lambda_l2': 0.22888040733238155} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4547354908191875, 'max_depth': 73, 'num_leaves': 1279, 'min_data_in_leaf': 40, 'lambda_l1': 0.061189307046341415, 'lambda_l2': 0.6550859469334169} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3838288182611242, 'max_depth': 67, 'num_leaves': 921, 'min_data_in_leaf': 37, 'lambda_l1': 0.049009098116331265, 'lambda_l2': 0.4533825384495499} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2728449161202169, 'max_depth': 70, 'num_leaves': 739, 'min_data_in_leaf': 33, 'lambda_l1': 0.0779577872578688, 'lambda_l2': 0.3313562428473623} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.004626560018797075, 'max_depth': 67, 'num_leaves': 1024, 'min_data_in_leaf': 3, 'lambda_l1': 0.017723528788080818, 'lambda_l2': 0.14995156621722727} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3317810426539579, 'max_depth': 64, 'num_leaves': 821, 'min_data_in_leaf': 35, 'lambda_l1': 0.032729085967671906, 'lambda_l2': 0.5178525395941045} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.19914963075415124, 'max_depth': 72, 'num_leaves': 1119, 'min_data_in_leaf': 96, 'lambda_l1': 0.06803282154928962, 'lambda_l2': 0.25535988737828563} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5279915065776574, 'max_depth': 68, 'num_leaves': 918, 'min_data_in_leaf': 30, 'lambda_l1': 0.0011549695318963243, 'lambda_l2': 0.38164869958864656} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.36589814524503056, 'max_depth': 74, 'num_leaves': 748, 'min_data_in_leaf': 40, 'lambda_l1': 0.04578271617090993, 'lambda_l2': 0.10643084347175416} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2382065651394684, 'max_depth': 66, 'num_leaves': 837, 'min_data_in_leaf': 37, 'lambda_l1': 0.09119969911416878, 'lambda_l2': 0.3093320378675073} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3037565416429749, 'max_depth': 70, 'num_leaves': 973, 'min_data_in_leaf': 32, 'lambda_l1': 0.03369762665924737, 'lambda_l2': 0.20191712554255625} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.42751425759380174, 'max_depth': 63, 'num_leaves': 749, 'min_data_in_leaf': 34, 'lambda_l1': 0.0621242117439081, 'lambda_l2': 0.40163978237807635} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.27302524924349003, 'max_depth': 71, 'num_leaves': 857, 'min_data_in_leaf': 28, 'lambda_l1': 0.00047321641715111426, 'lambda_l2': 0.24213770670348814} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3480440039665334, 'max_depth': 69, 'num_leaves': 1001, 'min_data_in_leaf': 39, 'lambda_l1': 0.02128571310147794, 'lambda_l2': 0.5181344431849078} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.46688696072671043, 'max_depth': 65, 'num_leaves': 910, 'min_data_in_leaf': 36, 'lambda_l1': 0.0852262991326363, 'lambda_l2': 0.30361811207758094} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3817475122650835, 'max_depth': 72, 'num_leaves': 736, 'min_data_in_leaf': 52, 'lambda_l1': 0.041803909048606966, 'lambda_l2': 0.1516923265796053} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.31948491325317624, 'max_depth': 66, 'num_leaves': 814, 'min_data_in_leaf': 38, 'lambda_l1': 0.06692305939822023, 'lambda_l2': 0.40186947826805286} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5883699576764477, 'max_depth': 75, 'num_leaves': 1076, 'min_data_in_leaf': 35, 'lambda_l1': 0.05020808309313571, 'lambda_l2': 0.6105916114576186} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4107781073685214, 'max_depth': 68, 'num_leaves': 885, 'min_data_in_leaf': 40, 'lambda_l1': 0.017737423977405957, 'lambda_l2': 0.10197873087409876} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.27573654018154725, 'max_depth': 63, 'num_leaves': 1155, 'min_data_in_leaf': 32, 'lambda_l1': 0.09123181771067738, 'lambda_l2': 0.22820582100490513} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.32274631994687286, 'max_depth': 70, 'num_leaves': 720, 'min_data_in_leaf': 37, 'lambda_l1': 0.03453465982595786, 'lambda_l2': 0.3549710678538195} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.23143461601752904, 'max_depth': 67, 'num_leaves': 807, 'min_data_in_leaf': 33, 'lambda_l1': 0.07004778151461796, 'lambda_l2': 0.4509999402939483} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5161632533086825, 'max_depth': 73, 'num_leaves': 960, 'min_data_in_leaf': 36, 'lambda_l1': 5.6802058802641687e-05, 'lambda_l2': 0.0914718722541499} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3692168269996225, 'max_depth': 64, 'num_leaves': 713, 'min_data_in_leaf': 41, 'lambda_l1': 0.0525072125324348, 'lambda_l2': 0.24747259421776327} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4351580045899587, 'max_depth': 69, 'num_leaves': 1039, 'min_data_in_leaf': 38, 'lambda_l1': 0.018580749380760257, 'lambda_l2': 0.31012837138817273} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3014132010343274, 'max_depth': 77, 'num_leaves': 877, 'min_data_in_leaf': 34, 'lambda_l1': 0.09058415969214073, 'lambda_l2': 0.17501305967238753} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3577204123446812, 'max_depth': 66, 'num_leaves': 963, 'min_data_in_leaf': 31, 'lambda_l1': 0.03297822817186137, 'lambda_l2': 0.5193561148219715} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.25545666991101307, 'max_depth': 71, 'num_leaves': 2486, 'min_data_in_leaf': 39, 'lambda_l1': 0.0003712188302871025, 'lambda_l2': 0.36578004772219497} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6537733307427942, 'max_depth': 74, 'num_leaves': 1233, 'min_data_in_leaf': 35, 'lambda_l1': 0.6041896577437553, 'lambda_l2': 0.15664418572710453} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4035932451744283, 'max_depth': 63, 'num_leaves': 801, 'min_data_in_leaf': 37, 'lambda_l1': 0.04990034846754136, 'lambda_l2': 0.4507367391945431} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.46984679801094786, 'max_depth': 68, 'num_leaves': 711, 'min_data_in_leaf': 30, 'lambda_l1': 0.07600123124833813, 'lambda_l2': 0.26091132737028766} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3170326494743898, 'max_depth': 72, 'num_leaves': 835, 'min_data_in_leaf': 34, 'lambda_l1': 0.10044976947390664, 'lambda_l2': 0.09116263606909657} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.8379535469950319, 'max_depth': 66, 'num_leaves': 887, 'min_data_in_leaf': 41, 'lambda_l1': 0.03161519974778822, 'lambda_l2': 0.8216715200587743} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.27067712083886103, 'max_depth': 69, 'num_leaves': 1351, 'min_data_in_leaf': 36, 'lambda_l1': 0.21144771834725296, 'lambda_l2': 0.37127318610106574} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.35831831076011805, 'max_depth': 64, 'num_leaves': 3466, 'min_data_in_leaf': 38, 'lambda_l1': 0.05446752611226929, 'lambda_l2': 0.2421023866972161} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3023929504057035, 'max_depth': 41, 'num_leaves': 688, 'min_data_in_leaf': 33, 'lambda_l1': 0.07461709109168788, 'lambda_l2': 0.5853725273243919} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.47099617819535466, 'max_depth': 71, 'num_leaves': 1118, 'min_data_in_leaf': 40, 'lambda_l1': 0.022822192920764196, 'lambda_l2': 0.32467336548101866} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.41431206877262333, 'max_depth': 66, 'num_leaves': 779, 'min_data_in_leaf': 36, 'lambda_l1': 0.05217843233774075, 'lambda_l2': 0.09765144012488775} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3409457576910278, 'max_depth': 68, 'num_leaves': 961, 'min_data_in_leaf': 38, 'lambda_l1': 0.0002288210035585169, 'lambda_l2': 0.47286841340371566} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.23808772696566852, 'max_depth': 63, 'num_leaves': 1029, 'min_data_in_leaf': 32, 'lambda_l1': 0.09949577383787156, 'lambda_l2': 0.17418875815231905} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5804859962461819, 'max_depth': 74, 'num_leaves': 821, 'min_data_in_leaf': 28, 'lambda_l1': 0.03079521072874845, 'lambda_l2': 0.6927865214548595} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.28068136142592043, 'max_depth': 69, 'num_leaves': 701, 'min_data_in_leaf': 34, 'lambda_l1': 0.9739445065526586, 'lambda_l2': 0.29269103974008503} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.38505840089713567, 'max_depth': 65, 'num_leaves': 938, 'min_data_in_leaf': 40, 'lambda_l1': 0.07197748039601017, 'lambda_l2': 0.42947539593832096} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3244184742736988, 'max_depth': 71, 'num_leaves': 776, 'min_data_in_leaf': 36, 'lambda_l1': 0.019389242890058302, 'lambda_l2': 0.18303512192588034} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.1996628370458358, 'max_depth': 63, 'num_leaves': 1018, 'min_data_in_leaf': 38, 'lambda_l1': 0.047844474240475054, 'lambda_l2': 0.33805974832406965} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5115869421719285, 'max_depth': 73, 'num_leaves': 898, 'min_data_in_leaf': 34, 'lambda_l1': 0.25128647166677437, 'lambda_l2': 0.09730999927683581} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4076561107774966, 'max_depth': 67, 'num_leaves': 703, 'min_data_in_leaf': 31, 'lambda_l1': 0.08609948055326552, 'lambda_l2': 0.23310869446397142} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2895704942848063, 'max_depth': 76, 'num_leaves': 848, 'min_data_in_leaf': 41, 'lambda_l1': 0.060463798253713494, 'lambda_l2': 0.5087388773385396} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3448772438946491, 'max_depth': 70, 'num_leaves': 766, 'min_data_in_leaf': 75, 'lambda_l1': 0.6990774606512018, 'lambda_l2': 0.38868874835460343} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4493235863602137, 'max_depth': 100, 'num_leaves': 1142, 'min_data_in_leaf': 35, 'lambda_l1': 0.036266740964368244, 'lambda_l2': 0.2400592121766644} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.24716636877448764, 'max_depth': 62, 'num_leaves': 903, 'min_data_in_leaf': 39, 'lambda_l1': 0.018844047516585034, 'lambda_l2': 0.09649725405549117} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.37909391635381773, 'max_depth': 67, 'num_leaves': 679, 'min_data_in_leaf': 37, 'lambda_l1': 0.04914380013226975, 'lambda_l2': 0.31276396315345434} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3192458237138205, 'max_depth': 69, 'num_leaves': 800, 'min_data_in_leaf': 33, 'lambda_l1': 0.09872724784462551, 'lambda_l2': 0.18865188275301117} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5396229305386111, 'max_depth': 65, 'num_leaves': 1072, 'min_data_in_leaf': 36, 'lambda_l1': 0.07242079286540137, 'lambda_l2': 0.4285358239724563} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2806942714098243, 'max_depth': 72, 'num_leaves': 948, 'min_data_in_leaf': 30, 'lambda_l1': 0.021972920740407943, 'lambda_l2': 0.5619534096904115} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.36315644078405074, 'max_depth': 42, 'num_leaves': 3879, 'min_data_in_leaf': 41, 'lambda_l1': 0.06501007905221062, 'lambda_l2': 0.3014040525552027} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.42809653174588813, 'max_depth': 62, 'num_leaves': 692, 'min_data_in_leaf': 38, 'lambda_l1': 0.04304288876530807, 'lambda_l2': 0.0773461701421568} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7151817270899985, 'max_depth': 67, 'num_leaves': 845, 'min_data_in_leaf': 35, 'lambda_l1': 0.10096940077035885, 'lambda_l2': 2.913753142036597} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.21286705404594486, 'max_depth': 69, 'num_leaves': 761, 'min_data_in_leaf': 32, 'lambda_l1': 0.01711609959740835, 'lambda_l2': 0.18774933139781955} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.31537417090168396, 'max_depth': 65, 'num_leaves': 1208, 'min_data_in_leaf': 36, 'lambda_l1': 0.08306687034719795, 'lambda_l2': 0.9612676421337945} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.48392409952657095, 'max_depth': 71, 'num_leaves': 993, 'min_data_in_leaf': 39, 'lambda_l1': 0.035932642509254126, 'lambda_l2': 0.36090247831303734} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.026847871335959467, 'max_depth': 73, 'num_leaves': 885, 'min_data_in_leaf': 34, 'lambda_l1': 0.06189671072093514, 'lambda_l2': 0.24975488110688737} : acc= 59.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2590996437949974, 'max_depth': 67, 'num_leaves': 685, 'min_data_in_leaf': 27, 'lambda_l1': 0.01590296495570411, 'lambda_l2': 0.46316923895184847} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.38598115174213327, 'max_depth': 64, 'num_leaves': 782, 'min_data_in_leaf': 37, 'lambda_l1': 0.043878943225642966, 'lambda_l2': 0.08622993699554174} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.31940607406840665, 'max_depth': 75, 'num_leaves': 1045, 'min_data_in_leaf': 41, 'lambda_l1': 0.08335501264613304, 'lambda_l2': 0.33938003742096867} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3655827806730548, 'max_depth': 71, 'num_leaves': 908, 'min_data_in_leaf': 32, 'lambda_l1': 0.11239752758356197, 'lambda_l2': 0.1844300569043165} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.28608603995598086, 'max_depth': 69, 'num_leaves': 812, 'min_data_in_leaf': 39, 'lambda_l1': 0.0575883828297325, 'lambda_l2': 0.5960125058495584} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44516918942738093, 'max_depth': 62, 'num_leaves': 686, 'min_data_in_leaf': 34, 'lambda_l1': 0.032169011301173556, 'lambda_l2': 0.26810197039194567} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5673005024016778, 'max_depth': 65, 'num_leaves': 981, 'min_data_in_leaf': 29, 'lambda_l1': 0.01772447335269265, 'lambda_l2': 0.4060053047602764} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34012326311738, 'max_depth': 68, 'num_leaves': 3696, 'min_data_in_leaf': 37, 'lambda_l1': 0.07313178711024715, 'lambda_l2': 0.16377452902621578} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23932284934401232, 'max_depth': 73, 'num_leaves': 747, 'min_data_in_leaf': 35, 'lambda_l1': 0.054466455540355445, 'lambda_l2': 0.30572260484100067} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.41443115641276146, 'max_depth': 70, 'num_leaves': 893, 'min_data_in_leaf': 39, 'lambda_l1': 0.09772869588185999, 'lambda_l2': 0.5184755990406359} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2926697139453827, 'max_depth': 79, 'num_leaves': 857, 'min_data_in_leaf': 32, 'lambda_l1': 0.035313993751438705, 'lambda_l2': 0.39228305383334316} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.15806984859772857, 'max_depth': 77, 'num_leaves': 675, 'min_data_in_leaf': 41, 'lambda_l1': 0.01913391572901083, 'lambda_l2': 0.6948161726239641} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.002005446715761674, 'max_depth': 66, 'num_leaves': 1077, 'min_data_in_leaf': 37, 'lambda_l1': 0.06854343056009013, 'lambda_l2': 0.0826669758477434} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.49591746627284294, 'max_depth': 62, 'num_leaves': 772, 'min_data_in_leaf': 35, 'lambda_l1': 0.04529838228777941, 'lambda_l2': 0.20476568965885075} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34925011912010273, 'max_depth': 71, 'num_leaves': 1917, 'min_data_in_leaf': 39, 'lambda_l1': 0.0812797090529167, 'lambda_l2': 0.27216587984945223} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4133683569739789, 'max_depth': 68, 'num_leaves': 981, 'min_data_in_leaf': 33, 'lambda_l1': 0.0005112529525198237, 'lambda_l2': 0.4684886536145932} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2639378607522145, 'max_depth': 65, 'num_leaves': 835, 'min_data_in_leaf': 30, 'lambda_l1': 0.035004470412536084, 'lambda_l2': 0.1591663830290939} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6366754632849845, 'max_depth': 43, 'num_leaves': 2785, 'min_data_in_leaf': 36, 'lambda_l1': 0.1154140928509795, 'lambda_l2': 0.35604982937489427} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3251531826031788, 'max_depth': 63, 'num_leaves': 1163, 'min_data_in_leaf': 42, 'lambda_l1': 0.05708703455263246, 'lambda_l2': 0.2670462993064567} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3798569119989082, 'max_depth': 74, 'num_leaves': 665, 'min_data_in_leaf': 38, 'lambda_l1': 0.09582934709243672, 'lambda_l2': 0.08849806067767398} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4754750749472186, 'max_depth': 69, 'num_leaves': 935, 'min_data_in_leaf': 34, 'lambda_l1': 0.020766659610252862, 'lambda_l2': 0.4184159083472455} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.22235378515891804, 'max_depth': 67, 'num_leaves': 745, 'min_data_in_leaf': 56, 'lambda_l1': 0.001131760740768173, 'lambda_l2': 0.21843521568310206} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3162008781863887, 'max_depth': 72, 'num_leaves': 848, 'min_data_in_leaf': 37, 'lambda_l1': 0.8397867126559662, 'lambda_l2': 0.547996974480151} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2719129230320384, 'max_depth': 64, 'num_leaves': 647, 'min_data_in_leaf': 40, 'lambda_l1': 0.06314587910584708, 'lambda_l2': 0.09354270886697297} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3677971476568601, 'max_depth': 70, 'num_leaves': 745, 'min_data_in_leaf': 32, 'lambda_l1': 0.03580587640646461, 'lambda_l2': 0.3278969508156159} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4231312676957424, 'max_depth': 67, 'num_leaves': 1100, 'min_data_in_leaf': 35, 'lambda_l1': 0.07711074053539871, 'lambda_l2': 0.18655420333505632} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.18302638165978294, 'max_depth': 75, 'num_leaves': 986, 'min_data_in_leaf': 37, 'lambda_l1': 0.00028171689430792415, 'lambda_l2': 0.43885434032086834} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3044041962918649, 'max_depth': 41, 'num_leaves': 801, 'min_data_in_leaf': 33, 'lambda_l1': 0.10725494505231539, 'lambda_l2': 0.2874017095311695} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5470260249525005, 'max_depth': 72, 'num_leaves': 943, 'min_data_in_leaf': 39, 'lambda_l1': 0.0479188027820797, 'lambda_l2': 0.34944564243474313} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.33793905489591985, 'max_depth': 65, 'num_leaves': 847, 'min_data_in_leaf': 30, 'lambda_l1': 0.016933572982554886, 'lambda_l2': 0.07881981537933888} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2517805949374739, 'max_depth': 61, 'num_leaves': 670, 'min_data_in_leaf': 42, 'lambda_l1': 0.09287129933762521, 'lambda_l2': 0.1720422669680296} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.19279875673116073, 'max_depth': 61, 'num_leaves': 697, 'min_data_in_leaf': 47, 'lambda_l1': 0.08920426833892844, 'lambda_l2': 0.08594620062375044} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.23906666921967137, 'max_depth': 61, 'num_leaves': 739, 'min_data_in_leaf': 43, 'lambda_l1': 0.03428867355438227, 'lambda_l2': 0.1638574472960928} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.21545034997428605, 'max_depth': 61, 'num_leaves': 661, 'min_data_in_leaf': 46, 'lambda_l1': 0.7990649207149401, 'lambda_l2': 0.08812231197794226} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.23415830168448154, 'max_depth': 62, 'num_leaves': 3178, 'min_data_in_leaf': 43, 'lambda_l1': 0.06111812971157604, 'lambda_l2': 0.21919016740956226} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.25897178986436387, 'max_depth': 61, 'num_leaves': 721, 'min_data_in_leaf': 46, 'lambda_l1': 0.10988408370993635, 'lambda_l2': 0.07858818868255454} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2809047423562761, 'max_depth': 63, 'num_leaves': 774, 'min_data_in_leaf': 43, 'lambda_l1': 0.04612304978220383, 'lambda_l2': 0.62751955466315} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.21878006654244617, 'max_depth': 63, 'num_leaves': 688, 'min_data_in_leaf': 44, 'lambda_l1': 0.01788137915441719, 'lambda_l2': 0.16079782552748964} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.27642310947631316, 'max_depth': 61, 'num_leaves': 800, 'min_data_in_leaf': 42, 'lambda_l1': 0.06988772116262007, 'lambda_l2': 0.294662839296535} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2481185586219276, 'max_depth': 63, 'num_leaves': 654, 'min_data_in_leaf': 50, 'lambda_l1': 0.0003375677063036757, 'lambda_l2': 0.4948563936142838} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2954023142169575, 'max_depth': 63, 'num_leaves': 760, 'min_data_in_leaf': 42, 'lambda_l1': 0.9142495815045208, 'lambda_l2': 0.22067010275021975} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2576451878170289, 'max_depth': 61, 'num_leaves': 869, 'min_data_in_leaf': 44, 'lambda_l1': 0.03281706569486028, 'lambda_l2': 0.3568558381777179} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2985243704732493, 'max_depth': 61, 'num_leaves': 815, 'min_data_in_leaf': 44, 'lambda_l1': 0.08465230555870955, 'lambda_l2': 0.07577566069809301} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.32623059613570826, 'max_depth': 62, 'num_leaves': 636, 'min_data_in_leaf': 42, 'lambda_l1': 0.05050688402771454, 'lambda_l2': 0.23643579370049458} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.25133073091879893, 'max_depth': 65, 'num_leaves': 730, 'min_data_in_leaf': 45, 'lambda_l1': 0.017384421868709414, 'lambda_l2': 0.3845622200238389} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.07874919320182003, 'max_depth': 64, 'num_leaves': 885, 'min_data_in_leaf': 41, 'lambda_l1': 0.12284104169005904, 'lambda_l2': 0.1602047354144291} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3754467571651674, 'max_depth': 61, 'num_leaves': 641, 'min_data_in_leaf': 40, 'lambda_l1': 0.07032426326196393, 'lambda_l2': 0.5111339140690601} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.20705752716332435, 'max_depth': 65, 'num_leaves': 792, 'min_data_in_leaf': 40, 'lambda_l1': 0.09905334049601547, 'lambda_l2': 0.2823897213294231} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.28541454622361534, 'max_depth': 63, 'num_leaves': 1030, 'min_data_in_leaf': 42, 'lambda_l1': 0.034684620020431274, 'lambda_l2': 0.008256860135407607} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.349773958605885, 'max_depth': 67, 'num_leaves': 921, 'min_data_in_leaf': 41, 'lambda_l1': 0.04785859133017251, 'lambda_l2': 0.40813177666113754} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.03425589589962017, 'max_depth': 66, 'num_leaves': 744, 'min_data_in_leaf': 47, 'lambda_l1': 0.00038515349243083835, 'lambda_l2': 0.17040614623367586} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.45567362582437665, 'max_depth': 64, 'num_leaves': 846, 'min_data_in_leaf': 49, 'lambda_l1': 0.07885379727715794, 'lambda_l2': 0.2932507379436634} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3001820691179839, 'max_depth': 61, 'num_leaves': 683, 'min_data_in_leaf': 44, 'lambda_l1': 0.0315399810535706, 'lambda_l2': 0.5982412791266289} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.37903363368919873, 'max_depth': 69, 'num_leaves': 938, 'min_data_in_leaf': 31, 'lambda_l1': 0.05789686631721151, 'lambda_l2': 0.4514042130059556} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5855340044742642, 'max_depth': 66, 'num_leaves': 2639, 'min_data_in_leaf': 40, 'lambda_l1': 0.017770695376277453, 'lambda_l2': 0.7999242153758178} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.24892981915522605, 'max_depth': 64, 'num_leaves': 1304, 'min_data_in_leaf': 29, 'lambda_l1': 0.09380477447306142, 'lambda_l2': 0.13838522226817015} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3333980862271924, 'max_depth': 68, 'num_leaves': 823, 'min_data_in_leaf': 42, 'lambda_l1': 0.11508964008879873, 'lambda_l2': 0.32028800869788165} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5012332725272203, 'max_depth': 61, 'num_leaves': 728, 'min_data_in_leaf': 34, 'lambda_l1': 0.0624864198854721, 'lambda_l2': 0.24984721012238748} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7845369610143714, 'max_depth': 61, 'num_leaves': 756, 'min_data_in_leaf': 33, 'lambda_l1': 0.05428428245673888, 'lambda_l2': 0.0897263436846414} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6299531154736719, 'max_depth': 60, 'num_leaves': 760, 'min_data_in_leaf': 38, 'lambda_l1': 0.0457351224018589, 'lambda_l2': 0.16070070452970087} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5682711842544536, 'max_depth': 60, 'num_leaves': 806, 'min_data_in_leaf': 35, 'lambda_l1': 0.061459281871190895, 'lambda_l2': 0.05219589094707347} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6445977004199451, 'max_depth': 62, 'num_leaves': 726, 'min_data_in_leaf': 41, 'lambda_l1': 0.0372917783099846, 'lambda_l2': 0.23472592582151214} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6305316578893297, 'max_depth': 60, 'num_leaves': 880, 'min_data_in_leaf': 36, 'lambda_l1': 0.06534125129400979, 'lambda_l2': 0.17397971630166545} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.7270170951555313, 'max_depth': 60, 'num_leaves': 766, 'min_data_in_leaf': 32, 'lambda_l1': 0.035873983201733364, 'lambda_l2': 0.07939052697322244} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5256348926859454, 'max_depth': 62, 'num_leaves': 825, 'min_data_in_leaf': 39, 'lambda_l1': 0.05210627436027947, 'lambda_l2': 0.24377161206484976} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6062089677557589, 'max_depth': 62, 'num_leaves': 706, 'min_data_in_leaf': 34, 'lambda_l1': 0.01790372229155808, 'lambda_l2': 0.07208044664096644} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.517127621434388, 'max_depth': 61, 'num_leaves': 879, 'min_data_in_leaf': 27, 'lambda_l1': 0.06202851427370808, 'lambda_l2': 0.23895360916661784} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6533836868638495, 'max_depth': 60, 'num_leaves': 810, 'min_data_in_leaf': 45, 'lambda_l1': 0.03319132856942962, 'lambda_l2': 0.00602519263246476} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.49349988003321527, 'max_depth': 63, 'num_leaves': 690, 'min_data_in_leaf': 37, 'lambda_l1': 0.07031880742157662, 'lambda_l2': 0.3496594024688344} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.727084073058402, 'max_depth': 64, 'num_leaves': 920, 'min_data_in_leaf': 31, 'lambda_l1': 0.9383078261590593, 'lambda_l2': 0.18805029129465844} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.562455284552261, 'max_depth': 62, 'num_leaves': 774, 'min_data_in_leaf': 39, 'lambda_l1': 0.6419781823604744, 'lambda_l2': 0.3079580678180365} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5663729911290863, 'max_depth': 63, 'num_leaves': 715, 'min_data_in_leaf': 35, 'lambda_l1': 0.04756625829804089, 'lambda_l2': 2.858572092020799} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4890103601555362, 'max_depth': 65, 'num_leaves': 861, 'min_data_in_leaf': 43, 'lambda_l1': 0.02688746746636822, 'lambda_l2': 0.15213614495936553} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5867364732399412, 'max_depth': 60, 'num_leaves': 994, 'min_data_in_leaf': 37, 'lambda_l1': 0.01913603695326904, 'lambda_l2': 0.39890849259758027} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5025426061662983, 'max_depth': 60, 'num_leaves': 810, 'min_data_in_leaf': 41, 'lambda_l1': 0.07433053848241489, 'lambda_l2': 0.2692677277312463} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6599131494754528, 'max_depth': 63, 'num_leaves': 682, 'min_data_in_leaf': 33, 'lambda_l1': 0.04614992413483768, 'lambda_l2': 0.15693937224306578} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5204443308454271, 'max_depth': 65, 'num_leaves': 903, 'min_data_in_leaf': 36, 'lambda_l1': 0.05536976489336678, 'lambda_l2': 0.43989673490360265} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4644416939767078, 'max_depth': 61, 'num_leaves': 745, 'min_data_in_leaf': 59, 'lambda_l1': 0.01787504840908509, 'lambda_l2': 0.23786796532925933} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.831513812405583, 'max_depth': 65, 'num_leaves': 835, 'min_data_in_leaf': 39, 'lambda_l1': 0.06997892596742952, 'lambda_l2': 0.0034652747052333344} : acc= 36.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5040753430743445, 'max_depth': 62, 'num_leaves': 1016, 'min_data_in_leaf': 34, 'lambda_l1': 0.03367214068595207, 'lambda_l2': 0.3862398709663192} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4488961118670509, 'max_depth': 63, 'num_leaves': 935, 'min_data_in_leaf': 29, 'lambda_l1': 4.976436723690483e-06, 'lambda_l2': 2.988759844148762} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5539053828778512, 'max_depth': 67, 'num_leaves': 648, 'min_data_in_leaf': 38, 'lambda_l1': 0.045639169838091964, 'lambda_l2': 0.33207607869122935} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4338033621226615, 'max_depth': 64, 'num_leaves': 739, 'min_data_in_leaf': 32, 'lambda_l1': 0.07990306594867169, 'lambda_l2': 0.5527594796333688} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7289565346950858, 'max_depth': 66, 'num_leaves': 1098, 'min_data_in_leaf': 41, 'lambda_l1': 0.02819700626021647, 'lambda_l2': 0.14755593848866422} : acc= 60.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4551640562011249, 'max_depth': 61, 'num_leaves': 862, 'min_data_in_leaf': 48, 'lambda_l1': 0.06340248839307557, 'lambda_l2': 0.2344211935208427} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5009057031449868, 'max_depth': 60, 'num_leaves': 661, 'min_data_in_leaf': 36, 'lambda_l1': 0.017210546692829534, 'lambda_l2': 0.002600309000227008} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.45043133086078957, 'max_depth': 69, 'num_leaves': 1239, 'min_data_in_leaf': 34, 'lambda_l1': 6.63090250808615e-05, 'lambda_l2': 0.4611687902032135} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.555937137997293, 'max_depth': 67, 'num_leaves': 803, 'min_data_in_leaf': 38, 'lambda_l1': 0.047967237704185706, 'lambda_l2': 0.2972693288509892} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4298991893323629, 'max_depth': 71, 'num_leaves': 945, 'min_data_in_leaf': 31, 'lambda_l1': 0.08204292421244427, 'lambda_l2': 0.6954494302408594} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40868565486232045, 'max_depth': 64, 'num_leaves': 740, 'min_data_in_leaf': 36, 'lambda_l1': 0.047496925912255294, 'lambda_l2': 0.09126569128670281} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6476322197110304, 'max_depth': 66, 'num_leaves': 869, 'min_data_in_leaf': 40, 'lambda_l1': 0.029592864201536423, 'lambda_l2': 0.35615064691703757} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.517707338997737, 'max_depth': 60, 'num_leaves': 1035, 'min_data_in_leaf': 42, 'lambda_l1': 0.06728620848564491, 'lambda_l2': 0.14777388212384646} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4169460098661814, 'max_depth': 70, 'num_leaves': 794, 'min_data_in_leaf': 53, 'lambda_l1': 0.03444448313417587, 'lambda_l2': 0.2231000883209062} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4568646434439111, 'max_depth': 74, 'num_leaves': 676, 'min_data_in_leaf': 34, 'lambda_l1': 0.00036468190756687446, 'lambda_l2': 0.4538863209101225} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5683266271573312, 'max_depth': 63, 'num_leaves': 970, 'min_data_in_leaf': 38, 'lambda_l1': 0.05881401910432198, 'lambda_l2': 0.29753227155073414} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4066664777090711, 'max_depth': 67, 'num_leaves': 889, 'min_data_in_leaf': 35, 'lambda_l1': 0.07416797984538756, 'lambda_l2': 0.1033749224123778} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4913807729272473, 'max_depth': 69, 'num_leaves': 3969, 'min_data_in_leaf': 44, 'lambda_l1': 0.016297123361685623, 'lambda_l2': 0.002415101040202927} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.9381496094017031, 'max_depth': 72, 'num_leaves': 1143, 'min_data_in_leaf': 32, 'lambda_l1': 0.03560565529671142, 'lambda_l2': 0.5522580063619028} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4067881596791469, 'max_depth': 62, 'num_leaves': 723, 'min_data_in_leaf': 37, 'lambda_l1': 0.051882412990733706, 'lambda_l2': 0.22911491283850355} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.38257442430273403, 'max_depth': 65, 'num_leaves': 803, 'min_data_in_leaf': 40, 'lambda_l1': 0.08134111044081216, 'lambda_l2': 0.3838937257516638} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.46401894648818104, 'max_depth': 60, 'num_leaves': 648, 'min_data_in_leaf': 36, 'lambda_l1': 0.017183941756278468, 'lambda_l2': 0.29126146445985507} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5331829356974646, 'max_depth': 76, 'num_leaves': 1043, 'min_data_in_leaf': 30, 'lambda_l1': 0.7718149564892715, 'lambda_l2': 0.16749360460068075} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3757837545847363, 'max_depth': 68, 'num_leaves': 913, 'min_data_in_leaf': 33, 'lambda_l1': 0.03252815453839561, 'lambda_l2': 0.4526180829822741} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3578282662481939, 'max_depth': 68, 'num_leaves': 977, 'min_data_in_leaf': 28, 'lambda_l1': 0.02214851344230748, 'lambda_l2': 0.6190731032859422} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35720991274896396, 'max_depth': 68, 'num_leaves': 927, 'min_data_in_leaf': 27, 'lambda_l1': 0.017644400813241496, 'lambda_l2': 0.7509994037847131} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3350935815342668, 'max_depth': 70, 'num_leaves': 1028, 'min_data_in_leaf': 29, 'lambda_l1': 0.01954442511554276, 'lambda_l2': 0.6218159710494717} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3772501158984618, 'max_depth': 69, 'num_leaves': 917, 'min_data_in_leaf': 31, 'lambda_l1': 0.034658722288506645, 'lambda_l2': 0.548042226020882} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31262357870156376, 'max_depth': 67, 'num_leaves': 1097, 'min_data_in_leaf': 29, 'lambda_l1': 0.000584021914553895, 'lambda_l2': 0.6916129316015379} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.38579314415422544, 'max_depth': 66, 'num_leaves': 983, 'min_data_in_leaf': 31, 'lambda_l1': 0.03146537852254199, 'lambda_l2': 0.5031046878426153} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2817250185908987, 'max_depth': 71, 'num_leaves': 949, 'min_data_in_leaf': 32, 'lambda_l1': 0.01577012671929584, 'lambda_l2': 0.5225687010545527} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3362695668887391, 'max_depth': 68, 'num_leaves': 1065, 'min_data_in_leaf': 32, 'lambda_l1': 0.03324210227884372, 'lambda_l2': 0.6343112711024896} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.12379528929816785, 'max_depth': 70, 'num_leaves': 893, 'min_data_in_leaf': 29, 'lambda_l1': 0.0006769442252970108, 'lambda_l2': 0.447663452899671} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3936380320456991, 'max_depth': 67, 'num_leaves': 857, 'min_data_in_leaf': 33, 'lambda_l1': 0.03587212597623919, 'lambda_l2': 0.5371007707624846} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29879266731387444, 'max_depth': 65, 'num_leaves': 867, 'min_data_in_leaf': 34, 'lambda_l1': 0.02143949454022599, 'lambda_l2': 0.4686748103386503} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.34776095029938014, 'max_depth': 70, 'num_leaves': 954, 'min_data_in_leaf': 32, 'lambda_l1': 0.016003616657472734, 'lambda_l2': 0.41428752207100333} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.26867065413715135, 'max_depth': 66, 'num_leaves': 1043, 'min_data_in_leaf': 31, 'lambda_l1': 0.04340302373316074, 'lambda_l2': 0.5368006462393982} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.40253876379542897, 'max_depth': 73, 'num_leaves': 831, 'min_data_in_leaf': 30, 'lambda_l1': 0.04408568607745404, 'lambda_l2': 0.45080174052767685} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.17280486201907358, 'max_depth': 72, 'num_leaves': 983, 'min_data_in_leaf': 33, 'lambda_l1': 0.01461627983372557, 'lambda_l2': 0.8641523335369434} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.30605392359771755, 'max_depth': 69, 'num_leaves': 1139, 'min_data_in_leaf': 33, 'lambda_l1': 0.047531053495570935, 'lambda_l2': 0.3858808706908002} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.358516670700924, 'max_depth': 65, 'num_leaves': 855, 'min_data_in_leaf': 26, 'lambda_l1': 0.02979392864473831, 'lambda_l2': 0.6452362248105543} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.23489601130716922, 'max_depth': 68, 'num_leaves': 911, 'min_data_in_leaf': 34, 'lambda_l1': 0.015986243515659734, 'lambda_l2': 0.3655667173898308} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4190348278266474, 'max_depth': 64, 'num_leaves': 800, 'min_data_in_leaf': 31, 'lambda_l1': 0.051451167045447804, 'lambda_l2': 0.5315510701459617} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3140285184276834, 'max_depth': 72, 'num_leaves': 924, 'min_data_in_leaf': 34, 'lambda_l1': 0.03266323361314748, 'lambda_l2': 0.3667581189381321} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.09431776845687644, 'max_depth': 67, 'num_leaves': 1033, 'min_data_in_leaf': 30, 'lambda_l1': 0.015530924132100154, 'lambda_l2': 0.44763653507278445} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2766941539734185, 'max_depth': 71, 'num_leaves': 801, 'min_data_in_leaf': 33, 'lambda_l1': 0.05086950278309408, 'lambda_l2': 0.34754640170904766} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3513253760136529, 'max_depth': 64, 'num_leaves': 879, 'min_data_in_leaf': 35, 'lambda_l1': 0.03482772747868651, 'lambda_l2': 0.5862730589995611} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.44920021384262127, 'max_depth': 69, 'num_leaves': 3062, 'min_data_in_leaf': 28, 'lambda_l1': 0.04897336129020074, 'lambda_l2': 0.2958311823749226} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3801852906767725, 'max_depth': 66, 'num_leaves': 1218, 'min_data_in_leaf': 33, 'lambda_l1': 0.019204700847271654, 'lambda_l2': 1.6964743702144691} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.31660688769319784, 'max_depth': 74, 'num_leaves': 764, 'min_data_in_leaf': 34, 'lambda_l1': 0.038606004854646436, 'lambda_l2': 0.4619719268776126} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2178037556577837, 'max_depth': 70, 'num_leaves': 983, 'min_data_in_leaf': 35, 'lambda_l1': 0.060160607308757406, 'lambda_l2': 0.36682955470999246} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2691075326605126, 'max_depth': 63, 'num_leaves': 1078, 'min_data_in_leaf': 31, 'lambda_l1': 0.0018944627513053508, 'lambda_l2': 0.7268872721912687} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.42233124758650015, 'max_depth': 68, 'num_leaves': 837, 'min_data_in_leaf': 35, 'lambda_l1': 0.058845978566741064, 'lambda_l2': 0.25863303715367686} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3414653148241961, 'max_depth': 66, 'num_leaves': 909, 'min_data_in_leaf': 32, 'lambda_l1': 0.0007005153195187505, 'lambda_l2': 0.4716954538085247} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.294678450649606, 'max_depth': 73, 'num_leaves': 727, 'min_data_in_leaf': 35, 'lambda_l1': 0.00025574195946843903, 'lambda_l2': 0.3122944714124291} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3949623965781936, 'max_depth': 71, 'num_leaves': 1002, 'min_data_in_leaf': 33, 'lambda_l1': 0.033055442646110975, 'lambda_l2': 0.23667965391641468} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.2557654264438823, 'max_depth': 64, 'num_leaves': 789, 'min_data_in_leaf': 30, 'lambda_l1': 0.06082733270340555, 'lambda_l2': 0.3846835711279525} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4605455452367363, 'max_depth': 68, 'num_leaves': 1127, 'min_data_in_leaf': 36, 'lambda_l1': 0.029135053562683984, 'lambda_l2': 0.563481286077882} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3383753476061119, 'max_depth': 62, 'num_leaves': 888, 'min_data_in_leaf': 33, 'lambda_l1': 0.04541718779790094, 'lambda_l2': 0.2221795297288979} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3785163203786439, 'max_depth': 70, 'num_leaves': 743, 'min_data_in_leaf': 36, 'lambda_l1': 0.016831796620487557, 'lambda_l2': 0.41765158569790645} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.6809348431443922, 'max_depth': 66, 'num_leaves': 834, 'min_data_in_leaf': 35, 'lambda_l1': 0.06546928971514558, 'lambda_l2': 0.15468258030345788} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.009000779840410986, 'max_depth': 75, 'num_leaves': 974, 'min_data_in_leaf': 65, 'lambda_l1': 0.03613740600339792, 'lambda_l2': 1.2707433394774819} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.30186070305394813, 'max_depth': 68, 'num_leaves': 776, 'min_data_in_leaf': 31, 'lambda_l1': 0.01626314262951937, 'lambda_l2': 0.29677422025123545} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.48370985077658996, 'max_depth': 72, 'num_leaves': 950, 'min_data_in_leaf': 28, 'lambda_l1': 0.05534544014448056, 'lambda_l2': 0.46489272362962397} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.23114840461094482, 'max_depth': 64, 'num_leaves': 856, 'min_data_in_leaf': 33, 'lambda_l1': 0.033252008704052656, 'lambda_l2': 0.33960590598085566} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3384464625472767, 'max_depth': 62, 'num_leaves': 1079, 'min_data_in_leaf': 36, 'lambda_l1': 0.06247588550281448, 'lambda_l2': 0.1667348001662157} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4117707290718369, 'max_depth': 66, 'num_leaves': 717, 'min_data_in_leaf': 34, 'lambda_l1': 0.019675662138339003, 'lambda_l2': 0.08423376904617008} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2872153427447791, 'max_depth': 70, 'num_leaves': 1180, 'min_data_in_leaf': 36, 'lambda_l1': 0.07215286524710764, 'lambda_l2': 0.6688276534423954} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3805790273250607, 'max_depth': 73, 'num_leaves': 798, 'min_data_in_leaf': 30, 'lambda_l1': 0.04306233238340913, 'lambda_l2': 0.2560671780826394} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3286104964530611, 'max_depth': 77, 'num_leaves': 923, 'min_data_in_leaf': 37, 'lambda_l1': 0.04644469238244524, 'lambda_l2': 0.5074409726301453} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.006450864891236321, 'max_depth': 68, 'num_leaves': 1035, 'min_data_in_leaf': 32, 'lambda_l1': 0.016826121885502417, 'lambda_l2': 0.36930434360979286} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2716117306284236, 'max_depth': 64, 'num_leaves': 700, 'min_data_in_leaf': 35, 'lambda_l1': 0.07148947726583268, 'lambda_l2': 0.23183378983191053} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44213802236591365, 'max_depth': 66, 'num_leaves': 829, 'min_data_in_leaf': 34, 'lambda_l1': 0.017432701868128668, 'lambda_l2': 0.1445146871552196} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.18816052694716662, 'max_depth': 60, 'num_leaves': 888, 'min_data_in_leaf': 37, 'lambda_l1': 0.0006518968090965596, 'lambda_l2': 0.31654282228900454} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6015270813324143, 'max_depth': 71, 'num_leaves': 736, 'min_data_in_leaf': 32, 'lambda_l1': 0.08165381326930268, 'lambda_l2': 0.5749943959259171} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.509983893001005, 'max_depth': 69, 'num_leaves': 990, 'min_data_in_leaf': 37, 'lambda_l1': 0.03510523048717325, 'lambda_l2': 0.3669410727347985} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.35407827573396333, 'max_depth': 63, 'num_leaves': 774, 'min_data_in_leaf': 34, 'lambda_l1': 0.05549873391569366, 'lambda_l2': 0.0023336388788401663} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.30932971859061487, 'max_depth': 74, 'num_leaves': 659, 'min_data_in_leaf': 36, 'lambda_l1': 0.0007547247222568325, 'lambda_l2': 0.4459791530126542} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.24302018247592297, 'max_depth': 68, 'num_leaves': 903, 'min_data_in_leaf': 29, 'lambda_l1': 0.03697528309898577, 'lambda_l2': 0.20568463554142646} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3929678925652682, 'max_depth': 65, 'num_leaves': 836, 'min_data_in_leaf': 32, 'lambda_l1': 0.07907024499699947, 'lambda_l2': 0.09790424683085155} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.46398344396026603, 'max_depth': 62, 'num_leaves': 1002, 'min_data_in_leaf': 85, 'lambda_l1': 0.055700488913985005, 'lambda_l2': 0.30550778946104085} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.27804605868423105, 'max_depth': 71, 'num_leaves': 684, 'min_data_in_leaf': 38, 'lambda_l1': 0.030689952094140254, 'lambda_l2': 0.22389632871888043} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3340326182320498, 'max_depth': 60, 'num_leaves': 1121, 'min_data_in_leaf': 34, 'lambda_l1': 0.058320863907401335, 'lambda_l2': 0.435246584504348} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.40929283925403775, 'max_depth': 67, 'num_leaves': 776, 'min_data_in_leaf': 36, 'lambda_l1': 0.08650176283502559, 'lambda_l2': 1.0815897646491015} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3062728415077979, 'max_depth': 69, 'num_leaves': 926, 'min_data_in_leaf': 31, 'lambda_l1': 0.0004708293136172839, 'lambda_l2': 0.14201092195003506} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3603371546383961, 'max_depth': 72, 'num_leaves': 845, 'min_data_in_leaf': 38, 'lambda_l1': 0.030754746133034312, 'lambda_l2': 0.2983091117511261} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5397987145246466, 'max_depth': 65, 'num_leaves': 717, 'min_data_in_leaf': 35, 'lambda_l1': 0.04754237919711489, 'lambda_l2': 0.5309259251735834} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2555078678622355, 'max_depth': 62, 'num_leaves': 935, 'min_data_in_leaf': 33, 'lambda_l1': 0.018767171390946063, 'lambda_l2': 0.08982551739183875} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4474327778166088, 'max_depth': 67, 'num_leaves': 646, 'min_data_in_leaf': 37, 'lambda_l1': 0.06959313054963606, 'lambda_l2': 0.38144282915113226} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.20611019412689466, 'max_depth': 75, 'num_leaves': 1069, 'min_data_in_leaf': 81, 'lambda_l1': 0.047008693891334365, 'lambda_l2': 0.23322709826072754} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3656691466445182, 'max_depth': 70, 'num_leaves': 783, 'min_data_in_leaf': 35, 'lambda_l1': 0.08683280048491901, 'lambda_l2': 0.17068024322733857} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2965487290307654, 'max_depth': 64, 'num_leaves': 1186, 'min_data_in_leaf': 26, 'lambda_l1': 0.02826478145821361, 'lambda_l2': 0.0005861096053224879} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4103036700396534, 'max_depth': 60, 'num_leaves': 866, 'min_data_in_leaf': 38, 'lambda_l1': 0.22975430003121758, 'lambda_l2': 0.6070532987768469} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.022538907176958417, 'max_depth': 73, 'num_leaves': 3354, 'min_data_in_leaf': 30, 'lambda_l1': 0.06396044533869552, 'lambda_l2': 0.3233003430554074} : acc= 55.83%\n",
            "[HPO] metrics with {'learning_rate': 0.6982296625370641, 'max_depth': 67, 'num_leaves': 748, 'min_data_in_leaf': 33, 'lambda_l1': 0.022647361455561857, 'lambda_l2': 0.7851326141673476} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3339544944702021, 'max_depth': 70, 'num_leaves': 1003, 'min_data_in_leaf': 36, 'lambda_l1': 0.07289852189592631, 'lambda_l2': 0.48328096872453946} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2364889769181522, 'max_depth': 65, 'num_leaves': 841, 'min_data_in_leaf': 38, 'lambda_l1': 0.04601933935412894, 'lambda_l2': 0.26228891034312707} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5049802547995693, 'max_depth': 63, 'num_leaves': 652, 'min_data_in_leaf': 34, 'lambda_l1': 0.0004346680038926701, 'lambda_l2': 0.3941335749788874} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2741034541062448, 'max_depth': 69, 'num_leaves': 922, 'min_data_in_leaf': 32, 'lambda_l1': 0.018033512889181456, 'lambda_l2': 0.15497780754247467} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.150752198893741, 'max_depth': 72, 'num_leaves': 785, 'min_data_in_leaf': 36, 'lambda_l1': 0.08938011530163374, 'lambda_l2': 0.08738917754531424} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3622279629649281, 'max_depth': 77, 'num_leaves': 1258, 'min_data_in_leaf': 28, 'lambda_l1': 0.04633596448850363, 'lambda_l2': 0.2798793662310319} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.311687702326642, 'max_depth': 67, 'num_leaves': 700, 'min_data_in_leaf': 38, 'lambda_l1': 0.06344853922036464, 'lambda_l2': 0.4142874396783231} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44141335978602136, 'max_depth': 61, 'num_leaves': 1022, 'min_data_in_leaf': 34, 'lambda_l1': 0.031521463530021575, 'lambda_l2': 0.191478718999274} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5947029403529096, 'max_depth': 69, 'num_leaves': 842, 'min_data_in_leaf': 31, 'lambda_l1': 0.09137094272686475, 'lambda_l2': 0.5069106612233829} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.37800703926650914, 'max_depth': 65, 'num_leaves': 926, 'min_data_in_leaf': 36, 'lambda_l1': 0.01784234537054898, 'lambda_l2': 0.323197552265337} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.31769066969529414, 'max_depth': 63, 'num_leaves': 648, 'min_data_in_leaf': 39, 'lambda_l1': 0.04641761324088403, 'lambda_l2': 0.6550297491647553} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.27561371672791907, 'max_depth': 74, 'num_leaves': 748, 'min_data_in_leaf': 34, 'lambda_l1': 0.0641678326145756, 'lambda_l2': 0.23234791136162233} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4153435206211122, 'max_depth': 60, 'num_leaves': 1109, 'min_data_in_leaf': 37, 'lambda_l1': 0.03293612686048759, 'lambda_l2': 0.08568161295941173} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.05556698773191589, 'max_depth': 67, 'num_leaves': 970, 'min_data_in_leaf': 33, 'lambda_l1': 0.018586468055949636, 'lambda_l2': 0.3967346734676336} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7775276115601606, 'max_depth': 71, 'num_leaves': 856, 'min_data_in_leaf': 30, 'lambda_l1': 0.0781600193304826, 'lambda_l2': 0.30857339052741184} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4993499633476149, 'max_depth': 66, 'num_leaves': 743, 'min_data_in_leaf': 35, 'lambda_l1': 0.0005896561266957256, 'lambda_l2': 0.0004538822033607892} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.35213265405991734, 'max_depth': 69, 'num_leaves': 632, 'min_data_in_leaf': 39, 'lambda_l1': 0.05209268444734738, 'lambda_l2': 0.205595478519078} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.251710489533099, 'max_depth': 79, 'num_leaves': 807, 'min_data_in_leaf': 37, 'lambda_l1': 0.03533636030105549, 'lambda_l2': 0.46657429880285783} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.31250158067532674, 'max_depth': 62, 'num_leaves': 1348, 'min_data_in_leaf': 32, 'lambda_l1': 0.06594775508177056, 'lambda_l2': 0.14066958095642482} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.389437499951089, 'max_depth': 72, 'num_leaves': 903, 'min_data_in_leaf': 35, 'lambda_l1': 0.09028810777259627, 'lambda_l2': 0.36475281947234495} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.0012177787625257685, 'max_depth': 97, 'num_leaves': 1036, 'min_data_in_leaf': 38, 'lambda_l1': 0.01744919119074207, 'lambda_l2': 0.2502869931542452} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4754554474349564, 'max_depth': 64, 'num_leaves': 707, 'min_data_in_leaf': 33, 'lambda_l1': 0.6731778218488846, 'lambda_l2': 0.5531033354808833} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.21878396511539108, 'max_depth': 59, 'num_leaves': 809, 'min_data_in_leaf': 36, 'lambda_l1': 0.04555104089140705, 'lambda_l2': 0.09822086602833915} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5731182707121198, 'max_depth': 68, 'num_leaves': 981, 'min_data_in_leaf': 39, 'lambda_l1': 0.00017730564120589307, 'lambda_l2': 0.3300001182475355} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2936285943755585, 'max_depth': 71, 'num_leaves': 637, 'min_data_in_leaf': 31, 'lambda_l1': 0.06962532699291733, 'lambda_l2': 0.4338197326877335} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.35921066172371885, 'max_depth': 74, 'num_leaves': 894, 'min_data_in_leaf': 35, 'lambda_l1': 0.03246158748002742, 'lambda_l2': 0.18980475803986482} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.448991728857828, 'max_depth': 66, 'num_leaves': 728, 'min_data_in_leaf': 37, 'lambda_l1': 0.09417882337276501, 'lambda_l2': 0.2590649750000289} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.33073397004236943, 'max_depth': 62, 'num_leaves': 808, 'min_data_in_leaf': 29, 'lambda_l1': 0.04714206917072269, 'lambda_l2': 0.3707344469358195} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.26149224412364824, 'max_depth': 70, 'num_leaves': 1180, 'min_data_in_leaf': 33, 'lambda_l1': 0.062157381045355314, 'lambda_l2': 0.1569211465933848} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.400175680029468, 'max_depth': 76, 'num_leaves': 1088, 'min_data_in_leaf': 39, 'lambda_l1': 0.031045570536888167, 'lambda_l2': 0.6147517892266876} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.9978362062570286, 'max_depth': 65, 'num_leaves': 942, 'min_data_in_leaf': 35, 'lambda_l1': 0.07810106163507206, 'lambda_l2': 0.5004927373660734} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.30091801664593065, 'max_depth': 68, 'num_leaves': 852, 'min_data_in_leaf': 27, 'lambda_l1': 0.02315230556744208, 'lambda_l2': 0.08331210439812205} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3470738033908446, 'max_depth': 59, 'num_leaves': 637, 'min_data_in_leaf': 37, 'lambda_l1': 0.04955556381638225, 'lambda_l2': 0.25656725034734734} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5269333106224472, 'max_depth': 72, 'num_leaves': 776, 'min_data_in_leaf': 32, 'lambda_l1': 0.09635385140904755, 'lambda_l2': 0.32944505713026734} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4143506797048463, 'max_depth': 63, 'num_leaves': 735, 'min_data_in_leaf': 40, 'lambda_l1': 0.7243962953463431, 'lambda_l2': 0.42503104809640335} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.2278761373426823, 'max_depth': 67, 'num_leaves': 1000, 'min_data_in_leaf': 35, 'lambda_l1': 0.016371770913414525, 'lambda_l2': 0.16374787912259905} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6345655309569145, 'max_depth': 61, 'num_leaves': 886, 'min_data_in_leaf': 38, 'lambda_l1': 0.0586118977774519, 'lambda_l2': 0.27756793018098097} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2837118255346081, 'max_depth': 70, 'num_leaves': 714, 'min_data_in_leaf': 36, 'lambda_l1': 0.03326587502648868, 'lambda_l2': 0.4317600129522484} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.38041560704213245, 'max_depth': 65, 'num_leaves': 849, 'min_data_in_leaf': 34, 'lambda_l1': 0.0006263618849544281, 'lambda_l2': 0.16122153762924435} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.015520750386703488, 'max_depth': 73, 'num_leaves': 1075, 'min_data_in_leaf': 31, 'lambda_l1': 0.00022312405781290887, 'lambda_l2': 0.09282598015535051} : acc= 53.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4613947231462863, 'max_depth': 69, 'num_leaves': 633, 'min_data_in_leaf': 39, 'lambda_l1': 0.07828705669012928, 'lambda_l2': 0.3263710352752346} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3212715744022674, 'max_depth': 64, 'num_leaves': 954, 'min_data_in_leaf': 33, 'lambda_l1': 0.048507288714570794, 'lambda_l2': 1.546315211256672} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2614948287090729, 'max_depth': 68, 'num_leaves': 814, 'min_data_in_leaf': 37, 'lambda_l1': 0.09668393794814494, 'lambda_l2': 0.5422229786645493} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35142746392398916, 'max_depth': 59, 'num_leaves': 706, 'min_data_in_leaf': 40, 'lambda_l1': 0.030387887228395406, 'lambda_l2': 0.2337234501389555} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.423252322548399, 'max_depth': 66, 'num_leaves': 922, 'min_data_in_leaf': 35, 'lambda_l1': 0.06856977626660216, 'lambda_l2': 0.3704787530396631} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.30410496422759536, 'max_depth': 71, 'num_leaves': 787, 'min_data_in_leaf': 30, 'lambda_l1': 0.04001067050996124, 'lambda_l2': 0.9139261951865087} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4899020761899464, 'max_depth': 75, 'num_leaves': 643, 'min_data_in_leaf': 37, 'lambda_l1': 0.01612570984729126, 'lambda_l2': 0.6923437313550913} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.363385793959648, 'max_depth': 62, 'num_leaves': 1017, 'min_data_in_leaf': 33, 'lambda_l1': 0.05554121053527294, 'lambda_l2': 0.06778412715489165} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.19042314190408954, 'max_depth': 68, 'num_leaves': 1130, 'min_data_in_leaf': 39, 'lambda_l1': 0.0787977368331518, 'lambda_l2': 0.23664895437211916} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2701721196934671, 'max_depth': 73, 'num_leaves': 860, 'min_data_in_leaf': 51, 'lambda_l1': 0.03352486931569602, 'lambda_l2': 0.4671652447542507} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5578589842745086, 'max_depth': 60, 'num_leaves': 765, 'min_data_in_leaf': 35, 'lambda_l1': 0.10345890726344259, 'lambda_l2': 0.004138520304480198} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3278107443001648, 'max_depth': 66, 'num_leaves': 695, 'min_data_in_leaf': 37, 'lambda_l1': 0.060004218439423364, 'lambda_l2': 0.32097281032143954} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.0027717118170356206, 'max_depth': 70, 'num_leaves': 938, 'min_data_in_leaf': 32, 'lambda_l1': 4.286094807987029e-05, 'lambda_l2': 0.16552831866406773} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2401154016365264, 'max_depth': 64, 'num_leaves': 627, 'min_data_in_leaf': 40, 'lambda_l1': 0.02380956526477254, 'lambda_l2': 0.38225790166059276} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.42120400761337773, 'max_depth': 62, 'num_leaves': 870, 'min_data_in_leaf': 34, 'lambda_l1': 0.07823970981867302, 'lambda_l2': 0.5864995204593377} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3906215138207974, 'max_depth': 71, 'num_leaves': 781, 'min_data_in_leaf': 37, 'lambda_l1': 0.04758950253636638, 'lambda_l2': 0.20629707123077007} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3003012029892483, 'max_depth': 67, 'num_leaves': 1046, 'min_data_in_leaf': 30, 'lambda_l1': 0.01687030583415177, 'lambda_l2': 0.29418532505204237} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.34864877785976006, 'max_depth': 69, 'num_leaves': 3558, 'min_data_in_leaf': 35, 'lambda_l1': 0.06527271885848601, 'lambda_l2': 0.08401314712649932} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4688160309985342, 'max_depth': 65, 'num_leaves': 1235, 'min_data_in_leaf': 38, 'lambda_l1': 0.09731223034143573, 'lambda_l2': 0.488579675682157} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.25998378919085485, 'max_depth': 73, 'num_leaves': 706, 'min_data_in_leaf': 41, 'lambda_l1': 0.040177635493019274, 'lambda_l2': 0.2489825853133672} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.38654117028355456, 'max_depth': 60, 'num_leaves': 988, 'min_data_in_leaf': 33, 'lambda_l1': 0.017851067118855247, 'lambda_l2': 0.3922257565174106} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.669170189508534, 'max_depth': 63, 'num_leaves': 892, 'min_data_in_leaf': 39, 'lambda_l1': 0.051909536119515064, 'lambda_l2': 0.15148877170934003} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.31683442631708125, 'max_depth': 76, 'num_leaves': 825, 'min_data_in_leaf': 36, 'lambda_l1': 0.07987049374349889, 'lambda_l2': 0.3392116423781103} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2190720040560029, 'max_depth': 67, 'num_leaves': 627, 'min_data_in_leaf': 29, 'lambda_l1': 0.035544228904035934, 'lambda_l2': 0.48734185009472064} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5401135164900085, 'max_depth': 69, 'num_leaves': 774, 'min_data_in_leaf': 34, 'lambda_l1': 0.00044070684018876136, 'lambda_l2': 0.22602717542558634} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.2847933797579279, 'max_depth': 71, 'num_leaves': 928, 'min_data_in_leaf': 32, 'lambda_l1': 0.06264570541966072, 'lambda_l2': 0.7528406004097845} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.36241215407044086, 'max_depth': 64, 'num_leaves': 1116, 'min_data_in_leaf': 36, 'lambda_l1': 0.10165598964353607, 'lambda_l2': 0.06698460612755656} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.01949850124420908, 'max_depth': 61, 'num_leaves': 700, 'min_data_in_leaf': 38, 'lambda_l1': 0.018323694998287947, 'lambda_l2': 0.27943253113068145} : acc= 54.58%\n",
            "[HPO] metrics with {'learning_rate': 0.011148051382835434, 'max_depth': 66, 'num_leaves': 843, 'min_data_in_leaf': 41, 'lambda_l1': 0.041013489253981565, 'lambda_l2': 0.4180135365985429} : acc= 49.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4334836731447725, 'max_depth': 59, 'num_leaves': 984, 'min_data_in_leaf': 34, 'lambda_l1': 0.08416857554510626, 'lambda_l2': 0.1316270117470792} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5852621657312725, 'max_depth': 59, 'num_leaves': 914, 'min_data_in_leaf': 37, 'lambda_l1': 0.11069610133129539, 'lambda_l2': 0.07294701232851028} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5067391908637666, 'max_depth': 59, 'num_leaves': 951, 'min_data_in_leaf': 39, 'lambda_l1': 0.11392704020059988, 'lambda_l2': 0.09754407641557347} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5155463352926997, 'max_depth': 60, 'num_leaves': 859, 'min_data_in_leaf': 36, 'lambda_l1': 0.09900806069302504, 'lambda_l2': 0.0047208133862050305} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.61627823926551, 'max_depth': 59, 'num_leaves': 784, 'min_data_in_leaf': 40, 'lambda_l1': 0.09735125466315056, 'lambda_l2': 0.004002922522899355} : acc= 41.67%\n",
            "[HPO] metrics with {'learning_rate': 0.48477530534835866, 'max_depth': 59, 'num_leaves': 865, 'min_data_in_leaf': 35, 'lambda_l1': 0.11702842852408687, 'lambda_l2': 0.002838662058210234} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.06894435544518251, 'max_depth': 61, 'num_leaves': 951, 'min_data_in_leaf': 37, 'lambda_l1': 0.08771688772305672, 'lambda_l2': 0.12921132293193016} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4812246005935446, 'max_depth': 60, 'num_leaves': 800, 'min_data_in_leaf': 38, 'lambda_l1': 0.10444469146995011, 'lambda_l2': 0.14722712691370182} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.46555921968547326, 'max_depth': 58, 'num_leaves': 712, 'min_data_in_leaf': 49, 'lambda_l1': 0.0843634457820076, 'lambda_l2': 0.08940314981376002} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5889523030861371, 'max_depth': 58, 'num_leaves': 977, 'min_data_in_leaf': 42, 'lambda_l1': 0.10072283876354844, 'lambda_l2': 0.14565701729861852} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5333117255938054, 'max_depth': 61, 'num_leaves': 881, 'min_data_in_leaf': 35, 'lambda_l1': 0.13194959168672218, 'lambda_l2': 0.16619726039555488} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4421453287794605, 'max_depth': 59, 'num_leaves': 623, 'min_data_in_leaf': 40, 'lambda_l1': 0.08634652275562962, 'lambda_l2': 0.08305876961586667} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.43545489170540214, 'max_depth': 62, 'num_leaves': 761, 'min_data_in_leaf': 34, 'lambda_l1': 0.08164217775426358, 'lambda_l2': 0.1949368632028625} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.44461804112653885, 'max_depth': 59, 'num_leaves': 809, 'min_data_in_leaf': 38, 'lambda_l1': 0.12334129147555677, 'lambda_l2': 0.1790450565515462} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6626599997493259, 'max_depth': 61, 'num_leaves': 889, 'min_data_in_leaf': 36, 'lambda_l1': 0.10689147404356855, 'lambda_l2': 0.07153934313099067} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5708164867739847, 'max_depth': 62, 'num_leaves': 704, 'min_data_in_leaf': 34, 'lambda_l1': 0.08081717687598118, 'lambda_l2': 0.2104319196749233} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7354342906220652, 'max_depth': 58, 'num_leaves': 1008, 'min_data_in_leaf': 39, 'lambda_l1': 0.09123569060972034, 'lambda_l2': 0.09909623483694345} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5149913679227055, 'max_depth': 63, 'num_leaves': 766, 'min_data_in_leaf': 36, 'lambda_l1': 0.07314030689249164, 'lambda_l2': 0.22835818180183048} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4326811684701044, 'max_depth': 59, 'num_leaves': 626, 'min_data_in_leaf': 32, 'lambda_l1': 0.10891443425047403, 'lambda_l2': 0.15494865912136913} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.42296830727897905, 'max_depth': 61, 'num_leaves': 925, 'min_data_in_leaf': 42, 'lambda_l1': 0.08106646164479447, 'lambda_l2': 0.004835320163365151} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.523746467500078, 'max_depth': 61, 'num_leaves': 836, 'min_data_in_leaf': 38, 'lambda_l1': 0.07332150403367384, 'lambda_l2': 0.25199571087073785} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.8322351063410209, 'max_depth': 63, 'num_leaves': 728, 'min_data_in_leaf': 34, 'lambda_l1': 0.12511463894666353, 'lambda_l2': 0.2684154486812756} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.42298032710669026, 'max_depth': 58, 'num_leaves': 971, 'min_data_in_leaf': 40, 'lambda_l1': 0.09676800232383273, 'lambda_l2': 0.16117984789011292} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4895652706587988, 'max_depth': 63, 'num_leaves': 850, 'min_data_in_leaf': 36, 'lambda_l1': 0.06957802247865073, 'lambda_l2': 0.27507786112489485} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.005271034966461639, 'max_depth': 59, 'num_leaves': 678, 'min_data_in_leaf': 32, 'lambda_l1': 0.06934810077106178, 'lambda_l2': 0.0665771182568353} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.0010331644930922606, 'max_depth': 64, 'num_leaves': 769, 'min_data_in_leaf': 37, 'lambda_l1': 0.09376155403559076, 'lambda_l2': 0.18819800633973519} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.410496195751322, 'max_depth': 61, 'num_leaves': 900, 'min_data_in_leaf': 34, 'lambda_l1': 0.11248791449375097, 'lambda_l2': 0.10966425385968648} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.46765601231477333, 'max_depth': 63, 'num_leaves': 627, 'min_data_in_leaf': 41, 'lambda_l1': 0.08419700499253495, 'lambda_l2': 0.2989489408465123} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.40555352796858934, 'max_depth': 59, 'num_leaves': 1014, 'min_data_in_leaf': 38, 'lambda_l1': 0.06459679946692891, 'lambda_l2': 0.2120691928869745} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.54682026258169, 'max_depth': 61, 'num_leaves': 2919, 'min_data_in_leaf': 35, 'lambda_l1': 0.06396829178440276, 'lambda_l2': 0.002730364679224417} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.39087041337807854, 'max_depth': 64, 'num_leaves': 813, 'min_data_in_leaf': 39, 'lambda_l1': 0.10270451248035754, 'lambda_l2': 0.3016448358744037} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6278076015386852, 'max_depth': 65, 'num_leaves': 945, 'min_data_in_leaf': 55, 'lambda_l1': 0.06576248340040286, 'lambda_l2': 0.14321922322356295} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.46676632966168885, 'max_depth': 62, 'num_leaves': 693, 'min_data_in_leaf': 31, 'lambda_l1': 0.1365906860482203, 'lambda_l2': 0.3173065312311976} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3954961461434021, 'max_depth': 64, 'num_leaves': 845, 'min_data_in_leaf': 36, 'lambda_l1': 0.08636286884758473, 'lambda_l2': 0.21726401723464994} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3739022835049624, 'max_depth': 59, 'num_leaves': 740, 'min_data_in_leaf': 33, 'lambda_l1': 0.06005824209857798, 'lambda_l2': 0.11024533114477877} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4590042130334191, 'max_depth': 61, 'num_leaves': 894, 'min_data_in_leaf': 43, 'lambda_l1': 0.08377928151050665, 'lambda_l2': 0.002588482253254365} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5793447623143764, 'max_depth': 66, 'num_leaves': 622, 'min_data_in_leaf': 37, 'lambda_l1': 0.12510115463218638, 'lambda_l2': 0.28967854417595307} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3823861827585106, 'max_depth': 65, 'num_leaves': 803, 'min_data_in_leaf': 40, 'lambda_l1': 0.05670083461378744, 'lambda_l2': 0.3673472673778053} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4507908993477489, 'max_depth': 61, 'num_leaves': 1027, 'min_data_in_leaf': 34, 'lambda_l1': 0.10347135558989184, 'lambda_l2': 0.20125039572271822} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.36063844534723827, 'max_depth': 63, 'num_leaves': 700, 'min_data_in_leaf': 31, 'lambda_l1': 0.05789593455803059, 'lambda_l2': 0.11179166824048391} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.40047368346964485, 'max_depth': 58, 'num_leaves': 959, 'min_data_in_leaf': 38, 'lambda_l1': 0.07394324467064821, 'lambda_l2': 0.34282642152370707} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3544221596745268, 'max_depth': 66, 'num_leaves': 602, 'min_data_in_leaf': 36, 'lambda_l1': 0.04835087684455873, 'lambda_l2': 0.2241971505872361} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.6945606666513304, 'max_depth': 58, 'num_leaves': 771, 'min_data_in_leaf': 41, 'lambda_l1': 0.08768794387982139, 'lambda_l2': 0.0969077354135886} : acc= 62.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5071237018370447, 'max_depth': 63, 'num_leaves': 888, 'min_data_in_leaf': 34, 'lambda_l1': 0.1090085547445867, 'lambda_l2': 0.32791791394736125} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.43517828432147193, 'max_depth': 65, 'num_leaves': 817, 'min_data_in_leaf': 38, 'lambda_l1': 0.051109696357442023, 'lambda_l2': 0.2291731805000681} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.35405651888265693, 'max_depth': 60, 'num_leaves': 720, 'min_data_in_leaf': 35, 'lambda_l1': 0.07204646107903218, 'lambda_l2': 0.38105655346267203} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5644764907110664, 'max_depth': 67, 'num_leaves': 988, 'min_data_in_leaf': 45, 'lambda_l1': 0.061016738253678496, 'lambda_l2': 0.1421965968560182} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4101577211104492, 'max_depth': 62, 'num_leaves': 874, 'min_data_in_leaf': 33, 'lambda_l1': 0.11529379620272001, 'lambda_l2': 0.22346976188880507} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5010994480859002, 'max_depth': 64, 'num_leaves': 633, 'min_data_in_leaf': 71, 'lambda_l1': 0.09112995242536445, 'lambda_l2': 0.29235178409542945} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.35196252286195984, 'max_depth': 68, 'num_leaves': 762, 'min_data_in_leaf': 40, 'lambda_l1': 0.048337901462301804, 'lambda_l2': 0.08462923046365145} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.40866938815261583, 'max_depth': 58, 'num_leaves': 1035, 'min_data_in_leaf': 10, 'lambda_l1': 0.076715716889975, 'lambda_l2': 0.39804396995461816} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.33800621099322686, 'max_depth': 66, 'num_leaves': 918, 'min_data_in_leaf': 36, 'lambda_l1': 0.04391964660541992, 'lambda_l2': 0.16888633960960192} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4596371393832719, 'max_depth': 60, 'num_leaves': 689, 'min_data_in_leaf': 29, 'lambda_l1': 0.06560003731394694, 'lambda_l2': 0.30603750580329087} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6103054285562283, 'max_depth': 62, 'num_leaves': 815, 'min_data_in_leaf': 32, 'lambda_l1': 0.13256738347464858, 'lambda_l2': 1.9879788554903732} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3790004870777378, 'max_depth': 67, 'num_leaves': 1760, 'min_data_in_leaf': 38, 'lambda_l1': 0.09442962875216215, 'lambda_l2': 0.08194016341607793} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3432512688182729, 'max_depth': 64, 'num_leaves': 617, 'min_data_in_leaf': 42, 'lambda_l1': 0.04794495163478744, 'lambda_l2': 0.3938949846970386} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5094986541083751, 'max_depth': 57, 'num_leaves': 1856, 'min_data_in_leaf': 36, 'lambda_l1': 0.03855385399770947, 'lambda_l2': 0.24758172345467472} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.41413939501457303, 'max_depth': 65, 'num_leaves': 949, 'min_data_in_leaf': 31, 'lambda_l1': 0.07581248330409061, 'lambda_l2': 0.17478784130759126} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32724578197679804, 'max_depth': 68, 'num_leaves': 852, 'min_data_in_leaf': 34, 'lambda_l1': 0.05508271684222952, 'lambda_l2': 0.29206630723464383} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.44737639609560137, 'max_depth': 62, 'num_leaves': 759, 'min_data_in_leaf': 7, 'lambda_l1': 0.08825335548669083, 'lambda_l2': 0.43590150146566725} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6550619973555707, 'max_depth': 60, 'num_leaves': 645, 'min_data_in_leaf': 13, 'lambda_l1': 0.1337226978116795, 'lambda_l2': 0.5106702657957283} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5714138988749422, 'max_depth': 61, 'num_leaves': 598, 'min_data_in_leaf': 6, 'lambda_l1': 0.09682653800244637, 'lambda_l2': 0.5267159329754454} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5140973532384163, 'max_depth': 62, 'num_leaves': 703, 'min_data_in_leaf': 7, 'lambda_l1': 0.14647271738581785, 'lambda_l2': 0.46393804033992075} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6089124311156747, 'max_depth': 60, 'num_leaves': 690, 'min_data_in_leaf': 1, 'lambda_l1': 0.12852733973208155, 'lambda_l2': 0.5731517731407182} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4650988751666455, 'max_depth': 59, 'num_leaves': 615, 'min_data_in_leaf': 5, 'lambda_l1': 0.10479251819431623, 'lambda_l2': 0.495133773487906} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5615827169753587, 'max_depth': 61, 'num_leaves': 732, 'min_data_in_leaf': 60, 'lambda_l1': 0.11043677901398827, 'lambda_l2': 0.4285032240512012} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.48149082368207075, 'max_depth': 58, 'num_leaves': 692, 'min_data_in_leaf': 11, 'lambda_l1': 0.10934912037416351, 'lambda_l2': 0.5911070188661376} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7372278930466363, 'max_depth': 62, 'num_leaves': 772, 'min_data_in_leaf': 54, 'lambda_l1': 0.11752464264147296, 'lambda_l2': 0.42318965477479387} : acc= 64.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5205008394824668, 'max_depth': 63, 'num_leaves': 623, 'min_data_in_leaf': 16, 'lambda_l1': 0.12354123688319385, 'lambda_l2': 0.4441370391612418} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.0036596694850008814, 'max_depth': 60, 'num_leaves': 746, 'min_data_in_leaf': 88, 'lambda_l1': 0.14133490901594264, 'lambda_l2': 0.3959235454082953} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4763344329267573, 'max_depth': 63, 'num_leaves': 594, 'min_data_in_leaf': 62, 'lambda_l1': 0.10385812553873566, 'lambda_l2': 0.5724978414181572} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5154259814193372, 'max_depth': 57, 'num_leaves': 678, 'min_data_in_leaf': 5, 'lambda_l1': 0.11675456433705536, 'lambda_l2': 0.4861579559695688} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5932922301577206, 'max_depth': 62, 'num_leaves': 755, 'min_data_in_leaf': 53, 'lambda_l1': 0.08845390962839554, 'lambda_l2': 0.37691034446255134} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.44717773812279504, 'max_depth': 59, 'num_leaves': 775, 'min_data_in_leaf': 43, 'lambda_l1': 0.09246607966977213, 'lambda_l2': 0.35907615071818866} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5267468831806339, 'max_depth': 63, 'num_leaves': 681, 'min_data_in_leaf': 15, 'lambda_l1': 0.09113952583149576, 'lambda_l2': 0.45749433153527297} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.45315821213966534, 'max_depth': 61, 'num_leaves': 599, 'min_data_in_leaf': 16, 'lambda_l1': 0.10146712476811529, 'lambda_l2': 0.32958314379715237} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6783958208165116, 'max_depth': 59, 'num_leaves': 802, 'min_data_in_leaf': 7, 'lambda_l1': 0.11863921998152256, 'lambda_l2': 0.3660153003180182} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.552713066815758, 'max_depth': 57, 'num_leaves': 710, 'min_data_in_leaf': 47, 'lambda_l1': 0.08198714709531746, 'lambda_l2': 0.6190329544994015} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4366967708811835, 'max_depth': 64, 'num_leaves': 772, 'min_data_in_leaf': 12, 'lambda_l1': 0.14301409150552513, 'lambda_l2': 0.23353036825157553} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4685402650231405, 'max_depth': 62, 'num_leaves': 691, 'min_data_in_leaf': 46, 'lambda_l1': 0.08237235342571325, 'lambda_l2': 0.07410338439741644} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4211330932882526, 'max_depth': 63, 'num_leaves': 818, 'min_data_in_leaf': 17, 'lambda_l1': 0.11500250120408484, 'lambda_l2': 0.48981544486794} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.543884536627318, 'max_depth': 60, 'num_leaves': 635, 'min_data_in_leaf': 3, 'lambda_l1': 0.0929962672662488, 'lambda_l2': 0.1789573354746761} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.656603777184178, 'max_depth': 58, 'num_leaves': 590, 'min_data_in_leaf': 14, 'lambda_l1': 0.07994071357117682, 'lambda_l2': 0.311847098758795} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.41487810262775826, 'max_depth': 64, 'num_leaves': 756, 'min_data_in_leaf': 10, 'lambda_l1': 0.1641134019358939, 'lambda_l2': 0.41871633473726716} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.48740877333000776, 'max_depth': 61, 'num_leaves': 826, 'min_data_in_leaf': 7, 'lambda_l1': 0.07335955131803401, 'lambda_l2': 0.0046991320604417575} : acc= 61.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4148070148719072, 'max_depth': 64, 'num_leaves': 677, 'min_data_in_leaf': 50, 'lambda_l1': 0.190425568737278, 'lambda_l2': 0.24506241118440775} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5743441546872569, 'max_depth': 59, 'num_leaves': 758, 'min_data_in_leaf': 47, 'lambda_l1': 0.10754684013017264, 'lambda_l2': 0.5264210528856959} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.48006816431246524, 'max_depth': 61, 'num_leaves': 855, 'min_data_in_leaf': 10, 'lambda_l1': 0.12058705789358588, 'lambda_l2': 0.1667937340397846} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.8449974968469959, 'max_depth': 64, 'num_leaves': 583, 'min_data_in_leaf': 56, 'lambda_l1': 0.07427614215139985, 'lambda_l2': 0.345421359279674} : acc= 63.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3927586414595595, 'max_depth': 62, 'num_leaves': 691, 'min_data_in_leaf': 70, 'lambda_l1': 0.09666960427993995, 'lambda_l2': 0.27498501921118984} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.39372756941706105, 'max_depth': 65, 'num_leaves': 823, 'min_data_in_leaf': 59, 'lambda_l1': 0.07190548604739645, 'lambda_l2': 0.09017613392678196} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4699016986821603, 'max_depth': 57, 'num_leaves': 748, 'min_data_in_leaf': 14, 'lambda_l1': 0.06766971407267262, 'lambda_l2': 1.8864121642125926} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.39501642885106725, 'max_depth': 60, 'num_leaves': 848, 'min_data_in_leaf': 26, 'lambda_l1': 0.13178962622922183, 'lambda_l2': 0.41368873261330324} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6211204063322782, 'max_depth': 62, 'num_leaves': 589, 'min_data_in_leaf': 67, 'lambda_l1': 0.0902931841526095, 'lambda_l2': 0.15743984017496598} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44589994439403563, 'max_depth': 65, 'num_leaves': 667, 'min_data_in_leaf': 50, 'lambda_l1': 0.06077754123383961, 'lambda_l2': 0.0075554839787454866} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5053340372280477, 'max_depth': 59, 'num_leaves': 745, 'min_data_in_leaf': 18, 'lambda_l1': 0.09930845846268645, 'lambda_l2': 0.25716337855877003} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.7501703607135151, 'max_depth': 57, 'num_leaves': 819, 'min_data_in_leaf': 58, 'lambda_l1': 0.06544442721529467, 'lambda_l2': 0.36355718000445036} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.38617832362042676, 'max_depth': 63, 'num_leaves': 893, 'min_data_in_leaf': 65, 'lambda_l1': 0.08235522203330287, 'lambda_l2': 0.0024506022940088412} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.37841675624337323, 'max_depth': 65, 'num_leaves': 679, 'min_data_in_leaf': 49, 'lambda_l1': 0.11666885381032607, 'lambda_l2': 0.5241473872839862} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5471093135771234, 'max_depth': 66, 'num_leaves': 745, 'min_data_in_leaf': 11, 'lambda_l1': 0.05789869961400673, 'lambda_l2': 0.17343556768589996} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.41418706867989447, 'max_depth': 60, 'num_leaves': 599, 'min_data_in_leaf': 78, 'lambda_l1': 0.14087990916340554, 'lambda_l2': 0.30993528892622263} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.459756102480311, 'max_depth': 64, 'num_leaves': 886, 'min_data_in_leaf': 63, 'lambda_l1': 0.09034500607501252, 'lambda_l2': 0.6296069106876709} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.38784470951348526, 'max_depth': 61, 'num_leaves': 813, 'min_data_in_leaf': 45, 'lambda_l1': 0.03902812958022955, 'lambda_l2': 0.45997120010586856} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.36233749038182106, 'max_depth': 57, 'num_leaves': 946, 'min_data_in_leaf': 51, 'lambda_l1': 0.5706040746758164, 'lambda_l2': 0.2293898385327399} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5130528566657769, 'max_depth': 63, 'num_leaves': 685, 'min_data_in_leaf': 5, 'lambda_l1': 0.07057871012632339, 'lambda_l2': 0.09619844333686453} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4316593215744073, 'max_depth': 66, 'num_leaves': 753, 'min_data_in_leaf': 44, 'lambda_l1': 0.27162041469250825, 'lambda_l2': 0.3691142428753218} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3519844723406257, 'max_depth': 62, 'num_leaves': 831, 'min_data_in_leaf': 42, 'lambda_l1': 0.052523644544495006, 'lambda_l2': 0.25514020051048447} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.029502152413667024, 'max_depth': 59, 'num_leaves': 600, 'min_data_in_leaf': 3, 'lambda_l1': 0.10837502480640496, 'lambda_l2': 0.4464464849369696} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5979894382052588, 'max_depth': 66, 'num_leaves': 926, 'min_data_in_leaf': 8, 'lambda_l1': 0.03555577432872278, 'lambda_l2': 0.15937718215848332} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.43621482835225434, 'max_depth': 64, 'num_leaves': 782, 'min_data_in_leaf': 25, 'lambda_l1': 0.08336713980078948, 'lambda_l2': 0.2972473161698882} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3500098355204601, 'max_depth': 61, 'num_leaves': 686, 'min_data_in_leaf': 14, 'lambda_l1': 0.0634889687959465, 'lambda_l2': 0.07962099362942157} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4973746873043798, 'max_depth': 66, 'num_leaves': 861, 'min_data_in_leaf': 43, 'lambda_l1': 0.032467399590676446, 'lambda_l2': 0.5514227175646031} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3702313224697616, 'max_depth': 57, 'num_leaves': 762, 'min_data_in_leaf': 1, 'lambda_l1': 0.12722013252241687, 'lambda_l2': 0.39072055286283136} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.44736512817277574, 'max_depth': 62, 'num_leaves': 1039, 'min_data_in_leaf': 48, 'lambda_l1': 0.05347765236747616, 'lambda_l2': 0.1817303036341138} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.6646606173926699, 'max_depth': 65, 'num_leaves': 592, 'min_data_in_leaf': 10, 'lambda_l1': 0.10241033181317499, 'lambda_l2': 0.31952883824270695} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.5449590122798788, 'max_depth': 58, 'num_leaves': 908, 'min_data_in_leaf': 9, 'lambda_l1': 0.0799129583885514, 'lambda_l2': 0.22746453112760656} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3459706997849577, 'max_depth': 67, 'num_leaves': 991, 'min_data_in_leaf': 45, 'lambda_l1': 0.033543736743539054, 'lambda_l2': 0.4475530422412355} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3939505476283127, 'max_depth': 60, 'num_leaves': 693, 'min_data_in_leaf': 42, 'lambda_l1': 0.05660383416858395, 'lambda_l2': 0.0876793886180601} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.3270384162570561, 'max_depth': 63, 'num_leaves': 795, 'min_data_in_leaf': 40, 'lambda_l1': 0.02854648155291761, 'lambda_l2': 0.3293648116179177} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4356261246386324, 'max_depth': 64, 'num_leaves': 829, 'min_data_in_leaf': 3, 'lambda_l1': 0.07825053453290266, 'lambda_l2': 0.15935069500174526} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.37374771675716045, 'max_depth': 67, 'num_leaves': 902, 'min_data_in_leaf': 41, 'lambda_l1': 0.017723079637458887, 'lambda_l2': 0.6349564805305759} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.5016984167983852, 'max_depth': 60, 'num_leaves': 654, 'min_data_in_leaf': 42, 'lambda_l1': 0.049055198912173865, 'lambda_l2': 0.26334527049437023} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33540008875441296, 'max_depth': 63, 'num_leaves': 728, 'min_data_in_leaf': 12, 'lambda_l1': 0.154392857687225, 'lambda_l2': 0.4080781441771858} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.03944159433950788, 'max_depth': 66, 'num_leaves': 1048, 'min_data_in_leaf': 40, 'lambda_l1': 0.08901557130691412, 'lambda_l2': 0.5230757366986787} : acc= 62.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43805258089576743, 'max_depth': 56, 'num_leaves': 967, 'min_data_in_leaf': 39, 'lambda_l1': 0.03326330212035421, 'lambda_l2': 0.1828250402455353} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.31617430787395606, 'max_depth': 59, 'num_leaves': 860, 'min_data_in_leaf': 44, 'lambda_l1': 0.10071481365789471, 'lambda_l2': 0.08790587051941161} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6221726387438182, 'max_depth': 65, 'num_leaves': 593, 'min_data_in_leaf': 52, 'lambda_l1': 0.05943628173983724, 'lambda_l2': 0.3368012628957789} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.37961083342792246, 'max_depth': 62, 'num_leaves': 782, 'min_data_in_leaf': 13, 'lambda_l1': 0.11935886961608065, 'lambda_l2': 0.2434380323408094} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.007422412485353288, 'max_depth': 68, 'num_leaves': 2562, 'min_data_in_leaf': 68, 'lambda_l1': 0.06449913808438246, 'lambda_l2': 0.39706134397767356} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5207192153997023, 'max_depth': 61, 'num_leaves': 742, 'min_data_in_leaf': 40, 'lambda_l1': 0.018891820338861647, 'lambda_l2': 0.08566571187971536} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.32138528840609343, 'max_depth': 65, 'num_leaves': 650, 'min_data_in_leaf': 46, 'lambda_l1': 0.045899427706982965, 'lambda_l2': 0.23797681623725178} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.41653619921025775, 'max_depth': 58, 'num_leaves': 859, 'min_data_in_leaf': 39, 'lambda_l1': 0.0769019931172521, 'lambda_l2': 0.4951372381008144} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.36522657496093724, 'max_depth': 67, 'num_leaves': 939, 'min_data_in_leaf': 41, 'lambda_l1': 0.0200267463716777, 'lambda_l2': 1.770383225856775} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4719882678380327, 'max_depth': 63, 'num_leaves': 1064, 'min_data_in_leaf': 39, 'lambda_l1': 4.3279143005441056e-05, 'lambda_l2': 0.3091334723190174} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3188050763760662, 'max_depth': 68, 'num_leaves': 798, 'min_data_in_leaf': 43, 'lambda_l1': 0.10196612956349789, 'lambda_l2': 0.1659955973161678} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.40724081524595096, 'max_depth': 65, 'num_leaves': 680, 'min_data_in_leaf': 100, 'lambda_l1': 0.04406946000810089, 'lambda_l2': 0.3710634066678462} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.7638277024983653, 'max_depth': 61, 'num_leaves': 592, 'min_data_in_leaf': 38, 'lambda_l1': 0.07165904052007199, 'lambda_l2': 0.5849784234267031} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.10849762859798792, 'max_depth': 57, 'num_leaves': 989, 'min_data_in_leaf': 40, 'lambda_l1': 0.7473137537829733, 'lambda_l2': 0.09233531537985509} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5523675505002233, 'max_depth': 68, 'num_leaves': 884, 'min_data_in_leaf': 38, 'lambda_l1': 0.13456747128547092, 'lambda_l2': 0.2395013216137717} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.30158223048584587, 'max_depth': 59, 'num_leaves': 765, 'min_data_in_leaf': 82, 'lambda_l1': 0.035982353362682414, 'lambda_l2': 0.0009349612788957518} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.36771325406729644, 'max_depth': 64, 'num_leaves': 719, 'min_data_in_leaf': 41, 'lambda_l1': 0.05968606611579363, 'lambda_l2': 0.46489263621507576} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4575477958386844, 'max_depth': 66, 'num_leaves': 848, 'min_data_in_leaf': 26, 'lambda_l1': 0.09064179574335868, 'lambda_l2': 0.3218412736015704} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.33740082497269336, 'max_depth': 62, 'num_leaves': 1107, 'min_data_in_leaf': 2, 'lambda_l1': 0.8077710379464822, 'lambda_l2': 0.1508493160097395} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3831833914237416, 'max_depth': 68, 'num_leaves': 959, 'min_data_in_leaf': 38, 'lambda_l1': 0.01800656407842843, 'lambda_l2': 0.4189002867202935} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5588125722983514, 'max_depth': 56, 'num_leaves': 665, 'min_data_in_leaf': 42, 'lambda_l1': 0.0454657866764449, 'lambda_l2': 0.004725719008837047} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.4359715800617931, 'max_depth': 63, 'num_leaves': 820, 'min_data_in_leaf': 38, 'lambda_l1': 6.602011492883725e-05, 'lambda_l2': 0.23499217814436593} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29130092979535543, 'max_depth': 60, 'num_leaves': 905, 'min_data_in_leaf': 46, 'lambda_l1': 0.11095451107401426, 'lambda_l2': 1.3521951219427184} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.328831844592544, 'max_depth': 66, 'num_leaves': 600, 'min_data_in_leaf': 44, 'lambda_l1': 0.0825211472536424, 'lambda_l2': 0.35345927551719386} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.48363825192071974, 'max_depth': 64, 'num_leaves': 734, 'min_data_in_leaf': 40, 'lambda_l1': 0.031594847827969424, 'lambda_l2': 0.15601526703907503} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.39544390350774106, 'max_depth': 69, 'num_leaves': 994, 'min_data_in_leaf': 56, 'lambda_l1': 0.06504909306431572, 'lambda_l2': 0.2773376653593704} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.606462125294586, 'max_depth': 61, 'num_leaves': 809, 'min_data_in_leaf': 37, 'lambda_l1': 0.018502101745869345, 'lambda_l2': 0.4891284339995149} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3037105134035386, 'max_depth': 58, 'num_leaves': 668, 'min_data_in_leaf': 37, 'lambda_l1': 0.0485462307765466, 'lambda_l2': 0.6439652122942336} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3543506375926918, 'max_depth': 67, 'num_leaves': 913, 'min_data_in_leaf': 39, 'lambda_l1': 0.0947753069500858, 'lambda_l2': 0.18914488398198534} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4232255747169398, 'max_depth': 69, 'num_leaves': 578, 'min_data_in_leaf': 48, 'lambda_l1': 0.067526845396211, 'lambda_l2': 0.32706221781853634} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3517260795275871, 'max_depth': 62, 'num_leaves': 726, 'min_data_in_leaf': 42, 'lambda_l1': 0.032565436714756896, 'lambda_l2': 0.4453875336761881} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.4988473290054988, 'max_depth': 65, 'num_leaves': 2442, 'min_data_in_leaf': 37, 'lambda_l1': 0.17621932375371135, 'lambda_l2': 0.13596430375410884} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.27811946784424824, 'max_depth': 59, 'num_leaves': 818, 'min_data_in_leaf': 40, 'lambda_l1': 0.13144860730998909, 'lambda_l2': 0.25847925516499776} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6694900490424522, 'max_depth': 67, 'num_leaves': 1048, 'min_data_in_leaf': 37, 'lambda_l1': 0.049832732773492795, 'lambda_l2': 0.5632216519670463} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.40829244924331326, 'max_depth': 63, 'num_leaves': 883, 'min_data_in_leaf': 40, 'lambda_l1': 0.0774094300976878, 'lambda_l2': 0.382399281410282} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3146334283605873, 'max_depth': 69, 'num_leaves': 746, 'min_data_in_leaf': 37, 'lambda_l1': 0.019853673576061524, 'lambda_l2': 0.09871190869741794} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.47072469105335535, 'max_depth': 60, 'num_leaves': 1147, 'min_data_in_leaf': 43, 'lambda_l1': 0.11024003052090739, 'lambda_l2': 0.23782510328116047} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.359058190270241, 'max_depth': 64, 'num_leaves': 648, 'min_data_in_leaf': 39, 'lambda_l1': 0.03437705664600178, 'lambda_l2': 0.0005118629523925} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2985724309282546, 'max_depth': 57, 'num_leaves': 947, 'min_data_in_leaf': 36, 'lambda_l1': 6.169106777279085e-05, 'lambda_l2': 0.3212924344985315} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5489374039585029, 'max_depth': 67, 'num_leaves': 796, 'min_data_in_leaf': 41, 'lambda_l1': 0.05924180653050226, 'lambda_l2': 0.17614447889415388} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4044330875443331, 'max_depth': 65, 'num_leaves': 868, 'min_data_in_leaf': 38, 'lambda_l1': 0.08222130120865503, 'lambda_l2': 0.44184676596161504} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.34025531664168046, 'max_depth': 61, 'num_leaves': 3639, 'min_data_in_leaf': 39, 'lambda_l1': 0.030767384656382738, 'lambda_l2': 0.09428915249631933} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2783802176456537, 'max_depth': 69, 'num_leaves': 582, 'min_data_in_leaf': 74, 'lambda_l1': 0.053289507348826204, 'lambda_l2': 0.2906309123928847} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.44941343250696153, 'max_depth': 66, 'num_leaves': 1009, 'min_data_in_leaf': 36, 'lambda_l1': 0.019155540718914645, 'lambda_l2': 0.5377759839283499} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.37954289146706394, 'max_depth': 63, 'num_leaves': 722, 'min_data_in_leaf': 36, 'lambda_l1': 0.8798635008402956, 'lambda_l2': 0.39981069790054213} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.31394757525535116, 'max_depth': 59, 'num_leaves': 814, 'min_data_in_leaf': 42, 'lambda_l1': 0.09236909794017137, 'lambda_l2': 0.22486563961412762} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.49371365030513825, 'max_depth': 56, 'num_leaves': 662, 'min_data_in_leaf': 19, 'lambda_l1': 0.07055609353965647, 'lambda_l2': 0.3373979074499316} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3811342012817594, 'max_depth': 70, 'num_leaves': 1087, 'min_data_in_leaf': 45, 'lambda_l1': 0.11952264001932847, 'lambda_l2': 0.16169966071170966} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2697930880839506, 'max_depth': 68, 'num_leaves': 904, 'min_data_in_leaf': 91, 'lambda_l1': 0.046037855013401255, 'lambda_l2': 0.08271112776893658} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3348333049531726, 'max_depth': 62, 'num_leaves': 736, 'min_data_in_leaf': 54, 'lambda_l1': 0.10096782244690458, 'lambda_l2': 0.4959157184824847} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5931748325625522, 'max_depth': 64, 'num_leaves': 823, 'min_data_in_leaf': 72, 'lambda_l1': 0.1505148266248272, 'lambda_l2': 0.2525290473542669} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.44544352627904876, 'max_depth': 66, 'num_leaves': 977, 'min_data_in_leaf': 38, 'lambda_l1': 0.5876923670043908, 'lambda_l2': 0.3108181068561412} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.7302368977547451, 'max_depth': 80, 'num_leaves': 584, 'min_data_in_leaf': 36, 'lambda_l1': 0.033206262068974354, 'lambda_l2': 0.6656910824225774} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.061383721140684855, 'max_depth': 70, 'num_leaves': 891, 'min_data_in_leaf': 4, 'lambda_l1': 0.06778782141975723, 'lambda_l2': 0.3993586395677324} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.024840732522189504, 'max_depth': 61, 'num_leaves': 671, 'min_data_in_leaf': 40, 'lambda_l1': 0.017688132548309792, 'lambda_l2': 0.15733427012843385} : acc= 57.92%\n",
            "[HPO] metrics with {'learning_rate': 0.39764328135233085, 'max_depth': 58, 'num_leaves': 767, 'min_data_in_leaf': 35, 'lambda_l1': 0.04880889346635886, 'lambda_l2': 0.08370569706071226} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2986590155937072, 'max_depth': 68, 'num_leaves': 966, 'min_data_in_leaf': 38, 'lambda_l1': 0.00036457140146470626, 'lambda_l2': 0.24206316820068427} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5333549976600358, 'max_depth': 8, 'num_leaves': 860, 'min_data_in_leaf': 9, 'lambda_l1': 0.07967852794438372, 'lambda_l2': 0.4000889037151122} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.34869134629777093, 'max_depth': 65, 'num_leaves': 755, 'min_data_in_leaf': 27, 'lambda_l1': 0.05379159316533663, 'lambda_l2': 0.189561481858719} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4350250095193449, 'max_depth': 56, 'num_leaves': 1038, 'min_data_in_leaf': 62, 'lambda_l1': 0.01899493586195546, 'lambda_l2': 0.5268581692608645} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.277281433662794, 'max_depth': 5, 'num_leaves': 654, 'min_data_in_leaf': 43, 'lambda_l1': 0.09871548865955257, 'lambda_l2': 0.32835772884503855} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3351579564684568, 'max_depth': 72, 'num_leaves': 841, 'min_data_in_leaf': 36, 'lambda_l1': 0.03496239441433475, 'lambda_l2': 0.08145360181244027} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.38148043445604657, 'max_depth': 60, 'num_leaves': 1142, 'min_data_in_leaf': 41, 'lambda_l1': 0.11930553072528574, 'lambda_l2': 0.4427593324861223} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.24759086241984915, 'max_depth': 63, 'num_leaves': 937, 'min_data_in_leaf': 39, 'lambda_l1': 0.06852039534447643, 'lambda_l2': 0.27444686463631907} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.49366387820373914, 'max_depth': 66, 'num_leaves': 580, 'min_data_in_leaf': 35, 'lambda_l1': 0.04326455604198392, 'lambda_l2': 0.22429637663322302} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3047270095834737, 'max_depth': 70, 'num_leaves': 719, 'min_data_in_leaf': 38, 'lambda_l1': 0.08502381144349243, 'lambda_l2': 0.5767379071649663} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2465611731263184, 'max_depth': 67, 'num_leaves': 590, 'min_data_in_leaf': 40, 'lambda_l1': 0.12264383167078208, 'lambda_l2': 0.6613206784662792} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.1399479078859308, 'max_depth': 68, 'num_leaves': 625, 'min_data_in_leaf': 42, 'lambda_l1': 0.13432932534245862, 'lambda_l2': 0.5756665436073207} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2742168540475449, 'max_depth': 68, 'num_leaves': 669, 'min_data_in_leaf': 41, 'lambda_l1': 0.14540354688024798, 'lambda_l2': 0.0031180033611882263} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.2508111113430993, 'max_depth': 65, 'num_leaves': 566, 'min_data_in_leaf': 40, 'lambda_l1': 0.11479385845690547, 'lambda_l2': 0.35222044724848234} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.8676621854972021, 'max_depth': 69, 'num_leaves': 716, 'min_data_in_leaf': 43, 'lambda_l1': 0.10744464344249886, 'lambda_l2': 0.0012874694673459808} : acc= 50.00%\n",
            "[HPO] metrics with {'learning_rate': 0.21379022191616065, 'max_depth': 66, 'num_leaves': 669, 'min_data_in_leaf': 44, 'lambda_l1': 0.10117533992053822, 'lambda_l2': 0.16619456385715003} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.30474852868845775, 'max_depth': 70, 'num_leaves': 651, 'min_data_in_leaf': 39, 'lambda_l1': 0.13159276081116528, 'lambda_l2': 0.5275262008293482} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.2914147423611623, 'max_depth': 64, 'num_leaves': 584, 'min_data_in_leaf': 41, 'lambda_l1': 0.09441869569297606, 'lambda_l2': 0.32170914374607046} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.24268701932221262, 'max_depth': 67, 'num_leaves': 709, 'min_data_in_leaf': 39, 'lambda_l1': 0.11531431917845729, 'lambda_l2': 0.16063275880926864} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6125140246004038, 'max_depth': 62, 'num_leaves': 561, 'min_data_in_leaf': 8, 'lambda_l1': 0.20615591144049325, 'lambda_l2': 0.44582669791117213} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3654905752169052, 'max_depth': 69, 'num_leaves': 705, 'min_data_in_leaf': 38, 'lambda_l1': 0.09319715369479695, 'lambda_l2': 0.23310849406298756} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.29845347422686014, 'max_depth': 64, 'num_leaves': 649, 'min_data_in_leaf': 41, 'lambda_l1': 0.1515701433003494, 'lambda_l2': 0.3595875826604985} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4475454933506984, 'max_depth': 59, 'num_leaves': 742, 'min_data_in_leaf': 38, 'lambda_l1': 0.0866881415731207, 'lambda_l2': 0.1006256782023148} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.17051315213847082, 'max_depth': 67, 'num_leaves': 572, 'min_data_in_leaf': 43, 'lambda_l1': 0.12739344624086996, 'lambda_l2': 0.2876325914057272} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3385156219496365, 'max_depth': 62, 'num_leaves': 737, 'min_data_in_leaf': 38, 'lambda_l1': 0.8283562296980954, 'lambda_l2': 0.1680453516539058} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.541946411828781, 'max_depth': 65, 'num_leaves': 624, 'min_data_in_leaf': 40, 'lambda_l1': 0.16969998938851963, 'lambda_l2': 0.001336183136797675} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4163905878347959, 'max_depth': 70, 'num_leaves': 758, 'min_data_in_leaf': 38, 'lambda_l1': 0.10718216262028528, 'lambda_l2': 0.7377200410753482} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.28754307736929474, 'max_depth': 67, 'num_leaves': 667, 'min_data_in_leaf': 46, 'lambda_l1': 0.08756269609851122, 'lambda_l2': 0.4937066686880878} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.04782975067916184, 'max_depth': 60, 'num_leaves': 693, 'min_data_in_leaf': 41, 'lambda_l1': 0.08213415337016898, 'lambda_l2': 0.37100491599028884} : acc= 61.67%\n",
            "[HPO] metrics with {'learning_rate': 0.37700370348914874, 'max_depth': 63, 'num_leaves': 780, 'min_data_in_leaf': 37, 'lambda_l1': 0.1063498990349068, 'lambda_l2': 0.22169278112530097} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2629569782813632, 'max_depth': 56, 'num_leaves': 763, 'min_data_in_leaf': 39, 'lambda_l1': 0.07901807304675769, 'lambda_l2': 0.585416574156794} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3304958301694359, 'max_depth': 70, 'num_leaves': 574, 'min_data_in_leaf': 37, 'lambda_l1': 0.13451733375119956, 'lambda_l2': 0.09954802604899843} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.46004731438890917, 'max_depth': 58, 'num_leaves': 673, 'min_data_in_leaf': 42, 'lambda_l1': 0.09734374378767643, 'lambda_l2': 0.2797715787752126} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.6536956963221905, 'max_depth': 66, 'num_leaves': 743, 'min_data_in_leaf': 39, 'lambda_l1': 0.07281573440766005, 'lambda_l2': 0.44248244034509226} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3965697255432519, 'max_depth': 68, 'num_leaves': 642, 'min_data_in_leaf': 37, 'lambda_l1': 0.11555910993753497, 'lambda_l2': 0.15557600441466268} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5039939968780155, 'max_depth': 61, 'num_leaves': 798, 'min_data_in_leaf': 44, 'lambda_l1': 0.07331821444541135, 'lambda_l2': 0.2971528627750475} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3255219362355896, 'max_depth': 64, 'num_leaves': 714, 'min_data_in_leaf': 41, 'lambda_l1': 0.09283311411891093, 'lambda_l2': 0.3799592575312605} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.21891530650485064, 'max_depth': 69, 'num_leaves': 556, 'min_data_in_leaf': 37, 'lambda_l1': 0.06639898612391416, 'lambda_l2': 0.22214266859555853} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2684389933457169, 'max_depth': 65, 'num_leaves': 815, 'min_data_in_leaf': 40, 'lambda_l1': 0.25477630458201783, 'lambda_l2': 0.07566140861434247} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.37671133226866577, 'max_depth': 62, 'num_leaves': 642, 'min_data_in_leaf': 39, 'lambda_l1': 0.09855262847717039, 'lambda_l2': 0.4818086642286804} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4228954946895227, 'max_depth': 58, 'num_leaves': 775, 'min_data_in_leaf': 37, 'lambda_l1': 0.12038021968038953, 'lambda_l2': 0.3472458519665479} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3161788703954306, 'max_depth': 71, 'num_leaves': 572, 'min_data_in_leaf': 42, 'lambda_l1': 0.0628299960283223, 'lambda_l2': 0.17371108802308205} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5698834537918657, 'max_depth': 60, 'num_leaves': 702, 'min_data_in_leaf': 45, 'lambda_l1': 0.018650974230928555, 'lambda_l2': 0.2569006037589289} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3611161600332897, 'max_depth': 67, 'num_leaves': 803, 'min_data_in_leaf': 36, 'lambda_l1': 0.14815232480343438, 'lambda_l2': 0.4023468903518605} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.48604299821980074, 'max_depth': 69, 'num_leaves': 710, 'min_data_in_leaf': 39, 'lambda_l1': 0.018307122555992907, 'lambda_l2': 0.6091622339163998} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.28307096337665827, 'max_depth': 63, 'num_leaves': 819, 'min_data_in_leaf': 36, 'lambda_l1': 0.08206633167052552, 'lambda_l2': 0.10582939491923195} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4048349661831608, 'max_depth': 65, 'num_leaves': 651, 'min_data_in_leaf': 38, 'lambda_l1': 0.061918478399999186, 'lambda_l2': 0.2772057278039807} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.2368460389263773, 'max_depth': 67, 'num_leaves': 3250, 'min_data_in_leaf': 15, 'lambda_l1': 0.04627890622197783, 'lambda_l2': 0.5180623257995135} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3202008522123785, 'max_depth': 71, 'num_leaves': 565, 'min_data_in_leaf': 41, 'lambda_l1': 0.1115060780059839, 'lambda_l2': 0.17409406756860962} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.48109202471094464, 'max_depth': 61, 'num_leaves': 778, 'min_data_in_leaf': 36, 'lambda_l1': 0.08687444228807782, 'lambda_l2': 2.071275145818828} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.08768230039767971, 'max_depth': 57, 'num_leaves': 728, 'min_data_in_leaf': 43, 'lambda_l1': 0.0324856279498405, 'lambda_l2': 0.3719594464959623} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6833875087163873, 'max_depth': 64, 'num_leaves': 841, 'min_data_in_leaf': 39, 'lambda_l1': 0.06413411734928565, 'lambda_l2': 0.09063210125705222} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.35511907345224464, 'max_depth': 68, 'num_leaves': 607, 'min_data_in_leaf': 1, 'lambda_l1': 0.04376287907626234, 'lambda_l2': 0.2742000967263284} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2945787903843432, 'max_depth': 59, 'num_leaves': 804, 'min_data_in_leaf': 47, 'lambda_l1': 0.08127208914467002, 'lambda_l2': 0.4401728563272168} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4146191806967563, 'max_depth': 62, 'num_leaves': 659, 'min_data_in_leaf': 37, 'lambda_l1': 0.018268345305062186, 'lambda_l2': 0.0043353286276566205} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.5726664025990038, 'max_depth': 66, 'num_leaves': 741, 'min_data_in_leaf': 35, 'lambda_l1': 0.001164645484524461, 'lambda_l2': 0.2026352526879876} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2532741415150704, 'max_depth': 70, 'num_leaves': 832, 'min_data_in_leaf': 40, 'lambda_l1': 0.13680531781904612, 'lambda_l2': 0.3303642667051579} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.35571677191121925, 'max_depth': 56, 'num_leaves': 1966, 'min_data_in_leaf': 38, 'lambda_l1': 0.051302080284942764, 'lambda_l2': 0.16407579329987154} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.44014579263528025, 'max_depth': 65, 'num_leaves': 700, 'min_data_in_leaf': 36, 'lambda_l1': 0.10113987639626716, 'lambda_l2': 0.5870240818175885} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3089371388954557, 'max_depth': 69, 'num_leaves': 554, 'min_data_in_leaf': 79, 'lambda_l1': 0.03685052992190395, 'lambda_l2': 0.4053489725856623} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5265326174541105, 'max_depth': 61, 'num_leaves': 2701, 'min_data_in_leaf': 41, 'lambda_l1': 0.07430734927212743, 'lambda_l2': 0.28637099898013474} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3819629599621258, 'max_depth': 72, 'num_leaves': 852, 'min_data_in_leaf': 35, 'lambda_l1': 0.017184594363508113, 'lambda_l2': 0.00163675887141429} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.19938083105890675, 'max_depth': 95, 'num_leaves': 732, 'min_data_in_leaf': 44, 'lambda_l1': 0.056127183574346144, 'lambda_l2': 0.4960941149301203} : acc= 66.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2685591721988974, 'max_depth': 63, 'num_leaves': 664, 'min_data_in_leaf': 52, 'lambda_l1': 0.10591864522528732, 'lambda_l2': 0.1864276897116361} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.32503985599325647, 'max_depth': 59, 'num_leaves': 1406, 'min_data_in_leaf': 38, 'lambda_l1': 0.030263147025130742, 'lambda_l2': 0.7107873202984303} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.45351312640074043, 'max_depth': 67, 'num_leaves': 784, 'min_data_in_leaf': 37, 'lambda_l1': 0.08458561974864279, 'lambda_l2': 0.33522871016680084} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3572160080613773, 'max_depth': 66, 'num_leaves': 878, 'min_data_in_leaf': 42, 'lambda_l1': 0.12286196217660289, 'lambda_l2': 0.08993168032587864} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.8049784968439674, 'max_depth': 70, 'num_leaves': 630, 'min_data_in_leaf': 48, 'lambda_l1': 0.000756048104500754, 'lambda_l2': 0.23983393696157893} : acc= 65.00%\n",
            "[HPO] metrics with {'learning_rate': 0.41990959431815766, 'max_depth': 63, 'num_leaves': 769, 'min_data_in_leaf': 35, 'lambda_l1': 0.055825922557129454, 'lambda_l2': 0.41171044293575354} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.29219870236189527, 'max_depth': 60, 'num_leaves': 854, 'min_data_in_leaf': 40, 'lambda_l1': 0.034702513028873755, 'lambda_l2': 0.13818538635858021} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.22973820689084878, 'max_depth': 68, 'num_leaves': 573, 'min_data_in_leaf': 38, 'lambda_l1': 0.07153878290472773, 'lambda_l2': 0.2933461358665067} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5154708270151418, 'max_depth': 56, 'num_leaves': 716, 'min_data_in_leaf': 36, 'lambda_l1': 0.017881454896624963, 'lambda_l2': 0.5171149634266141} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3465902403044103, 'max_depth': 65, 'num_leaves': 894, 'min_data_in_leaf': 39, 'lambda_l1': 0.09561402261143734, 'lambda_l2': 0.21810616728921658} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3985059159092822, 'max_depth': 73, 'num_leaves': 639, 'min_data_in_leaf': 35, 'lambda_l1': 0.04728172049751676, 'lambda_l2': 0.41158821798918566} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5969040543144876, 'max_depth': 62, 'num_leaves': 807, 'min_data_in_leaf': 37, 'lambda_l1': 0.06617843776248168, 'lambda_l2': 0.08689270206703649} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.31158150874796353, 'max_depth': 71, 'num_leaves': 739, 'min_data_in_leaf': 12, 'lambda_l1': 0.03069286368734312, 'lambda_l2': 0.2990028721399015} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.27067028596660225, 'max_depth': 68, 'num_leaves': 882, 'min_data_in_leaf': 40, 'lambda_l1': 0.015394333855370201, 'lambda_l2': 0.19981983201269155} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4725015742807097, 'max_depth': 59, 'num_leaves': 2994, 'min_data_in_leaf': 35, 'lambda_l1': 0.08833167878831695, 'lambda_l2': 0.3602682654145555} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.37391816093815083, 'max_depth': 64, 'num_leaves': 790, 'min_data_in_leaf': 42, 'lambda_l1': 0.11766744899769463, 'lambda_l2': 0.0006873963468347021} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32852186199958805, 'max_depth': 66, 'num_leaves': 633, 'min_data_in_leaf': 38, 'lambda_l1': 0.04980539163582299, 'lambda_l2': 0.47619710179861674} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24910132882849612, 'max_depth': 70, 'num_leaves': 875, 'min_data_in_leaf': 45, 'lambda_l1': 0.07780814383925425, 'lambda_l2': 0.15056395814001897} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.43167147314356674, 'max_depth': 58, 'num_leaves': 690, 'min_data_in_leaf': 36, 'lambda_l1': 0.15602387794062633, 'lambda_l2': 0.5877971173859968} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.013421585673848853, 'max_depth': 61, 'num_leaves': 784, 'min_data_in_leaf': 39, 'lambda_l1': 0.033223372190961706, 'lambda_l2': 0.2711657180326349} : acc= 52.08%\n",
            "[HPO] metrics with {'learning_rate': 0.28991449051830087, 'max_depth': 68, 'num_leaves': 555, 'min_data_in_leaf': 34, 'lambda_l1': 0.06240024316562338, 'lambda_l2': 0.34700132173415654} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.372350914843657, 'max_depth': 63, 'num_leaves': 923, 'min_data_in_leaf': 41, 'lambda_l1': 0.10773055554667199, 'lambda_l2': 0.10077119543020802} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.5215204165064067, 'max_depth': 72, 'num_leaves': 730, 'min_data_in_leaf': 37, 'lambda_l1': 0.017448076668451606, 'lambda_l2': 0.24374613814778695} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.32808956932925437, 'max_depth': 55, 'num_leaves': 635, 'min_data_in_leaf': 35, 'lambda_l1': 0.04935904364623284, 'lambda_l2': 0.4394244370475005} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.6715363414047837, 'max_depth': 66, 'num_leaves': 830, 'min_data_in_leaf': 43, 'lambda_l1': 0.07691495571485485, 'lambda_l2': 0.34846099316345125} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.43433689295446826, 'max_depth': 69, 'num_leaves': 961, 'min_data_in_leaf': 39, 'lambda_l1': 0.016902220890360916, 'lambda_l2': 0.6514693350784875} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3952868877151047, 'max_depth': 64, 'num_leaves': 566, 'min_data_in_leaf': 37, 'lambda_l1': 0.03429827866474311, 'lambda_l2': 0.1735351108299014} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2878505050519163, 'max_depth': 60, 'num_leaves': 708, 'min_data_in_leaf': 34, 'lambda_l1': 0.09897655715400952, 'lambda_l2': 2.03641135050614e-05} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.49251165046340684, 'max_depth': 67, 'num_leaves': 845, 'min_data_in_leaf': 40, 'lambda_l1': 0.06535544638742766, 'lambda_l2': 0.5155568620695146} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.34342817419729854, 'max_depth': 71, 'num_leaves': 775, 'min_data_in_leaf': 35, 'lambda_l1': 0.13692283384911202, 'lambda_l2': 0.24977074236353813} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.23971639043277823, 'max_depth': 61, 'num_leaves': 927, 'min_data_in_leaf': 38, 'lambda_l1': 0.0469218182539023, 'lambda_l2': 0.1023505207050699} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6069220961114009, 'max_depth': 57, 'num_leaves': 666, 'min_data_in_leaf': 37, 'lambda_l1': 0.015506392035377889, 'lambda_l2': 0.37081965422523017} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.41860179258379976, 'max_depth': 65, 'num_leaves': 786, 'min_data_in_leaf': 42, 'lambda_l1': 0.09294906188245344, 'lambda_l2': 0.22889135460374477} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3225962514842106, 'max_depth': 74, 'num_leaves': 855, 'min_data_in_leaf': 34, 'lambda_l1': 0.0002871390727206616, 'lambda_l2': 0.4253189789405103} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.37123381870650135, 'max_depth': 63, 'num_leaves': 1006, 'min_data_in_leaf': 40, 'lambda_l1': 0.03491186069260883, 'lambda_l2': 0.14474202977949338} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.26665255228285434, 'max_depth': 69, 'num_leaves': 567, 'min_data_in_leaf': 36, 'lambda_l1': 0.07558039886949412, 'lambda_l2': 0.29938836701415605} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4575429196188808, 'max_depth': 67, 'num_leaves': 1188, 'min_data_in_leaf': 39, 'lambda_l1': 0.12798297659006552, 'lambda_l2': 0.5680062160478616} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.5360272031372671, 'max_depth': 58, 'num_leaves': 715, 'min_data_in_leaf': 44, 'lambda_l1': 0.0563623453227978, 'lambda_l2': 0.0998002009733129} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2086930086522632, 'max_depth': 83, 'num_leaves': 635, 'min_data_in_leaf': 34, 'lambda_l1': 0.039218255925471554, 'lambda_l2': 0.7897139526877925} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3061100592748009, 'max_depth': 2, 'num_leaves': 900, 'min_data_in_leaf': 37, 'lambda_l1': 0.09063849439973265, 'lambda_l2': 0.32007040861884406} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.36214587307925233, 'max_depth': 62, 'num_leaves': 765, 'min_data_in_leaf': 49, 'lambda_l1': 0.01603593750696615, 'lambda_l2': 0.4616595422911518} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4107260165187259, 'max_depth': 65, 'num_leaves': 831, 'min_data_in_leaf': 35, 'lambda_l1': 0.00042049479439526527, 'lambda_l2': 0.20000596852164607} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.2738188072869425, 'max_depth': 71, 'num_leaves': 1081, 'min_data_in_leaf': 41, 'lambda_l1': 0.06102183333362847, 'lambda_l2': 0.24559739636825212} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.48493081226903023, 'max_depth': 16, 'num_leaves': 715, 'min_data_in_leaf': 38, 'lambda_l1': 0.0002416177420234318, 'lambda_l2': 0.37183529122716075} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3307624587883899, 'max_depth': 60, 'num_leaves': 1701, 'min_data_in_leaf': 58, 'lambda_l1': 0.03356847128999421, 'lambda_l2': 0.0833230912410213} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.36705836037166345, 'max_depth': 55, 'num_leaves': 963, 'min_data_in_leaf': 36, 'lambda_l1': 0.10667303595920086, 'lambda_l2': 0.1968293012642583} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.29649979734168247, 'max_depth': 69, 'num_leaves': 625, 'min_data_in_leaf': 46, 'lambda_l1': 0.07592169190598783, 'lambda_l2': 0.4668588839324012} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.7538992118091165, 'max_depth': 64, 'num_leaves': 1266, 'min_data_in_leaf': 34, 'lambda_l1': 0.05721939642435987, 'lambda_l2': 0.31830051460863046} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.0015317788701832966, 'max_depth': 73, 'num_leaves': 553, 'min_data_in_leaf': 39, 'lambda_l1': 0.03466145696361517, 'lambda_l2': 0.0895392113993228} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.5728423815470042, 'max_depth': 67, 'num_leaves': 885, 'min_data_in_leaf': 43, 'lambda_l1': 0.12267516528250375, 'lambda_l2': 0.3791952507721439} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2371406134486882, 'max_depth': 62, 'num_leaves': 801, 'min_data_in_leaf': 97, 'lambda_l1': 0.08043368373956133, 'lambda_l2': 0.24182915912202374} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.4242628011967298, 'max_depth': 58, 'num_leaves': 702, 'min_data_in_leaf': 37, 'lambda_l1': 0.048930843549012254, 'lambda_l2': 0.6379902821910769} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33966581328201306, 'max_depth': 70, 'num_leaves': 1005, 'min_data_in_leaf': 41, 'lambda_l1': 0.018947773100272878, 'lambda_l2': 0.5119109223239224} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.47111348884387055, 'max_depth': 66, 'num_leaves': 872, 'min_data_in_leaf': 34, 'lambda_l1': 0.16668933889546245, 'lambda_l2': 0.18477709090426475} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.18930543219978244, 'max_depth': 64, 'num_leaves': 770, 'min_data_in_leaf': 36, 'lambda_l1': 0.10072016785068852, 'lambda_l2': 1.2149164229452505} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3885758315020865, 'max_depth': 60, 'num_leaves': 647, 'min_data_in_leaf': 39, 'lambda_l1': 7.920235331692477e-05, 'lambda_l2': 0.3165268869984879} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.26688302927019064, 'max_depth': 68, 'num_leaves': 948, 'min_data_in_leaf': 33, 'lambda_l1': 0.06679453140624139, 'lambda_l2': 0.09747124408922672} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3105886690805662, 'max_depth': 71, 'num_leaves': 547, 'min_data_in_leaf': 37, 'lambda_l1': 0.032328636036283755, 'lambda_l2': 0.4217258365337161} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3905217147228848, 'max_depth': 62, 'num_leaves': 716, 'min_data_in_leaf': 40, 'lambda_l1': 0.08383122348872252, 'lambda_l2': 1.426408917403267} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4516659933925101, 'max_depth': 73, 'num_leaves': 821, 'min_data_in_leaf': 35, 'lambda_l1': 0.05007147415482155, 'lambda_l2': 0.2546493090295281} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.53913225542284, 'max_depth': 65, 'num_leaves': 904, 'min_data_in_leaf': 38, 'lambda_l1': 0.11381370353933881, 'lambda_l2': 0.32639165739127085} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.323031805660155, 'max_depth': 68, 'num_leaves': 1062, 'min_data_in_leaf': 42, 'lambda_l1': 0.06492510906576508, 'lambda_l2': 0.001991585571995802} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.35546939679999645, 'max_depth': 57, 'num_leaves': 782, 'min_data_in_leaf': 34, 'lambda_l1': 0.026694571437353366, 'lambda_l2': 0.16963039534765856} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6410776521701473, 'max_depth': 60, 'num_leaves': 697, 'min_data_in_leaf': 36, 'lambda_l1': 0.24111513988222458, 'lambda_l2': 0.4281291337432546} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.28640932175525874, 'max_depth': 66, 'num_leaves': 843, 'min_data_in_leaf': 44, 'lambda_l1': 0.045772000770422774, 'lambda_l2': 0.5601619110740816} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4186279923865473, 'max_depth': 63, 'num_leaves': 615, 'min_data_in_leaf': 39, 'lambda_l1': 0.6118719840778097, 'lambda_l2': 0.1824498036354801} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.23658138259597364, 'max_depth': 70, 'num_leaves': 1131, 'min_data_in_leaf': 33, 'lambda_l1': 0.8506861341199519, 'lambda_l2': 0.2797725358911039} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4934835095178925, 'max_depth': 72, 'num_leaves': 927, 'min_data_in_leaf': 37, 'lambda_l1': 0.08976184091009434, 'lambda_l2': 0.10229600405008753} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.00409387520092098, 'max_depth': 68, 'num_leaves': 767, 'min_data_in_leaf': 41, 'lambda_l1': 0.06728973808504278, 'lambda_l2': 0.3787004664768388} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.35803847880020245, 'max_depth': 55, 'num_leaves': 543, 'min_data_in_leaf': 35, 'lambda_l1': 0.01873695137610075, 'lambda_l2': 0.5162659162723342} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3062569749851298, 'max_depth': 62, 'num_leaves': 1020, 'min_data_in_leaf': 38, 'lambda_l1': 0.13215083179319384, 'lambda_l2': 0.27845505523861525} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.2721555515148587, 'max_depth': 75, 'num_leaves': 668, 'min_data_in_leaf': 40, 'lambda_l1': 0.046480742676948565, 'lambda_l2': 0.1626906304901302} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4088108103967302, 'max_depth': 66, 'num_leaves': 856, 'min_data_in_leaf': 33, 'lambda_l1': 0.10676305616534924, 'lambda_l2': 0.4138608031082778} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.556442351203971, 'max_depth': 59, 'num_leaves': 746, 'min_data_in_leaf': 36, 'lambda_l1': 0.016576458517884834, 'lambda_l2': 0.0811046018845411} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3504482114418284, 'max_depth': 64, 'num_leaves': 953, 'min_data_in_leaf': 38, 'lambda_l1': 0.07918435878010952, 'lambda_l2': 0.2533225117275934} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.46619633939939037, 'max_depth': 69, 'num_leaves': 621, 'min_data_in_leaf': 42, 'lambda_l1': 0.0005649691369398538, 'lambda_l2': 0.3407748615842328} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.38596021817164083, 'max_depth': 61, 'num_leaves': 827, 'min_data_in_leaf': 33, 'lambda_l1': 0.04041174280088135, 'lambda_l2': 0.6490351254077518} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.25313666762558523, 'max_depth': 71, 'num_leaves': 709, 'min_data_in_leaf': 35, 'lambda_l1': 0.06080785192706765, 'lambda_l2': 0.16348192053861915} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3174589650564429, 'max_depth': 67, 'num_leaves': 1016, 'min_data_in_leaf': 8, 'lambda_l1': 0.031246109951575906, 'lambda_l2': 0.45962762808648194} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.21791264696478943, 'max_depth': 58, 'num_leaves': 900, 'min_data_in_leaf': 39, 'lambda_l1': 0.08316723468577258, 'lambda_l2': 0.23964313336333462} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.29086280649621066, 'max_depth': 64, 'num_leaves': 777, 'min_data_in_leaf': 24, 'lambda_l1': 0.10350277075991332, 'lambda_l2': 0.3168216612055115} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.44955595237061735, 'max_depth': 74, 'num_leaves': 551, 'min_data_in_leaf': 45, 'lambda_l1': 0.05379346202885942, 'lambda_l2': 0.52182401047416} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3735545711670744, 'max_depth': 69, 'num_leaves': 675, 'min_data_in_leaf': 37, 'lambda_l1': 0.14322347046090195, 'lambda_l2': 0.003039167341549298} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.5151355300109643, 'max_depth': 56, 'num_leaves': 833, 'min_data_in_leaf': 35, 'lambda_l1': 0.0003598481027715511, 'lambda_l2': 0.14646007424143925} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3335021812552681, 'max_depth': 61, 'num_leaves': 1176, 'min_data_in_leaf': 40, 'lambda_l1': 0.06868219743093709, 'lambda_l2': 0.36268353302357276} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.6651437304413945, 'max_depth': 66, 'num_leaves': 957, 'min_data_in_leaf': 33, 'lambda_l1': 0.024897999571734053, 'lambda_l2': 0.08196445755568277} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.415645409972369, 'max_depth': 63, 'num_leaves': 752, 'min_data_in_leaf': 37, 'lambda_l1': 0.09459487500144391, 'lambda_l2': 0.24014565543852354} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2703367519380003, 'max_depth': 72, 'num_leaves': 659, 'min_data_in_leaf': 42, 'lambda_l1': 0.03766443567405948, 'lambda_l2': 0.43571299291847027} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.33834580447986523, 'max_depth': 65, 'num_leaves': 1074, 'min_data_in_leaf': 18, 'lambda_l1': 0.11821262479168927, 'lambda_l2': 0.34342122949808507} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5833743812275074, 'max_depth': 59, 'num_leaves': 859, 'min_data_in_leaf': 36, 'lambda_l1': 0.05713469141141847, 'lambda_l2': 0.20873991948024087} : acc= 66.25%\n",
            "[HPO] metrics with {'learning_rate': 0.11851281385172709, 'max_depth': 70, 'num_leaves': 1346, 'min_data_in_leaf': 39, 'lambda_l1': 0.9592505004229237, 'lambda_l2': 0.15282475472574436} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.39393698902330726, 'max_depth': 67, 'num_leaves': 789, 'min_data_in_leaf': 33, 'lambda_l1': 0.07502856674046013, 'lambda_l2': 0.5780584670129013} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.03303003222491127, 'max_depth': 61, 'num_leaves': 606, 'min_data_in_leaf': 35, 'lambda_l1': 0.7002643448667001, 'lambda_l2': 0.2919676365328956} : acc= 60.00%\n",
            "[HPO] metrics with {'learning_rate': 0.45300428154567884, 'max_depth': 68, 'num_leaves': 912, 'min_data_in_leaf': 47, 'lambda_l1': 0.03009811810648965, 'lambda_l2': 0.700597497839593} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3075925734080456, 'max_depth': 22, 'num_leaves': 715, 'min_data_in_leaf': 43, 'lambda_l1': 0.04328548024204483, 'lambda_l2': 0.07430160578199774} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.24803778989487643, 'max_depth': 64, 'num_leaves': 989, 'min_data_in_leaf': 37, 'lambda_l1': 0.01994451947008423, 'lambda_l2': 0.4316505316567263} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.35249551088017556, 'max_depth': 70, 'num_leaves': 537, 'min_data_in_leaf': 40, 'lambda_l1': 0.08329600655099699, 'lambda_l2': 0.25940609952828625} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4608213457532852, 'max_depth': 58, 'num_leaves': 816, 'min_data_in_leaf': 32, 'lambda_l1': 0.0570927773256444, 'lambda_l2': 0.3720410137874182} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.29023491036450577, 'max_depth': 66, 'num_leaves': 720, 'min_data_in_leaf': 38, 'lambda_l1': 0.01770516007968906, 'lambda_l2': 1.6389063039066138} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.5155171450219421, 'max_depth': 73, 'num_leaves': 893, 'min_data_in_leaf': 35, 'lambda_l1': 0.10444594178013497, 'lambda_l2': 0.16697115612350333} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.4045937998623902, 'max_depth': 62, 'num_leaves': 622, 'min_data_in_leaf': 41, 'lambda_l1': 0.6566084167644327, 'lambda_l2': 0.5198445477891737} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.0023585955180108007, 'max_depth': 68, 'num_leaves': 1068, 'min_data_in_leaf': 38, 'lambda_l1': 0.045600521694272075, 'lambda_l2': 2.154649998392789} : acc= 47.92%\n",
            "[HPO] metrics with {'learning_rate': 0.35706592718095326, 'max_depth': 60, 'num_leaves': 782, 'min_data_in_leaf': 34, 'lambda_l1': 0.06665694186999185, 'lambda_l2': 0.08110623074018292} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3097476751608209, 'max_depth': 56, 'num_leaves': 695, 'min_data_in_leaf': 32, 'lambda_l1': 0.09027635192814287, 'lambda_l2': 0.293790039627589} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.7543959800474271, 'max_depth': 64, 'num_leaves': 965, 'min_data_in_leaf': 36, 'lambda_l1': 0.017814527999223582, 'lambda_l2': 0.21341734714766736} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3941360772243294, 'max_depth': 71, 'num_leaves': 844, 'min_data_in_leaf': 39, 'lambda_l1': 0.12588039748911858, 'lambda_l2': 0.40423892386410254} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.21390395367402823, 'max_depth': 66, 'num_leaves': 640, 'min_data_in_leaf': 37, 'lambda_l1': 0.03318780265787298, 'lambda_l2': 0.32913799185193904} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.6114335522852925, 'max_depth': 75, 'num_leaves': 760, 'min_data_in_leaf': 43, 'lambda_l1': 0.06837706260724985, 'lambda_l2': 0.5035142655032552} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2593400777546262, 'max_depth': 63, 'num_leaves': 535, 'min_data_in_leaf': 34, 'lambda_l1': 0.14669098505369849, 'lambda_l2': 0.002843397363024136} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3298551071041872, 'max_depth': 68, 'num_leaves': 893, 'min_data_in_leaf': 40, 'lambda_l1': 0.0002328358784787544, 'lambda_l2': 0.15976785960316517} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.5172970598853605, 'max_depth': 70, 'num_leaves': 1106, 'min_data_in_leaf': 36, 'lambda_l1': 0.2862216560885099, 'lambda_l2': 0.269596314034518} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.36674918048708155, 'max_depth': 60, 'num_leaves': 991, 'min_data_in_leaf': 94, 'lambda_l1': 0.04752642178453609, 'lambda_l2': 0.4230937740838762} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.43869464085404175, 'max_depth': 77, 'num_leaves': 808, 'min_data_in_leaf': 32, 'lambda_l1': 0.09333736387378767, 'lambda_l2': 0.08936379283764359} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.1719070319998135, 'max_depth': 55, 'num_leaves': 706, 'min_data_in_leaf': 64, 'lambda_l1': 0.03181673038322168, 'lambda_l2': 0.20790722184781044} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.28186707436883446, 'max_depth': 65, 'num_leaves': 887, 'min_data_in_leaf': 45, 'lambda_l1': 0.07246006575450147, 'lambda_l2': 0.6075167785577513} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32158599211788835, 'max_depth': 62, 'num_leaves': 625, 'min_data_in_leaf': 38, 'lambda_l1': 0.11114340442779777, 'lambda_l2': 0.33485648694057} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.43729111238698887, 'max_depth': 72, 'num_leaves': 744, 'min_data_in_leaf': 41, 'lambda_l1': 0.04447208886069827, 'lambda_l2': 0.0017226104208561345} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3779741128015285, 'max_depth': 58, 'num_leaves': 1242, 'min_data_in_leaf': 36, 'lambda_l1': 0.058446172310088286, 'lambda_l2': 0.16122945545592804} : acc= 64.58%\n",
            "[HPO] metrics with {'learning_rate': 0.23680180092898692, 'max_depth': 67, 'num_leaves': 811, 'min_data_in_leaf': 21, 'lambda_l1': 0.01860601970888943, 'lambda_l2': 0.4710535158889997} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.5449209489176672, 'max_depth': 69, 'num_leaves': 930, 'min_data_in_leaf': 34, 'lambda_l1': 0.08639590242374928, 'lambda_l2': 0.2502846011552613} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.29603763355478513, 'max_depth': 63, 'num_leaves': 558, 'min_data_in_leaf': 39, 'lambda_l1': 0.05290693822190857, 'lambda_l2': 0.37235394893692664} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.4686641123732183, 'max_depth': 66, 'num_leaves': 687, 'min_data_in_leaf': 35, 'lambda_l1': 0.12466953822310776, 'lambda_l2': 0.15219761641717966} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.3385585530885067, 'max_depth': 73, 'num_leaves': 1813, 'min_data_in_leaf': 38, 'lambda_l1': 0.01463318920183633, 'lambda_l2': 0.3260553338818761} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.4151403442353488, 'max_depth': 76, 'num_leaves': 2092, 'min_data_in_leaf': 44, 'lambda_l1': 0.012987360691467331, 'lambda_l2': 0.7188920070425042} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4906853458019039, 'max_depth': 74, 'num_leaves': 1205, 'min_data_in_leaf': 41, 'lambda_l1': 0.021847363597471147, 'lambda_l2': 0.6013350753675282} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.37457650658273944, 'max_depth': 76, 'num_leaves': 1202, 'min_data_in_leaf': 43, 'lambda_l1': 0.009508661735368346, 'lambda_l2': 0.5333684034779774} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.6062551306833355, 'max_depth': 76, 'num_leaves': 1619, 'min_data_in_leaf': 41, 'lambda_l1': 0.014743292718234133, 'lambda_l2': 0.5208461196500178} : acc= 62.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4187247100567917, 'max_depth': 78, 'num_leaves': 1819, 'min_data_in_leaf': 40, 'lambda_l1': 0.0027752101440631227, 'lambda_l2': 0.4658411398246313} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3581170796964854, 'max_depth': 73, 'num_leaves': 1494, 'min_data_in_leaf': 38, 'lambda_l1': 0.013658913460667776, 'lambda_l2': 0.3961557840581926} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.9184344175113285, 'max_depth': 72, 'num_leaves': 1570, 'min_data_in_leaf': 46, 'lambda_l1': 2.8996510855715252e-05, 'lambda_l2': 0.6173773085626273} : acc= 65.42%\n",
            "[HPO] metrics with {'learning_rate': 0.5038139734997589, 'max_depth': 79, 'num_leaves': 2595, 'min_data_in_leaf': 49, 'lambda_l1': 0.0012333626328313307, 'lambda_l2': 0.47365482581540697} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.40800863341014243, 'max_depth': 77, 'num_leaves': 1419, 'min_data_in_leaf': 43, 'lambda_l1': 0.019467118926266007, 'lambda_l2': 0.4039382251023955} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.6940520456529079, 'max_depth': 75, 'num_leaves': 2762, 'min_data_in_leaf': 39, 'lambda_l1': 0.0183615397042831, 'lambda_l2': 0.32922566080119336} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.34869709801388504, 'max_depth': 73, 'num_leaves': 1466, 'min_data_in_leaf': 42, 'lambda_l1': 0.015232049665990002, 'lambda_l2': 0.47183779226174233} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3215786945416092, 'max_depth': 78, 'num_leaves': 1920, 'min_data_in_leaf': 39, 'lambda_l1': 0.031870567869302396, 'lambda_l2': 0.8459154886654501} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4511476068475476, 'max_depth': 73, 'num_leaves': 1349, 'min_data_in_leaf': 37, 'lambda_l1': 0.017784530828093788, 'lambda_l2': 0.37167057064056297} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3798822770018981, 'max_depth': 75, 'num_leaves': 1708, 'min_data_in_leaf': 41, 'lambda_l1': 0.029027245342899712, 'lambda_l2': 0.5386922149403744} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.5706050281482468, 'max_depth': 74, 'num_leaves': 1157, 'min_data_in_leaf': 31, 'lambda_l1': 3.87691978767056e-05, 'lambda_l2': 0.31377640009779106} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.27996226144732045, 'max_depth': 75, 'num_leaves': 2093, 'min_data_in_leaf': 37, 'lambda_l1': 0.03309236398294179, 'lambda_l2': 0.3820135080490669} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4836649694748047, 'max_depth': 75, 'num_leaves': 2411, 'min_data_in_leaf': 4, 'lambda_l1': 0.001257756831689126, 'lambda_l2': 0.454811688405367} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.32966804709719166, 'max_depth': 73, 'num_leaves': 1135, 'min_data_in_leaf': 39, 'lambda_l1': 0.03328866268962909, 'lambda_l2': 0.6290025090121556} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.4047988649703898, 'max_depth': 74, 'num_leaves': 1052, 'min_data_in_leaf': 35, 'lambda_l1': 0.1784956461116593, 'lambda_l2': 0.28435401357816026} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.28855872830168317, 'max_depth': 76, 'num_leaves': 1005, 'min_data_in_leaf': 30, 'lambda_l1': 0.1381634671152384, 'lambda_l2': 0.4331776198168482} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3604566492376312, 'max_depth': 81, 'num_leaves': 2190, 'min_data_in_leaf': 33, 'lambda_l1': 0.16796281704016275, 'lambda_l2': 0.5285407495062684} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2640570704556463, 'max_depth': 80, 'num_leaves': 2514, 'min_data_in_leaf': 28, 'lambda_l1': 0.1472491222490655, 'lambda_l2': 0.38744279894868894} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3374963814785895, 'max_depth': 79, 'num_leaves': 1132, 'min_data_in_leaf': 51, 'lambda_l1': 0.16176072147529158, 'lambda_l2': 0.4549075735720401} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.301416497209115, 'max_depth': 78, 'num_leaves': 1288, 'min_data_in_leaf': 16, 'lambda_l1': 0.18206207101121935, 'lambda_l2': 0.3702875319599715} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.39366022329829614, 'max_depth': 76, 'num_leaves': 1228, 'min_data_in_leaf': 33, 'lambda_l1': 0.11867453834900957, 'lambda_l2': 0.5723537951516133} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3216993507384868, 'max_depth': 77, 'num_leaves': 1074, 'min_data_in_leaf': 31, 'lambda_l1': 0.14618024712183686, 'lambda_l2': 0.328407641781483} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.37698477935185476, 'max_depth': 76, 'num_leaves': 1220, 'min_data_in_leaf': 34, 'lambda_l1': 0.14428955161120932, 'lambda_l2': 0.43913488093196984} : acc= 73.33%\n",
            "[HPO] metrics with {'learning_rate': 0.2623219418874132, 'max_depth': 81, 'num_leaves': 1162, 'min_data_in_leaf': 26, 'lambda_l1': 0.13517845665680062, 'lambda_l2': 0.6817708347981343} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3071659849158515, 'max_depth': 76, 'num_leaves': 1289, 'min_data_in_leaf': 29, 'lambda_l1': 0.14331981511356529, 'lambda_l2': 0.7072759348564119} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.340481731626915, 'max_depth': 76, 'num_leaves': 1201, 'min_data_in_leaf': 32, 'lambda_l1': 0.20900045089935848, 'lambda_l2': 0.6542733543877135} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.280409993920431, 'max_depth': 77, 'num_leaves': 1359, 'min_data_in_leaf': 31, 'lambda_l1': 0.14379714322189346, 'lambda_l2': 0.5716544504920549} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.23520357140330098, 'max_depth': 82, 'num_leaves': 1636, 'min_data_in_leaf': 32, 'lambda_l1': 0.1734763433230911, 'lambda_l2': 0.5146478909635985} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3034734372545614, 'max_depth': 79, 'num_leaves': 1106, 'min_data_in_leaf': 54, 'lambda_l1': 0.17199515484494, 'lambda_l2': 0.611559052566273} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.35798793742023205, 'max_depth': 78, 'num_leaves': 2274, 'min_data_in_leaf': 29, 'lambda_l1': 0.19614600192359505, 'lambda_l2': 0.7827925300785159} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.32138286570191993, 'max_depth': 80, 'num_leaves': 2333, 'min_data_in_leaf': 34, 'lambda_l1': 0.1468472496224782, 'lambda_l2': 0.5633774188144305} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2689822151458514, 'max_depth': 81, 'num_leaves': 1790, 'min_data_in_leaf': 31, 'lambda_l1': 0.1548214200721326, 'lambda_l2': 0.544787795030776} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.37985517982227324, 'max_depth': 78, 'num_leaves': 1321, 'min_data_in_leaf': 33, 'lambda_l1': 0.1790374354813905, 'lambda_l2': 0.7106355309260226} : acc= 72.92%\n",
            "[HPO] metrics with {'learning_rate': 0.23910870937685735, 'max_depth': 77, 'num_leaves': 1979, 'min_data_in_leaf': 34, 'lambda_l1': 0.10775798352265176, 'lambda_l2': 0.4762866642776568} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.35258893587502027, 'max_depth': 77, 'num_leaves': 1286, 'min_data_in_leaf': 35, 'lambda_l1': 0.174663589755463, 'lambda_l2': 0.6014355907313413} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.29918704852916084, 'max_depth': 80, 'num_leaves': 1487, 'min_data_in_leaf': 28, 'lambda_l1': 0.16427949146358997, 'lambda_l2': 0.49515895649408126} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.21030842251003856, 'max_depth': 75, 'num_leaves': 1860, 'min_data_in_leaf': 32, 'lambda_l1': 0.19595735889371274, 'lambda_l2': 0.4735858649782351} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3575039697887127, 'max_depth': 74, 'num_leaves': 1150, 'min_data_in_leaf': 35, 'lambda_l1': 0.16534536509449815, 'lambda_l2': 0.4661993645758987} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.2686412119796155, 'max_depth': 73, 'num_leaves': 1296, 'min_data_in_leaf': 33, 'lambda_l1': 0.1541411096151741, 'lambda_l2': 0.5713499071534357} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.32384012498136594, 'max_depth': 79, 'num_leaves': 1205, 'min_data_in_leaf': 36, 'lambda_l1': 0.14908600518630652, 'lambda_l2': 0.4479933828765834} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.37240101774392453, 'max_depth': 78, 'num_leaves': 1188, 'min_data_in_leaf': 30, 'lambda_l1': 0.14217153315463724, 'lambda_l2': 0.657023921357697} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3056593605812663, 'max_depth': 83, 'num_leaves': 1265, 'min_data_in_leaf': 45, 'lambda_l1': 0.12565531725581494, 'lambda_l2': 0.39953383776688445} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3910251439922634, 'max_depth': 75, 'num_leaves': 1244, 'min_data_in_leaf': 34, 'lambda_l1': 0.1442121723756302, 'lambda_l2': 0.47725162878111693} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.24786990683046714, 'max_depth': 75, 'num_leaves': 1397, 'min_data_in_leaf': 37, 'lambda_l1': 0.15295171624380036, 'lambda_l2': 0.414787626382923} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32816632865377865, 'max_depth': 76, 'num_leaves': 1377, 'min_data_in_leaf': 35, 'lambda_l1': 0.1365590299180332, 'lambda_l2': 0.7723499435138197} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.3017356993711238, 'max_depth': 85, 'num_leaves': 1212, 'min_data_in_leaf': 42, 'lambda_l1': 0.16676744019671086, 'lambda_l2': 0.5102030917136795} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3907069720690985, 'max_depth': 80, 'num_leaves': 1262, 'min_data_in_leaf': 31, 'lambda_l1': 0.13487949233307084, 'lambda_l2': 0.5667812268815481} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.07426000089747022, 'max_depth': 78, 'num_leaves': 1332, 'min_data_in_leaf': 38, 'lambda_l1': 0.16635986931070004, 'lambda_l2': 0.41025745586392787} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.350870897895083, 'max_depth': 77, 'num_leaves': 1547, 'min_data_in_leaf': 40, 'lambda_l1': 0.10731728017449414, 'lambda_l2': 0.3873861647166269} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.27011480255767867, 'max_depth': 77, 'num_leaves': 1272, 'min_data_in_leaf': 33, 'lambda_l1': 0.12534332759230818, 'lambda_l2': 0.3620056297351572} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.39930825157369754, 'max_depth': 79, 'num_leaves': 1789, 'min_data_in_leaf': 48, 'lambda_l1': 0.23319649243239937, 'lambda_l2': 0.6453798143104753} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.29379421156821645, 'max_depth': 75, 'num_leaves': 1078, 'min_data_in_leaf': 37, 'lambda_l1': 0.16585151984642568, 'lambda_l2': 0.5183775136936319} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.19903669358673462, 'max_depth': 74, 'num_leaves': 1269, 'min_data_in_leaf': 35, 'lambda_l1': 0.1806373499124559, 'lambda_l2': 0.35734213794788955} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.016403428646259006, 'max_depth': 76, 'num_leaves': 1119, 'min_data_in_leaf': 44, 'lambda_l1': 0.137323759696589, 'lambda_l2': 0.37366288728299535} : acc= 53.75%\n",
            "[HPO] metrics with {'learning_rate': 0.3379854898596504, 'max_depth': 78, 'num_leaves': 1169, 'min_data_in_leaf': 26, 'lambda_l1': 0.13506821309288505, 'lambda_l2': 0.4565310697577699} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.40711904463017373, 'max_depth': 77, 'num_leaves': 1156, 'min_data_in_leaf': 40, 'lambda_l1': 0.16027670025236543, 'lambda_l2': 0.5423091037538919} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.25582311783136324, 'max_depth': 74, 'num_leaves': 1118, 'min_data_in_leaf': 36, 'lambda_l1': 0.1951844288185064, 'lambda_l2': 0.31935100238416747} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3427890116007534, 'max_depth': 76, 'num_leaves': 1652, 'min_data_in_leaf': 32, 'lambda_l1': 0.18492325807083032, 'lambda_l2': 0.42716364300509285} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.29059323235288015, 'max_depth': 74, 'num_leaves': 1121, 'min_data_in_leaf': 6, 'lambda_l1': 0.12356947793243991, 'lambda_l2': 0.32847816987410366} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.41198553954532574, 'max_depth': 74, 'num_leaves': 1216, 'min_data_in_leaf': 77, 'lambda_l1': 0.18660626621533447, 'lambda_l2': 0.6113993763126562} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.3583595793137744, 'max_depth': 79, 'num_leaves': 1104, 'min_data_in_leaf': 38, 'lambda_l1': 0.15334807060936104, 'lambda_l2': 0.4574556480555473} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3206201438333024, 'max_depth': 77, 'num_leaves': 1141, 'min_data_in_leaf': 34, 'lambda_l1': 0.12541829225745185, 'lambda_l2': 0.3364646041200977} : acc= 74.17%\n",
            "[HPO] metrics with {'learning_rate': 0.22388844415142867, 'max_depth': 80, 'num_leaves': 1365, 'min_data_in_leaf': 35, 'lambda_l1': 0.17650604713252727, 'lambda_l2': 0.5772056298986548} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.28242517473412687, 'max_depth': 79, 'num_leaves': 1032, 'min_data_in_leaf': 29, 'lambda_l1': 0.2172491075009383, 'lambda_l2': 0.5065157798942914} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.32839942090019303, 'max_depth': 82, 'num_leaves': 1246, 'min_data_in_leaf': 28, 'lambda_l1': 0.16259654354615902, 'lambda_l2': 0.7411691445238298} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.24606505886095692, 'max_depth': 81, 'num_leaves': 1353, 'min_data_in_leaf': 31, 'lambda_l1': 0.14906663113722166, 'lambda_l2': 0.4752352559714193} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.39473467961105063, 'max_depth': 83, 'num_leaves': 1158, 'min_data_in_leaf': 32, 'lambda_l1': 0.15713335386684577, 'lambda_l2': 0.6567872644753212} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.4346325454297385, 'max_depth': 78, 'num_leaves': 1181, 'min_data_in_leaf': 31, 'lambda_l1': 0.14199175040586587, 'lambda_l2': 0.8898686454562617} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.30133942593319313, 'max_depth': 79, 'num_leaves': 1192, 'min_data_in_leaf': 33, 'lambda_l1': 0.12523747007080033, 'lambda_l2': 1.0411022358914426} : acc= 67.08%\n",
            "[HPO] metrics with {'learning_rate': 0.3660372557809475, 'max_depth': 78, 'num_leaves': 1240, 'min_data_in_leaf': 30, 'lambda_l1': 0.13561864123009812, 'lambda_l2': 0.5548759202321507} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2648739216845347, 'max_depth': 77, 'num_leaves': 1282, 'min_data_in_leaf': 33, 'lambda_l1': 0.15321987425300115, 'lambda_l2': 0.4243022955115304} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.33052128051021973, 'max_depth': 79, 'num_leaves': 1180, 'min_data_in_leaf': 33, 'lambda_l1': 0.1262995776503056, 'lambda_l2': 0.4359995052541119} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.440115865971553, 'max_depth': 83, 'num_leaves': 1211, 'min_data_in_leaf': 29, 'lambda_l1': 0.13410389534504297, 'lambda_l2': 0.5237265687419159} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3732841450359872, 'max_depth': 77, 'num_leaves': 1319, 'min_data_in_leaf': 32, 'lambda_l1': 0.16686860665105507, 'lambda_l2': 0.3786017755180451} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.3003892306509806, 'max_depth': 77, 'num_leaves': 1154, 'min_data_in_leaf': 30, 'lambda_l1': 0.138717988928607, 'lambda_l2': 0.37493669174662925} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.4161705842464475, 'max_depth': 76, 'num_leaves': 1168, 'min_data_in_leaf': 34, 'lambda_l1': 0.1290616278320731, 'lambda_l2': 0.47257708389288133} : acc= 72.50%\n",
            "[HPO] metrics with {'learning_rate': 0.22759486595641693, 'max_depth': 80, 'num_leaves': 1985, 'min_data_in_leaf': 34, 'lambda_l1': 0.1613928350265162, 'lambda_l2': 1.5110121274870323} : acc= 67.50%\n",
            "[HPO] metrics with {'learning_rate': 0.34847893138536457, 'max_depth': 76, 'num_leaves': 1240, 'min_data_in_leaf': 32, 'lambda_l1': 0.12263238975121933, 'lambda_l2': 0.35287247716099657} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.29195511097064497, 'max_depth': 80, 'num_leaves': 1183, 'min_data_in_leaf': 34, 'lambda_l1': 0.19781639432205206, 'lambda_l2': 0.564515586978132} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.3732369625622878, 'max_depth': 76, 'num_leaves': 1885, 'min_data_in_leaf': 31, 'lambda_l1': 0.17992055568824086, 'lambda_l2': 0.6529965288188331} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.044611277335549294, 'max_depth': 75, 'num_leaves': 1294, 'min_data_in_leaf': 27, 'lambda_l1': 0.12831161107340017, 'lambda_l2': 0.41582330391239936} : acc= 61.67%\n",
            "[HPO] metrics with {'learning_rate': 0.26219634055308233, 'max_depth': 82, 'num_leaves': 1120, 'min_data_in_leaf': 34, 'lambda_l1': 0.12510566470209578, 'lambda_l2': 0.3236315414873199} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.44476363571726585, 'max_depth': 77, 'num_leaves': 1401, 'min_data_in_leaf': 35, 'lambda_l1': 0.11917032577918928, 'lambda_l2': 0.47228639020436997} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.34478255236263045, 'max_depth': 77, 'num_leaves': 1092, 'min_data_in_leaf': 32, 'lambda_l1': 0.15382468406055524, 'lambda_l2': 0.32439078852173564} : acc= 72.08%\n",
            "[HPO] metrics with {'learning_rate': 0.31633901010245197, 'max_depth': 77, 'num_leaves': 1119, 'min_data_in_leaf': 34, 'lambda_l1': 0.1430076127461567, 'lambda_l2': 0.3284386876316608} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4041461282564152, 'max_depth': 75, 'num_leaves': 1102, 'min_data_in_leaf': 35, 'lambda_l1': 0.1268267139356132, 'lambda_l2': 0.5510704414178521} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.28010869440400354, 'max_depth': 75, 'num_leaves': 1251, 'min_data_in_leaf': 30, 'lambda_l1': 0.14595294523050784, 'lambda_l2': 0.41721179500073036} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.4479929199832933, 'max_depth': 79, 'num_leaves': 1155, 'min_data_in_leaf': 36, 'lambda_l1': 0.12122529377684119, 'lambda_l2': 0.33611315862625857} : acc= 68.33%\n",
            "[HPO] metrics with {'learning_rate': 0.19881452092385574, 'max_depth': 75, 'num_leaves': 1075, 'min_data_in_leaf': 61, 'lambda_l1': 0.1881091957514427, 'lambda_l2': 0.4619156499246503} : acc= 69.17%\n",
            "[HPO] metrics with {'learning_rate': 0.1523282954025525, 'max_depth': 79, 'num_leaves': 1318, 'min_data_in_leaf': 33, 'lambda_l1': 0.12598772297737704, 'lambda_l2': 0.30320839865810123} : acc= 68.75%\n",
            "[HPO] metrics with {'learning_rate': 0.38247024654301814, 'max_depth': 74, 'num_leaves': 1199, 'min_data_in_leaf': 24, 'lambda_l1': 0.11414923201218884, 'lambda_l2': 0.5760058737027904} : acc= 65.83%\n",
            "[HPO] metrics with {'learning_rate': 0.32406791357022624, 'max_depth': 74, 'num_leaves': 1084, 'min_data_in_leaf': 35, 'lambda_l1': 0.11842361881869456, 'lambda_l2': 0.7327159249611779} : acc= 70.00%\n",
            "[HPO] metrics with {'learning_rate': 0.2671641039154536, 'max_depth': 77, 'num_leaves': 1086, 'min_data_in_leaf': 30, 'lambda_l1': 0.14790513388117055, 'lambda_l2': 0.40619495193888844} : acc= 67.92%\n",
            "[HPO] metrics with {'learning_rate': 0.3625884067803946, 'max_depth': 74, 'num_leaves': 1741, 'min_data_in_leaf': 36, 'lambda_l1': 0.11453822796511778, 'lambda_l2': 0.3083570706329171} : acc= 70.42%\n",
            "[HPO] metrics with {'learning_rate': 0.2319713248041632, 'max_depth': 81, 'num_leaves': 1130, 'min_data_in_leaf': 33, 'lambda_l1': 0.16323306918505615, 'lambda_l2': 0.49909927273490373} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.4650804644067415, 'max_depth': 74, 'num_leaves': 1200, 'min_data_in_leaf': 36, 'lambda_l1': 0.13795282077147328, 'lambda_l2': 0.40673654258525727} : acc= 71.67%\n",
            "[HPO] metrics with {'learning_rate': 0.3127683970526768, 'max_depth': 81, 'num_leaves': 1535, 'min_data_in_leaf': 32, 'lambda_l1': 0.12097865925813762, 'lambda_l2': 0.3088798483187051} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.4324869025899744, 'max_depth': 75, 'num_leaves': 1083, 'min_data_in_leaf': 36, 'lambda_l1': 0.10863875861275975, 'lambda_l2': 0.6126331516659118} : acc= 70.83%\n",
            "[HPO] metrics with {'learning_rate': 0.3846857439084391, 'max_depth': 78, 'num_leaves': 1220, 'min_data_in_leaf': 34, 'lambda_l1': 0.10919461574499632, 'lambda_l2': 0.30982594364466204} : acc= 71.25%\n",
            "[HPO] metrics with {'learning_rate': 0.3306911284680229, 'max_depth': 74, 'num_leaves': 1061, 'min_data_in_leaf': 31, 'lambda_l1': 0.11764034264067938, 'lambda_l2': 0.4697158226923769} : acc= 69.58%\n",
            "[HPO] metrics with {'learning_rate': 0.25216375138983427, 'max_depth': 73, 'num_leaves': 1099, 'min_data_in_leaf': 37, 'lambda_l1': 0.1568853268666347, 'lambda_l2': 0.4032989632720646} : acc= 69.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 하이퍼파라미터 확인\n",
        "\n",
        "best_params_optuna = study.best_params\n",
        "print(f'Best Parameters : {best_params_optuna}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZGCDMIbLztH",
        "outputId": "bf945b92-919f-4104-ed02-f4be4b9f7930"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters : {'learning_rate': 0.4759536385740368, 'max_depth': 66, 'num_leaves': 872, 'min_data_in_leaf': 34, 'lambda_l1': 0.11542781261424431, 'lambda_l2': 0.2527873058857757}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 학습된 모델을 이용하여 New dataset 에 대한 성능 도출\n",
        "\n",
        "new_dataset_accuracy = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    preds_new = model.predict(X_test_new)\n",
        "    accuracy_new = accuracy_score(preds_new, y_test_new)\n",
        "    acc = f'{(100 * accuracy_new):6.2f}'\n",
        "\n",
        "    new_dataset_accuracy.append(100 * accuracy_new)\n",
        "    print(f'[NEW data] metrics for {i + 1}-th model : acc={acc}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KtdeuwNNaux",
        "outputId": "ee403c53-c26b-4c3f-81c6-58932b6a1210"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NEW data] metrics for 1-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2-th model : acc= 65.33%\n",
            "[NEW data] metrics for 3-th model : acc= 67.00%\n",
            "[NEW data] metrics for 4-th model : acc= 47.67%\n",
            "[NEW data] metrics for 5-th model : acc= 59.33%\n",
            "[NEW data] metrics for 6-th model : acc= 47.67%\n",
            "[NEW data] metrics for 7-th model : acc= 65.00%\n",
            "[NEW data] metrics for 8-th model : acc= 47.67%\n",
            "[NEW data] metrics for 9-th model : acc= 47.67%\n",
            "[NEW data] metrics for 10-th model : acc= 65.67%\n",
            "[NEW data] metrics for 11-th model : acc= 62.33%\n",
            "[NEW data] metrics for 12-th model : acc= 69.00%\n",
            "[NEW data] metrics for 13-th model : acc= 64.67%\n",
            "[NEW data] metrics for 14-th model : acc= 61.00%\n",
            "[NEW data] metrics for 15-th model : acc= 68.67%\n",
            "[NEW data] metrics for 16-th model : acc= 67.67%\n",
            "[NEW data] metrics for 17-th model : acc= 64.67%\n",
            "[NEW data] metrics for 18-th model : acc= 54.00%\n",
            "[NEW data] metrics for 19-th model : acc= 67.67%\n",
            "[NEW data] metrics for 20-th model : acc= 66.00%\n",
            "[NEW data] metrics for 21-th model : acc= 65.00%\n",
            "[NEW data] metrics for 22-th model : acc= 64.00%\n",
            "[NEW data] metrics for 23-th model : acc= 66.33%\n",
            "[NEW data] metrics for 24-th model : acc= 64.33%\n",
            "[NEW data] metrics for 25-th model : acc= 60.67%\n",
            "[NEW data] metrics for 26-th model : acc= 67.33%\n",
            "[NEW data] metrics for 27-th model : acc= 66.67%\n",
            "[NEW data] metrics for 28-th model : acc= 62.33%\n",
            "[NEW data] metrics for 29-th model : acc= 54.67%\n",
            "[NEW data] metrics for 30-th model : acc= 47.67%\n",
            "[NEW data] metrics for 31-th model : acc= 67.67%\n",
            "[NEW data] metrics for 32-th model : acc= 68.00%\n",
            "[NEW data] metrics for 33-th model : acc= 67.00%\n",
            "[NEW data] metrics for 34-th model : acc= 65.00%\n",
            "[NEW data] metrics for 35-th model : acc= 66.67%\n",
            "[NEW data] metrics for 36-th model : acc= 66.00%\n",
            "[NEW data] metrics for 37-th model : acc= 63.33%\n",
            "[NEW data] metrics for 38-th model : acc= 68.33%\n",
            "[NEW data] metrics for 39-th model : acc= 68.33%\n",
            "[NEW data] metrics for 40-th model : acc= 64.00%\n",
            "[NEW data] metrics for 41-th model : acc= 47.67%\n",
            "[NEW data] metrics for 42-th model : acc= 68.33%\n",
            "[NEW data] metrics for 43-th model : acc= 66.33%\n",
            "[NEW data] metrics for 44-th model : acc= 66.67%\n",
            "[NEW data] metrics for 45-th model : acc= 67.33%\n",
            "[NEW data] metrics for 46-th model : acc= 67.33%\n",
            "[NEW data] metrics for 47-th model : acc= 66.67%\n",
            "[NEW data] metrics for 48-th model : acc= 65.00%\n",
            "[NEW data] metrics for 49-th model : acc= 65.67%\n",
            "[NEW data] metrics for 50-th model : acc= 66.00%\n",
            "[NEW data] metrics for 51-th model : acc= 63.67%\n",
            "[NEW data] metrics for 52-th model : acc= 67.67%\n",
            "[NEW data] metrics for 53-th model : acc= 67.00%\n",
            "[NEW data] metrics for 54-th model : acc= 67.00%\n",
            "[NEW data] metrics for 55-th model : acc= 65.67%\n",
            "[NEW data] metrics for 56-th model : acc= 65.00%\n",
            "[NEW data] metrics for 57-th model : acc= 63.00%\n",
            "[NEW data] metrics for 58-th model : acc= 67.33%\n",
            "[NEW data] metrics for 59-th model : acc= 68.00%\n",
            "[NEW data] metrics for 60-th model : acc= 67.00%\n",
            "[NEW data] metrics for 61-th model : acc= 66.00%\n",
            "[NEW data] metrics for 62-th model : acc= 68.67%\n",
            "[NEW data] metrics for 63-th model : acc= 66.33%\n",
            "[NEW data] metrics for 64-th model : acc= 66.67%\n",
            "[NEW data] metrics for 65-th model : acc= 64.00%\n",
            "[NEW data] metrics for 66-th model : acc= 66.00%\n",
            "[NEW data] metrics for 67-th model : acc= 67.00%\n",
            "[NEW data] metrics for 68-th model : acc= 64.33%\n",
            "[NEW data] metrics for 69-th model : acc= 67.00%\n",
            "[NEW data] metrics for 70-th model : acc= 68.33%\n",
            "[NEW data] metrics for 71-th model : acc= 47.67%\n",
            "[NEW data] metrics for 72-th model : acc= 68.33%\n",
            "[NEW data] metrics for 73-th model : acc= 68.33%\n",
            "[NEW data] metrics for 74-th model : acc= 67.67%\n",
            "[NEW data] metrics for 75-th model : acc= 66.33%\n",
            "[NEW data] metrics for 76-th model : acc= 67.33%\n",
            "[NEW data] metrics for 77-th model : acc= 69.00%\n",
            "[NEW data] metrics for 78-th model : acc= 67.33%\n",
            "[NEW data] metrics for 79-th model : acc= 47.67%\n",
            "[NEW data] metrics for 80-th model : acc= 67.67%\n",
            "[NEW data] metrics for 81-th model : acc= 68.33%\n",
            "[NEW data] metrics for 82-th model : acc= 67.00%\n",
            "[NEW data] metrics for 83-th model : acc= 65.67%\n",
            "[NEW data] metrics for 84-th model : acc= 67.33%\n",
            "[NEW data] metrics for 85-th model : acc= 65.67%\n",
            "[NEW data] metrics for 86-th model : acc= 67.67%\n",
            "[NEW data] metrics for 87-th model : acc= 65.33%\n",
            "[NEW data] metrics for 88-th model : acc= 67.67%\n",
            "[NEW data] metrics for 89-th model : acc= 69.00%\n",
            "[NEW data] metrics for 90-th model : acc= 66.00%\n",
            "[NEW data] metrics for 91-th model : acc= 53.33%\n",
            "[NEW data] metrics for 92-th model : acc= 68.33%\n",
            "[NEW data] metrics for 93-th model : acc= 52.67%\n",
            "[NEW data] metrics for 94-th model : acc= 68.00%\n",
            "[NEW data] metrics for 95-th model : acc= 66.67%\n",
            "[NEW data] metrics for 96-th model : acc= 69.00%\n",
            "[NEW data] metrics for 97-th model : acc= 68.33%\n",
            "[NEW data] metrics for 98-th model : acc= 66.33%\n",
            "[NEW data] metrics for 99-th model : acc= 68.67%\n",
            "[NEW data] metrics for 100-th model : acc= 66.67%\n",
            "[NEW data] metrics for 101-th model : acc= 65.00%\n",
            "[NEW data] metrics for 102-th model : acc= 68.33%\n",
            "[NEW data] metrics for 103-th model : acc= 68.00%\n",
            "[NEW data] metrics for 104-th model : acc= 69.00%\n",
            "[NEW data] metrics for 105-th model : acc= 66.00%\n",
            "[NEW data] metrics for 106-th model : acc= 65.33%\n",
            "[NEW data] metrics for 107-th model : acc= 66.00%\n",
            "[NEW data] metrics for 108-th model : acc= 67.00%\n",
            "[NEW data] metrics for 109-th model : acc= 66.00%\n",
            "[NEW data] metrics for 110-th model : acc= 66.00%\n",
            "[NEW data] metrics for 111-th model : acc= 66.67%\n",
            "[NEW data] metrics for 112-th model : acc= 69.00%\n",
            "[NEW data] metrics for 113-th model : acc= 66.33%\n",
            "[NEW data] metrics for 114-th model : acc= 66.33%\n",
            "[NEW data] metrics for 115-th model : acc= 70.00%\n",
            "[NEW data] metrics for 116-th model : acc= 68.00%\n",
            "[NEW data] metrics for 117-th model : acc= 65.33%\n",
            "[NEW data] metrics for 118-th model : acc= 67.00%\n",
            "[NEW data] metrics for 119-th model : acc= 68.00%\n",
            "[NEW data] metrics for 120-th model : acc= 69.33%\n",
            "[NEW data] metrics for 121-th model : acc= 66.67%\n",
            "[NEW data] metrics for 122-th model : acc= 65.33%\n",
            "[NEW data] metrics for 123-th model : acc= 59.67%\n",
            "[NEW data] metrics for 124-th model : acc= 67.67%\n",
            "[NEW data] metrics for 125-th model : acc= 62.33%\n",
            "[NEW data] metrics for 126-th model : acc= 64.33%\n",
            "[NEW data] metrics for 127-th model : acc= 65.33%\n",
            "[NEW data] metrics for 128-th model : acc= 67.33%\n",
            "[NEW data] metrics for 129-th model : acc= 70.00%\n",
            "[NEW data] metrics for 130-th model : acc= 67.67%\n",
            "[NEW data] metrics for 131-th model : acc= 67.33%\n",
            "[NEW data] metrics for 132-th model : acc= 66.33%\n",
            "[NEW data] metrics for 133-th model : acc= 67.00%\n",
            "[NEW data] metrics for 134-th model : acc= 67.00%\n",
            "[NEW data] metrics for 135-th model : acc= 69.67%\n",
            "[NEW data] metrics for 136-th model : acc= 70.33%\n",
            "[NEW data] metrics for 137-th model : acc= 68.33%\n",
            "[NEW data] metrics for 138-th model : acc= 67.00%\n",
            "[NEW data] metrics for 139-th model : acc= 66.00%\n",
            "[NEW data] metrics for 140-th model : acc= 65.33%\n",
            "[NEW data] metrics for 141-th model : acc= 62.33%\n",
            "[NEW data] metrics for 142-th model : acc= 67.67%\n",
            "[NEW data] metrics for 143-th model : acc= 67.67%\n",
            "[NEW data] metrics for 144-th model : acc= 65.00%\n",
            "[NEW data] metrics for 145-th model : acc= 65.67%\n",
            "[NEW data] metrics for 146-th model : acc= 68.33%\n",
            "[NEW data] metrics for 147-th model : acc= 65.67%\n",
            "[NEW data] metrics for 148-th model : acc= 66.67%\n",
            "[NEW data] metrics for 149-th model : acc= 68.67%\n",
            "[NEW data] metrics for 150-th model : acc= 64.33%\n",
            "[NEW data] metrics for 151-th model : acc= 68.67%\n",
            "[NEW data] metrics for 152-th model : acc= 67.67%\n",
            "[NEW data] metrics for 153-th model : acc= 68.00%\n",
            "[NEW data] metrics for 154-th model : acc= 69.00%\n",
            "[NEW data] metrics for 155-th model : acc= 70.00%\n",
            "[NEW data] metrics for 156-th model : acc= 61.33%\n",
            "[NEW data] metrics for 157-th model : acc= 69.33%\n",
            "[NEW data] metrics for 158-th model : acc= 68.00%\n",
            "[NEW data] metrics for 159-th model : acc= 68.00%\n",
            "[NEW data] metrics for 160-th model : acc= 67.33%\n",
            "[NEW data] metrics for 161-th model : acc= 69.33%\n",
            "[NEW data] metrics for 162-th model : acc= 69.00%\n",
            "[NEW data] metrics for 163-th model : acc= 67.00%\n",
            "[NEW data] metrics for 164-th model : acc= 67.00%\n",
            "[NEW data] metrics for 165-th model : acc= 66.33%\n",
            "[NEW data] metrics for 166-th model : acc= 68.33%\n",
            "[NEW data] metrics for 167-th model : acc= 69.67%\n",
            "[NEW data] metrics for 168-th model : acc= 47.67%\n",
            "[NEW data] metrics for 169-th model : acc= 68.67%\n",
            "[NEW data] metrics for 170-th model : acc= 64.00%\n",
            "[NEW data] metrics for 171-th model : acc= 68.00%\n",
            "[NEW data] metrics for 172-th model : acc= 68.67%\n",
            "[NEW data] metrics for 173-th model : acc= 65.67%\n",
            "[NEW data] metrics for 174-th model : acc= 66.33%\n",
            "[NEW data] metrics for 175-th model : acc= 68.33%\n",
            "[NEW data] metrics for 176-th model : acc= 67.67%\n",
            "[NEW data] metrics for 177-th model : acc= 69.33%\n",
            "[NEW data] metrics for 178-th model : acc= 67.00%\n",
            "[NEW data] metrics for 179-th model : acc= 69.00%\n",
            "[NEW data] metrics for 180-th model : acc= 69.00%\n",
            "[NEW data] metrics for 181-th model : acc= 69.00%\n",
            "[NEW data] metrics for 182-th model : acc= 67.67%\n",
            "[NEW data] metrics for 183-th model : acc= 66.00%\n",
            "[NEW data] metrics for 184-th model : acc= 68.00%\n",
            "[NEW data] metrics for 185-th model : acc= 64.67%\n",
            "[NEW data] metrics for 186-th model : acc= 69.00%\n",
            "[NEW data] metrics for 187-th model : acc= 69.00%\n",
            "[NEW data] metrics for 188-th model : acc= 67.00%\n",
            "[NEW data] metrics for 189-th model : acc= 68.00%\n",
            "[NEW data] metrics for 190-th model : acc= 66.67%\n",
            "[NEW data] metrics for 191-th model : acc= 67.33%\n",
            "[NEW data] metrics for 192-th model : acc= 68.67%\n",
            "[NEW data] metrics for 193-th model : acc= 68.33%\n",
            "[NEW data] metrics for 194-th model : acc= 69.00%\n",
            "[NEW data] metrics for 195-th model : acc= 68.00%\n",
            "[NEW data] metrics for 196-th model : acc= 69.00%\n",
            "[NEW data] metrics for 197-th model : acc= 70.33%\n",
            "[NEW data] metrics for 198-th model : acc= 67.67%\n",
            "[NEW data] metrics for 199-th model : acc= 69.00%\n",
            "[NEW data] metrics for 200-th model : acc= 66.33%\n",
            "[NEW data] metrics for 201-th model : acc= 68.67%\n",
            "[NEW data] metrics for 202-th model : acc= 69.33%\n",
            "[NEW data] metrics for 203-th model : acc= 68.33%\n",
            "[NEW data] metrics for 204-th model : acc= 69.67%\n",
            "[NEW data] metrics for 205-th model : acc= 69.33%\n",
            "[NEW data] metrics for 206-th model : acc= 69.00%\n",
            "[NEW data] metrics for 207-th model : acc= 66.00%\n",
            "[NEW data] metrics for 208-th model : acc= 66.33%\n",
            "[NEW data] metrics for 209-th model : acc= 66.33%\n",
            "[NEW data] metrics for 210-th model : acc= 69.00%\n",
            "[NEW data] metrics for 211-th model : acc= 67.33%\n",
            "[NEW data] metrics for 212-th model : acc= 66.00%\n",
            "[NEW data] metrics for 213-th model : acc= 66.67%\n",
            "[NEW data] metrics for 214-th model : acc= 68.33%\n",
            "[NEW data] metrics for 215-th model : acc= 53.33%\n",
            "[NEW data] metrics for 216-th model : acc= 66.67%\n",
            "[NEW data] metrics for 217-th model : acc= 67.00%\n",
            "[NEW data] metrics for 218-th model : acc= 66.33%\n",
            "[NEW data] metrics for 219-th model : acc= 68.00%\n",
            "[NEW data] metrics for 220-th model : acc= 65.33%\n",
            "[NEW data] metrics for 221-th model : acc= 69.00%\n",
            "[NEW data] metrics for 222-th model : acc= 68.33%\n",
            "[NEW data] metrics for 223-th model : acc= 65.00%\n",
            "[NEW data] metrics for 224-th model : acc= 68.00%\n",
            "[NEW data] metrics for 225-th model : acc= 68.33%\n",
            "[NEW data] metrics for 226-th model : acc= 68.00%\n",
            "[NEW data] metrics for 227-th model : acc= 69.00%\n",
            "[NEW data] metrics for 228-th model : acc= 68.00%\n",
            "[NEW data] metrics for 229-th model : acc= 63.33%\n",
            "[NEW data] metrics for 230-th model : acc= 64.33%\n",
            "[NEW data] metrics for 231-th model : acc= 67.00%\n",
            "[NEW data] metrics for 232-th model : acc= 68.33%\n",
            "[NEW data] metrics for 233-th model : acc= 69.67%\n",
            "[NEW data] metrics for 234-th model : acc= 67.33%\n",
            "[NEW data] metrics for 235-th model : acc= 67.00%\n",
            "[NEW data] metrics for 236-th model : acc= 65.00%\n",
            "[NEW data] metrics for 237-th model : acc= 68.67%\n",
            "[NEW data] metrics for 238-th model : acc= 67.67%\n",
            "[NEW data] metrics for 239-th model : acc= 69.67%\n",
            "[NEW data] metrics for 240-th model : acc= 47.67%\n",
            "[NEW data] metrics for 241-th model : acc= 68.00%\n",
            "[NEW data] metrics for 242-th model : acc= 66.33%\n",
            "[NEW data] metrics for 243-th model : acc= 69.67%\n",
            "[NEW data] metrics for 244-th model : acc= 67.33%\n",
            "[NEW data] metrics for 245-th model : acc= 68.33%\n",
            "[NEW data] metrics for 246-th model : acc= 69.00%\n",
            "[NEW data] metrics for 247-th model : acc= 69.67%\n",
            "[NEW data] metrics for 248-th model : acc= 68.00%\n",
            "[NEW data] metrics for 249-th model : acc= 68.00%\n",
            "[NEW data] metrics for 250-th model : acc= 63.33%\n",
            "[NEW data] metrics for 251-th model : acc= 67.00%\n",
            "[NEW data] metrics for 252-th model : acc= 68.33%\n",
            "[NEW data] metrics for 253-th model : acc= 69.00%\n",
            "[NEW data] metrics for 254-th model : acc= 63.00%\n",
            "[NEW data] metrics for 255-th model : acc= 66.67%\n",
            "[NEW data] metrics for 256-th model : acc= 67.00%\n",
            "[NEW data] metrics for 257-th model : acc= 66.00%\n",
            "[NEW data] metrics for 258-th model : acc= 67.67%\n",
            "[NEW data] metrics for 259-th model : acc= 67.67%\n",
            "[NEW data] metrics for 260-th model : acc= 65.00%\n",
            "[NEW data] metrics for 261-th model : acc= 67.67%\n",
            "[NEW data] metrics for 262-th model : acc= 68.67%\n",
            "[NEW data] metrics for 263-th model : acc= 65.67%\n",
            "[NEW data] metrics for 264-th model : acc= 67.00%\n",
            "[NEW data] metrics for 265-th model : acc= 67.67%\n",
            "[NEW data] metrics for 266-th model : acc= 67.00%\n",
            "[NEW data] metrics for 267-th model : acc= 69.67%\n",
            "[NEW data] metrics for 268-th model : acc= 67.33%\n",
            "[NEW data] metrics for 269-th model : acc= 67.00%\n",
            "[NEW data] metrics for 270-th model : acc= 67.67%\n",
            "[NEW data] metrics for 271-th model : acc= 67.33%\n",
            "[NEW data] metrics for 272-th model : acc= 64.33%\n",
            "[NEW data] metrics for 273-th model : acc= 64.00%\n",
            "[NEW data] metrics for 274-th model : acc= 67.67%\n",
            "[NEW data] metrics for 275-th model : acc= 69.33%\n",
            "[NEW data] metrics for 276-th model : acc= 65.67%\n",
            "[NEW data] metrics for 277-th model : acc= 68.00%\n",
            "[NEW data] metrics for 278-th model : acc= 47.67%\n",
            "[NEW data] metrics for 279-th model : acc= 70.00%\n",
            "[NEW data] metrics for 280-th model : acc= 62.67%\n",
            "[NEW data] metrics for 281-th model : acc= 66.67%\n",
            "[NEW data] metrics for 282-th model : acc= 65.67%\n",
            "[NEW data] metrics for 283-th model : acc= 70.00%\n",
            "[NEW data] metrics for 284-th model : acc= 62.33%\n",
            "[NEW data] metrics for 285-th model : acc= 55.00%\n",
            "[NEW data] metrics for 286-th model : acc= 66.67%\n",
            "[NEW data] metrics for 287-th model : acc= 68.67%\n",
            "[NEW data] metrics for 288-th model : acc= 68.00%\n",
            "[NEW data] metrics for 289-th model : acc= 65.33%\n",
            "[NEW data] metrics for 290-th model : acc= 47.67%\n",
            "[NEW data] metrics for 291-th model : acc= 67.00%\n",
            "[NEW data] metrics for 292-th model : acc= 67.00%\n",
            "[NEW data] metrics for 293-th model : acc= 68.00%\n",
            "[NEW data] metrics for 294-th model : acc= 70.67%\n",
            "[NEW data] metrics for 295-th model : acc= 68.33%\n",
            "[NEW data] metrics for 296-th model : acc= 67.67%\n",
            "[NEW data] metrics for 297-th model : acc= 67.00%\n",
            "[NEW data] metrics for 298-th model : acc= 65.33%\n",
            "[NEW data] metrics for 299-th model : acc= 70.33%\n",
            "[NEW data] metrics for 300-th model : acc= 68.67%\n",
            "[NEW data] metrics for 301-th model : acc= 67.00%\n",
            "[NEW data] metrics for 302-th model : acc= 67.67%\n",
            "[NEW data] metrics for 303-th model : acc= 66.33%\n",
            "[NEW data] metrics for 304-th model : acc= 69.67%\n",
            "[NEW data] metrics for 305-th model : acc= 66.67%\n",
            "[NEW data] metrics for 306-th model : acc= 67.00%\n",
            "[NEW data] metrics for 307-th model : acc= 47.67%\n",
            "[NEW data] metrics for 308-th model : acc= 65.67%\n",
            "[NEW data] metrics for 309-th model : acc= 67.67%\n",
            "[NEW data] metrics for 310-th model : acc= 67.33%\n",
            "[NEW data] metrics for 311-th model : acc= 69.00%\n",
            "[NEW data] metrics for 312-th model : acc= 68.33%\n",
            "[NEW data] metrics for 313-th model : acc= 65.67%\n",
            "[NEW data] metrics for 314-th model : acc= 66.67%\n",
            "[NEW data] metrics for 315-th model : acc= 69.67%\n",
            "[NEW data] metrics for 316-th model : acc= 70.00%\n",
            "[NEW data] metrics for 317-th model : acc= 66.00%\n",
            "[NEW data] metrics for 318-th model : acc= 67.33%\n",
            "[NEW data] metrics for 319-th model : acc= 64.33%\n",
            "[NEW data] metrics for 320-th model : acc= 67.67%\n",
            "[NEW data] metrics for 321-th model : acc= 65.33%\n",
            "[NEW data] metrics for 322-th model : acc= 66.67%\n",
            "[NEW data] metrics for 323-th model : acc= 67.00%\n",
            "[NEW data] metrics for 324-th model : acc= 67.00%\n",
            "[NEW data] metrics for 325-th model : acc= 67.33%\n",
            "[NEW data] metrics for 326-th model : acc= 67.67%\n",
            "[NEW data] metrics for 327-th model : acc= 65.67%\n",
            "[NEW data] metrics for 328-th model : acc= 68.33%\n",
            "[NEW data] metrics for 329-th model : acc= 68.33%\n",
            "[NEW data] metrics for 330-th model : acc= 69.33%\n",
            "[NEW data] metrics for 331-th model : acc= 67.67%\n",
            "[NEW data] metrics for 332-th model : acc= 67.00%\n",
            "[NEW data] metrics for 333-th model : acc= 66.67%\n",
            "[NEW data] metrics for 334-th model : acc= 69.67%\n",
            "[NEW data] metrics for 335-th model : acc= 68.00%\n",
            "[NEW data] metrics for 336-th model : acc= 66.33%\n",
            "[NEW data] metrics for 337-th model : acc= 67.00%\n",
            "[NEW data] metrics for 338-th model : acc= 66.67%\n",
            "[NEW data] metrics for 339-th model : acc= 63.00%\n",
            "[NEW data] metrics for 340-th model : acc= 66.67%\n",
            "[NEW data] metrics for 341-th model : acc= 66.67%\n",
            "[NEW data] metrics for 342-th model : acc= 67.00%\n",
            "[NEW data] metrics for 343-th model : acc= 68.33%\n",
            "[NEW data] metrics for 344-th model : acc= 66.67%\n",
            "[NEW data] metrics for 345-th model : acc= 69.33%\n",
            "[NEW data] metrics for 346-th model : acc= 66.33%\n",
            "[NEW data] metrics for 347-th model : acc= 64.33%\n",
            "[NEW data] metrics for 348-th model : acc= 68.00%\n",
            "[NEW data] metrics for 349-th model : acc= 64.67%\n",
            "[NEW data] metrics for 350-th model : acc= 65.67%\n",
            "[NEW data] metrics for 351-th model : acc= 66.00%\n",
            "[NEW data] metrics for 352-th model : acc= 67.33%\n",
            "[NEW data] metrics for 353-th model : acc= 66.67%\n",
            "[NEW data] metrics for 354-th model : acc= 68.33%\n",
            "[NEW data] metrics for 355-th model : acc= 66.67%\n",
            "[NEW data] metrics for 356-th model : acc= 67.33%\n",
            "[NEW data] metrics for 357-th model : acc= 66.00%\n",
            "[NEW data] metrics for 358-th model : acc= 68.00%\n",
            "[NEW data] metrics for 359-th model : acc= 69.00%\n",
            "[NEW data] metrics for 360-th model : acc= 47.67%\n",
            "[NEW data] metrics for 361-th model : acc= 65.33%\n",
            "[NEW data] metrics for 362-th model : acc= 68.00%\n",
            "[NEW data] metrics for 363-th model : acc= 67.33%\n",
            "[NEW data] metrics for 364-th model : acc= 66.67%\n",
            "[NEW data] metrics for 365-th model : acc= 68.00%\n",
            "[NEW data] metrics for 366-th model : acc= 62.00%\n",
            "[NEW data] metrics for 367-th model : acc= 70.00%\n",
            "[NEW data] metrics for 368-th model : acc= 69.67%\n",
            "[NEW data] metrics for 369-th model : acc= 66.33%\n",
            "[NEW data] metrics for 370-th model : acc= 67.00%\n",
            "[NEW data] metrics for 371-th model : acc= 67.67%\n",
            "[NEW data] metrics for 372-th model : acc= 66.67%\n",
            "[NEW data] metrics for 373-th model : acc= 53.67%\n",
            "[NEW data] metrics for 374-th model : acc= 68.67%\n",
            "[NEW data] metrics for 375-th model : acc= 68.33%\n",
            "[NEW data] metrics for 376-th model : acc= 67.00%\n",
            "[NEW data] metrics for 377-th model : acc= 70.33%\n",
            "[NEW data] metrics for 378-th model : acc= 67.33%\n",
            "[NEW data] metrics for 379-th model : acc= 67.00%\n",
            "[NEW data] metrics for 380-th model : acc= 66.00%\n",
            "[NEW data] metrics for 381-th model : acc= 67.67%\n",
            "[NEW data] metrics for 382-th model : acc= 66.67%\n",
            "[NEW data] metrics for 383-th model : acc= 69.00%\n",
            "[NEW data] metrics for 384-th model : acc= 68.33%\n",
            "[NEW data] metrics for 385-th model : acc= 67.33%\n",
            "[NEW data] metrics for 386-th model : acc= 65.67%\n",
            "[NEW data] metrics for 387-th model : acc= 68.00%\n",
            "[NEW data] metrics for 388-th model : acc= 65.67%\n",
            "[NEW data] metrics for 389-th model : acc= 47.67%\n",
            "[NEW data] metrics for 390-th model : acc= 68.33%\n",
            "[NEW data] metrics for 391-th model : acc= 70.33%\n",
            "[NEW data] metrics for 392-th model : acc= 66.00%\n",
            "[NEW data] metrics for 393-th model : acc= 67.33%\n",
            "[NEW data] metrics for 394-th model : acc= 64.00%\n",
            "[NEW data] metrics for 395-th model : acc= 66.67%\n",
            "[NEW data] metrics for 396-th model : acc= 68.00%\n",
            "[NEW data] metrics for 397-th model : acc= 68.67%\n",
            "[NEW data] metrics for 398-th model : acc= 64.00%\n",
            "[NEW data] metrics for 399-th model : acc= 66.33%\n",
            "[NEW data] metrics for 400-th model : acc= 65.00%\n",
            "[NEW data] metrics for 401-th model : acc= 60.00%\n",
            "[NEW data] metrics for 402-th model : acc= 65.33%\n",
            "[NEW data] metrics for 403-th model : acc= 69.33%\n",
            "[NEW data] metrics for 404-th model : acc= 69.00%\n",
            "[NEW data] metrics for 405-th model : acc= 67.00%\n",
            "[NEW data] metrics for 406-th model : acc= 68.00%\n",
            "[NEW data] metrics for 407-th model : acc= 62.00%\n",
            "[NEW data] metrics for 408-th model : acc= 68.33%\n",
            "[NEW data] metrics for 409-th model : acc= 67.00%\n",
            "[NEW data] metrics for 410-th model : acc= 68.67%\n",
            "[NEW data] metrics for 411-th model : acc= 69.00%\n",
            "[NEW data] metrics for 412-th model : acc= 69.00%\n",
            "[NEW data] metrics for 413-th model : acc= 68.67%\n",
            "[NEW data] metrics for 414-th model : acc= 66.67%\n",
            "[NEW data] metrics for 415-th model : acc= 67.33%\n",
            "[NEW data] metrics for 416-th model : acc= 66.00%\n",
            "[NEW data] metrics for 417-th model : acc= 65.33%\n",
            "[NEW data] metrics for 418-th model : acc= 65.33%\n",
            "[NEW data] metrics for 419-th model : acc= 67.33%\n",
            "[NEW data] metrics for 420-th model : acc= 64.33%\n",
            "[NEW data] metrics for 421-th model : acc= 68.67%\n",
            "[NEW data] metrics for 422-th model : acc= 68.67%\n",
            "[NEW data] metrics for 423-th model : acc= 68.33%\n",
            "[NEW data] metrics for 424-th model : acc= 67.33%\n",
            "[NEW data] metrics for 425-th model : acc= 68.33%\n",
            "[NEW data] metrics for 426-th model : acc= 66.00%\n",
            "[NEW data] metrics for 427-th model : acc= 66.67%\n",
            "[NEW data] metrics for 428-th model : acc= 71.00%\n",
            "[NEW data] metrics for 429-th model : acc= 67.33%\n",
            "[NEW data] metrics for 430-th model : acc= 68.67%\n",
            "[NEW data] metrics for 431-th model : acc= 66.33%\n",
            "[NEW data] metrics for 432-th model : acc= 65.67%\n",
            "[NEW data] metrics for 433-th model : acc= 67.00%\n",
            "[NEW data] metrics for 434-th model : acc= 67.33%\n",
            "[NEW data] metrics for 435-th model : acc= 66.33%\n",
            "[NEW data] metrics for 436-th model : acc= 67.67%\n",
            "[NEW data] metrics for 437-th model : acc= 64.33%\n",
            "[NEW data] metrics for 438-th model : acc= 67.67%\n",
            "[NEW data] metrics for 439-th model : acc= 65.00%\n",
            "[NEW data] metrics for 440-th model : acc= 67.00%\n",
            "[NEW data] metrics for 441-th model : acc= 67.00%\n",
            "[NEW data] metrics for 442-th model : acc= 66.00%\n",
            "[NEW data] metrics for 443-th model : acc= 67.33%\n",
            "[NEW data] metrics for 444-th model : acc= 67.67%\n",
            "[NEW data] metrics for 445-th model : acc= 65.67%\n",
            "[NEW data] metrics for 446-th model : acc= 66.67%\n",
            "[NEW data] metrics for 447-th model : acc= 68.00%\n",
            "[NEW data] metrics for 448-th model : acc= 65.67%\n",
            "[NEW data] metrics for 449-th model : acc= 68.00%\n",
            "[NEW data] metrics for 450-th model : acc= 65.00%\n",
            "[NEW data] metrics for 451-th model : acc= 67.00%\n",
            "[NEW data] metrics for 452-th model : acc= 66.67%\n",
            "[NEW data] metrics for 453-th model : acc= 69.33%\n",
            "[NEW data] metrics for 454-th model : acc= 65.67%\n",
            "[NEW data] metrics for 455-th model : acc= 65.67%\n",
            "[NEW data] metrics for 456-th model : acc= 67.33%\n",
            "[NEW data] metrics for 457-th model : acc= 65.33%\n",
            "[NEW data] metrics for 458-th model : acc= 65.00%\n",
            "[NEW data] metrics for 459-th model : acc= 69.33%\n",
            "[NEW data] metrics for 460-th model : acc= 64.33%\n",
            "[NEW data] metrics for 461-th model : acc= 69.33%\n",
            "[NEW data] metrics for 462-th model : acc= 63.67%\n",
            "[NEW data] metrics for 463-th model : acc= 65.67%\n",
            "[NEW data] metrics for 464-th model : acc= 65.00%\n",
            "[NEW data] metrics for 465-th model : acc= 68.67%\n",
            "[NEW data] metrics for 466-th model : acc= 66.00%\n",
            "[NEW data] metrics for 467-th model : acc= 68.67%\n",
            "[NEW data] metrics for 468-th model : acc= 47.67%\n",
            "[NEW data] metrics for 469-th model : acc= 67.00%\n",
            "[NEW data] metrics for 470-th model : acc= 66.67%\n",
            "[NEW data] metrics for 471-th model : acc= 66.33%\n",
            "[NEW data] metrics for 472-th model : acc= 67.33%\n",
            "[NEW data] metrics for 473-th model : acc= 66.33%\n",
            "[NEW data] metrics for 474-th model : acc= 66.67%\n",
            "[NEW data] metrics for 475-th model : acc= 68.00%\n",
            "[NEW data] metrics for 476-th model : acc= 67.67%\n",
            "[NEW data] metrics for 477-th model : acc= 66.00%\n",
            "[NEW data] metrics for 478-th model : acc= 47.67%\n",
            "[NEW data] metrics for 479-th model : acc= 67.67%\n",
            "[NEW data] metrics for 480-th model : acc= 65.67%\n",
            "[NEW data] metrics for 481-th model : acc= 66.67%\n",
            "[NEW data] metrics for 482-th model : acc= 67.33%\n",
            "[NEW data] metrics for 483-th model : acc= 67.00%\n",
            "[NEW data] metrics for 484-th model : acc= 67.00%\n",
            "[NEW data] metrics for 485-th model : acc= 68.33%\n",
            "[NEW data] metrics for 486-th model : acc= 70.00%\n",
            "[NEW data] metrics for 487-th model : acc= 66.00%\n",
            "[NEW data] metrics for 488-th model : acc= 70.33%\n",
            "[NEW data] metrics for 489-th model : acc= 68.67%\n",
            "[NEW data] metrics for 490-th model : acc= 63.67%\n",
            "[NEW data] metrics for 491-th model : acc= 69.33%\n",
            "[NEW data] metrics for 492-th model : acc= 66.67%\n",
            "[NEW data] metrics for 493-th model : acc= 68.67%\n",
            "[NEW data] metrics for 494-th model : acc= 65.33%\n",
            "[NEW data] metrics for 495-th model : acc= 68.33%\n",
            "[NEW data] metrics for 496-th model : acc= 68.33%\n",
            "[NEW data] metrics for 497-th model : acc= 68.67%\n",
            "[NEW data] metrics for 498-th model : acc= 69.33%\n",
            "[NEW data] metrics for 499-th model : acc= 70.67%\n",
            "[NEW data] metrics for 500-th model : acc= 69.67%\n",
            "[NEW data] metrics for 501-th model : acc= 69.00%\n",
            "[NEW data] metrics for 502-th model : acc= 64.33%\n",
            "[NEW data] metrics for 503-th model : acc= 66.33%\n",
            "[NEW data] metrics for 504-th model : acc= 65.00%\n",
            "[NEW data] metrics for 505-th model : acc= 61.67%\n",
            "[NEW data] metrics for 506-th model : acc= 68.33%\n",
            "[NEW data] metrics for 507-th model : acc= 65.00%\n",
            "[NEW data] metrics for 508-th model : acc= 66.33%\n",
            "[NEW data] metrics for 509-th model : acc= 69.00%\n",
            "[NEW data] metrics for 510-th model : acc= 69.33%\n",
            "[NEW data] metrics for 511-th model : acc= 67.67%\n",
            "[NEW data] metrics for 512-th model : acc= 65.67%\n",
            "[NEW data] metrics for 513-th model : acc= 66.00%\n",
            "[NEW data] metrics for 514-th model : acc= 67.67%\n",
            "[NEW data] metrics for 515-th model : acc= 65.00%\n",
            "[NEW data] metrics for 516-th model : acc= 67.00%\n",
            "[NEW data] metrics for 517-th model : acc= 66.33%\n",
            "[NEW data] metrics for 518-th model : acc= 66.00%\n",
            "[NEW data] metrics for 519-th model : acc= 69.33%\n",
            "[NEW data] metrics for 520-th model : acc= 68.67%\n",
            "[NEW data] metrics for 521-th model : acc= 68.67%\n",
            "[NEW data] metrics for 522-th model : acc= 51.00%\n",
            "[NEW data] metrics for 523-th model : acc= 66.67%\n",
            "[NEW data] metrics for 524-th model : acc= 61.00%\n",
            "[NEW data] metrics for 525-th model : acc= 67.67%\n",
            "[NEW data] metrics for 526-th model : acc= 68.00%\n",
            "[NEW data] metrics for 527-th model : acc= 66.33%\n",
            "[NEW data] metrics for 528-th model : acc= 67.00%\n",
            "[NEW data] metrics for 529-th model : acc= 66.33%\n",
            "[NEW data] metrics for 530-th model : acc= 61.00%\n",
            "[NEW data] metrics for 531-th model : acc= 64.33%\n",
            "[NEW data] metrics for 532-th model : acc= 68.00%\n",
            "[NEW data] metrics for 533-th model : acc= 69.00%\n",
            "[NEW data] metrics for 534-th model : acc= 66.00%\n",
            "[NEW data] metrics for 535-th model : acc= 63.67%\n",
            "[NEW data] metrics for 536-th model : acc= 66.00%\n",
            "[NEW data] metrics for 537-th model : acc= 69.00%\n",
            "[NEW data] metrics for 538-th model : acc= 69.00%\n",
            "[NEW data] metrics for 539-th model : acc= 68.00%\n",
            "[NEW data] metrics for 540-th model : acc= 67.67%\n",
            "[NEW data] metrics for 541-th model : acc= 69.00%\n",
            "[NEW data] metrics for 542-th model : acc= 70.33%\n",
            "[NEW data] metrics for 543-th model : acc= 67.67%\n",
            "[NEW data] metrics for 544-th model : acc= 68.00%\n",
            "[NEW data] metrics for 545-th model : acc= 67.67%\n",
            "[NEW data] metrics for 546-th model : acc= 69.00%\n",
            "[NEW data] metrics for 547-th model : acc= 66.00%\n",
            "[NEW data] metrics for 548-th model : acc= 67.33%\n",
            "[NEW data] metrics for 549-th model : acc= 67.00%\n",
            "[NEW data] metrics for 550-th model : acc= 67.33%\n",
            "[NEW data] metrics for 551-th model : acc= 67.67%\n",
            "[NEW data] metrics for 552-th model : acc= 68.67%\n",
            "[NEW data] metrics for 553-th model : acc= 68.33%\n",
            "[NEW data] metrics for 554-th model : acc= 63.67%\n",
            "[NEW data] metrics for 555-th model : acc= 67.33%\n",
            "[NEW data] metrics for 556-th model : acc= 68.33%\n",
            "[NEW data] metrics for 557-th model : acc= 55.33%\n",
            "[NEW data] metrics for 558-th model : acc= 68.67%\n",
            "[NEW data] metrics for 559-th model : acc= 66.67%\n",
            "[NEW data] metrics for 560-th model : acc= 67.33%\n",
            "[NEW data] metrics for 561-th model : acc= 66.00%\n",
            "[NEW data] metrics for 562-th model : acc= 67.00%\n",
            "[NEW data] metrics for 563-th model : acc= 67.33%\n",
            "[NEW data] metrics for 564-th model : acc= 67.00%\n",
            "[NEW data] metrics for 565-th model : acc= 69.67%\n",
            "[NEW data] metrics for 566-th model : acc= 64.33%\n",
            "[NEW data] metrics for 567-th model : acc= 66.33%\n",
            "[NEW data] metrics for 568-th model : acc= 68.33%\n",
            "[NEW data] metrics for 569-th model : acc= 67.33%\n",
            "[NEW data] metrics for 570-th model : acc= 67.33%\n",
            "[NEW data] metrics for 571-th model : acc= 67.00%\n",
            "[NEW data] metrics for 572-th model : acc= 63.67%\n",
            "[NEW data] metrics for 573-th model : acc= 66.67%\n",
            "[NEW data] metrics for 574-th model : acc= 66.00%\n",
            "[NEW data] metrics for 575-th model : acc= 66.33%\n",
            "[NEW data] metrics for 576-th model : acc= 64.67%\n",
            "[NEW data] metrics for 577-th model : acc= 66.33%\n",
            "[NEW data] metrics for 578-th model : acc= 66.00%\n",
            "[NEW data] metrics for 579-th model : acc= 69.33%\n",
            "[NEW data] metrics for 580-th model : acc= 65.00%\n",
            "[NEW data] metrics for 581-th model : acc= 66.67%\n",
            "[NEW data] metrics for 582-th model : acc= 66.33%\n",
            "[NEW data] metrics for 583-th model : acc= 68.33%\n",
            "[NEW data] metrics for 584-th model : acc= 67.67%\n",
            "[NEW data] metrics for 585-th model : acc= 69.67%\n",
            "[NEW data] metrics for 586-th model : acc= 57.33%\n",
            "[NEW data] metrics for 587-th model : acc= 64.67%\n",
            "[NEW data] metrics for 588-th model : acc= 61.00%\n",
            "[NEW data] metrics for 589-th model : acc= 66.33%\n",
            "[NEW data] metrics for 590-th model : acc= 67.33%\n",
            "[NEW data] metrics for 591-th model : acc= 60.33%\n",
            "[NEW data] metrics for 592-th model : acc= 68.00%\n",
            "[NEW data] metrics for 593-th model : acc= 68.00%\n",
            "[NEW data] metrics for 594-th model : acc= 67.33%\n",
            "[NEW data] metrics for 595-th model : acc= 67.33%\n",
            "[NEW data] metrics for 596-th model : acc= 68.33%\n",
            "[NEW data] metrics for 597-th model : acc= 68.33%\n",
            "[NEW data] metrics for 598-th model : acc= 58.00%\n",
            "[NEW data] metrics for 599-th model : acc= 68.67%\n",
            "[NEW data] metrics for 600-th model : acc= 67.33%\n",
            "[NEW data] metrics for 601-th model : acc= 65.67%\n",
            "[NEW data] metrics for 602-th model : acc= 65.67%\n",
            "[NEW data] metrics for 603-th model : acc= 67.33%\n",
            "[NEW data] metrics for 604-th model : acc= 68.00%\n",
            "[NEW data] metrics for 605-th model : acc= 67.33%\n",
            "[NEW data] metrics for 606-th model : acc= 66.00%\n",
            "[NEW data] metrics for 607-th model : acc= 69.67%\n",
            "[NEW data] metrics for 608-th model : acc= 67.00%\n",
            "[NEW data] metrics for 609-th model : acc= 68.67%\n",
            "[NEW data] metrics for 610-th model : acc= 70.00%\n",
            "[NEW data] metrics for 611-th model : acc= 68.67%\n",
            "[NEW data] metrics for 612-th model : acc= 62.67%\n",
            "[NEW data] metrics for 613-th model : acc= 47.67%\n",
            "[NEW data] metrics for 614-th model : acc= 47.67%\n",
            "[NEW data] metrics for 615-th model : acc= 66.00%\n",
            "[NEW data] metrics for 616-th model : acc= 47.67%\n",
            "[NEW data] metrics for 617-th model : acc= 66.67%\n",
            "[NEW data] metrics for 618-th model : acc= 67.33%\n",
            "[NEW data] metrics for 619-th model : acc= 66.67%\n",
            "[NEW data] metrics for 620-th model : acc= 67.33%\n",
            "[NEW data] metrics for 621-th model : acc= 68.00%\n",
            "[NEW data] metrics for 622-th model : acc= 65.67%\n",
            "[NEW data] metrics for 623-th model : acc= 68.67%\n",
            "[NEW data] metrics for 624-th model : acc= 67.00%\n",
            "[NEW data] metrics for 625-th model : acc= 66.33%\n",
            "[NEW data] metrics for 626-th model : acc= 66.67%\n",
            "[NEW data] metrics for 627-th model : acc= 68.33%\n",
            "[NEW data] metrics for 628-th model : acc= 67.00%\n",
            "[NEW data] metrics for 629-th model : acc= 52.33%\n",
            "[NEW data] metrics for 630-th model : acc= 66.67%\n",
            "[NEW data] metrics for 631-th model : acc= 60.67%\n",
            "[NEW data] metrics for 632-th model : acc= 70.33%\n",
            "[NEW data] metrics for 633-th model : acc= 59.00%\n",
            "[NEW data] metrics for 634-th model : acc= 60.67%\n",
            "[NEW data] metrics for 635-th model : acc= 47.67%\n",
            "[NEW data] metrics for 636-th model : acc= 66.67%\n",
            "[NEW data] metrics for 637-th model : acc= 66.67%\n",
            "[NEW data] metrics for 638-th model : acc= 66.33%\n",
            "[NEW data] metrics for 639-th model : acc= 67.67%\n",
            "[NEW data] metrics for 640-th model : acc= 66.33%\n",
            "[NEW data] metrics for 641-th model : acc= 68.33%\n",
            "[NEW data] metrics for 642-th model : acc= 65.67%\n",
            "[NEW data] metrics for 643-th model : acc= 66.67%\n",
            "[NEW data] metrics for 644-th model : acc= 66.67%\n",
            "[NEW data] metrics for 645-th model : acc= 68.67%\n",
            "[NEW data] metrics for 646-th model : acc= 67.67%\n",
            "[NEW data] metrics for 647-th model : acc= 67.00%\n",
            "[NEW data] metrics for 648-th model : acc= 68.33%\n",
            "[NEW data] metrics for 649-th model : acc= 67.33%\n",
            "[NEW data] metrics for 650-th model : acc= 67.00%\n",
            "[NEW data] metrics for 651-th model : acc= 67.00%\n",
            "[NEW data] metrics for 652-th model : acc= 67.67%\n",
            "[NEW data] metrics for 653-th model : acc= 67.67%\n",
            "[NEW data] metrics for 654-th model : acc= 66.33%\n",
            "[NEW data] metrics for 655-th model : acc= 67.00%\n",
            "[NEW data] metrics for 656-th model : acc= 68.00%\n",
            "[NEW data] metrics for 657-th model : acc= 66.33%\n",
            "[NEW data] metrics for 658-th model : acc= 66.67%\n",
            "[NEW data] metrics for 659-th model : acc= 66.67%\n",
            "[NEW data] metrics for 660-th model : acc= 67.33%\n",
            "[NEW data] metrics for 661-th model : acc= 68.33%\n",
            "[NEW data] metrics for 662-th model : acc= 68.67%\n",
            "[NEW data] metrics for 663-th model : acc= 67.67%\n",
            "[NEW data] metrics for 664-th model : acc= 69.67%\n",
            "[NEW data] metrics for 665-th model : acc= 66.67%\n",
            "[NEW data] metrics for 666-th model : acc= 67.67%\n",
            "[NEW data] metrics for 667-th model : acc= 67.00%\n",
            "[NEW data] metrics for 668-th model : acc= 66.33%\n",
            "[NEW data] metrics for 669-th model : acc= 68.67%\n",
            "[NEW data] metrics for 670-th model : acc= 68.00%\n",
            "[NEW data] metrics for 671-th model : acc= 70.00%\n",
            "[NEW data] metrics for 672-th model : acc= 68.00%\n",
            "[NEW data] metrics for 673-th model : acc= 65.67%\n",
            "[NEW data] metrics for 674-th model : acc= 65.33%\n",
            "[NEW data] metrics for 675-th model : acc= 66.67%\n",
            "[NEW data] metrics for 676-th model : acc= 68.00%\n",
            "[NEW data] metrics for 677-th model : acc= 68.33%\n",
            "[NEW data] metrics for 678-th model : acc= 66.33%\n",
            "[NEW data] metrics for 679-th model : acc= 68.00%\n",
            "[NEW data] metrics for 680-th model : acc= 66.67%\n",
            "[NEW data] metrics for 681-th model : acc= 68.33%\n",
            "[NEW data] metrics for 682-th model : acc= 68.33%\n",
            "[NEW data] metrics for 683-th model : acc= 67.33%\n",
            "[NEW data] metrics for 684-th model : acc= 68.00%\n",
            "[NEW data] metrics for 685-th model : acc= 67.67%\n",
            "[NEW data] metrics for 686-th model : acc= 69.00%\n",
            "[NEW data] metrics for 687-th model : acc= 68.00%\n",
            "[NEW data] metrics for 688-th model : acc= 67.33%\n",
            "[NEW data] metrics for 689-th model : acc= 64.33%\n",
            "[NEW data] metrics for 690-th model : acc= 68.67%\n",
            "[NEW data] metrics for 691-th model : acc= 66.00%\n",
            "[NEW data] metrics for 692-th model : acc= 65.33%\n",
            "[NEW data] metrics for 693-th model : acc= 67.33%\n",
            "[NEW data] metrics for 694-th model : acc= 68.33%\n",
            "[NEW data] metrics for 695-th model : acc= 68.67%\n",
            "[NEW data] metrics for 696-th model : acc= 69.67%\n",
            "[NEW data] metrics for 697-th model : acc= 68.00%\n",
            "[NEW data] metrics for 698-th model : acc= 66.67%\n",
            "[NEW data] metrics for 699-th model : acc= 67.00%\n",
            "[NEW data] metrics for 700-th model : acc= 68.00%\n",
            "[NEW data] metrics for 701-th model : acc= 69.00%\n",
            "[NEW data] metrics for 702-th model : acc= 64.33%\n",
            "[NEW data] metrics for 703-th model : acc= 63.67%\n",
            "[NEW data] metrics for 704-th model : acc= 67.33%\n",
            "[NEW data] metrics for 705-th model : acc= 67.67%\n",
            "[NEW data] metrics for 706-th model : acc= 68.00%\n",
            "[NEW data] metrics for 707-th model : acc= 69.33%\n",
            "[NEW data] metrics for 708-th model : acc= 69.33%\n",
            "[NEW data] metrics for 709-th model : acc= 67.67%\n",
            "[NEW data] metrics for 710-th model : acc= 67.33%\n",
            "[NEW data] metrics for 711-th model : acc= 68.33%\n",
            "[NEW data] metrics for 712-th model : acc= 69.00%\n",
            "[NEW data] metrics for 713-th model : acc= 67.67%\n",
            "[NEW data] metrics for 714-th model : acc= 68.67%\n",
            "[NEW data] metrics for 715-th model : acc= 64.33%\n",
            "[NEW data] metrics for 716-th model : acc= 68.33%\n",
            "[NEW data] metrics for 717-th model : acc= 68.67%\n",
            "[NEW data] metrics for 718-th model : acc= 68.00%\n",
            "[NEW data] metrics for 719-th model : acc= 63.67%\n",
            "[NEW data] metrics for 720-th model : acc= 65.67%\n",
            "[NEW data] metrics for 721-th model : acc= 70.33%\n",
            "[NEW data] metrics for 722-th model : acc= 65.00%\n",
            "[NEW data] metrics for 723-th model : acc= 67.33%\n",
            "[NEW data] metrics for 724-th model : acc= 67.00%\n",
            "[NEW data] metrics for 725-th model : acc= 47.67%\n",
            "[NEW data] metrics for 726-th model : acc= 68.67%\n",
            "[NEW data] metrics for 727-th model : acc= 67.00%\n",
            "[NEW data] metrics for 728-th model : acc= 54.00%\n",
            "[NEW data] metrics for 729-th model : acc= 66.33%\n",
            "[NEW data] metrics for 730-th model : acc= 68.00%\n",
            "[NEW data] metrics for 731-th model : acc= 68.33%\n",
            "[NEW data] metrics for 732-th model : acc= 67.00%\n",
            "[NEW data] metrics for 733-th model : acc= 66.00%\n",
            "[NEW data] metrics for 734-th model : acc= 67.00%\n",
            "[NEW data] metrics for 735-th model : acc= 66.33%\n",
            "[NEW data] metrics for 736-th model : acc= 66.67%\n",
            "[NEW data] metrics for 737-th model : acc= 67.67%\n",
            "[NEW data] metrics for 738-th model : acc= 68.33%\n",
            "[NEW data] metrics for 739-th model : acc= 65.33%\n",
            "[NEW data] metrics for 740-th model : acc= 68.00%\n",
            "[NEW data] metrics for 741-th model : acc= 67.67%\n",
            "[NEW data] metrics for 742-th model : acc= 68.00%\n",
            "[NEW data] metrics for 743-th model : acc= 66.33%\n",
            "[NEW data] metrics for 744-th model : acc= 65.67%\n",
            "[NEW data] metrics for 745-th model : acc= 67.33%\n",
            "[NEW data] metrics for 746-th model : acc= 67.33%\n",
            "[NEW data] metrics for 747-th model : acc= 67.00%\n",
            "[NEW data] metrics for 748-th model : acc= 68.33%\n",
            "[NEW data] metrics for 749-th model : acc= 66.00%\n",
            "[NEW data] metrics for 750-th model : acc= 66.00%\n",
            "[NEW data] metrics for 751-th model : acc= 67.00%\n",
            "[NEW data] metrics for 752-th model : acc= 71.00%\n",
            "[NEW data] metrics for 753-th model : acc= 67.33%\n",
            "[NEW data] metrics for 754-th model : acc= 68.67%\n",
            "[NEW data] metrics for 755-th model : acc= 66.33%\n",
            "[NEW data] metrics for 756-th model : acc= 66.33%\n",
            "[NEW data] metrics for 757-th model : acc= 67.33%\n",
            "[NEW data] metrics for 758-th model : acc= 53.00%\n",
            "[NEW data] metrics for 759-th model : acc= 69.00%\n",
            "[NEW data] metrics for 760-th model : acc= 69.33%\n",
            "[NEW data] metrics for 761-th model : acc= 66.33%\n",
            "[NEW data] metrics for 762-th model : acc= 66.00%\n",
            "[NEW data] metrics for 763-th model : acc= 67.33%\n",
            "[NEW data] metrics for 764-th model : acc= 69.33%\n",
            "[NEW data] metrics for 765-th model : acc= 68.33%\n",
            "[NEW data] metrics for 766-th model : acc= 47.67%\n",
            "[NEW data] metrics for 767-th model : acc= 39.67%\n",
            "[NEW data] metrics for 768-th model : acc= 69.00%\n",
            "[NEW data] metrics for 769-th model : acc= 67.33%\n",
            "[NEW data] metrics for 770-th model : acc= 69.00%\n",
            "[NEW data] metrics for 771-th model : acc= 67.67%\n",
            "[NEW data] metrics for 772-th model : acc= 65.33%\n",
            "[NEW data] metrics for 773-th model : acc= 64.33%\n",
            "[NEW data] metrics for 774-th model : acc= 67.33%\n",
            "[NEW data] metrics for 775-th model : acc= 67.33%\n",
            "[NEW data] metrics for 776-th model : acc= 69.67%\n",
            "[NEW data] metrics for 777-th model : acc= 69.33%\n",
            "[NEW data] metrics for 778-th model : acc= 65.33%\n",
            "[NEW data] metrics for 779-th model : acc= 66.00%\n",
            "[NEW data] metrics for 780-th model : acc= 68.00%\n",
            "[NEW data] metrics for 781-th model : acc= 66.67%\n",
            "[NEW data] metrics for 782-th model : acc= 67.67%\n",
            "[NEW data] metrics for 783-th model : acc= 67.33%\n",
            "[NEW data] metrics for 784-th model : acc= 68.33%\n",
            "[NEW data] metrics for 785-th model : acc= 63.00%\n",
            "[NEW data] metrics for 786-th model : acc= 67.33%\n",
            "[NEW data] metrics for 787-th model : acc= 66.33%\n",
            "[NEW data] metrics for 788-th model : acc= 67.33%\n",
            "[NEW data] metrics for 789-th model : acc= 67.33%\n",
            "[NEW data] metrics for 790-th model : acc= 67.67%\n",
            "[NEW data] metrics for 791-th model : acc= 69.00%\n",
            "[NEW data] metrics for 792-th model : acc= 67.33%\n",
            "[NEW data] metrics for 793-th model : acc= 69.33%\n",
            "[NEW data] metrics for 794-th model : acc= 65.67%\n",
            "[NEW data] metrics for 795-th model : acc= 68.33%\n",
            "[NEW data] metrics for 796-th model : acc= 68.33%\n",
            "[NEW data] metrics for 797-th model : acc= 65.00%\n",
            "[NEW data] metrics for 798-th model : acc= 66.00%\n",
            "[NEW data] metrics for 799-th model : acc= 64.00%\n",
            "[NEW data] metrics for 800-th model : acc= 64.33%\n",
            "[NEW data] metrics for 801-th model : acc= 68.67%\n",
            "[NEW data] metrics for 802-th model : acc= 68.33%\n",
            "[NEW data] metrics for 803-th model : acc= 67.00%\n",
            "[NEW data] metrics for 804-th model : acc= 66.67%\n",
            "[NEW data] metrics for 805-th model : acc= 68.33%\n",
            "[NEW data] metrics for 806-th model : acc= 66.33%\n",
            "[NEW data] metrics for 807-th model : acc= 67.00%\n",
            "[NEW data] metrics for 808-th model : acc= 47.67%\n",
            "[NEW data] metrics for 809-th model : acc= 68.67%\n",
            "[NEW data] metrics for 810-th model : acc= 65.33%\n",
            "[NEW data] metrics for 811-th model : acc= 67.67%\n",
            "[NEW data] metrics for 812-th model : acc= 68.33%\n",
            "[NEW data] metrics for 813-th model : acc= 67.00%\n",
            "[NEW data] metrics for 814-th model : acc= 71.33%\n",
            "[NEW data] metrics for 815-th model : acc= 65.33%\n",
            "[NEW data] metrics for 816-th model : acc= 68.33%\n",
            "[NEW data] metrics for 817-th model : acc= 65.67%\n",
            "[NEW data] metrics for 818-th model : acc= 67.67%\n",
            "[NEW data] metrics for 819-th model : acc= 70.33%\n",
            "[NEW data] metrics for 820-th model : acc= 67.00%\n",
            "[NEW data] metrics for 821-th model : acc= 66.67%\n",
            "[NEW data] metrics for 822-th model : acc= 66.67%\n",
            "[NEW data] metrics for 823-th model : acc= 66.67%\n",
            "[NEW data] metrics for 824-th model : acc= 68.00%\n",
            "[NEW data] metrics for 825-th model : acc= 67.33%\n",
            "[NEW data] metrics for 826-th model : acc= 66.33%\n",
            "[NEW data] metrics for 827-th model : acc= 69.33%\n",
            "[NEW data] metrics for 828-th model : acc= 67.67%\n",
            "[NEW data] metrics for 829-th model : acc= 65.67%\n",
            "[NEW data] metrics for 830-th model : acc= 65.67%\n",
            "[NEW data] metrics for 831-th model : acc= 65.33%\n",
            "[NEW data] metrics for 832-th model : acc= 67.33%\n",
            "[NEW data] metrics for 833-th model : acc= 65.00%\n",
            "[NEW data] metrics for 834-th model : acc= 68.33%\n",
            "[NEW data] metrics for 835-th model : acc= 66.00%\n",
            "[NEW data] metrics for 836-th model : acc= 68.67%\n",
            "[NEW data] metrics for 837-th model : acc= 67.00%\n",
            "[NEW data] metrics for 838-th model : acc= 68.33%\n",
            "[NEW data] metrics for 839-th model : acc= 66.00%\n",
            "[NEW data] metrics for 840-th model : acc= 67.33%\n",
            "[NEW data] metrics for 841-th model : acc= 68.00%\n",
            "[NEW data] metrics for 842-th model : acc= 67.33%\n",
            "[NEW data] metrics for 843-th model : acc= 66.00%\n",
            "[NEW data] metrics for 844-th model : acc= 67.67%\n",
            "[NEW data] metrics for 845-th model : acc= 65.33%\n",
            "[NEW data] metrics for 846-th model : acc= 68.67%\n",
            "[NEW data] metrics for 847-th model : acc= 67.33%\n",
            "[NEW data] metrics for 848-th model : acc= 68.67%\n",
            "[NEW data] metrics for 849-th model : acc= 66.67%\n",
            "[NEW data] metrics for 850-th model : acc= 68.67%\n",
            "[NEW data] metrics for 851-th model : acc= 67.67%\n",
            "[NEW data] metrics for 852-th model : acc= 67.67%\n",
            "[NEW data] metrics for 853-th model : acc= 66.00%\n",
            "[NEW data] metrics for 854-th model : acc= 47.67%\n",
            "[NEW data] metrics for 855-th model : acc= 65.67%\n",
            "[NEW data] metrics for 856-th model : acc= 66.67%\n",
            "[NEW data] metrics for 857-th model : acc= 69.33%\n",
            "[NEW data] metrics for 858-th model : acc= 68.33%\n",
            "[NEW data] metrics for 859-th model : acc= 68.33%\n",
            "[NEW data] metrics for 860-th model : acc= 68.00%\n",
            "[NEW data] metrics for 861-th model : acc= 67.33%\n",
            "[NEW data] metrics for 862-th model : acc= 69.67%\n",
            "[NEW data] metrics for 863-th model : acc= 66.00%\n",
            "[NEW data] metrics for 864-th model : acc= 68.33%\n",
            "[NEW data] metrics for 865-th model : acc= 67.67%\n",
            "[NEW data] metrics for 866-th model : acc= 65.33%\n",
            "[NEW data] metrics for 867-th model : acc= 68.67%\n",
            "[NEW data] metrics for 868-th model : acc= 66.33%\n",
            "[NEW data] metrics for 869-th model : acc= 68.67%\n",
            "[NEW data] metrics for 870-th model : acc= 70.00%\n",
            "[NEW data] metrics for 871-th model : acc= 69.67%\n",
            "[NEW data] metrics for 872-th model : acc= 67.33%\n",
            "[NEW data] metrics for 873-th model : acc= 69.67%\n",
            "[NEW data] metrics for 874-th model : acc= 68.00%\n",
            "[NEW data] metrics for 875-th model : acc= 69.67%\n",
            "[NEW data] metrics for 876-th model : acc= 69.33%\n",
            "[NEW data] metrics for 877-th model : acc= 70.00%\n",
            "[NEW data] metrics for 878-th model : acc= 67.00%\n",
            "[NEW data] metrics for 879-th model : acc= 66.67%\n",
            "[NEW data] metrics for 880-th model : acc= 67.33%\n",
            "[NEW data] metrics for 881-th model : acc= 68.33%\n",
            "[NEW data] metrics for 882-th model : acc= 67.67%\n",
            "[NEW data] metrics for 883-th model : acc= 68.33%\n",
            "[NEW data] metrics for 884-th model : acc= 67.33%\n",
            "[NEW data] metrics for 885-th model : acc= 68.33%\n",
            "[NEW data] metrics for 886-th model : acc= 66.33%\n",
            "[NEW data] metrics for 887-th model : acc= 66.00%\n",
            "[NEW data] metrics for 888-th model : acc= 66.33%\n",
            "[NEW data] metrics for 889-th model : acc= 69.33%\n",
            "[NEW data] metrics for 890-th model : acc= 67.33%\n",
            "[NEW data] metrics for 891-th model : acc= 67.00%\n",
            "[NEW data] metrics for 892-th model : acc= 66.33%\n",
            "[NEW data] metrics for 893-th model : acc= 68.33%\n",
            "[NEW data] metrics for 894-th model : acc= 67.67%\n",
            "[NEW data] metrics for 895-th model : acc= 67.67%\n",
            "[NEW data] metrics for 896-th model : acc= 67.67%\n",
            "[NEW data] metrics for 897-th model : acc= 68.00%\n",
            "[NEW data] metrics for 898-th model : acc= 66.00%\n",
            "[NEW data] metrics for 899-th model : acc= 67.00%\n",
            "[NEW data] metrics for 900-th model : acc= 67.67%\n",
            "[NEW data] metrics for 901-th model : acc= 68.67%\n",
            "[NEW data] metrics for 902-th model : acc= 68.00%\n",
            "[NEW data] metrics for 903-th model : acc= 67.67%\n",
            "[NEW data] metrics for 904-th model : acc= 66.33%\n",
            "[NEW data] metrics for 905-th model : acc= 67.67%\n",
            "[NEW data] metrics for 906-th model : acc= 65.00%\n",
            "[NEW data] metrics for 907-th model : acc= 70.00%\n",
            "[NEW data] metrics for 908-th model : acc= 67.00%\n",
            "[NEW data] metrics for 909-th model : acc= 66.67%\n",
            "[NEW data] metrics for 910-th model : acc= 67.33%\n",
            "[NEW data] metrics for 911-th model : acc= 67.67%\n",
            "[NEW data] metrics for 912-th model : acc= 69.67%\n",
            "[NEW data] metrics for 913-th model : acc= 67.67%\n",
            "[NEW data] metrics for 914-th model : acc= 68.00%\n",
            "[NEW data] metrics for 915-th model : acc= 68.33%\n",
            "[NEW data] metrics for 916-th model : acc= 47.67%\n",
            "[NEW data] metrics for 917-th model : acc= 65.67%\n",
            "[NEW data] metrics for 918-th model : acc= 65.33%\n",
            "[NEW data] metrics for 919-th model : acc= 69.00%\n",
            "[NEW data] metrics for 920-th model : acc= 64.67%\n",
            "[NEW data] metrics for 921-th model : acc= 67.67%\n",
            "[NEW data] metrics for 922-th model : acc= 66.67%\n",
            "[NEW data] metrics for 923-th model : acc= 66.00%\n",
            "[NEW data] metrics for 924-th model : acc= 66.67%\n",
            "[NEW data] metrics for 925-th model : acc= 67.67%\n",
            "[NEW data] metrics for 926-th model : acc= 67.00%\n",
            "[NEW data] metrics for 927-th model : acc= 67.67%\n",
            "[NEW data] metrics for 928-th model : acc= 67.67%\n",
            "[NEW data] metrics for 929-th model : acc= 70.67%\n",
            "[NEW data] metrics for 930-th model : acc= 66.00%\n",
            "[NEW data] metrics for 931-th model : acc= 68.67%\n",
            "[NEW data] metrics for 932-th model : acc= 65.33%\n",
            "[NEW data] metrics for 933-th model : acc= 66.00%\n",
            "[NEW data] metrics for 934-th model : acc= 66.00%\n",
            "[NEW data] metrics for 935-th model : acc= 66.33%\n",
            "[NEW data] metrics for 936-th model : acc= 66.67%\n",
            "[NEW data] metrics for 937-th model : acc= 61.00%\n",
            "[NEW data] metrics for 938-th model : acc= 66.33%\n",
            "[NEW data] metrics for 939-th model : acc= 66.67%\n",
            "[NEW data] metrics for 940-th model : acc= 64.67%\n",
            "[NEW data] metrics for 941-th model : acc= 65.33%\n",
            "[NEW data] metrics for 942-th model : acc= 68.00%\n",
            "[NEW data] metrics for 943-th model : acc= 69.00%\n",
            "[NEW data] metrics for 944-th model : acc= 67.00%\n",
            "[NEW data] metrics for 945-th model : acc= 67.00%\n",
            "[NEW data] metrics for 946-th model : acc= 66.33%\n",
            "[NEW data] metrics for 947-th model : acc= 67.00%\n",
            "[NEW data] metrics for 948-th model : acc= 69.00%\n",
            "[NEW data] metrics for 949-th model : acc= 58.33%\n",
            "[NEW data] metrics for 950-th model : acc= 66.33%\n",
            "[NEW data] metrics for 951-th model : acc= 68.00%\n",
            "[NEW data] metrics for 952-th model : acc= 67.00%\n",
            "[NEW data] metrics for 953-th model : acc= 67.33%\n",
            "[NEW data] metrics for 954-th model : acc= 66.00%\n",
            "[NEW data] metrics for 955-th model : acc= 65.33%\n",
            "[NEW data] metrics for 956-th model : acc= 69.00%\n",
            "[NEW data] metrics for 957-th model : acc= 67.67%\n",
            "[NEW data] metrics for 958-th model : acc= 67.33%\n",
            "[NEW data] metrics for 959-th model : acc= 66.67%\n",
            "[NEW data] metrics for 960-th model : acc= 65.00%\n",
            "[NEW data] metrics for 961-th model : acc= 66.67%\n",
            "[NEW data] metrics for 962-th model : acc= 70.67%\n",
            "[NEW data] metrics for 963-th model : acc= 70.67%\n",
            "[NEW data] metrics for 964-th model : acc= 65.33%\n",
            "[NEW data] metrics for 965-th model : acc= 68.00%\n",
            "[NEW data] metrics for 966-th model : acc= 65.33%\n",
            "[NEW data] metrics for 967-th model : acc= 66.00%\n",
            "[NEW data] metrics for 968-th model : acc= 66.00%\n",
            "[NEW data] metrics for 969-th model : acc= 65.00%\n",
            "[NEW data] metrics for 970-th model : acc= 66.00%\n",
            "[NEW data] metrics for 971-th model : acc= 69.00%\n",
            "[NEW data] metrics for 972-th model : acc= 69.00%\n",
            "[NEW data] metrics for 973-th model : acc= 66.33%\n",
            "[NEW data] metrics for 974-th model : acc= 53.33%\n",
            "[NEW data] metrics for 975-th model : acc= 66.67%\n",
            "[NEW data] metrics for 976-th model : acc= 69.33%\n",
            "[NEW data] metrics for 977-th model : acc= 66.67%\n",
            "[NEW data] metrics for 978-th model : acc= 72.00%\n",
            "[NEW data] metrics for 979-th model : acc= 68.33%\n",
            "[NEW data] metrics for 980-th model : acc= 65.67%\n",
            "[NEW data] metrics for 981-th model : acc= 66.00%\n",
            "[NEW data] metrics for 982-th model : acc= 64.00%\n",
            "[NEW data] metrics for 983-th model : acc= 69.33%\n",
            "[NEW data] metrics for 984-th model : acc= 66.33%\n",
            "[NEW data] metrics for 985-th model : acc= 66.67%\n",
            "[NEW data] metrics for 986-th model : acc= 66.00%\n",
            "[NEW data] metrics for 987-th model : acc= 65.67%\n",
            "[NEW data] metrics for 988-th model : acc= 51.00%\n",
            "[NEW data] metrics for 989-th model : acc= 69.67%\n",
            "[NEW data] metrics for 990-th model : acc= 68.00%\n",
            "[NEW data] metrics for 991-th model : acc= 67.00%\n",
            "[NEW data] metrics for 992-th model : acc= 64.00%\n",
            "[NEW data] metrics for 993-th model : acc= 66.67%\n",
            "[NEW data] metrics for 994-th model : acc= 68.33%\n",
            "[NEW data] metrics for 995-th model : acc= 64.33%\n",
            "[NEW data] metrics for 996-th model : acc= 68.67%\n",
            "[NEW data] metrics for 997-th model : acc= 66.67%\n",
            "[NEW data] metrics for 998-th model : acc= 47.67%\n",
            "[NEW data] metrics for 999-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1000-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1001-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1002-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1003-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1004-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1005-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1006-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1007-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1008-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1009-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1010-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1011-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1012-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1013-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1014-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1015-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1016-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1017-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1018-th model : acc= 55.00%\n",
            "[NEW data] metrics for 1019-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1020-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1021-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1022-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1023-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1024-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1025-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1026-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1027-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1028-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1029-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1030-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1031-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1032-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1033-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1034-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1035-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1036-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1037-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1038-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1039-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1040-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1041-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1042-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1043-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1044-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1045-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1046-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1047-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1048-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1049-th model : acc= 60.67%\n",
            "[NEW data] metrics for 1050-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1051-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1052-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1053-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1054-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1055-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1056-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1057-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1058-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1059-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1060-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1061-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1062-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1063-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1064-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1065-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1066-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1067-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1068-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1069-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1070-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1071-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1072-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1073-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1074-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1075-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1076-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1077-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1078-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1079-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1080-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1081-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1082-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1083-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1084-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1085-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1086-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1087-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1088-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1089-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1090-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1091-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1092-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1093-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1094-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1095-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1096-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1097-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1098-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1099-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1100-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1101-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1102-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1103-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1104-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1105-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1106-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1107-th model : acc= 60.67%\n",
            "[NEW data] metrics for 1108-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1109-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1110-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1111-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1112-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1113-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1114-th model : acc= 51.33%\n",
            "[NEW data] metrics for 1115-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1116-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1117-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1118-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1119-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1120-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1121-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1122-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1123-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1124-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1125-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1126-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1127-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1128-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1129-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1130-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1131-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1132-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1133-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1134-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1135-th model : acc= 61.33%\n",
            "[NEW data] metrics for 1136-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1137-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1138-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1139-th model : acc= 53.67%\n",
            "[NEW data] metrics for 1140-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1141-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1142-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1143-th model : acc= 71.00%\n",
            "[NEW data] metrics for 1144-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1145-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1146-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1147-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1148-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1149-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1150-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1151-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1152-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1153-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1154-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1155-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1156-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1157-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1158-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1159-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1160-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1161-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1162-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1163-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1164-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1165-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1166-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1167-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1168-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1169-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1170-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1171-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1172-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1173-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1174-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1175-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1176-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1177-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1178-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1179-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1180-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1181-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1182-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1183-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1184-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1185-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1186-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1187-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1188-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1189-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1190-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1191-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1192-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1193-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1194-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1195-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1196-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1197-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1198-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1199-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1200-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1201-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1202-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1203-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1204-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1205-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1206-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1207-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1208-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1209-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1210-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1211-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1212-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1213-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1214-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1215-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1216-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1217-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1218-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1219-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1220-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1221-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1222-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1223-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1224-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1225-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1226-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1227-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1228-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1229-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1230-th model : acc= 71.00%\n",
            "[NEW data] metrics for 1231-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1232-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1233-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1234-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1235-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1236-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1237-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1238-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1239-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1240-th model : acc= 59.67%\n",
            "[NEW data] metrics for 1241-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1242-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1243-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1244-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1245-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1246-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1247-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1248-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1249-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1250-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1251-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1252-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1253-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1254-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1255-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1256-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1257-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1258-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1259-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1260-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1261-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1262-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1263-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1264-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1265-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1266-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1267-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1268-th model : acc= 62.67%\n",
            "[NEW data] metrics for 1269-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1270-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1271-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1272-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1273-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1274-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1275-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1276-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1277-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1278-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1279-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1280-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1281-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1282-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1283-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1284-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1285-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1286-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1287-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1288-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1289-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1290-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1291-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1292-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1293-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1294-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1295-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1296-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1297-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1298-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1299-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1300-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1301-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1302-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1303-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1304-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1305-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1306-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1307-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1308-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1309-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1310-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1311-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1312-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1313-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1314-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1315-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1316-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1317-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1318-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1319-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1320-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1321-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1322-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1323-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1324-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1325-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1326-th model : acc= 63.33%\n",
            "[NEW data] metrics for 1327-th model : acc= 71.33%\n",
            "[NEW data] metrics for 1328-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1329-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1330-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1331-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1332-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1333-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1334-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1335-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1336-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1337-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1338-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1339-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1340-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1341-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1342-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1343-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1344-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1345-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1346-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1347-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1348-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1349-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1350-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1351-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1352-th model : acc= 54.00%\n",
            "[NEW data] metrics for 1353-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1354-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1355-th model : acc= 62.67%\n",
            "[NEW data] metrics for 1356-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1357-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1358-th model : acc= 62.33%\n",
            "[NEW data] metrics for 1359-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1360-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1361-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1362-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1363-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1364-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1365-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1366-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1367-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1368-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1369-th model : acc= 59.33%\n",
            "[NEW data] metrics for 1370-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1371-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1372-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1373-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1374-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1375-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1376-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1377-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1378-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1379-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1380-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1381-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1382-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1383-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1384-th model : acc= 71.67%\n",
            "[NEW data] metrics for 1385-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1386-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1387-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1388-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1389-th model : acc= 63.00%\n",
            "[NEW data] metrics for 1390-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1391-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1392-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1393-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1394-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1395-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1396-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1397-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1398-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1399-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1400-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1401-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1402-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1403-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1404-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1405-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1406-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1407-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1408-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1409-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1410-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1411-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1412-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1413-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1414-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1415-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1416-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1417-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1418-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1419-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1420-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1421-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1422-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1423-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1424-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1425-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1426-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1427-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1428-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1429-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1430-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1431-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1432-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1433-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1434-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1435-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1436-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1437-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1438-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1439-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1440-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1441-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1442-th model : acc= 71.00%\n",
            "[NEW data] metrics for 1443-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1444-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1445-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1446-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1447-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1448-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1449-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1450-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1451-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1452-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1453-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1454-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1455-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1456-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1457-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1458-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1459-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1460-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1461-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1462-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1463-th model : acc= 51.67%\n",
            "[NEW data] metrics for 1464-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1465-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1466-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1467-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1468-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1469-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1470-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1471-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1472-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1473-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1474-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1475-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1476-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1477-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1478-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1479-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1480-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1481-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1482-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1483-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1484-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1485-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1486-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1487-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1488-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1489-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1490-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1491-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1492-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1493-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1494-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1495-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1496-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1497-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1498-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1499-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1500-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1501-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1502-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1503-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1504-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1505-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1506-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1507-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1508-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1509-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1510-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1511-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1512-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1513-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1514-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1515-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1516-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1517-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1518-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1519-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1520-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1521-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1522-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1523-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1524-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1525-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1526-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1527-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1528-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1529-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1530-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1531-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1532-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1533-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1534-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1535-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1536-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1537-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1538-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1539-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1540-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1541-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1542-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1543-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1544-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1545-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1546-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1547-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1548-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1549-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1550-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1551-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1552-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1553-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1554-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1555-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1556-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1557-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1558-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1559-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1560-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1561-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1562-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1563-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1564-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1565-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1566-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1567-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1568-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1569-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1570-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1571-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1572-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1573-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1574-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1575-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1576-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1577-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1578-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1579-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1580-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1581-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1582-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1583-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1584-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1585-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1586-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1587-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1588-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1589-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1590-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1591-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1592-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1593-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1594-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1595-th model : acc= 53.67%\n",
            "[NEW data] metrics for 1596-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1597-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1598-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1599-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1600-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1601-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1602-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1603-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1604-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1605-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1606-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1607-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1608-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1609-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1610-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1611-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1612-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1613-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1614-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1615-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1616-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1617-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1618-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1619-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1620-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1621-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1622-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1623-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1624-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1625-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1626-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1627-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1628-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1629-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1630-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1631-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1632-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1633-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1634-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1635-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1636-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1637-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1638-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1639-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1640-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1641-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1642-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1643-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1644-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1645-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1646-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1647-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1648-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1649-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1650-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1651-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1652-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1653-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1654-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1655-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1656-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1657-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1658-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1659-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1660-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1661-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1662-th model : acc= 72.00%\n",
            "[NEW data] metrics for 1663-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1664-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1665-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1666-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1667-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1668-th model : acc= 53.33%\n",
            "[NEW data] metrics for 1669-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1670-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1671-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1672-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1673-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1674-th model : acc= 52.00%\n",
            "[NEW data] metrics for 1675-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1676-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1677-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1678-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1679-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1680-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1681-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1682-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1683-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1684-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1685-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1686-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1687-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1688-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1689-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1690-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1691-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1692-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1693-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1694-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1695-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1696-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1697-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1698-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1699-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1700-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1701-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1702-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1703-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1704-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1705-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1706-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1707-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1708-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1709-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1710-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1711-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1712-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1713-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1714-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1715-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1716-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1717-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1718-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1719-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1720-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1721-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1722-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1723-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1724-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1725-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1726-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1727-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1728-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1729-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1730-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1731-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1732-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1733-th model : acc= 58.33%\n",
            "[NEW data] metrics for 1734-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1735-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1736-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1737-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1738-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1739-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1740-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1741-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1742-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1743-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1744-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1745-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1746-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1747-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1748-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1749-th model : acc= 70.00%\n",
            "[NEW data] metrics for 1750-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1751-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1752-th model : acc= 70.67%\n",
            "[NEW data] metrics for 1753-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1754-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1755-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1756-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1757-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1758-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1759-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1760-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1761-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1762-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1763-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1764-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1765-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1766-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1767-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1768-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1769-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1770-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1771-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1772-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1773-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1774-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1775-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1776-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1777-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1778-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1779-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1780-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1781-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1782-th model : acc= 60.67%\n",
            "[NEW data] metrics for 1783-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1784-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1785-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1786-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1787-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1788-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1789-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1790-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1791-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1792-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1793-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1794-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1795-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1796-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1797-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1798-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1799-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1800-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1801-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1802-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1803-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1804-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1805-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1806-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1807-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1808-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1809-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1810-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1811-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1812-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1813-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1814-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1815-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1816-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1817-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1818-th model : acc= 70.33%\n",
            "[NEW data] metrics for 1819-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1820-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1821-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1822-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1823-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1824-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1825-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1826-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1827-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1828-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1829-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1830-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1831-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1832-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1833-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1834-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1835-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1836-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1837-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1838-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1839-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1840-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1841-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1842-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1843-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1844-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1845-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1846-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1847-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1848-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1849-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1850-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1851-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1852-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1853-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1854-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1855-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1856-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1857-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1858-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1859-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1860-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1861-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1862-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1863-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1864-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1865-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1866-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1867-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1868-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1869-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1870-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1871-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1872-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1873-th model : acc= 62.00%\n",
            "[NEW data] metrics for 1874-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1875-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1876-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1877-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1878-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1879-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1880-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1881-th model : acc= 64.00%\n",
            "[NEW data] metrics for 1882-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1883-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1884-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1885-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1886-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1887-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1888-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1889-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1890-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1891-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1892-th model : acc= 69.67%\n",
            "[NEW data] metrics for 1893-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1894-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1895-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1896-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1897-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1898-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1899-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1900-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1901-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1902-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1903-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1904-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1905-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1906-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1907-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1908-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1909-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1910-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1911-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1912-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1913-th model : acc= 50.00%\n",
            "[NEW data] metrics for 1914-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1915-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1916-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1917-th model : acc= 60.00%\n",
            "[NEW data] metrics for 1918-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1919-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1920-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1921-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1922-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1923-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1924-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1925-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1926-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1927-th model : acc= 64.33%\n",
            "[NEW data] metrics for 1928-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1929-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1930-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1931-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1932-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1933-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1934-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1935-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1936-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1937-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1938-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1939-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1940-th model : acc= 68.67%\n",
            "[NEW data] metrics for 1941-th model : acc= 69.00%\n",
            "[NEW data] metrics for 1942-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1943-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1944-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1945-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1946-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1947-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1948-th model : acc= 65.33%\n",
            "[NEW data] metrics for 1949-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1950-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1951-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1952-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1953-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1954-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1955-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1956-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1957-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1958-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1959-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1960-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1961-th model : acc= 65.67%\n",
            "[NEW data] metrics for 1962-th model : acc= 63.67%\n",
            "[NEW data] metrics for 1963-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1964-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1965-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1966-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1967-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1968-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1969-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1970-th model : acc= 67.67%\n",
            "[NEW data] metrics for 1971-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1972-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1973-th model : acc= 66.00%\n",
            "[NEW data] metrics for 1974-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1975-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1976-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1977-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1978-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1979-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1980-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1981-th model : acc= 47.67%\n",
            "[NEW data] metrics for 1982-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1983-th model : acc= 55.00%\n",
            "[NEW data] metrics for 1984-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1985-th model : acc= 67.00%\n",
            "[NEW data] metrics for 1986-th model : acc= 67.33%\n",
            "[NEW data] metrics for 1987-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1988-th model : acc= 65.00%\n",
            "[NEW data] metrics for 1989-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1990-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1991-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1992-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1993-th model : acc= 66.67%\n",
            "[NEW data] metrics for 1994-th model : acc= 66.33%\n",
            "[NEW data] metrics for 1995-th model : acc= 68.33%\n",
            "[NEW data] metrics for 1996-th model : acc= 64.67%\n",
            "[NEW data] metrics for 1997-th model : acc= 68.00%\n",
            "[NEW data] metrics for 1998-th model : acc= 69.33%\n",
            "[NEW data] metrics for 1999-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2000-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2001-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2002-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2003-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2004-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2005-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2006-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2007-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2008-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2009-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2010-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2011-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2012-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2013-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2014-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2015-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2016-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2017-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2018-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2019-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2020-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2021-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2022-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2023-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2024-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2025-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2026-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2027-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2028-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2029-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2030-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2031-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2032-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2033-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2034-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2035-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2036-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2037-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2038-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2039-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2040-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2041-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2042-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2043-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2044-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2045-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2046-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2047-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2048-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2049-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2050-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2051-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2052-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2053-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2054-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2055-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2056-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2057-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2058-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2059-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2060-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2061-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2062-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2063-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2064-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2065-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2066-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2067-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2068-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2069-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2070-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2071-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2072-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2073-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2074-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2075-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2076-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2077-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2078-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2079-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2080-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2081-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2082-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2083-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2084-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2085-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2086-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2087-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2088-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2089-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2090-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2091-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2092-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2093-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2094-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2095-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2096-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2097-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2098-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2099-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2100-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2101-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2102-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2103-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2104-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2105-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2106-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2107-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2108-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2109-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2110-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2111-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2112-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2113-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2114-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2115-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2116-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2117-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2118-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2119-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2120-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2121-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2122-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2123-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2124-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2125-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2126-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2127-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2128-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2129-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2130-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2131-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2132-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2133-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2134-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2135-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2136-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2137-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2138-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2139-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2140-th model : acc= 51.00%\n",
            "[NEW data] metrics for 2141-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2142-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2143-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2144-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2145-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2146-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2147-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2148-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2149-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2150-th model : acc= 61.33%\n",
            "[NEW data] metrics for 2151-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2152-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2153-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2154-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2155-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2156-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2157-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2158-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2159-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2160-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2161-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2162-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2163-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2164-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2165-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2166-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2167-th model : acc= 59.67%\n",
            "[NEW data] metrics for 2168-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2169-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2170-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2171-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2172-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2173-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2174-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2175-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2176-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2177-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2178-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2179-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2180-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2181-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2182-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2183-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2184-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2185-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2186-th model : acc= 54.33%\n",
            "[NEW data] metrics for 2187-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2188-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2189-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2190-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2191-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2192-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2193-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2194-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2195-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2196-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2197-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2198-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2199-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2200-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2201-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2202-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2203-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2204-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2205-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2206-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2207-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2208-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2209-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2210-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2211-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2212-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2213-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2214-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2215-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2216-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2217-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2218-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2219-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2220-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2221-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2222-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2223-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2224-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2225-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2226-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2227-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2228-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2229-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2230-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2231-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2232-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2233-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2234-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2235-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2236-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2237-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2238-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2239-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2240-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2241-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2242-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2243-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2244-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2245-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2246-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2247-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2248-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2249-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2250-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2251-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2252-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2253-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2254-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2255-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2256-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2257-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2258-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2259-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2260-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2261-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2262-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2263-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2264-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2265-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2266-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2267-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2268-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2269-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2270-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2271-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2272-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2273-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2274-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2275-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2276-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2277-th model : acc= 70.67%\n",
            "[NEW data] metrics for 2278-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2279-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2280-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2281-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2282-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2283-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2284-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2285-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2286-th model : acc= 57.33%\n",
            "[NEW data] metrics for 2287-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2288-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2289-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2290-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2291-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2292-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2293-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2294-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2295-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2296-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2297-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2298-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2299-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2300-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2301-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2302-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2303-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2304-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2305-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2306-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2307-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2308-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2309-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2310-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2311-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2312-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2313-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2314-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2315-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2316-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2317-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2318-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2319-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2320-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2321-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2322-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2323-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2324-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2325-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2326-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2327-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2328-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2329-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2330-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2331-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2332-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2333-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2334-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2335-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2336-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2337-th model : acc= 60.00%\n",
            "[NEW data] metrics for 2338-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2339-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2340-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2341-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2342-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2343-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2344-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2345-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2346-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2347-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2348-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2349-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2350-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2351-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2352-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2353-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2354-th model : acc= 62.33%\n",
            "[NEW data] metrics for 2355-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2356-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2357-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2358-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2359-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2360-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2361-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2362-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2363-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2364-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2365-th model : acc= 41.00%\n",
            "[NEW data] metrics for 2366-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2367-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2368-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2369-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2370-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2371-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2372-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2373-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2374-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2375-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2376-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2377-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2378-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2379-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2380-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2381-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2382-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2383-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2384-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2385-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2386-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2387-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2388-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2389-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2390-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2391-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2392-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2393-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2394-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2395-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2396-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2397-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2398-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2399-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2400-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2401-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2402-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2403-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2404-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2405-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2406-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2407-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2408-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2409-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2410-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2411-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2412-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2413-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2414-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2415-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2416-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2417-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2418-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2419-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2420-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2421-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2422-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2423-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2424-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2425-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2426-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2427-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2428-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2429-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2430-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2431-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2432-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2433-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2434-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2435-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2436-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2437-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2438-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2439-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2440-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2441-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2442-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2443-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2444-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2445-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2446-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2447-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2448-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2449-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2450-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2451-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2452-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2453-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2454-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2455-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2456-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2457-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2458-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2459-th model : acc= 54.67%\n",
            "[NEW data] metrics for 2460-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2461-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2462-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2463-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2464-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2465-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2466-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2467-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2468-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2469-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2470-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2471-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2472-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2473-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2474-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2475-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2476-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2477-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2478-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2479-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2480-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2481-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2482-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2483-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2484-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2485-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2486-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2487-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2488-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2489-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2490-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2491-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2492-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2493-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2494-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2495-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2496-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2497-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2498-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2499-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2500-th model : acc= 53.33%\n",
            "[NEW data] metrics for 2501-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2502-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2503-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2504-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2505-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2506-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2507-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2508-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2509-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2510-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2511-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2512-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2513-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2514-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2515-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2516-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2517-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2518-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2519-th model : acc= 71.67%\n",
            "[NEW data] metrics for 2520-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2521-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2522-th model : acc= 63.33%\n",
            "[NEW data] metrics for 2523-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2524-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2525-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2526-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2527-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2528-th model : acc= 54.00%\n",
            "[NEW data] metrics for 2529-th model : acc= 48.33%\n",
            "[NEW data] metrics for 2530-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2531-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2532-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2533-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2534-th model : acc= 44.67%\n",
            "[NEW data] metrics for 2535-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2536-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2537-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2538-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2539-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2540-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2541-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2542-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2543-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2544-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2545-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2546-th model : acc= 60.00%\n",
            "[NEW data] metrics for 2547-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2548-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2549-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2550-th model : acc= 64.00%\n",
            "[NEW data] metrics for 2551-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2552-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2553-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2554-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2555-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2556-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2557-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2558-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2559-th model : acc= 71.00%\n",
            "[NEW data] metrics for 2560-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2561-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2562-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2563-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2564-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2565-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2566-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2567-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2568-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2569-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2570-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2571-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2572-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2573-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2574-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2575-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2576-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2577-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2578-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2579-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2580-th model : acc= 71.33%\n",
            "[NEW data] metrics for 2581-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2582-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2583-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2584-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2585-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2586-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2587-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2588-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2589-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2590-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2591-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2592-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2593-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2594-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2595-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2596-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2597-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2598-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2599-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2600-th model : acc= 71.33%\n",
            "[NEW data] metrics for 2601-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2602-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2603-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2604-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2605-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2606-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2607-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2608-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2609-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2610-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2611-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2612-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2613-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2614-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2615-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2616-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2617-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2618-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2619-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2620-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2621-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2622-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2623-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2624-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2625-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2626-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2627-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2628-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2629-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2630-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2631-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2632-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2633-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2634-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2635-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2636-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2637-th model : acc= 61.33%\n",
            "[NEW data] metrics for 2638-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2639-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2640-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2641-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2642-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2643-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2644-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2645-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2646-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2647-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2648-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2649-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2650-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2651-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2652-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2653-th model : acc= 60.00%\n",
            "[NEW data] metrics for 2654-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2655-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2656-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2657-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2658-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2659-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2660-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2661-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2662-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2663-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2664-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2665-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2666-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2667-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2668-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2669-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2670-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2671-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2672-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2673-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2674-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2675-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2676-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2677-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2678-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2679-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2680-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2681-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2682-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2683-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2684-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2685-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2686-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2687-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2688-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2689-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2690-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2691-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2692-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2693-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2694-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2695-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2696-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2697-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2698-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2699-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2700-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2701-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2702-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2703-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2704-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2705-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2706-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2707-th model : acc= 62.67%\n",
            "[NEW data] metrics for 2708-th model : acc= 55.00%\n",
            "[NEW data] metrics for 2709-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2710-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2711-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2712-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2713-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2714-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2715-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2716-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2717-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2718-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2719-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2720-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2721-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2722-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2723-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2724-th model : acc= 44.67%\n",
            "[NEW data] metrics for 2725-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2726-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2727-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2728-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2729-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2730-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2731-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2732-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2733-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2734-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2735-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2736-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2737-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2738-th model : acc= 59.33%\n",
            "[NEW data] metrics for 2739-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2740-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2741-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2742-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2743-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2744-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2745-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2746-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2747-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2748-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2749-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2750-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2751-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2752-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2753-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2754-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2755-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2756-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2757-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2758-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2759-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2760-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2761-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2762-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2763-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2764-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2765-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2766-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2767-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2768-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2769-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2770-th model : acc= 62.33%\n",
            "[NEW data] metrics for 2771-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2772-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2773-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2774-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2775-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2776-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2777-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2778-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2779-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2780-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2781-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2782-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2783-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2784-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2785-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2786-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2787-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2788-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2789-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2790-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2791-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2792-th model : acc= 50.67%\n",
            "[NEW data] metrics for 2793-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2794-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2795-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2796-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2797-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2798-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2799-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2800-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2801-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2802-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2803-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2804-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2805-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2806-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2807-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2808-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2809-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2810-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2811-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2812-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2813-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2814-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2815-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2816-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2817-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2818-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2819-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2820-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2821-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2822-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2823-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2824-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2825-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2826-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2827-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2828-th model : acc= 64.33%\n",
            "[NEW data] metrics for 2829-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2830-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2831-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2832-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2833-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2834-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2835-th model : acc= 70.33%\n",
            "[NEW data] metrics for 2836-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2837-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2838-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2839-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2840-th model : acc= 63.67%\n",
            "[NEW data] metrics for 2841-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2842-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2843-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2844-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2845-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2846-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2847-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2848-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2849-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2850-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2851-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2852-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2853-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2854-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2855-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2856-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2857-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2858-th model : acc= 62.00%\n",
            "[NEW data] metrics for 2859-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2860-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2861-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2862-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2863-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2864-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2865-th model : acc= 60.33%\n",
            "[NEW data] metrics for 2866-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2867-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2868-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2869-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2870-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2871-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2872-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2873-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2874-th model : acc= 47.67%\n",
            "[NEW data] metrics for 2875-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2876-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2877-th model : acc= 61.67%\n",
            "[NEW data] metrics for 2878-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2879-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2880-th model : acc= 63.00%\n",
            "[NEW data] metrics for 2881-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2882-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2883-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2884-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2885-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2886-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2887-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2888-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2889-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2890-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2891-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2892-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2893-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2894-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2895-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2896-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2897-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2898-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2899-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2900-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2901-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2902-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2903-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2904-th model : acc= 64.67%\n",
            "[NEW data] metrics for 2905-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2906-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2907-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2908-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2909-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2910-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2911-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2912-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2913-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2914-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2915-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2916-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2917-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2918-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2919-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2920-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2921-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2922-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2923-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2924-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2925-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2926-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2927-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2928-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2929-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2930-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2931-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2932-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2933-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2934-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2935-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2936-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2937-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2938-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2939-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2940-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2941-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2942-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2943-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2944-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2945-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2946-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2947-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2948-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2949-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2950-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2951-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2952-th model : acc= 69.33%\n",
            "[NEW data] metrics for 2953-th model : acc= 53.33%\n",
            "[NEW data] metrics for 2954-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2955-th model : acc= 65.33%\n",
            "[NEW data] metrics for 2956-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2957-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2958-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2959-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2960-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2961-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2962-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2963-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2964-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2965-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2966-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2967-th model : acc= 67.33%\n",
            "[NEW data] metrics for 2968-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2969-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2970-th model : acc= 67.67%\n",
            "[NEW data] metrics for 2971-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2972-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2973-th model : acc= 69.67%\n",
            "[NEW data] metrics for 2974-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2975-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2976-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2977-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2978-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2979-th model : acc= 68.67%\n",
            "[NEW data] metrics for 2980-th model : acc= 62.33%\n",
            "[NEW data] metrics for 2981-th model : acc= 68.33%\n",
            "[NEW data] metrics for 2982-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2983-th model : acc= 69.00%\n",
            "[NEW data] metrics for 2984-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2985-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2986-th model : acc= 71.33%\n",
            "[NEW data] metrics for 2987-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2988-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2989-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2990-th model : acc= 66.67%\n",
            "[NEW data] metrics for 2991-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2992-th model : acc= 66.00%\n",
            "[NEW data] metrics for 2993-th model : acc= 65.00%\n",
            "[NEW data] metrics for 2994-th model : acc= 67.00%\n",
            "[NEW data] metrics for 2995-th model : acc= 65.67%\n",
            "[NEW data] metrics for 2996-th model : acc= 68.00%\n",
            "[NEW data] metrics for 2997-th model : acc= 66.33%\n",
            "[NEW data] metrics for 2998-th model : acc= 70.00%\n",
            "[NEW data] metrics for 2999-th model : acc= 68.00%\n",
            "[NEW data] metrics for 3000-th model : acc= 68.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotly 를 이용하여 성능 비교\n",
        "\n",
        "WINDOW_SIZE = 30\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "trial_nos = np.array(range(TRIAL_COUNT))\n",
        "trials_df = study.trials_dataframe()\n",
        "hpo_accuracy = 100 * trials_df['value'].to_numpy()\n",
        "\n",
        "# 성능 추이 표시\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=hpo_accuracy,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 4, 'color': '#F70'},\n",
        "                         name='HPO test dataset accuracy'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=new_dataset_accuracy,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 4, 'color': '#07F'},\n",
        "                         name='NEW test dataset accuracy'))\n",
        "\n",
        "# 성능 추이의 이동평균 표시\n",
        "hpo_accuracy_ma = np.convolve(hpo_accuracy,\n",
        "                              np.ones(WINDOW_SIZE) / WINDOW_SIZE,\n",
        "                              mode='valid')\n",
        "\n",
        "new_dataset_accuracy_ma = np.convolve(new_dataset_accuracy,\n",
        "                                      np.ones(WINDOW_SIZE) / WINDOW_SIZE,\n",
        "                                      mode='valid')\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=hpo_accuracy_ma,\n",
        "                         mode='lines',\n",
        "                         line={'color': '#FA0'},\n",
        "                         name='HPO test dataset accuracy (Moving Average)'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=new_dataset_accuracy_ma,\n",
        "                         mode='lines',\n",
        "                         line={'color': '#0AF'},\n",
        "                         name='NEW test dataset accuracy (Moving Average)'))\n",
        "\n",
        "# 차트 표시\n",
        "fig.update_layout(width=1200,\n",
        "                  height=600,\n",
        "                  xaxis_title='trial No.',\n",
        "                  yaxis_title='Accuracy (%)')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "LB0lJNhKNcTe",
        "outputId": "5824ce3b-476e-4cbf-d5f6-6b307641acad"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a37a2bc8-c3d5-4f31-9d2c-16eac6491e6a\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a37a2bc8-c3d5-4f31-9d2c-16eac6491e6a\")) {                    Plotly.newPlot(                        \"a37a2bc8-c3d5-4f31-9d2c-16eac6491e6a\",                        [{\"marker\":{\"color\":\"#F70\",\"size\":4},\"mode\":\"markers\",\"name\":\"HPO test dataset accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[47.91666666666667,65.0,68.75,47.91666666666667,60.0,47.91666666666667,67.5,47.91666666666667,47.91666666666667,67.5,62.916666666666664,67.08333333333333,63.33333333333333,60.416666666666664,69.16666666666667,70.41666666666667,65.83333333333333,55.833333333333336,69.58333333333333,69.16666666666667,70.0,68.75,70.41666666666667,68.33333333333333,63.33333333333333,68.33333333333333,67.08333333333333,62.5,57.08333333333333,47.91666666666667,70.41666666666667,69.16666666666667,69.16666666666667,69.58333333333333,67.08333333333333,65.0,66.25,66.66666666666666,67.91666666666667,69.58333333333333,47.91666666666667,67.91666666666667,70.83333333333334,68.33333333333333,67.5,67.5,68.75,62.5,68.75,69.58333333333333,69.58333333333333,72.5,66.25,67.08333333333333,67.5,65.41666666666667,67.5,68.75,68.33333333333333,66.66666666666666,67.5,67.91666666666667,70.41666666666667,70.41666666666667,69.58333333333333,67.91666666666667,68.33333333333333,69.58333333333333,66.25,65.83333333333333,47.91666666666667,70.0,68.75,63.74999999999999,70.41666666666667,67.91666666666667,70.41666666666667,68.33333333333333,47.91666666666667,68.75,66.25,70.0,70.0,70.41666666666667,69.16666666666667,67.5,70.0,67.91666666666667,70.83333333333334,67.91666666666667,54.166666666666664,67.5,52.916666666666664,70.83333333333334,70.41666666666667,67.91666666666667,67.91666666666667,66.25,67.5,67.91666666666667,67.91666666666667,68.75,67.08333333333333,67.5,67.5,69.16666666666667,67.08333333333333,69.16666666666667,67.5,71.25,72.08333333333333,70.0,68.75,65.83333333333333,70.0,70.83333333333334,70.83333333333334,70.41666666666667,68.75,66.66666666666666,67.5,70.0,60.83333333333333,69.16666666666667,63.74999999999999,68.75,65.41666666666667,67.5,66.25,68.75,66.66666666666666,68.33333333333333,72.08333333333333,67.91666666666667,67.5,66.66666666666666,67.5,67.91666666666667,66.66666666666666,68.33333333333333,63.74999999999999,69.16666666666667,71.25,72.08333333333333,67.08333333333333,67.91666666666667,68.33333333333333,65.0,67.5,69.58333333333333,69.16666666666667,69.58333333333333,69.16666666666667,68.75,70.83333333333334,60.416666666666664,67.5,69.16666666666667,69.58333333333333,67.5,64.58333333333334,68.33333333333333,67.5,68.33333333333333,70.0,68.75,67.08333333333333,47.91666666666667,67.91666666666667,65.41666666666667,70.83333333333334,66.66666666666666,65.0,70.41666666666667,67.5,71.25,68.75,66.25,67.91666666666667,66.66666666666666,68.33333333333333,68.75,69.16666666666667,72.08333333333333,67.5,71.25,69.58333333333333,68.33333333333333,65.41666666666667,70.83333333333334,67.08333333333333,70.41666666666667,68.33333333333333,66.66666666666666,68.33333333333333,68.33333333333333,65.83333333333333,70.0,67.91666666666667,63.74999999999999,72.08333333333333,69.58333333333333,67.5,68.75,68.33333333333333,70.0,67.5,67.08333333333333,69.58333333333333,67.08333333333333,67.5,67.91666666666667,68.33333333333333,67.5,52.916666666666664,69.58333333333333,67.5,69.58333333333333,67.91666666666667,67.91666666666667,67.5,69.16666666666667,66.25,68.33333333333333,67.5,70.0,69.58333333333333,67.5,67.91666666666667,70.0,68.75,67.91666666666667,70.83333333333334,67.91666666666667,71.25,69.16666666666667,67.91666666666667,68.75,69.58333333333333,47.91666666666667,67.91666666666667,67.5,67.5,69.58333333333333,68.75,70.0,68.33333333333333,68.75,69.58333333333333,66.25,70.41666666666667,70.0,69.16666666666667,66.66666666666666,67.91666666666667,69.16666666666667,67.91666666666667,65.41666666666667,67.08333333333333,71.25,69.16666666666667,69.16666666666667,66.25,69.58333333333333,69.16666666666667,68.75,70.0,70.83333333333334,67.08333333333333,69.58333333333333,68.33333333333333,69.58333333333333,67.08333333333333,67.91666666666667,67.91666666666667,66.25,70.0,47.91666666666667,67.08333333333333,64.58333333333334,66.25,67.5,67.5,63.74999999999999,57.08333333333333,70.41666666666667,72.08333333333333,67.5,69.58333333333333,47.91666666666667,68.75,67.08333333333333,68.33333333333333,68.33333333333333,65.41666666666667,66.66666666666666,68.33333333333333,68.33333333333333,66.66666666666666,65.41666666666667,68.33333333333333,69.16666666666667,67.5,70.0,70.0,68.33333333333333,47.91666666666667,70.0,68.33333333333333,70.0,71.25,67.5,68.33333333333333,67.5,68.75,69.16666666666667,70.0,70.41666666666667,67.5,70.0,69.16666666666667,70.0,68.33333333333333,68.75,68.75,67.5,66.25,66.66666666666666,67.91666666666667,68.75,69.58333333333333,69.58333333333333,72.08333333333333,69.16666666666667,66.66666666666666,69.16666666666667,70.0,66.66666666666666,61.25000000000001,66.66666666666666,69.58333333333333,69.58333333333333,69.58333333333333,67.5,67.08333333333333,64.16666666666667,66.66666666666666,69.58333333333333,67.5,67.91666666666667,69.58333333333333,69.16666666666667,67.08333333333333,70.83333333333334,70.41666666666667,66.66666666666666,70.83333333333334,69.16666666666667,66.66666666666666,47.91666666666667,67.91666666666667,68.33333333333333,66.66666666666666,70.0,69.58333333333333,62.5,70.0,69.16666666666667,68.33333333333333,67.91666666666667,68.33333333333333,70.41666666666667,54.166666666666664,67.5,66.66666666666666,67.5,67.91666666666667,68.33333333333333,69.16666666666667,67.5,67.5,70.83333333333334,70.0,65.0,68.75,68.33333333333333,70.0,70.83333333333334,47.91666666666667,69.58333333333333,67.5,67.5,67.08333333333333,72.08333333333333,66.66666666666666,67.5,67.08333333333333,67.91666666666667,67.5,67.91666666666667,57.91666666666667,66.25,68.75,68.75,67.08333333333333,70.0,65.83333333333333,67.91666666666667,66.25,67.91666666666667,65.83333333333333,67.08333333333333,67.91666666666667,70.0,67.91666666666667,69.58333333333333,69.16666666666667,68.33333333333333,69.16666666666667,69.58333333333333,69.16666666666667,69.58333333333333,67.08333333333333,66.66666666666666,69.16666666666667,68.75,70.83333333333334,67.08333333333333,70.83333333333334,65.83333333333333,68.33333333333333,65.0,69.58333333333333,68.33333333333333,70.0,68.75,71.25,69.16666666666667,68.33333333333333,69.16666666666667,67.08333333333333,67.91666666666667,69.16666666666667,68.33333333333333,69.16666666666667,69.58333333333333,66.66666666666666,67.91666666666667,71.66666666666667,70.0,69.58333333333333,70.83333333333334,69.16666666666667,65.83333333333333,70.41666666666667,69.16666666666667,69.58333333333333,68.75,66.66666666666666,69.16666666666667,67.08333333333333,64.16666666666667,67.5,67.08333333333333,68.33333333333333,70.0,70.41666666666667,47.91666666666667,66.25,67.5,70.0,68.33333333333333,69.58333333333333,68.75,68.33333333333333,69.58333333333333,66.25,47.91666666666667,67.5,68.33333333333333,67.08333333333333,70.0,65.83333333333333,67.5,68.33333333333333,69.58333333333333,66.66666666666666,67.91666666666667,67.91666666666667,69.16666666666667,66.66666666666666,71.25,70.83333333333334,70.83333333333334,67.08333333333333,70.0,67.5,67.08333333333333,69.16666666666667,69.16666666666667,66.66666666666666,66.66666666666666,67.5,68.75,64.16666666666667,69.58333333333333,69.16666666666667,67.5,70.83333333333334,67.5,68.75,70.0,70.41666666666667,68.33333333333333,68.33333333333333,71.66666666666667,70.41666666666667,70.83333333333334,66.25,68.33333333333333,69.16666666666667,51.24999999999999,69.58333333333333,65.83333333333333,66.25,68.33333333333333,69.16666666666667,67.5,69.58333333333333,66.66666666666666,67.08333333333333,66.25,68.33333333333333,69.58333333333333,69.58333333333333,68.75,67.5,67.5,69.16666666666667,67.5,67.5,68.75,66.66666666666666,69.16666666666667,68.75,68.33333333333333,69.58333333333333,70.0,69.58333333333333,70.0,66.25,69.58333333333333,65.83333333333333,69.16666666666667,70.0,69.16666666666667,55.00000000000001,67.08333333333333,67.08333333333333,68.75,66.25,67.91666666666667,70.41666666666667,68.33333333333333,66.25,64.58333333333334,66.25,69.16666666666667,68.33333333333333,69.58333333333333,68.75,70.0,67.91666666666667,70.0,68.33333333333333,68.33333333333333,64.16666666666667,68.33333333333333,68.75,69.58333333333333,68.33333333333333,69.58333333333333,69.16666666666667,68.75,68.33333333333333,58.333333333333336,67.5,62.083333333333336,70.0,67.91666666666667,61.25000000000001,67.5,67.5,69.16666666666667,66.25,70.83333333333334,68.33333333333333,64.58333333333334,68.75,68.33333333333333,69.16666666666667,67.08333333333333,67.91666666666667,70.0,68.75,70.83333333333334,66.25,68.75,69.16666666666667,68.75,69.16666666666667,66.25,47.91666666666667,47.91666666666667,70.83333333333334,47.91666666666667,65.41666666666667,68.75,70.0,68.33333333333333,67.91666666666667,68.75,68.33333333333333,70.41666666666667,66.25,67.91666666666667,70.83333333333334,70.41666666666667,53.75,68.75,65.83333333333333,69.16666666666667,64.16666666666667,63.74999999999999,47.91666666666667,70.83333333333334,68.33333333333333,69.58333333333333,66.25,71.25,69.16666666666667,69.16666666666667,67.5,67.5,69.58333333333333,68.75,67.91666666666667,67.91666666666667,71.25,66.25,70.41666666666667,65.83333333333333,68.75,69.16666666666667,71.25,69.16666666666667,69.58333333333333,68.33333333333333,67.91666666666667,68.33333333333333,67.5,68.75,69.58333333333333,68.75,69.16666666666667,67.5,69.16666666666667,68.33333333333333,65.41666666666667,71.25,69.16666666666667,69.58333333333333,67.08333333333333,70.0,67.08333333333333,68.75,67.91666666666667,67.5,68.33333333333333,67.5,68.33333333333333,69.16666666666667,69.16666666666667,66.66666666666666,66.25,69.16666666666667,68.33333333333333,70.41666666666667,67.08333333333333,66.25,67.5,69.16666666666667,68.33333333333333,66.25,68.33333333333333,66.25,68.75,67.5,70.83333333333334,68.75,67.08333333333333,67.5,68.33333333333333,70.0,68.33333333333333,68.33333333333333,69.16666666666667,68.75,68.33333333333333,69.58333333333333,70.0,70.41666666666667,67.5,72.08333333333333,63.33333333333333,69.58333333333333,67.08333333333333,68.75,66.25,70.83333333333334,67.91666666666667,68.75,67.5,69.16666666666667,47.91666666666667,69.58333333333333,68.75,55.833333333333336,70.0,67.5,70.0,67.91666666666667,68.75,70.41666666666667,71.66666666666667,66.66666666666666,69.16666666666667,70.83333333333334,70.0,70.0,69.58333333333333,69.16666666666667,65.41666666666667,70.0,65.41666666666667,67.08333333333333,68.33333333333333,70.0,69.58333333333333,65.0,64.58333333333334,67.08333333333333,67.91666666666667,70.41666666666667,68.33333333333333,67.08333333333333,67.08333333333333,50.416666666666664,68.33333333333333,67.91666666666667,67.91666666666667,69.58333333333333,67.91666666666667,70.0,71.25,47.91666666666667,39.58333333333333,70.0,64.16666666666667,68.75,70.0,69.16666666666667,70.41666666666667,68.75,69.58333333333333,68.33333333333333,67.91666666666667,66.66666666666666,68.33333333333333,69.58333333333333,68.33333333333333,69.16666666666667,67.08333333333333,70.0,68.33333333333333,66.25,70.41666666666667,66.25,70.0,70.83333333333334,70.0,68.33333333333333,70.83333333333334,70.41666666666667,68.75,67.5,66.66666666666666,68.75,70.83333333333334,67.91666666666667,68.33333333333333,68.75,69.58333333333333,66.66666666666666,69.58333333333333,67.08333333333333,65.83333333333333,47.91666666666667,68.75,70.41666666666667,68.75,70.83333333333334,65.83333333333333,65.83333333333333,66.25,71.66666666666667,69.58333333333333,70.41666666666667,72.5,67.5,70.41666666666667,69.16666666666667,72.5,69.16666666666667,70.0,68.75,70.83333333333334,66.25,66.66666666666666,70.41666666666667,72.5,69.16666666666667,66.66666666666666,70.83333333333334,69.16666666666667,70.0,69.58333333333333,67.5,68.75,72.08333333333333,71.25,70.41666666666667,70.0,68.33333333333333,70.83333333333334,71.66666666666667,71.66666666666667,70.83333333333334,67.08333333333333,68.33333333333333,70.0,69.58333333333333,71.25,47.91666666666667,68.75,69.58333333333333,71.25,69.58333333333333,72.5,68.33333333333333,69.58333333333333,67.91666666666667,67.5,70.41666666666667,66.66666666666666,71.66666666666667,70.83333333333334,69.58333333333333,70.0,68.75,70.83333333333334,67.91666666666667,70.83333333333334,67.91666666666667,67.5,70.83333333333334,72.08333333333333,72.08333333333333,69.16666666666667,70.41666666666667,71.66666666666667,69.16666666666667,69.58333333333333,67.5,70.41666666666667,68.33333333333333,69.16666666666667,66.66666666666666,68.75,70.41666666666667,69.58333333333333,67.08333333333333,70.0,70.41666666666667,70.41666666666667,68.33333333333333,69.58333333333333,69.16666666666667,70.0,66.25,67.5,70.41666666666667,69.16666666666667,72.08333333333333,70.83333333333334,70.41666666666667,70.41666666666667,68.33333333333333,70.0,71.25,68.75,67.91666666666667,69.58333333333333,70.0,71.25,47.91666666666667,67.5,68.33333333333333,69.58333333333333,72.5,68.33333333333333,66.66666666666666,70.41666666666667,68.33333333333333,70.0,70.0,68.33333333333333,67.91666666666667,69.58333333333333,70.41666666666667,68.75,70.41666666666667,70.41666666666667,68.33333333333333,69.58333333333333,68.75,60.0,70.0,70.41666666666667,70.83333333333334,70.0,69.16666666666667,69.58333333333333,72.08333333333333,72.5,72.08333333333333,72.5,68.75,60.0,70.41666666666667,68.75,67.91666666666667,65.41666666666667,69.58333333333333,69.58333333333333,67.08333333333333,71.25,70.0,70.41666666666667,70.0,68.33333333333333,67.5,68.33333333333333,70.83333333333334,70.0,68.75,68.33333333333333,69.16666666666667,67.08333333333333,69.58333333333333,70.0,70.41666666666667,71.25,52.916666666666664,67.5,70.0,70.41666666666667,67.08333333333333,68.33333333333333,69.58333333333333,70.41666666666667,68.33333333333333,67.91666666666667,68.75,69.16666666666667,67.91666666666667,67.91666666666667,51.66666666666667,68.33333333333333,70.0,67.08333333333333,69.58333333333333,71.25,69.16666666666667,65.0,69.16666666666667,71.25,47.91666666666667,71.25,67.91666666666667,67.08333333333333,72.5,70.83333333333334,70.41666666666667,67.91666666666667,69.58333333333333,69.58333333333333,70.41666666666667,70.0,70.0,70.83333333333334,69.16666666666667,67.5,71.66666666666667,70.0,47.91666666666667,68.33333333333333,57.91666666666667,68.33333333333333,70.0,69.58333333333333,72.5,68.33333333333333,68.33333333333333,69.58333333333333,70.0,68.75,67.91666666666667,72.5,69.16666666666667,70.41666666666667,68.33333333333333,68.33333333333333,70.41666666666667,70.0,66.66666666666666,67.5,66.66666666666666,65.83333333333333,70.0,72.5,68.75,70.83333333333334,70.0,71.25,67.5,72.08333333333333,68.33333333333333,62.916666666666664,69.16666666666667,70.0,69.58333333333333,67.91666666666667,69.16666666666667,68.75,69.16666666666667,68.75,69.58333333333333,67.91666666666667,69.58333333333333,67.5,67.5,68.75,72.5,67.91666666666667,69.16666666666667,47.91666666666667,68.33333333333333,70.0,66.66666666666666,67.91666666666667,70.0,70.0,70.41666666666667,69.16666666666667,70.83333333333334,67.5,68.33333333333333,68.75,70.41666666666667,69.58333333333333,70.0,70.41666666666667,68.75,68.75,67.91666666666667,70.41666666666667,68.33333333333333,71.66666666666667,68.75,71.25,68.33333333333333,69.58333333333333,67.5,67.08333333333333,68.75,72.5,69.16666666666667,70.0,70.41666666666667,70.41666666666667,72.91666666666666,70.0,71.25,71.25,70.41666666666667,57.08333333333333,69.16666666666667,67.91666666666667,71.66666666666667,69.16666666666667,47.91666666666667,71.25,52.5,70.41666666666667,68.75,70.41666666666667,70.41666666666667,69.16666666666667,71.25,67.91666666666667,69.58333333333333,69.58333333333333,71.66666666666667,70.41666666666667,72.91666666666666,47.91666666666667,71.25,68.75,67.5,68.33333333333333,69.16666666666667,70.0,65.0,63.33333333333333,66.66666666666666,67.5,66.66666666666666,54.58333333333333,70.83333333333334,67.08333333333333,69.58333333333333,69.58333333333333,68.33333333333333,69.58333333333333,69.58333333333333,70.41666666666667,68.33333333333333,68.33333333333333,71.25,66.66666666666666,68.33333333333333,69.58333333333333,70.41666666666667,69.16666666666667,68.75,68.33333333333333,69.16666666666667,69.16666666666667,70.41666666666667,72.5,68.75,67.08333333333333,69.16666666666667,66.66666666666666,67.5,69.58333333333333,66.66666666666666,65.83333333333333,69.16666666666667,65.83333333333333,67.91666666666667,67.91666666666667,70.0,70.41666666666667,47.91666666666667,67.5,67.08333333333333,68.33333333333333,70.83333333333334,67.08333333333333,72.08333333333333,67.08333333333333,68.75,69.58333333333333,69.58333333333333,68.33333333333333,70.0,47.91666666666667,72.08333333333333,67.5,70.0,69.58333333333333,70.41666666666667,69.16666666666667,67.5,70.41666666666667,67.08333333333333,68.33333333333333,67.08333333333333,70.83333333333334,68.75,71.25,67.91666666666667,73.75,70.0,70.0,69.16666666666667,68.75,69.16666666666667,65.41666666666667,72.08333333333333,68.33333333333333,67.91666666666667,70.41666666666667,70.0,70.41666666666667,65.83333333333333,71.25,69.58333333333333,71.66666666666667,68.75,69.58333333333333,70.41666666666667,67.91666666666667,69.16666666666667,70.83333333333334,69.58333333333333,68.33333333333333,66.66666666666666,69.58333333333333,70.0,70.83333333333334,69.16666666666667,67.08333333333333,70.0,47.91666666666667,70.0,67.5,60.416666666666664,70.41666666666667,69.16666666666667,67.5,70.83333333333334,64.58333333333334,70.83333333333334,68.33333333333333,47.91666666666667,71.25,71.66666666666667,70.41666666666667,69.16666666666667,70.83333333333334,68.33333333333333,69.58333333333333,69.16666666666667,69.16666666666667,69.16666666666667,67.91666666666667,65.0,67.5,68.75,66.25,72.5,69.58333333333333,67.08333333333333,69.16666666666667,66.66666666666666,66.25,69.16666666666667,67.91666666666667,67.5,66.66666666666666,70.41666666666667,68.75,70.83333333333334,69.58333333333333,66.66666666666666,70.83333333333334,70.41666666666667,72.5,67.91666666666667,66.25,67.91666666666667,71.66666666666667,69.58333333333333,69.58333333333333,65.41666666666667,65.83333333333333,71.66666666666667,68.33333333333333,69.58333333333333,71.25,70.41666666666667,71.25,70.0,70.0,69.58333333333333,69.58333333333333,68.33333333333333,70.83333333333334,72.08333333333333,68.33333333333333,70.83333333333334,71.66666666666667,67.5,68.33333333333333,68.33333333333333,70.41666666666667,68.75,69.58333333333333,68.75,70.41666666666667,67.91666666666667,47.91666666666667,70.41666666666667,68.75,68.75,68.75,69.16666666666667,70.0,65.83333333333333,71.66666666666667,66.66666666666666,68.75,67.08333333333333,67.91666666666667,70.83333333333334,68.75,67.91666666666667,72.08333333333333,67.5,69.58333333333333,68.33333333333333,71.66666666666667,67.91666666666667,69.16666666666667,65.83333333333333,69.58333333333333,69.16666666666667,68.75,71.66666666666667,69.16666666666667,47.91666666666667,67.91666666666667,66.66666666666666,67.5,65.83333333333333,68.75,66.66666666666666,67.08333333333333,55.41666666666667,69.58333333333333,67.08333333333333,62.916666666666664,67.5,71.25,67.5,70.83333333333334,68.75,68.33333333333333,70.83333333333334,68.33333333333333,71.25,68.75,70.83333333333334,66.66666666666666,69.16666666666667,60.416666666666664,70.0,68.33333333333333,65.0,70.41666666666667,69.58333333333333,70.0,69.58333333333333,70.41666666666667,69.16666666666667,68.75,70.0,69.16666666666667,69.16666666666667,69.58333333333333,70.0,68.33333333333333,68.75,70.83333333333334,67.5,63.74999999999999,70.0,65.41666666666667,47.91666666666667,62.5,67.08333333333333,70.83333333333334,70.0,66.25,70.0,70.83333333333334,71.66666666666667,68.75,73.33333333333333,70.0,72.5,71.25,69.58333333333333,69.58333333333333,67.5,68.33333333333333,69.58333333333333,68.33333333333333,69.58333333333333,68.75,66.66666666666666,70.83333333333334,71.25,69.58333333333333,70.0,69.58333333333333,70.83333333333334,71.25,67.5,68.75,70.0,68.75,70.83333333333334,70.0,70.0,66.25,65.0,71.25,70.83333333333334,70.0,67.91666666666667,68.75,67.08333333333333,72.08333333333333,70.83333333333334,67.5,68.33333333333333,68.75,69.16666666666667,68.75,71.25,70.83333333333334,68.75,70.41666666666667,70.41666666666667,67.91666666666667,71.25,69.58333333333333,72.5,65.0,67.91666666666667,67.08333333333333,68.33333333333333,70.83333333333334,70.83333333333334,72.08333333333333,47.91666666666667,68.75,67.91666666666667,52.916666666666664,70.0,72.91666666666666,70.0,71.25,70.0,69.58333333333333,72.08333333333333,69.16666666666667,70.0,69.58333333333333,71.25,70.41666666666667,72.08333333333333,70.41666666666667,70.83333333333334,70.0,70.0,70.41666666666667,70.0,71.25,69.16666666666667,70.41666666666667,70.41666666666667,68.75,72.08333333333333,69.58333333333333,67.91666666666667,69.16666666666667,70.0,69.16666666666667,68.75,68.75,69.58333333333333,70.41666666666667,68.33333333333333,69.58333333333333,70.83333333333334,70.83333333333334,67.08333333333333,70.0,67.91666666666667,71.66666666666667,67.5,67.5,70.0,67.5,70.41666666666667,69.16666666666667,70.41666666666667,70.83333333333334,69.58333333333333,72.08333333333333,70.41666666666667,68.33333333333333,69.58333333333333,69.58333333333333,70.41666666666667,69.58333333333333,70.41666666666667,70.0,69.58333333333333,65.0,70.0,70.0,70.0,68.75,47.91666666666667,71.25,71.25,47.91666666666667,68.33333333333333,68.75,70.41666666666667,67.91666666666667,69.16666666666667,68.33333333333333,70.83333333333334,71.66666666666667,68.75,69.58333333333333,69.58333333333333,71.66666666666667,70.0,67.91666666666667,70.83333333333334,67.5,67.5,68.33333333333333,69.16666666666667,71.25,71.25,67.91666666666667,70.41666666666667,68.75,69.16666666666667,72.08333333333333,70.0,71.25,70.41666666666667,73.33333333333333,69.16666666666667,70.41666666666667,69.58333333333333,67.08333333333333,68.75,72.91666666666666,67.08333333333333,68.33333333333333,68.75,67.5,70.0,71.25,67.5,68.75,70.41666666666667,69.58333333333333,68.33333333333333,69.58333333333333,65.83333333333333,70.41666666666667,70.0,70.83333333333334,68.75,67.5,68.33333333333333,67.91666666666667,70.0,69.16666666666667,69.58333333333333,69.58333333333333,67.5,55.00000000000001,70.41666666666667,71.25,71.25,68.33333333333333,71.66666666666667,47.91666666666667,66.66666666666666,68.33333333333333,69.16666666666667,65.83333333333333,69.58333333333333,70.0,69.58333333333333,68.75,69.16666666666667,72.08333333333333,69.16666666666667,70.83333333333334,70.0,67.91666666666667,68.75,66.66666666666666,62.5,70.41666666666667,70.83333333333334,68.75,69.58333333333333,69.58333333333333,73.75,70.41666666666667,69.16666666666667,68.33333333333333,70.41666666666667,70.0,70.0,67.5,70.83333333333334,70.0,70.83333333333334,67.08333333333333,68.33333333333333,73.33333333333333,68.75,71.25,71.25,69.58333333333333,68.75,72.91666666666666,72.08333333333333,72.5,69.16666666666667,70.0,65.83333333333333,67.5,68.75,68.33333333333333,71.25,47.91666666666667,70.0,67.08333333333333,67.91666666666667,71.25,72.5,70.41666666666667,68.75,67.5,70.41666666666667,71.25,70.0,70.83333333333334,73.33333333333333,70.0,53.333333333333336,67.5,67.5,69.58333333333333,70.41666666666667,69.58333333333333,52.083333333333336,47.91666666666667,70.41666666666667,71.66666666666667,71.25,68.75,70.0,69.58333333333333,68.75,71.25,70.83333333333334,71.66666666666667,71.25,69.16666666666667,73.33333333333333,68.33333333333333,69.16666666666667,70.83333333333334,69.16666666666667,72.5,71.25,69.58333333333333,69.58333333333333,71.66666666666667,70.0,67.91666666666667,72.91666666666666,68.75,68.33333333333333,67.91666666666667,66.66666666666666,68.75,67.08333333333333,66.66666666666666,70.41666666666667,70.0,70.41666666666667,69.16666666666667,68.33333333333333,68.75,70.41666666666667,70.41666666666667,68.75,69.58333333333333,67.91666666666667,69.58333333333333,67.91666666666667,67.91666666666667,68.75,71.66666666666667,69.58333333333333,70.83333333333334,69.16666666666667,68.75,69.58333333333333,69.58333333333333,67.5,69.16666666666667,68.33333333333333,58.75,71.66666666666667,66.66666666666666,68.75,68.75,70.41666666666667,70.0,69.16666666666667,67.08333333333333,67.08333333333333,69.58333333333333,47.91666666666667,68.75,68.33333333333333,66.66666666666666,70.41666666666667,69.16666666666667,73.33333333333333,66.66666666666666,69.16666666666667,67.91666666666667,70.83333333333334,71.25,67.91666666666667,69.58333333333333,69.58333333333333,70.0,70.41666666666667,67.5,72.5,71.25,70.41666666666667,69.58333333333333,69.58333333333333,68.33333333333333,68.75,72.5,71.66666666666667,72.08333333333333,71.66666666666667,67.5,68.33333333333333,72.08333333333333,69.58333333333333,69.58333333333333,69.58333333333333,69.16666666666667,71.66666666666667,69.16666666666667,62.5,68.33333333333333,71.25,69.16666666666667,70.0,65.83333333333333,70.83333333333334,70.83333333333334,70.0,69.58333333333333,68.33333333333333,70.41666666666667,67.5,68.75,70.0,68.33333333333333,70.83333333333334,70.41666666666667,67.91666666666667,67.91666666666667,69.58333333333333,67.5,67.5,70.83333333333334,70.83333333333334,70.41666666666667,70.41666666666667,73.75,70.83333333333334,66.25,69.58333333333333,69.58333333333333,67.91666666666667,68.75,70.41666666666667,67.5,67.08333333333333,68.33333333333333,68.33333333333333,69.16666666666667,68.33333333333333,75.0,69.58333333333333,70.41666666666667,68.33333333333333,69.16666666666667,65.83333333333333,70.41666666666667,70.83333333333334,67.91666666666667,68.75,69.16666666666667,71.25,67.91666666666667,71.66666666666667,70.0,70.41666666666667,71.66666666666667,67.5,67.91666666666667,66.66666666666666,67.5,69.16666666666667,69.58333333333333,61.25000000000001,47.91666666666667,69.58333333333333,67.91666666666667,70.0,65.83333333333333,68.75,68.33333333333333,68.75,69.16666666666667,67.91666666666667,69.16666666666667,70.83333333333334,68.33333333333333,67.91666666666667,69.16666666666667,70.83333333333334,71.25,67.5,66.66666666666666,69.58333333333333,67.08333333333333,68.75,69.58333333333333,71.25,69.58333333333333,67.91666666666667,62.5,69.58333333333333,70.83333333333334,70.41666666666667,67.91666666666667,67.5,70.41666666666667,68.75,71.66666666666667,67.91666666666667,70.83333333333334,70.0,68.75,69.16666666666667,68.75,68.75,68.33333333333333,71.25,67.91666666666667,70.41666666666667,68.75,69.16666666666667,70.0,71.25,66.25,72.08333333333333,69.58333333333333,64.58333333333334,69.16666666666667,69.16666666666667,70.41666666666667,70.41666666666667,69.16666666666667,69.16666666666667,68.33333333333333,71.66666666666667,72.08333333333333,68.33333333333333,68.33333333333333,67.5,50.0,47.91666666666667,70.0,71.25,61.25000000000001,71.66666666666667,69.58333333333333,70.0,67.08333333333333,66.66666666666666,71.66666666666667,68.75,70.41666666666667,65.41666666666667,70.0,70.83333333333334,70.0,70.83333333333334,69.58333333333333,72.08333333333333,71.25,69.58333333333333,67.91666666666667,69.16666666666667,70.0,67.08333333333333,70.83333333333334,65.0,68.75,66.66666666666666,70.0,70.83333333333334,47.91666666666667,68.33333333333333,67.5,70.83333333333334,70.0,68.75,69.16666666666667,72.08333333333333,71.25,71.66666666666667,67.08333333333333,69.16666666666667,65.0,69.58333333333333,68.33333333333333,71.25,68.75,68.75,72.5,69.58333333333333,70.83333333333334,65.83333333333333,70.41666666666667,67.91666666666667,69.58333333333333,70.0,67.5,69.58333333333333,66.66666666666666,68.75,64.16666666666667,70.41666666666667,70.83333333333334,47.91666666666667,69.58333333333333,69.58333333333333,47.91666666666667,69.58333333333333,57.91666666666667,70.41666666666667,66.66666666666666,70.41666666666667,71.25,67.5,70.0,70.83333333333334,69.16666666666667,69.16666666666667,70.83333333333334,70.83333333333334,66.66666666666666,63.74999999999999,71.25,67.5,70.41666666666667,70.41666666666667,72.5,67.08333333333333,69.58333333333333,70.83333333333334,70.0,71.25,71.25,68.33333333333333,66.66666666666666,68.75,69.16666666666667,67.08333333333333,69.58333333333333,67.91666666666667,71.25,70.83333333333334,70.0,67.5,69.58333333333333,68.33333333333333,69.58333333333333,70.41666666666667,70.83333333333334,70.41666666666667,71.66666666666667,67.08333333333333,66.25,67.08333333333333,72.91666666666666,68.75,70.41666666666667,70.83333333333334,66.66666666666666,68.33333333333333,67.91666666666667,71.25,66.66666666666666,67.91666666666667,70.83333333333334,72.91666666666666,70.0,69.16666666666667,72.08333333333333,66.66666666666666,67.5,70.83333333333334,70.0,70.83333333333334,70.0,72.08333333333333,69.16666666666667,70.41666666666667,71.66666666666667,71.66666666666667,71.66666666666667,71.66666666666667,68.75,70.0,68.33333333333333,71.25,47.91666666666667,69.16666666666667,71.66666666666667,70.0,71.66666666666667,71.25,66.66666666666666,68.75,68.75,69.16666666666667,69.58333333333333,67.5,70.0,70.83333333333334,69.58333333333333,73.33333333333333,69.58333333333333,69.16666666666667,67.08333333333333,72.08333333333333,69.16666666666667,68.33333333333333,69.16666666666667,70.0,72.5,70.0,72.08333333333333,68.75,70.0,70.41666666666667,70.41666666666667,69.16666666666667,70.0,71.66666666666667,69.58333333333333,72.91666666666666,68.75,72.08333333333333,47.91666666666667,70.83333333333334,71.66666666666667,68.33333333333333,69.16666666666667,67.91666666666667,67.91666666666667,73.33333333333333,69.16666666666667,70.83333333333334,69.16666666666667,67.08333333333333,65.0,68.33333333333333,70.41666666666667,69.58333333333333,70.83333333333334,71.66666666666667,70.0,67.5,68.75,72.91666666666666,47.91666666666667,69.16666666666667,69.58333333333333,66.25,67.5,70.41666666666667,68.33333333333333,69.16666666666667,71.66666666666667,69.16666666666667,72.08333333333333,69.16666666666667,70.0,70.41666666666667,70.0,67.08333333333333,67.5,67.5,67.08333333333333,51.66666666666667,70.83333333333334,69.58333333333333,69.58333333333333,68.75,68.33333333333333,71.25,63.74999999999999,68.75,68.75,61.66666666666667,67.91666666666667,70.0,68.75,69.16666666666667,65.41666666666667,66.25,68.33333333333333,68.75,63.74999999999999,67.5,69.58333333333333,72.5,70.83333333333334,68.33333333333333,69.58333333333333,68.75,62.083333333333336,72.08333333333333,67.5,70.41666666666667,70.0,70.83333333333334,72.08333333333333,68.75,70.41666666666667,70.0,71.25,72.5,69.16666666666667,67.08333333333333,68.75,69.16666666666667,68.33333333333333,67.08333333333333,70.41666666666667,52.916666666666664,69.16666666666667,69.58333333333333,67.5,70.41666666666667,68.33333333333333,67.91666666666667,70.0,69.58333333333333,70.0,71.66666666666667,70.0,69.58333333333333,70.41666666666667,70.0,68.75,67.5,70.0,70.41666666666667,66.66666666666666,72.5,70.41666666666667,70.41666666666667,69.16666666666667,70.0,69.16666666666667,69.16666666666667,70.83333333333334,69.16666666666667,67.5,70.41666666666667,67.91666666666667,70.0,69.58333333333333,70.41666666666667,69.16666666666667,68.33333333333333,69.58333333333333,66.25,70.83333333333334,72.08333333333333,70.83333333333334,70.41666666666667,47.91666666666667,67.91666666666667,66.25,72.5,69.16666666666667,68.33333333333333,69.16666666666667,67.5,69.58333333333333,69.58333333333333,70.83333333333334,66.66666666666666,72.08333333333333,67.5,71.66666666666667,68.75,71.66666666666667,69.16666666666667,67.91666666666667,70.41666666666667,67.91666666666667,69.58333333333333,68.75,70.0,67.5,71.25,69.58333333333333,70.83333333333334,63.74999999999999,68.75,70.83333333333334,72.08333333333333,68.33333333333333,67.5,70.41666666666667,69.16666666666667,68.75,67.91666666666667,68.75,67.5,69.58333333333333,67.08333333333333,66.66666666666666,68.75,68.33333333333333,68.33333333333333,67.91666666666667,68.75,71.25,71.25,70.41666666666667,70.83333333333334,68.33333333333333,67.5,70.0,67.91666666666667,72.08333333333333,59.583333333333336,69.58333333333333,67.5,69.16666666666667,72.08333333333333,70.83333333333334,69.16666666666667,67.08333333333333,69.58333333333333,69.58333333333333,69.16666666666667,70.41666666666667,69.58333333333333,47.91666666666667,72.08333333333333,70.41666666666667,70.41666666666667,70.83333333333334,67.91666666666667,71.25,66.66666666666666,70.83333333333334,70.0,69.16666666666667,69.16666666666667,70.41666666666667,68.33333333333333,68.33333333333333,68.75,70.41666666666667,70.41666666666667,73.33333333333333,68.33333333333333,68.33333333333333,68.75,68.75,69.58333333333333,67.5,67.91666666666667,67.91666666666667,69.16666666666667,68.75,67.91666666666667,69.16666666666667,72.08333333333333,67.5,67.5,69.16666666666667,69.58333333333333,70.41666666666667,70.41666666666667,62.916666666666664,67.91666666666667,69.58333333333333,69.16666666666667,66.66666666666666,70.41666666666667,70.41666666666667,73.33333333333333,64.16666666666667,67.91666666666667,69.16666666666667,67.08333333333333,65.83333333333333,66.66666666666666,68.33333333333333,68.75,70.83333333333334,60.416666666666664,70.0,68.75,65.83333333333333,68.33333333333333,69.58333333333333,66.25,68.75,67.08333333333333,67.91666666666667,68.33333333333333,36.25,72.5,67.08333333333333,72.08333333333333,69.58333333333333,60.416666666666664,70.41666666666667,71.25,70.0,67.91666666666667,69.16666666666667,70.0,68.33333333333333,69.58333333333333,68.33333333333333,70.41666666666667,68.33333333333333,69.58333333333333,70.41666666666667,62.5,67.91666666666667,70.0,70.83333333333334,69.16666666666667,73.33333333333333,70.0,68.75,69.16666666666667,69.16666666666667,72.5,72.08333333333333,69.58333333333333,69.16666666666667,69.58333333333333,70.0,70.83333333333334,69.16666666666667,69.16666666666667,72.08333333333333,68.75,70.41666666666667,70.0,67.91666666666667,69.58333333333333,72.08333333333333,67.91666666666667,69.58333333333333,67.91666666666667,68.75,67.91666666666667,70.0,68.33333333333333,67.91666666666667,68.75,71.25,72.08333333333333,71.25,70.0,68.33333333333333,72.91666666666666,72.91666666666666,66.25,47.91666666666667,71.25,67.91666666666667,71.25,71.66666666666667,66.66666666666666,71.25,70.0,69.58333333333333,47.91666666666667,70.83333333333334,71.66666666666667,69.58333333333333,68.33333333333333,67.5,70.41666666666667,70.83333333333334,69.58333333333333,66.66666666666666,67.08333333333333,70.41666666666667,67.91666666666667,67.91666666666667,70.83333333333334,68.33333333333333,68.33333333333333,70.83333333333334,69.58333333333333,67.5,70.83333333333334,70.83333333333334,70.83333333333334,55.833333333333336,70.41666666666667,70.41666666666667,69.16666666666667,69.58333333333333,69.16666666666667,70.0,67.5,70.83333333333334,67.91666666666667,68.33333333333333,68.33333333333333,69.16666666666667,70.0,72.91666666666666,64.16666666666667,66.66666666666666,67.91666666666667,71.25,69.16666666666667,68.33333333333333,72.08333333333333,47.91666666666667,69.16666666666667,68.33333333333333,66.66666666666666,69.16666666666667,69.16666666666667,70.0,68.75,70.0,71.66666666666667,64.58333333333334,69.58333333333333,70.0,67.08333333333333,67.5,71.25,69.58333333333333,69.16666666666667,70.0,53.333333333333336,70.83333333333334,71.66666666666667,70.0,67.5,67.08333333333333,66.66666666666666,67.08333333333333,72.91666666666666,68.33333333333333,70.83333333333334,69.58333333333333,70.0,47.91666666666667,68.33333333333333,68.33333333333333,69.58333333333333,69.16666666666667,72.5,69.16666666666667,69.16666666666667,70.83333333333334,66.66666666666666,70.0,68.75,67.08333333333333,67.5,69.58333333333333,54.58333333333333,49.166666666666664,73.33333333333333,69.16666666666667,68.33333333333333,66.66666666666666,41.66666666666667,69.58333333333333,65.83333333333333,68.75,70.0,68.33333333333333,68.75,69.16666666666667,70.83333333333334,67.08333333333333,65.0,69.16666666666667,64.16666666666667,70.41666666666667,69.58333333333333,70.41666666666667,68.75,66.25,69.16666666666667,70.0,47.91666666666667,47.91666666666667,70.83333333333334,68.75,68.75,69.58333333333333,70.0,68.75,68.75,70.0,71.25,68.33333333333333,65.41666666666667,68.33333333333333,70.0,70.41666666666667,70.41666666666667,71.25,62.5,70.41666666666667,69.58333333333333,70.83333333333334,69.16666666666667,71.25,64.16666666666667,70.83333333333334,67.91666666666667,70.41666666666667,69.16666666666667,71.25,69.16666666666667,71.66666666666667,66.25,68.33333333333333,71.66666666666667,73.33333333333333,67.08333333333333,70.83333333333334,68.75,70.41666666666667,67.91666666666667,65.83333333333333,68.33333333333333,64.16666666666667,68.33333333333333,47.91666666666667,68.33333333333333,68.75,64.58333333333334,65.83333333333333,66.66666666666666,68.75,69.16666666666667,66.66666666666666,65.83333333333333,66.66666666666666,67.91666666666667,71.25,64.58333333333334,68.75,61.66666666666667,69.16666666666667,66.66666666666666,66.25,63.74999999999999,67.5,67.5,70.83333333333334,68.75,66.25,70.0,69.58333333333333,66.66666666666666,68.75,67.91666666666667,70.41666666666667,65.83333333333333,70.41666666666667,69.16666666666667,69.16666666666667,71.66666666666667,68.75,69.16666666666667,65.0,67.91666666666667,68.33333333333333,70.41666666666667,68.75,70.41666666666667,67.5,66.25,66.25,71.66666666666667,67.5,70.83333333333334,70.0,69.16666666666667,68.33333333333333,70.41666666666667,62.083333333333336,69.58333333333333,70.0,66.25,69.16666666666667,47.91666666666667,67.08333333333333,69.16666666666667,67.91666666666667,69.58333333333333,68.75,68.33333333333333,68.33333333333333,67.08333333333333,69.58333333333333,69.58333333333333,67.5,69.58333333333333,67.08333333333333,68.75,68.33333333333333,72.5,70.0,67.08333333333333,68.75,71.66666666666667,68.33333333333333,68.75,67.91666666666667,70.41666666666667,68.33333333333333,69.16666666666667,70.0,70.0,66.25,67.08333333333333,72.08333333333333,69.58333333333333,68.33333333333333,71.66666666666667,70.83333333333334,68.33333333333333,71.66666666666667,68.33333333333333,70.83333333333334,69.58333333333333,70.41666666666667,70.41666666666667,69.16666666666667,68.33333333333333,69.58333333333333,66.25,69.16666666666667,68.75,67.5,57.91666666666667,69.58333333333333,71.66666666666667,69.16666666666667,67.08333333333333,66.66666666666666,69.58333333333333,69.58333333333333,70.41666666666667,66.66666666666666,68.75,73.33333333333333,69.58333333333333,69.16666666666667,69.58333333333333,67.5,50.0,69.16666666666667,69.16666666666667,66.25,69.16666666666667,65.41666666666667,71.66666666666667,70.0,70.0,69.16666666666667,70.83333333333334,65.41666666666667,70.83333333333334,70.41666666666667,61.66666666666667,70.83333333333334,69.58333333333333,69.16666666666667,72.08333333333333,69.58333333333333,70.0,68.75,69.58333333333333,70.0,70.41666666666667,68.33333333333333,68.75,70.41666666666667,68.33333333333333,72.08333333333333,69.16666666666667,70.0,70.83333333333334,68.33333333333333,71.66666666666667,67.91666666666667,68.33333333333333,62.916666666666664,67.91666666666667,68.33333333333333,71.66666666666667,67.91666666666667,67.08333333333333,70.41666666666667,68.75,68.33333333333333,67.91666666666667,70.0,66.66666666666666,69.16666666666667,69.58333333333333,70.41666666666667,68.33333333333333,65.0,69.16666666666667,69.58333333333333,70.41666666666667,70.41666666666667,71.66666666666667,67.08333333333333,70.83333333333334,70.41666666666667,67.91666666666667,70.0,70.0,69.58333333333333,70.41666666666667,71.66666666666667,52.083333333333336,70.0,69.58333333333333,71.66666666666667,70.0,67.08333333333333,68.33333333333333,68.33333333333333,71.66666666666667,70.41666666666667,70.41666666666667,69.16666666666667,68.33333333333333,70.0,70.83333333333334,70.0,69.58333333333333,67.08333333333333,67.91666666666667,69.16666666666667,69.16666666666667,68.33333333333333,71.66666666666667,70.83333333333334,70.41666666666667,66.25,69.16666666666667,66.25,65.41666666666667,47.91666666666667,68.75,67.08333333333333,68.33333333333333,71.66666666666667,67.08333333333333,69.16666666666667,70.0,70.83333333333334,70.0,68.33333333333333,70.83333333333334,71.66666666666667,70.83333333333334,69.16666666666667,67.5,68.75,70.83333333333334,70.41666666666667,67.08333333333333,47.91666666666667,70.0,72.91666666666666,67.91666666666667,70.41666666666667,69.16666666666667,71.66666666666667,67.91666666666667,70.41666666666667,70.0,71.25,70.41666666666667,67.5,69.16666666666667,68.33333333333333,68.33333333333333,69.58333333333333,67.91666666666667,70.41666666666667,68.33333333333333,70.41666666666667,66.25,69.16666666666667,72.08333333333333,60.0,69.58333333333333,69.58333333333333,70.41666666666667,70.0,68.75,67.5,70.0,70.41666666666667,47.91666666666667,70.41666666666667,67.91666666666667,62.916666666666664,68.33333333333333,68.33333333333333,70.41666666666667,68.33333333333333,70.0,67.5,69.58333333333333,70.83333333333334,67.08333333333333,70.0,71.66666666666667,65.83333333333333,64.58333333333334,70.83333333333334,67.91666666666667,68.75,68.33333333333333,73.33333333333333,69.58333333333333,67.91666666666667,68.75,62.916666666666664,70.41666666666667,68.75,65.41666666666667,68.75,69.16666666666667,67.08333333333333,69.16666666666667,70.41666666666667,70.0,68.75,68.33333333333333,69.58333333333333,70.0,67.91666666666667,73.33333333333333,71.66666666666667,70.41666666666667,67.91666666666667,69.58333333333333,68.33333333333333,70.83333333333334,68.75,73.33333333333333,69.58333333333333,69.16666666666667,70.41666666666667,70.83333333333334,67.91666666666667,69.58333333333333,68.75,68.75,69.58333333333333,72.91666666666666,70.0,67.08333333333333,69.58333333333333,68.75,68.75,71.25,71.66666666666667,70.41666666666667,69.58333333333333,72.08333333333333,68.33333333333333,69.58333333333333,68.75,70.83333333333334,67.91666666666667,70.83333333333334,71.66666666666667,65.83333333333333,69.58333333333333,71.66666666666667,53.75,71.25,71.25,70.0,70.0,70.83333333333334,69.16666666666667,70.41666666666667,74.16666666666667,69.16666666666667,68.33333333333333,71.25,69.16666666666667,70.41666666666667,69.16666666666667,67.08333333333333,70.0,70.83333333333334,69.16666666666667,71.66666666666667,70.0,71.66666666666667,72.5,67.5,71.66666666666667,70.41666666666667,69.58333333333333,61.66666666666667,69.16666666666667,69.58333333333333,72.08333333333333,71.25,69.16666666666667,70.83333333333334,68.33333333333333,69.16666666666667,68.75,65.83333333333333,70.0,67.91666666666667,70.41666666666667,71.25,71.66666666666667,69.58333333333333,70.83333333333334,71.25,69.58333333333333,69.58333333333333],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#07F\",\"size\":4},\"mode\":\"markers\",\"name\":\"NEW test dataset accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[47.66666666666667,65.33333333333333,67.0,47.66666666666667,59.333333333333336,47.66666666666667,65.0,47.66666666666667,47.66666666666667,65.66666666666666,62.33333333333333,69.0,64.66666666666666,61.0,68.66666666666667,67.66666666666666,64.66666666666666,54.0,67.66666666666666,66.0,65.0,64.0,66.33333333333333,64.33333333333333,60.66666666666667,67.33333333333333,66.66666666666666,62.33333333333333,54.666666666666664,47.66666666666667,67.66666666666666,68.0,67.0,65.0,66.66666666666666,66.0,63.33333333333333,68.33333333333333,68.33333333333333,64.0,47.66666666666667,68.33333333333333,66.33333333333333,66.66666666666666,67.33333333333333,67.33333333333333,66.66666666666666,65.0,65.66666666666666,66.0,63.66666666666667,67.66666666666666,67.0,67.0,65.66666666666666,65.0,63.0,67.33333333333333,68.0,67.0,66.0,68.66666666666667,66.33333333333333,66.66666666666666,64.0,66.0,67.0,64.33333333333333,67.0,68.33333333333333,47.66666666666667,68.33333333333333,68.33333333333333,67.66666666666666,66.33333333333333,67.33333333333333,69.0,67.33333333333333,47.66666666666667,67.66666666666666,68.33333333333333,67.0,65.66666666666666,67.33333333333333,65.66666666666666,67.66666666666666,65.33333333333333,67.66666666666666,69.0,66.0,53.333333333333336,68.33333333333333,52.666666666666664,68.0,66.66666666666666,69.0,68.33333333333333,66.33333333333333,68.66666666666667,66.66666666666666,65.0,68.33333333333333,68.0,69.0,66.0,65.33333333333333,66.0,67.0,66.0,66.0,66.66666666666666,69.0,66.33333333333333,66.33333333333333,70.0,68.0,65.33333333333333,67.0,68.0,69.33333333333334,66.66666666666666,65.33333333333333,59.66666666666667,67.66666666666666,62.33333333333333,64.33333333333333,65.33333333333333,67.33333333333333,70.0,67.66666666666666,67.33333333333333,66.33333333333333,67.0,67.0,69.66666666666667,70.33333333333334,68.33333333333333,67.0,66.0,65.33333333333333,62.33333333333333,67.66666666666666,67.66666666666666,65.0,65.66666666666666,68.33333333333333,65.66666666666666,66.66666666666666,68.66666666666667,64.33333333333333,68.66666666666667,67.66666666666666,68.0,69.0,70.0,61.33333333333333,69.33333333333334,68.0,68.0,67.33333333333333,69.33333333333334,69.0,67.0,67.0,66.33333333333333,68.33333333333333,69.66666666666667,47.66666666666667,68.66666666666667,64.0,68.0,68.66666666666667,65.66666666666666,66.33333333333333,68.33333333333333,67.66666666666666,69.33333333333334,67.0,69.0,69.0,69.0,67.66666666666666,66.0,68.0,64.66666666666666,69.0,69.0,67.0,68.0,66.66666666666666,67.33333333333333,68.66666666666667,68.33333333333333,69.0,68.0,69.0,70.33333333333334,67.66666666666666,69.0,66.33333333333333,68.66666666666667,69.33333333333334,68.33333333333333,69.66666666666667,69.33333333333334,69.0,66.0,66.33333333333333,66.33333333333333,69.0,67.33333333333333,66.0,66.66666666666666,68.33333333333333,53.333333333333336,66.66666666666666,67.0,66.33333333333333,68.0,65.33333333333333,69.0,68.33333333333333,65.0,68.0,68.33333333333333,68.0,69.0,68.0,63.33333333333333,64.33333333333333,67.0,68.33333333333333,69.66666666666667,67.33333333333333,67.0,65.0,68.66666666666667,67.66666666666666,69.66666666666667,47.66666666666667,68.0,66.33333333333333,69.66666666666667,67.33333333333333,68.33333333333333,69.0,69.66666666666667,68.0,68.0,63.33333333333333,67.0,68.33333333333333,69.0,63.0,66.66666666666666,67.0,66.0,67.66666666666666,67.66666666666666,65.0,67.66666666666666,68.66666666666667,65.66666666666666,67.0,67.66666666666666,67.0,69.66666666666667,67.33333333333333,67.0,67.66666666666666,67.33333333333333,64.33333333333333,64.0,67.66666666666666,69.33333333333334,65.66666666666666,68.0,47.66666666666667,70.0,62.66666666666667,66.66666666666666,65.66666666666666,70.0,62.33333333333333,55.00000000000001,66.66666666666666,68.66666666666667,68.0,65.33333333333333,47.66666666666667,67.0,67.0,68.0,70.66666666666667,68.33333333333333,67.66666666666666,67.0,65.33333333333333,70.33333333333334,68.66666666666667,67.0,67.66666666666666,66.33333333333333,69.66666666666667,66.66666666666666,67.0,47.66666666666667,65.66666666666666,67.66666666666666,67.33333333333333,69.0,68.33333333333333,65.66666666666666,66.66666666666666,69.66666666666667,70.0,66.0,67.33333333333333,64.33333333333333,67.66666666666666,65.33333333333333,66.66666666666666,67.0,67.0,67.33333333333333,67.66666666666666,65.66666666666666,68.33333333333333,68.33333333333333,69.33333333333334,67.66666666666666,67.0,66.66666666666666,69.66666666666667,68.0,66.33333333333333,67.0,66.66666666666666,63.0,66.66666666666666,66.66666666666666,67.0,68.33333333333333,66.66666666666666,69.33333333333334,66.33333333333333,64.33333333333333,68.0,64.66666666666666,65.66666666666666,66.0,67.33333333333333,66.66666666666666,68.33333333333333,66.66666666666666,67.33333333333333,66.0,68.0,69.0,47.66666666666667,65.33333333333333,68.0,67.33333333333333,66.66666666666666,68.0,62.0,70.0,69.66666666666667,66.33333333333333,67.0,67.66666666666666,66.66666666666666,53.666666666666664,68.66666666666667,68.33333333333333,67.0,70.33333333333334,67.33333333333333,67.0,66.0,67.66666666666666,66.66666666666666,69.0,68.33333333333333,67.33333333333333,65.66666666666666,68.0,65.66666666666666,47.66666666666667,68.33333333333333,70.33333333333334,66.0,67.33333333333333,64.0,66.66666666666666,68.0,68.66666666666667,64.0,66.33333333333333,65.0,60.0,65.33333333333333,69.33333333333334,69.0,67.0,68.0,62.0,68.33333333333333,67.0,68.66666666666667,69.0,69.0,68.66666666666667,66.66666666666666,67.33333333333333,66.0,65.33333333333333,65.33333333333333,67.33333333333333,64.33333333333333,68.66666666666667,68.66666666666667,68.33333333333333,67.33333333333333,68.33333333333333,66.0,66.66666666666666,71.0,67.33333333333333,68.66666666666667,66.33333333333333,65.66666666666666,67.0,67.33333333333333,66.33333333333333,67.66666666666666,64.33333333333333,67.66666666666666,65.0,67.0,67.0,66.0,67.33333333333333,67.66666666666666,65.66666666666666,66.66666666666666,68.0,65.66666666666666,68.0,65.0,67.0,66.66666666666666,69.33333333333334,65.66666666666666,65.66666666666666,67.33333333333333,65.33333333333333,65.0,69.33333333333334,64.33333333333333,69.33333333333334,63.66666666666667,65.66666666666666,65.0,68.66666666666667,66.0,68.66666666666667,47.66666666666667,67.0,66.66666666666666,66.33333333333333,67.33333333333333,66.33333333333333,66.66666666666666,68.0,67.66666666666666,66.0,47.66666666666667,67.66666666666666,65.66666666666666,66.66666666666666,67.33333333333333,67.0,67.0,68.33333333333333,70.0,66.0,70.33333333333334,68.66666666666667,63.66666666666667,69.33333333333334,66.66666666666666,68.66666666666667,65.33333333333333,68.33333333333333,68.33333333333333,68.66666666666667,69.33333333333334,70.66666666666667,69.66666666666667,69.0,64.33333333333333,66.33333333333333,65.0,61.66666666666667,68.33333333333333,65.0,66.33333333333333,69.0,69.33333333333334,67.66666666666666,65.66666666666666,66.0,67.66666666666666,65.0,67.0,66.33333333333333,66.0,69.33333333333334,68.66666666666667,68.66666666666667,51.0,66.66666666666666,61.0,67.66666666666666,68.0,66.33333333333333,67.0,66.33333333333333,61.0,64.33333333333333,68.0,69.0,66.0,63.66666666666667,66.0,69.0,69.0,68.0,67.66666666666666,69.0,70.33333333333334,67.66666666666666,68.0,67.66666666666666,69.0,66.0,67.33333333333333,67.0,67.33333333333333,67.66666666666666,68.66666666666667,68.33333333333333,63.66666666666667,67.33333333333333,68.33333333333333,55.333333333333336,68.66666666666667,66.66666666666666,67.33333333333333,66.0,67.0,67.33333333333333,67.0,69.66666666666667,64.33333333333333,66.33333333333333,68.33333333333333,67.33333333333333,67.33333333333333,67.0,63.66666666666667,66.66666666666666,66.0,66.33333333333333,64.66666666666666,66.33333333333333,66.0,69.33333333333334,65.0,66.66666666666666,66.33333333333333,68.33333333333333,67.66666666666666,69.66666666666667,57.333333333333336,64.66666666666666,61.0,66.33333333333333,67.33333333333333,60.333333333333336,68.0,68.0,67.33333333333333,67.33333333333333,68.33333333333333,68.33333333333333,57.99999999999999,68.66666666666667,67.33333333333333,65.66666666666666,65.66666666666666,67.33333333333333,68.0,67.33333333333333,66.0,69.66666666666667,67.0,68.66666666666667,70.0,68.66666666666667,62.66666666666667,47.66666666666667,47.66666666666667,66.0,47.66666666666667,66.66666666666666,67.33333333333333,66.66666666666666,67.33333333333333,68.0,65.66666666666666,68.66666666666667,67.0,66.33333333333333,66.66666666666666,68.33333333333333,67.0,52.33333333333333,66.66666666666666,60.66666666666667,70.33333333333334,59.0,60.66666666666667,47.66666666666667,66.66666666666666,66.66666666666666,66.33333333333333,67.66666666666666,66.33333333333333,68.33333333333333,65.66666666666666,66.66666666666666,66.66666666666666,68.66666666666667,67.66666666666666,67.0,68.33333333333333,67.33333333333333,67.0,67.0,67.66666666666666,67.66666666666666,66.33333333333333,67.0,68.0,66.33333333333333,66.66666666666666,66.66666666666666,67.33333333333333,68.33333333333333,68.66666666666667,67.66666666666666,69.66666666666667,66.66666666666666,67.66666666666666,67.0,66.33333333333333,68.66666666666667,68.0,70.0,68.0,65.66666666666666,65.33333333333333,66.66666666666666,68.0,68.33333333333333,66.33333333333333,68.0,66.66666666666666,68.33333333333333,68.33333333333333,67.33333333333333,68.0,67.66666666666666,69.0,68.0,67.33333333333333,64.33333333333333,68.66666666666667,66.0,65.33333333333333,67.33333333333333,68.33333333333333,68.66666666666667,69.66666666666667,68.0,66.66666666666666,67.0,68.0,69.0,64.33333333333333,63.66666666666667,67.33333333333333,67.66666666666666,68.0,69.33333333333334,69.33333333333334,67.66666666666666,67.33333333333333,68.33333333333333,69.0,67.66666666666666,68.66666666666667,64.33333333333333,68.33333333333333,68.66666666666667,68.0,63.66666666666667,65.66666666666666,70.33333333333334,65.0,67.33333333333333,67.0,47.66666666666667,68.66666666666667,67.0,54.0,66.33333333333333,68.0,68.33333333333333,67.0,66.0,67.0,66.33333333333333,66.66666666666666,67.66666666666666,68.33333333333333,65.33333333333333,68.0,67.66666666666666,68.0,66.33333333333333,65.66666666666666,67.33333333333333,67.33333333333333,67.0,68.33333333333333,66.0,66.0,67.0,71.0,67.33333333333333,68.66666666666667,66.33333333333333,66.33333333333333,67.33333333333333,53.0,69.0,69.33333333333334,66.33333333333333,66.0,67.33333333333333,69.33333333333334,68.33333333333333,47.66666666666667,39.666666666666664,69.0,67.33333333333333,69.0,67.66666666666666,65.33333333333333,64.33333333333333,67.33333333333333,67.33333333333333,69.66666666666667,69.33333333333334,65.33333333333333,66.0,68.0,66.66666666666666,67.66666666666666,67.33333333333333,68.33333333333333,63.0,67.33333333333333,66.33333333333333,67.33333333333333,67.33333333333333,67.66666666666666,69.0,67.33333333333333,69.33333333333334,65.66666666666666,68.33333333333333,68.33333333333333,65.0,66.0,64.0,64.33333333333333,68.66666666666667,68.33333333333333,67.0,66.66666666666666,68.33333333333333,66.33333333333333,67.0,47.66666666666667,68.66666666666667,65.33333333333333,67.66666666666666,68.33333333333333,67.0,71.33333333333334,65.33333333333333,68.33333333333333,65.66666666666666,67.66666666666666,70.33333333333334,67.0,66.66666666666666,66.66666666666666,66.66666666666666,68.0,67.33333333333333,66.33333333333333,69.33333333333334,67.66666666666666,65.66666666666666,65.66666666666666,65.33333333333333,67.33333333333333,65.0,68.33333333333333,66.0,68.66666666666667,67.0,68.33333333333333,66.0,67.33333333333333,68.0,67.33333333333333,66.0,67.66666666666666,65.33333333333333,68.66666666666667,67.33333333333333,68.66666666666667,66.66666666666666,68.66666666666667,67.66666666666666,67.66666666666666,66.0,47.66666666666667,65.66666666666666,66.66666666666666,69.33333333333334,68.33333333333333,68.33333333333333,68.0,67.33333333333333,69.66666666666667,66.0,68.33333333333333,67.66666666666666,65.33333333333333,68.66666666666667,66.33333333333333,68.66666666666667,70.0,69.66666666666667,67.33333333333333,69.66666666666667,68.0,69.66666666666667,69.33333333333334,70.0,67.0,66.66666666666666,67.33333333333333,68.33333333333333,67.66666666666666,68.33333333333333,67.33333333333333,68.33333333333333,66.33333333333333,66.0,66.33333333333333,69.33333333333334,67.33333333333333,67.0,66.33333333333333,68.33333333333333,67.66666666666666,67.66666666666666,67.66666666666666,68.0,66.0,67.0,67.66666666666666,68.66666666666667,68.0,67.66666666666666,66.33333333333333,67.66666666666666,65.0,70.0,67.0,66.66666666666666,67.33333333333333,67.66666666666666,69.66666666666667,67.66666666666666,68.0,68.33333333333333,47.66666666666667,65.66666666666666,65.33333333333333,69.0,64.66666666666666,67.66666666666666,66.66666666666666,66.0,66.66666666666666,67.66666666666666,67.0,67.66666666666666,67.66666666666666,70.66666666666667,66.0,68.66666666666667,65.33333333333333,66.0,66.0,66.33333333333333,66.66666666666666,61.0,66.33333333333333,66.66666666666666,64.66666666666666,65.33333333333333,68.0,69.0,67.0,67.0,66.33333333333333,67.0,69.0,58.333333333333336,66.33333333333333,68.0,67.0,67.33333333333333,66.0,65.33333333333333,69.0,67.66666666666666,67.33333333333333,66.66666666666666,65.0,66.66666666666666,70.66666666666667,70.66666666666667,65.33333333333333,68.0,65.33333333333333,66.0,66.0,65.0,66.0,69.0,69.0,66.33333333333333,53.333333333333336,66.66666666666666,69.33333333333334,66.66666666666666,72.0,68.33333333333333,65.66666666666666,66.0,64.0,69.33333333333334,66.33333333333333,66.66666666666666,66.0,65.66666666666666,51.0,69.66666666666667,68.0,67.0,64.0,66.66666666666666,68.33333333333333,64.33333333333333,68.66666666666667,66.66666666666666,47.66666666666667,68.66666666666667,66.0,68.33333333333333,66.66666666666666,64.33333333333333,70.33333333333334,68.0,67.0,67.0,67.66666666666666,67.0,65.66666666666666,64.66666666666666,67.66666666666666,68.33333333333333,69.66666666666667,67.0,47.66666666666667,67.66666666666666,55.00000000000001,66.33333333333333,67.0,66.33333333333333,68.66666666666667,67.33333333333333,67.33333333333333,68.0,66.33333333333333,66.66666666666666,69.0,69.33333333333334,65.66666666666666,65.66666666666666,66.66666666666666,67.66666666666666,68.0,67.0,68.0,68.66666666666667,67.33333333333333,69.66666666666667,69.0,66.33333333333333,66.33333333333333,67.66666666666666,69.0,66.0,68.66666666666667,68.0,66.0,60.66666666666667,67.0,66.66666666666666,67.0,69.0,67.33333333333333,67.33333333333333,67.33333333333333,67.0,65.66666666666666,64.66666666666666,68.0,66.0,65.66666666666666,66.66666666666666,66.33333333333333,69.0,67.66666666666666,47.66666666666667,65.33333333333333,66.66666666666666,66.33333333333333,68.33333333333333,65.33333333333333,67.33333333333333,67.0,67.33333333333333,67.66666666666666,68.33333333333333,66.66666666666666,67.33333333333333,65.0,66.33333333333333,67.66666666666666,68.0,68.66666666666667,65.33333333333333,69.0,67.66666666666666,68.33333333333333,69.33333333333334,68.33333333333333,68.33333333333333,67.66666666666666,67.66666666666666,67.0,67.0,68.33333333333333,67.0,67.66666666666666,67.33333333333333,68.0,66.0,67.66666666666666,65.33333333333333,67.66666666666666,69.0,70.33333333333334,60.66666666666667,69.66666666666667,69.0,69.33333333333334,66.66666666666666,47.66666666666667,67.33333333333333,51.33333333333333,67.66666666666666,64.66666666666666,67.33333333333333,67.66666666666666,68.33333333333333,66.66666666666666,66.0,67.66666666666666,69.0,64.66666666666666,67.0,66.33333333333333,47.66666666666667,67.0,66.33333333333333,66.66666666666666,67.0,69.33333333333334,68.66666666666667,65.66666666666666,61.33333333333333,65.33333333333333,67.66666666666666,68.0,53.666666666666664,68.0,67.0,67.33333333333333,71.0,68.0,68.33333333333333,67.0,68.33333333333333,67.66666666666666,66.33333333333333,70.33333333333334,65.33333333333333,67.0,66.66666666666666,68.0,67.66666666666666,68.0,67.0,69.66666666666667,66.66666666666666,67.33333333333333,68.33333333333333,68.33333333333333,66.66666666666666,68.66666666666667,68.0,66.66666666666666,64.66666666666666,67.0,68.33333333333333,69.33333333333334,69.66666666666667,66.66666666666666,67.66666666666666,67.0,67.0,47.66666666666667,66.33333333333333,66.0,69.33333333333334,67.33333333333333,69.0,65.66666666666666,68.66666666666667,66.0,69.0,69.0,67.0,66.0,47.66666666666667,69.33333333333334,67.66666666666666,67.33333333333333,64.0,67.0,68.0,69.66666666666667,67.33333333333333,68.0,67.33333333333333,66.0,66.66666666666666,68.33333333333333,69.33333333333334,67.33333333333333,69.0,66.0,66.0,65.66666666666666,67.0,66.0,65.66666666666666,67.33333333333333,68.0,67.0,68.33333333333333,65.66666666666666,66.33333333333333,67.66666666666666,67.33333333333333,67.66666666666666,68.33333333333333,66.66666666666666,65.33333333333333,68.0,66.33333333333333,68.0,69.0,64.33333333333333,67.0,71.0,66.66666666666666,66.66666666666666,66.66666666666666,66.33333333333333,67.0,65.66666666666666,47.66666666666667,66.33333333333333,67.33333333333333,59.66666666666667,66.33333333333333,68.33333333333333,64.0,68.33333333333333,65.0,65.66666666666666,64.33333333333333,47.66666666666667,66.66666666666666,68.33333333333333,69.66666666666667,67.0,67.33333333333333,67.0,67.0,67.66666666666666,66.33333333333333,67.33333333333333,66.66666666666666,66.0,69.66666666666667,66.0,67.33333333333333,68.0,65.66666666666666,63.33333333333333,65.66666666666666,62.66666666666667,63.66666666666667,66.0,68.0,65.33333333333333,65.33333333333333,68.66666666666667,67.0,68.0,67.33333333333333,65.66666666666666,65.66666666666666,65.0,65.66666666666666,65.66666666666666,67.33333333333333,67.0,65.66666666666666,68.33333333333333,69.33333333333334,67.33333333333333,70.33333333333334,65.0,66.0,67.66666666666666,66.66666666666666,66.66666666666666,64.33333333333333,67.0,65.66666666666666,66.33333333333333,68.0,65.66666666666666,69.0,67.33333333333333,67.0,69.33333333333334,66.0,66.33333333333333,68.33333333333333,67.66666666666666,65.33333333333333,67.0,66.33333333333333,68.0,67.66666666666666,67.0,47.66666666666667,64.66666666666666,67.0,65.66666666666666,67.0,65.0,68.0,67.0,67.0,66.33333333333333,66.66666666666666,63.33333333333333,71.33333333333334,68.33333333333333,66.66666666666666,63.66666666666667,68.66666666666667,69.33333333333334,66.66666666666666,68.33333333333333,68.0,66.66666666666666,68.66666666666667,67.66666666666666,65.33333333333333,67.33333333333333,66.66666666666666,66.66666666666666,66.66666666666666,47.66666666666667,65.66666666666666,67.66666666666666,66.66666666666666,69.33333333333334,68.66666666666667,64.66666666666666,66.33333333333333,54.0,65.66666666666666,68.66666666666667,62.66666666666667,64.66666666666666,65.33333333333333,62.33333333333333,67.33333333333333,66.0,68.0,65.66666666666666,65.66666666666666,69.33333333333334,65.66666666666666,67.0,68.66666666666667,65.0,59.333333333333336,67.33333333333333,69.0,64.66666666666666,66.66666666666666,66.33333333333333,68.33333333333333,68.0,68.33333333333333,66.33333333333333,68.66666666666667,65.66666666666666,64.66666666666666,67.0,68.33333333333333,71.66666666666667,67.0,66.66666666666666,68.66666666666667,69.33333333333334,63.0,66.0,67.0,47.66666666666667,63.66666666666667,66.66666666666666,67.0,67.0,67.0,68.66666666666667,68.66666666666667,67.0,68.66666666666667,66.66666666666666,67.33333333333333,67.33333333333333,68.66666666666667,67.33333333333333,68.0,69.0,66.66666666666666,68.66666666666667,66.0,66.0,67.33333333333333,67.0,68.0,67.0,66.0,66.66666666666666,65.33333333333333,66.66666666666666,67.66666666666666,66.0,67.66666666666666,66.0,64.66666666666666,66.33333333333333,68.0,67.33333333333333,64.66666666666666,64.33333333333333,69.0,68.0,67.33333333333333,68.33333333333333,67.66666666666666,67.33333333333333,68.66666666666667,66.0,64.66666666666666,67.66666666666666,66.33333333333333,71.0,65.33333333333333,69.0,67.0,70.0,67.0,67.66666666666666,67.33333333333333,65.33333333333333,67.33333333333333,67.33333333333333,66.66666666666666,67.0,67.33333333333333,66.33333333333333,70.0,65.66666666666666,66.0,47.66666666666667,67.66666666666666,68.0,51.66666666666667,66.33333333333333,70.0,66.33333333333333,69.0,66.0,65.66666666666666,67.33333333333333,67.33333333333333,67.66666666666666,67.33333333333333,68.33333333333333,66.33333333333333,69.0,68.33333333333333,68.33333333333333,66.66666666666666,68.0,65.66666666666666,68.33333333333333,67.0,66.66666666666666,69.0,67.0,68.33333333333333,67.33333333333333,67.0,64.66666666666666,66.33333333333333,66.33333333333333,68.66666666666667,66.66666666666666,66.66666666666666,68.0,68.0,67.66666666666666,65.0,68.33333333333333,67.33333333333333,66.33333333333333,66.0,69.0,67.66666666666666,65.0,68.33333333333333,66.66666666666666,65.66666666666666,67.33333333333333,69.0,67.66666666666666,66.33333333333333,67.33333333333333,66.66666666666666,68.66666666666667,69.66666666666667,67.0,65.66666666666666,66.66666666666666,68.33333333333333,67.0,66.66666666666666,68.66666666666667,64.0,66.0,68.33333333333333,67.33333333333333,68.33333333333333,47.66666666666667,65.33333333333333,67.66666666666666,47.66666666666667,68.33333333333333,65.66666666666666,64.33333333333333,67.0,68.0,68.33333333333333,65.0,66.0,68.0,68.0,68.66666666666667,65.66666666666666,68.0,67.0,66.66666666666666,67.66666666666666,69.0,67.66666666666666,67.33333333333333,69.33333333333334,69.0,67.0,66.66666666666666,70.33333333333334,66.33333333333333,69.33333333333334,67.0,67.66666666666666,68.33333333333333,67.0,69.33333333333334,67.33333333333333,66.33333333333333,68.66666666666667,68.66666666666667,67.66666666666666,68.33333333333333,67.0,67.66666666666666,67.33333333333333,66.0,66.33333333333333,65.66666666666666,65.33333333333333,66.33333333333333,68.66666666666667,68.33333333333333,67.33333333333333,68.33333333333333,67.66666666666666,67.66666666666666,66.0,66.33333333333333,65.66666666666666,65.0,67.66666666666666,66.66666666666666,66.33333333333333,66.33333333333333,68.0,65.33333333333333,53.666666666666664,68.0,69.33333333333334,69.0,64.66666666666666,65.66666666666666,47.66666666666667,67.33333333333333,68.66666666666667,67.33333333333333,67.33333333333333,66.0,67.0,65.66666666666666,68.33333333333333,66.0,66.0,68.66666666666667,65.66666666666666,63.66666666666667,67.33333333333333,68.0,67.0,62.0,67.66666666666666,68.33333333333333,68.66666666666667,67.33333333333333,66.66666666666666,68.0,66.33333333333333,68.0,68.0,66.0,65.66666666666666,67.66666666666666,66.0,66.66666666666666,67.66666666666666,64.33333333333333,68.66666666666667,65.0,65.0,67.0,67.33333333333333,68.33333333333333,67.33333333333333,64.66666666666666,70.66666666666667,68.33333333333333,69.0,67.0,65.66666666666666,67.66666666666666,68.66666666666667,65.66666666666666,67.33333333333333,67.33333333333333,47.66666666666667,66.66666666666666,65.0,70.0,67.0,68.66666666666667,67.33333333333333,69.0,68.33333333333333,72.0,68.33333333333333,69.0,66.33333333333333,66.0,68.33333333333333,53.333333333333336,67.33333333333333,68.0,68.0,67.0,70.33333333333334,52.0,47.66666666666667,65.0,66.33333333333333,67.33333333333333,66.0,67.33333333333333,64.0,68.0,66.66666666666666,67.0,67.66666666666666,67.33333333333333,67.0,68.0,69.0,67.33333333333333,67.33333333333333,69.0,68.0,68.66666666666667,67.0,67.0,66.66666666666666,65.0,67.33333333333333,66.33333333333333,65.33333333333333,65.33333333333333,64.0,66.33333333333333,67.33333333333333,68.66666666666667,65.66666666666666,66.33333333333333,69.66666666666667,67.33333333333333,67.66666666666666,69.33333333333334,67.0,68.66666666666667,66.0,67.0,66.0,68.66666666666667,68.0,70.0,66.0,67.33333333333333,68.66666666666667,65.0,68.33333333333333,68.0,69.33333333333334,65.33333333333333,68.0,68.66666666666667,67.0,66.66666666666666,58.333333333333336,67.66666666666666,70.0,66.66666666666666,67.0,66.0,65.33333333333333,67.0,68.66666666666667,66.0,67.33333333333333,47.66666666666667,65.0,65.66666666666666,67.0,66.33333333333333,70.0,67.0,68.33333333333333,70.66666666666667,69.66666666666667,68.0,68.66666666666667,65.0,67.33333333333333,68.66666666666667,67.33333333333333,67.66666666666666,67.33333333333333,68.0,68.33333333333333,69.0,64.33333333333333,68.66666666666667,67.66666666666666,67.0,67.66666666666666,66.66666666666666,65.66666666666666,66.66666666666666,67.66666666666666,66.66666666666666,69.66666666666667,66.0,68.66666666666667,66.66666666666666,66.33333333333333,68.0,68.0,60.66666666666667,68.33333333333333,66.66666666666666,66.33333333333333,66.0,66.33333333333333,68.33333333333333,68.0,68.33333333333333,67.0,67.66666666666666,67.33333333333333,67.33333333333333,67.33333333333333,67.33333333333333,68.0,66.0,68.66666666666667,68.0,68.0,68.0,65.66666666666666,66.66666666666666,68.0,64.66666666666666,67.33333333333333,65.33333333333333,65.33333333333333,66.33333333333333,65.66666666666666,69.0,67.33333333333333,67.0,67.33333333333333,68.66666666666667,67.66666666666666,70.33333333333334,65.66666666666666,69.66666666666667,68.33333333333333,66.66666666666666,65.66666666666666,67.66666666666666,65.66666666666666,65.66666666666666,63.66666666666667,67.33333333333333,64.66666666666666,65.66666666666666,67.33333333333333,65.0,65.0,67.33333333333333,65.66666666666666,66.0,68.66666666666667,66.0,69.0,66.33333333333333,67.66666666666666,68.33333333333333,67.66666666666666,69.66666666666667,66.0,62.0,47.66666666666667,67.66666666666666,64.66666666666666,64.0,66.66666666666666,65.0,67.66666666666666,64.66666666666666,65.0,64.66666666666666,65.0,69.0,68.33333333333333,67.0,67.33333333333333,67.33333333333333,66.0,66.33333333333333,68.0,67.0,68.0,67.0,67.33333333333333,68.0,67.0,65.66666666666666,62.0,67.33333333333333,65.33333333333333,67.66666666666666,67.33333333333333,68.66666666666667,66.33333333333333,64.33333333333333,64.0,64.66666666666666,67.33333333333333,67.0,65.33333333333333,68.0,68.66666666666667,69.33333333333334,66.33333333333333,66.33333333333333,68.0,69.66666666666667,68.0,67.0,63.66666666666667,66.33333333333333,66.66666666666666,68.33333333333333,66.0,64.66666666666666,68.66666666666667,65.33333333333333,66.66666666666666,65.66666666666666,68.0,66.33333333333333,65.33333333333333,66.0,66.33333333333333,67.33333333333333,68.0,66.0,50.0,47.66666666666667,68.66666666666667,65.66666666666666,60.0,67.0,69.33333333333334,64.66666666666666,67.33333333333333,65.66666666666666,66.33333333333333,68.0,67.0,67.66666666666666,64.33333333333333,67.33333333333333,66.66666666666666,66.66666666666666,67.33333333333333,67.0,66.33333333333333,66.0,65.33333333333333,68.0,65.66666666666666,69.33333333333334,68.0,68.66666666666667,69.0,67.33333333333333,67.66666666666666,67.66666666666666,47.66666666666667,67.66666666666666,66.66666666666666,65.33333333333333,67.0,67.33333333333333,67.0,67.33333333333333,68.33333333333333,68.33333333333333,66.0,66.0,69.33333333333334,68.0,66.66666666666666,67.0,65.66666666666666,63.66666666666667,69.33333333333334,68.0,66.33333333333333,67.66666666666666,68.0,67.66666666666666,66.33333333333333,67.66666666666666,66.0,68.0,66.0,66.66666666666666,66.66666666666666,67.33333333333333,67.33333333333333,47.66666666666667,68.0,68.33333333333333,47.66666666666667,66.33333333333333,55.00000000000001,65.0,67.0,67.33333333333333,66.33333333333333,65.0,66.33333333333333,68.0,69.33333333333334,68.33333333333333,66.66666666666666,66.33333333333333,68.33333333333333,64.66666666666666,68.0,69.33333333333334,67.33333333333333,67.33333333333333,68.0,64.66666666666666,65.66666666666666,65.33333333333333,69.0,69.66666666666667,65.33333333333333,66.66666666666666,67.33333333333333,70.33333333333334,66.33333333333333,69.0,68.66666666666667,66.33333333333333,68.0,66.33333333333333,66.66666666666666,66.0,66.0,66.33333333333333,67.0,68.66666666666667,66.33333333333333,66.0,68.0,66.66666666666666,68.33333333333333,65.33333333333333,68.66666666666667,68.0,68.33333333333333,68.66666666666667,67.66666666666666,66.0,66.0,69.66666666666667,64.66666666666666,65.0,68.0,69.0,66.33333333333333,69.0,67.0,68.33333333333333,68.0,68.33333333333333,70.0,68.0,65.0,68.0,68.33333333333333,67.33333333333333,67.33333333333333,68.66666666666667,66.0,66.0,67.33333333333333,65.0,66.33333333333333,68.33333333333333,47.66666666666667,66.0,67.33333333333333,68.66666666666667,67.66666666666666,67.33333333333333,66.66666666666666,65.33333333333333,67.0,67.33333333333333,68.33333333333333,67.0,68.0,68.0,67.0,66.66666666666666,68.33333333333333,66.66666666666666,68.0,68.33333333333333,68.0,69.33333333333334,67.66666666666666,67.33333333333333,67.0,67.33333333333333,65.33333333333333,67.0,68.66666666666667,67.66666666666666,67.33333333333333,65.33333333333333,67.66666666666666,68.0,66.66666666666666,67.33333333333333,70.66666666666667,63.66666666666667,47.66666666666667,67.33333333333333,64.33333333333333,68.0,66.33333333333333,67.0,67.0,70.0,67.33333333333333,68.0,66.66666666666666,68.0,65.33333333333333,67.33333333333333,66.66666666666666,65.66666666666666,66.66666666666666,67.0,66.33333333333333,67.66666666666666,66.33333333333333,68.66666666666667,47.66666666666667,70.33333333333334,67.0,66.0,69.33333333333334,68.0,68.0,67.66666666666666,66.66666666666666,67.66666666666666,67.0,69.66666666666667,67.0,69.33333333333334,67.66666666666666,67.66666666666666,65.66666666666666,68.66666666666667,65.66666666666666,51.0,67.66666666666666,65.33333333333333,67.0,67.0,67.0,68.33333333333333,63.33333333333333,68.66666666666667,67.66666666666666,61.33333333333333,68.0,65.33333333333333,68.66666666666667,67.33333333333333,67.66666666666666,65.33333333333333,68.0,66.33333333333333,68.0,66.33333333333333,68.33333333333333,69.0,67.0,66.0,69.0,69.0,59.66666666666667,67.66666666666666,69.0,68.66666666666667,67.33333333333333,67.33333333333333,69.0,67.33333333333333,69.0,67.33333333333333,68.33333333333333,67.66666666666666,67.33333333333333,68.33333333333333,66.33333333333333,64.0,65.33333333333333,68.33333333333333,67.66666666666666,54.333333333333336,68.66666666666667,66.33333333333333,67.66666666666666,67.66666666666666,68.33333333333333,66.66666666666666,67.66666666666666,67.0,68.0,69.0,67.33333333333333,64.66666666666666,67.33333333333333,66.33333333333333,67.0,65.0,66.66666666666666,67.66666666666666,65.0,68.0,67.0,68.33333333333333,65.0,68.0,67.33333333333333,69.0,66.66666666666666,65.66666666666666,66.66666666666666,66.66666666666666,65.66666666666666,68.33333333333333,66.0,69.0,68.33333333333333,63.66666666666667,66.33333333333333,65.66666666666666,69.0,67.66666666666666,69.66666666666667,66.33333333333333,47.66666666666667,67.33333333333333,64.0,67.0,65.33333333333333,65.66666666666666,66.33333333333333,65.33333333333333,67.66666666666666,65.66666666666666,68.66666666666667,68.66666666666667,66.0,63.33333333333333,64.66666666666666,67.66666666666666,66.0,68.66666666666667,67.0,65.0,69.0,68.33333333333333,65.33333333333333,67.33333333333333,65.0,68.66666666666667,68.0,69.33333333333334,63.33333333333333,67.66666666666666,64.33333333333333,69.66666666666667,68.66666666666667,67.33333333333333,68.0,67.66666666666666,68.33333333333333,68.0,66.66666666666666,67.0,68.66666666666667,63.0,70.66666666666667,68.33333333333333,68.0,67.66666666666666,67.0,67.66666666666666,70.66666666666667,64.0,66.33333333333333,68.66666666666667,67.0,66.0,65.33333333333333,66.33333333333333,68.0,57.333333333333336,69.66666666666667,66.33333333333333,65.33333333333333,67.0,67.0,66.33333333333333,66.0,68.66666666666667,66.66666666666666,67.33333333333333,70.0,67.33333333333333,47.66666666666667,65.33333333333333,64.66666666666666,66.0,69.33333333333334,69.0,67.0,65.66666666666666,65.0,67.66666666666666,68.33333333333333,66.0,70.0,66.33333333333333,69.33333333333334,69.0,63.0,67.66666666666666,66.66666666666666,68.33333333333333,67.0,68.33333333333333,67.66666666666666,67.66666666666666,66.66666666666666,66.0,66.33333333333333,68.66666666666667,67.33333333333333,64.66666666666666,67.66666666666666,66.66666666666666,65.33333333333333,65.33333333333333,64.33333333333333,66.33333333333333,66.33333333333333,66.33333333333333,60.0,70.0,67.33333333333333,68.33333333333333,64.66666666666666,69.0,67.0,68.33333333333333,66.0,64.0,66.0,64.66666666666666,65.33333333333333,63.0,65.0,67.33333333333333,65.0,62.33333333333333,67.66666666666666,64.66666666666666,68.66666666666667,68.0,63.0,66.33333333333333,65.66666666666666,62.66666666666667,68.66666666666667,68.33333333333333,41.0,67.0,69.33333333333334,65.66666666666666,66.33333333333333,65.33333333333333,68.0,69.0,67.0,64.66666666666666,67.0,64.66666666666666,65.0,67.66666666666666,66.0,69.66666666666667,68.33333333333333,64.33333333333333,65.66666666666666,63.66666666666667,65.33333333333333,65.66666666666666,69.66666666666667,69.33333333333334,69.33333333333334,67.66666666666666,67.33333333333333,67.33333333333333,68.66666666666667,68.0,66.33333333333333,68.0,69.0,67.33333333333333,65.33333333333333,68.66666666666667,67.33333333333333,67.33333333333333,66.33333333333333,65.33333333333333,67.33333333333333,70.33333333333334,66.33333333333333,63.66666666666667,67.66666666666666,62.66666666666667,69.0,65.33333333333333,69.0,68.0,68.66666666666667,67.0,68.33333333333333,67.33333333333333,67.66666666666666,69.0,68.33333333333333,66.66666666666666,67.66666666666666,68.0,67.33333333333333,65.0,47.66666666666667,67.33333333333333,66.66666666666666,66.33333333333333,68.33333333333333,64.33333333333333,66.33333333333333,69.33333333333334,68.0,47.66666666666667,66.0,67.66666666666666,67.66666666666666,67.33333333333333,67.0,68.33333333333333,69.33333333333334,68.66666666666667,67.33333333333333,67.66666666666666,67.33333333333333,68.66666666666667,66.33333333333333,66.33333333333333,68.66666666666667,65.66666666666666,69.0,67.0,65.33333333333333,66.33333333333333,69.66666666666667,68.33333333333333,54.666666666666664,69.0,66.66666666666666,68.0,71.0,69.66666666666667,67.33333333333333,66.66666666666666,68.0,67.66666666666666,65.0,65.66666666666666,68.0,68.0,66.66666666666666,63.66666666666667,61.66666666666667,67.66666666666666,67.0,68.0,66.33333333333333,67.66666666666666,47.66666666666667,68.0,68.0,66.33333333333333,68.0,66.66666666666666,66.33333333333333,68.0,66.66666666666666,66.33333333333333,65.66666666666666,68.66666666666667,67.66666666666666,67.0,67.0,67.0,68.0,68.33333333333333,69.66666666666667,53.333333333333336,65.33333333333333,69.33333333333334,67.0,65.66666666666666,65.66666666666666,65.0,68.0,69.66666666666667,65.66666666666666,68.0,68.0,67.66666666666666,47.66666666666667,66.66666666666666,67.33333333333333,68.33333333333333,69.0,67.33333333333333,71.66666666666667,67.66666666666666,66.0,63.33333333333333,67.33333333333333,67.0,65.66666666666666,69.0,66.0,54.0,48.333333333333336,69.66666666666667,66.66666666666666,66.33333333333333,65.0,44.666666666666664,66.33333333333333,66.33333333333333,66.66666666666666,68.66666666666667,63.66666666666667,66.66666666666666,65.33333333333333,66.0,67.0,67.0,67.33333333333333,60.0,66.66666666666666,67.66666666666666,66.33333333333333,64.0,65.33333333333333,66.0,68.0,47.66666666666667,47.66666666666667,66.66666666666666,66.0,67.33333333333333,71.0,67.0,65.66666666666666,65.33333333333333,64.66666666666666,67.33333333333333,68.0,68.0,65.33333333333333,66.0,68.33333333333333,67.33333333333333,65.66666666666666,67.33333333333333,67.0,65.33333333333333,68.33333333333333,66.66666666666666,67.33333333333333,68.0,65.0,71.33333333333334,67.66666666666666,65.66666666666666,67.0,64.66666666666666,66.0,66.0,69.0,67.0,68.66666666666667,68.33333333333333,64.33333333333333,68.66666666666667,67.33333333333333,68.66666666666667,68.0,66.33333333333333,68.0,68.66666666666667,47.66666666666667,71.33333333333334,65.33333333333333,66.66666666666666,67.0,67.0,68.33333333333333,67.0,65.33333333333333,67.0,65.0,68.33333333333333,65.66666666666666,65.0,70.0,61.66666666666667,66.33333333333333,66.0,65.33333333333333,61.66666666666667,66.66666666666666,66.33333333333333,65.0,68.66666666666667,67.33333333333333,66.33333333333333,67.66666666666666,66.33333333333333,68.66666666666667,68.66666666666667,62.66666666666667,66.66666666666666,69.0,67.0,70.0,69.0,65.33333333333333,66.0,61.33333333333333,67.66666666666666,70.0,68.66666666666667,65.66666666666666,67.33333333333333,66.66666666666666,68.66666666666667,67.66666666666666,66.66666666666666,67.33333333333333,64.66666666666666,68.0,67.33333333333333,69.0,68.0,60.0,67.0,68.33333333333333,66.66666666666666,66.66666666666666,47.66666666666667,64.66666666666666,67.33333333333333,65.33333333333333,66.0,67.66666666666666,67.33333333333333,67.0,66.0,67.33333333333333,65.33333333333333,66.66666666666666,66.66666666666666,68.66666666666667,64.66666666666666,68.0,65.66666666666666,68.0,68.0,66.66666666666666,67.0,68.0,68.0,66.66666666666666,66.0,68.33333333333333,66.33333333333333,67.66666666666666,68.0,66.0,66.0,69.0,66.0,66.33333333333333,68.0,65.33333333333333,68.0,67.66666666666666,67.33333333333333,67.0,66.33333333333333,66.0,66.66666666666666,67.33333333333333,65.66666666666666,68.33333333333333,69.33333333333334,67.66666666666666,66.33333333333333,62.66666666666667,55.00000000000001,65.33333333333333,67.33333333333333,66.33333333333333,66.0,69.66666666666667,65.66666666666666,67.66666666666666,67.0,68.66666666666667,66.33333333333333,65.66666666666666,65.33333333333333,67.33333333333333,66.33333333333333,67.0,44.666666666666664,68.0,68.33333333333333,67.0,67.66666666666666,65.66666666666666,67.66666666666666,67.0,67.0,67.66666666666666,65.66666666666666,66.33333333333333,65.33333333333333,69.33333333333334,59.333333333333336,68.33333333333333,67.0,66.0,66.66666666666666,65.0,67.66666666666666,67.33333333333333,63.66666666666667,68.33333333333333,66.33333333333333,65.0,66.33333333333333,67.0,67.33333333333333,67.0,66.66666666666666,65.66666666666666,66.66666666666666,65.33333333333333,68.66666666666667,65.66666666666666,66.0,66.66666666666666,64.33333333333333,69.0,65.0,67.66666666666666,69.0,67.33333333333333,68.33333333333333,67.33333333333333,62.33333333333333,65.66666666666666,67.66666666666666,68.66666666666667,67.66666666666666,67.33333333333333,66.66666666666666,67.33333333333333,67.66666666666666,68.66666666666667,69.0,66.66666666666666,68.33333333333333,69.0,65.66666666666666,68.66666666666667,65.0,69.0,66.33333333333333,67.66666666666666,67.66666666666666,65.66666666666666,50.66666666666667,67.66666666666666,65.66666666666666,65.33333333333333,68.33333333333333,67.33333333333333,68.0,67.0,66.66666666666666,69.33333333333334,65.66666666666666,68.0,64.33333333333333,66.66666666666666,69.0,65.66666666666666,65.66666666666666,66.0,65.33333333333333,67.66666666666666,67.0,68.66666666666667,67.66666666666666,67.0,66.33333333333333,67.66666666666666,68.0,66.66666666666666,63.66666666666667,47.66666666666667,65.66666666666666,66.33333333333333,66.66666666666666,67.0,68.0,67.0,64.33333333333333,66.66666666666666,66.66666666666666,65.33333333333333,66.66666666666666,67.0,66.66666666666666,70.33333333333334,65.33333333333333,66.33333333333333,65.66666666666666,65.66666666666666,63.66666666666667,47.66666666666667,67.0,65.33333333333333,66.33333333333333,67.66666666666666,66.66666666666666,67.33333333333333,65.33333333333333,69.0,67.33333333333333,67.33333333333333,69.0,69.0,67.0,68.66666666666667,67.33333333333333,65.33333333333333,62.0,65.33333333333333,67.0,67.33333333333333,65.0,66.33333333333333,67.33333333333333,60.333333333333336,67.66666666666666,65.33333333333333,67.33333333333333,69.0,69.0,66.66666666666666,67.33333333333333,66.33333333333333,47.66666666666667,67.0,68.66666666666667,61.66666666666667,65.0,67.0,63.0,66.33333333333333,67.66666666666666,67.33333333333333,68.0,66.0,68.66666666666667,67.66666666666666,68.66666666666667,68.0,67.66666666666666,70.0,65.0,68.66666666666667,65.33333333333333,69.0,66.66666666666666,66.66666666666666,66.66666666666666,68.0,65.0,68.0,67.33333333333333,65.33333333333333,64.66666666666666,65.66666666666666,65.33333333333333,66.66666666666666,66.33333333333333,66.33333333333333,66.66666666666666,66.33333333333333,67.0,67.0,66.66666666666666,67.33333333333333,67.0,67.66666666666666,68.66666666666667,66.0,67.33333333333333,67.0,69.33333333333334,69.0,69.66666666666667,67.33333333333333,68.0,67.0,69.0,67.0,65.66666666666666,69.33333333333334,68.0,68.0,65.66666666666666,68.33333333333333,67.33333333333333,68.66666666666667,69.33333333333334,68.0,67.33333333333333,65.66666666666666,68.33333333333333,67.0,67.33333333333333,67.0,67.66666666666666,66.0,68.66666666666667,68.66666666666667,66.0,67.66666666666666,69.33333333333334,53.333333333333336,67.0,65.33333333333333,66.66666666666666,68.66666666666667,69.0,66.33333333333333,68.0,68.33333333333333,66.33333333333333,67.33333333333333,67.66666666666666,67.33333333333333,66.66666666666666,67.33333333333333,68.33333333333333,66.66666666666666,67.66666666666666,68.33333333333333,68.33333333333333,69.66666666666667,65.66666666666666,68.33333333333333,68.33333333333333,68.33333333333333,68.0,68.66666666666667,62.33333333333333,68.33333333333333,66.0,69.0,65.66666666666666,66.66666666666666,71.33333333333334,66.0,68.0,68.0,66.66666666666666,68.0,66.0,65.0,67.0,65.66666666666666,68.0,66.33333333333333,70.0,68.0,68.66666666666667],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FA0\"},\"mode\":\"lines\",\"name\":\"HPO test dataset accuracy (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[62.19444444444445,62.94444444444444,63.08333333333333,63.09722222222223,63.81944444444444,64.05555555555556,64.62500000000001,64.58333333333333,65.20833333333334,65.875,65.94444444444446,65.44444444444444,65.47222222222221,65.72222222222221,65.9861111111111,65.93055555555554,65.83333333333331,65.93055555555554,66.15277777777777,66.125,66.13888888888889,66.12499999999999,66.24999999999999,66.1111111111111,66.06944444444443,66.20833333333333,66.11111111111111,66.125,66.33333333333333,66.70833333333333,67.33333333333333,67.23611111111111,67.19444444444443,67.23611111111111,67.26388888888889,67.34722222222223,67.44444444444444,67.51388888888889,67.6111111111111,67.55555555555554,67.43055555555554,67.43055555555556,67.49999999999999,67.43055555555554,67.27777777777777,67.37499999999999,67.38888888888887,67.44444444444444,67.63888888888887,66.94444444444444,66.91666666666667,66.80555555555554,66.7222222222222,66.84722222222221,66.95833333333333,67.0138888888889,67.08333333333333,67.16666666666667,67.13888888888889,67.22222222222223,67.26388888888889,66.81944444444444,66.80555555555556,66.22222222222223,66.23611111111111,66.2638888888889,66.26388888888889,66.25,66.13888888888889,66.18055555555554,66.25,66.91666666666666,66.875,66.81944444444444,66.94444444444443,66.8472222222222,66.88888888888887,66.77777777777777,66.80555555555554,67.45833333333333,67.54166666666667,67.73611111111111,67.7361111111111,67.69444444444446,67.54166666666667,67.56944444444444,67.68055555555557,67.70833333333334,67.79166666666669,67.72222222222224,67.68055555555557,68.12500000000001,68.20833333333333,68.47222222222221,68.41666666666667,68.19444444444446,68.22222222222223,68.1388888888889,68.18055555555556,68.13888888888889,68.16666666666667,68.12500000000001,68.1111111111111,68.27777777777777,68.29166666666667,68.29166666666667,68.20833333333334,68.22222222222223,68.18055555555554,68.15277777777779,68.05555555555554,67.77777777777777,67.75,67.83333333333333,68.04166666666666,67.94444444444444,67.84722222222221,67.76388888888887,67.58333333333333,67.54166666666666,67.63888888888887,67.69444444444443,67.68055555555554,67.95833333333333,67.94444444444444,68.18055555555556,67.90277777777776,67.97222222222221,68.02777777777779,68.13888888888887,68.09722222222223,68.02777777777777,68.02777777777777,67.87499999999999,67.88888888888889,67.97222222222221,68.04166666666667,68.02777777777779,67.36111111111111,67.40277777777779,67.30555555555556,67.54166666666666,67.45833333333333,67.25,67.19444444444446,67.20833333333333,67.31944444444444,67.33333333333333,67.375,67.38888888888887,67.29166666666667,67.26388888888889,67.23611111111111,67.23611111111111,67.34722222222221,67.2361111111111,67.59722222222221,67.66666666666667,67.63888888888889,67.49999999999999,67.6111111111111,67.69444444444444,67.7638888888889,67.79166666666667,67.73611111111111,67.68055555555556,67.66666666666667,67.625,68.36111111111111,68.36111111111111,68.30555555555556,68.34722222222221,68.44444444444444,68.52777777777779,68.47222222222221,68.49999999999999,68.45833333333333,68.41666666666666,68.44444444444446,68.5,68.51388888888889,68.48611111111111,68.45833333333333,68.43055555555554,68.27777777777777,67.79166666666666,67.73611111111111,67.66666666666666,67.70833333333333,67.79166666666666,67.69444444444444,67.70833333333333,67.66666666666664,67.59722222222219,67.65277777777776,67.62499999999999,67.68055555555553,67.80555555555554,67.72222222222221,67.7222222222222,67.93055555555554,67.81944444444444,67.76388888888889,67.875,67.84722222222221,67.94444444444444,67.91666666666667,67.93055555555554,67.98611111111111,67.98611111111111,67.34722222222223,67.3611111111111,67.34722222222221,67.31944444444443,67.38888888888887,67.91666666666666,67.93055555555554,67.95833333333331,67.93055555555554,67.9861111111111,67.93055555555554,68.02777777777777,68.05555555555554,68.15277777777777,68.09722222222223,68.11111111111111,68.08333333333333,68.02777777777777,67.95833333333333,67.93055555555556,67.97222222222223,67.98611111111111,68.02777777777779,67.875,67.93055555555554,67.86111111111113,67.84722222222221,67.91666666666666,67.98611111111111,67.90277777777779,68.625,68.63888888888889,68.70833333333333,68.69444444444444,68.6388888888889,68.6111111111111,68.4861111111111,68.54166666666664,67.84722222222223,67.7638888888889,67.70833333333333,67.56944444444443,67.4861111111111,67.43055555555554,67.33333333333333,66.97222222222221,67.01388888888889,67.15277777777777,67.22222222222221,67.30555555555556,66.5277777777778,66.51388888888889,66.44444444444446,66.51388888888889,66.47222222222221,66.34722222222223,66.27777777777779,66.22222222222221,66.13888888888889,66.125,65.98611111111111,65.98611111111111,65.97222222222221,65.98611111111111,66.05555555555556,66.125,66.19444444444446,65.45833333333334,66.19444444444446,66.23611111111111,66.41666666666667,66.58333333333334,66.58333333333334,66.61111111111111,66.73611111111111,67.12500000000001,67.08333333333334,67.01388888888889,67.11111111111113,67.04166666666669,67.77777777777779,67.79166666666667,67.88888888888889,67.88888888888889,67.90277777777779,68.0138888888889,68.04166666666669,67.97222222222223,67.91666666666667,67.95833333333334,68.06944444444446,68.11111111111111,68.125,68.27777777777777,68.25,68.13888888888889,68.16666666666667,68.90277777777777,68.79166666666666,68.55555555555556,68.44444444444446,68.38888888888889,68.45833333333333,68.5,68.5,68.44444444444444,68.27777777777777,68.16666666666666,68.13888888888889,68.13888888888889,68.06944444444443,68.08333333333331,68.05555555555554,68.01388888888887,68.08333333333331,68.13888888888887,68.11111111111111,68.26388888888889,68.34722222222221,68.30555555555556,67.61111111111113,67.55555555555556,67.51388888888889,67.33333333333333,67.3611111111111,67.45833333333333,67.23611111111111,67.23611111111111,67.31944444444444,67.55555555555556,67.59722222222223,67.55555555555556,67.58333333333333,67.06944444444446,67.06944444444444,67.05555555555557,67.16666666666667,67.20833333333334,67.16666666666666,67.22222222222221,67.20833333333333,67.13888888888889,67.19444444444446,67.29166666666666,67.09722222222223,67.04166666666669,67.09722222222223,67.06944444444444,67.125,66.50000000000001,67.22222222222223,67.20833333333334,67.18055555555556,67.19444444444446,67.26388888888889,67.16666666666667,67.33333333333333,67.23611111111111,67.19444444444444,67.16666666666667,67.16666666666667,66.81944444444444,66.68055555555554,67.16666666666667,67.20833333333334,67.22222222222223,67.30555555555554,67.2361111111111,67.22222222222221,67.12499999999999,67.13888888888887,67.08333333333331,66.95833333333333,66.88888888888887,67.05555555555554,67.02777777777776,67.06944444444444,67.04166666666666,66.95833333333331,67.66666666666666,67.66666666666666,67.72222222222221,67.79166666666666,67.79166666666666,67.61111111111111,67.69444444444446,67.7361111111111,67.86111111111111,67.83333333333333,67.94444444444446,67.87500000000001,68.22222222222221,68.18055555555556,68.20833333333333,68.19444444444444,68.29166666666666,68.25000000000001,68.43055555555557,68.47222222222221,68.54166666666666,68.58333333333333,68.625,68.65277777777777,68.69444444444444,68.63888888888889,68.68055555555554,68.68055555555556,68.59722222222223,68.58333333333334,68.66666666666666,68.68055555555554,68.69444444444443,68.7361111111111,68.80555555555557,68.77777777777777,68.81944444444444,68.83333333333334,68.79166666666667,68.84722222222221,68.70833333333334,68.81944444444446,68.77777777777779,68.75,68.68055555555556,68.63888888888889,68.58333333333333,68.62499999999999,68.59722222222223,67.8888888888889,67.81944444444446,67.76388888888889,67.8611111111111,67.875,67.88888888888889,67.9027777777778,67.87499999999999,67.875,67.86111111111111,67.19444444444444,67.05555555555556,67.0,66.91666666666667,66.88888888888889,66.77777777777777,66.83333333333334,66.76388888888889,66.77777777777777,66.68055555555556,66.65277777777779,66.69444444444444,66.69444444444444,66.68055555555554,66.91666666666666,67.02777777777777,67.15277777777777,67.11111111111111,67.1111111111111,67.01388888888889,67.65277777777777,67.75,67.80555555555556,67.69444444444444,67.6388888888889,67.56944444444444,67.56944444444444,67.43055555555556,67.43055555555556,67.52777777777779,68.18055555555554,68.29166666666666,68.26388888888889,68.31944444444444,68.31944444444444,68.47222222222223,68.49999999999999,68.49999999999999,68.56944444444444,68.69444444444444,68.79166666666667,68.73611111111111,68.70833333333333,68.79166666666666,68.125,68.08333333333333,67.91666666666667,67.88888888888889,67.83333333333333,67.8888888888889,67.90277777777779,67.91666666666667,67.83333333333334,67.84722222222224,67.83333333333334,67.8611111111111,67.8888888888889,68.06944444444446,68.04166666666667,67.98611111111111,67.98611111111111,67.93055555555556,67.93055555555554,67.88888888888889,67.84722222222221,67.72222222222223,67.75,67.76388888888889,67.65277777777777,67.62499999999999,67.59722222222221,67.70833333333333,67.76388888888889,67.66666666666666,68.27777777777777,68.15277777777777,68.26388888888889,68.38888888888887,68.41666666666667,67.94444444444444,67.93055555555556,67.84722222222223,67.91666666666667,67.8888888888889,67.94444444444444,68.0138888888889,67.97222222222223,67.86111111111111,67.72222222222221,67.68055555555556,67.73611111111111,67.70833333333333,67.77777777777779,67.81944444444446,67.86111111111111,67.90277777777777,67.93055555555556,67.91666666666666,67.91666666666667,67.73611111111111,67.68055555555556,67.65277777777777,67.63888888888889,67.70833333333333,67.70833333333331,67.81944444444444,67.80555555555556,67.74999999999999,67.38888888888887,67.80555555555554,67.63888888888887,67.7361111111111,67.70833333333331,67.54166666666666,67.52777777777777,67.43055555555554,67.45833333333333,67.45833333333331,67.66666666666666,67.7361111111111,67.58333333333333,67.59722222222223,67.55555555555556,67.56944444444444,67.47222222222223,67.47222222222223,67.47222222222221,67.48611111111111,67.56944444444446,67.63888888888889,67.65277777777779,67.66666666666667,67.6388888888889,67.66666666666667,67.55555555555554,66.84722222222223,66.1527777777778,66.23611111111111,65.8888888888889,65.81944444444444,66.04166666666667,66.04166666666667,66.05555555555556,66.27777777777777,66.31944444444446,66.34722222222223,66.3888888888889,66.38888888888889,66.29166666666666,66.37500000000001,66.56944444444446,66.06944444444446,66.08333333333333,65.97222222222221,66.04166666666666,65.91666666666666,65.70833333333331,65.01388888888889,65.01388888888889,65.08333333333333,65.11111111111111,65.01388888888889,65.09722222222223,65.09722222222221,65.19444444444444,65.84722222222223,66.5,66.45833333333333,67.15277777777779,67.23611111111111,67.20833333333333,67.25,67.18055555555554,67.26388888888889,67.16666666666666,67.18055555555556,67.13888888888889,67.30555555555554,67.34722222222221,67.30555555555554,67.23611111111109,67.70833333333331,67.69444444444443,67.74999999999999,67.7361111111111,67.91666666666666,68.08333333333333,68.79166666666667,68.68055555555556,68.70833333333333,68.66666666666666,68.63888888888887,68.63888888888889,68.6388888888889,68.65277777777777,68.63888888888889,68.72222222222223,68.63888888888889,68.6388888888889,68.6388888888889,68.625,68.52777777777777,68.56944444444443,68.49999999999999,68.6111111111111,68.62499999999999,68.54166666666666,68.37499999999999,68.375,68.33333333333333,68.40277777777779,68.37500000000001,68.30555555555556,68.30555555555556,68.31944444444444,68.27777777777777,68.19444444444444,68.16666666666667,68.12500000000001,68.11111111111113,68.08333333333334,68.2638888888889,68.18055555555557,68.11111111111113,68.04166666666667,68.08333333333334,68.08333333333333,68.125,68.11111111111111,68.15277777777779,68.19444444444446,68.19444444444444,68.2638888888889,68.31944444444444,68.36111111111111,68.30555555555556,68.48611111111111,68.3888888888889,68.40277777777779,68.36111111111111,68.30555555555557,68.27777777777779,68.43055555555556,68.44444444444444,68.43055555555557,68.40277777777779,68.50000000000001,67.81944444444444,67.93055555555556,67.93055555555556,67.54166666666667,67.51388888888887,67.47222222222221,67.56944444444444,67.58333333333333,67.59722222222223,67.61111111111111,67.72222222222221,67.66666666666667,67.66666666666667,67.7361111111111,67.79166666666666,67.80555555555554,67.79166666666667,67.75000000000001,67.68055555555556,67.6111111111111,67.68055555555556,67.59722222222223,67.63888888888889,67.68055555555556,67.79166666666669,67.59722222222224,67.48611111111113,67.43055555555557,67.44444444444446,67.48611111111113,68.16666666666667,68.08333333333334,68.02777777777779,67.84722222222223,67.79166666666667,67.80555555555556,67.73611111111111,67.79166666666667,67.76388888888889,67.75,67.73611111111111,67.11111111111111,66.125,66.09722222222221,65.90277777777777,65.8611111111111,65.87499999999999,65.87499999999999,66.04166666666666,66.0,66.13888888888889,66.18055555555554,66.16666666666666,66.05555555555554,66.01388888888887,66.16666666666666,66.29166666666666,66.3611111111111,66.33333333333333,66.31944444444443,66.31944444444443,66.29166666666666,66.40277777777777,66.93055555555556,66.9861111111111,67.08333333333334,67.15277777777779,67.11111111111111,67.20833333333336,67.22222222222224,67.13888888888893,67.79166666666669,68.69444444444447,68.6527777777778,68.87500000000003,68.84722222222223,68.79166666666667,68.77777777777779,68.75,68.68055555555556,68.68055555555556,68.63888888888889,68.56944444444444,67.94444444444444,67.95833333333334,67.9861111111111,68.0,68.05555555555554,68.01388888888887,67.87499999999999,67.80555555555554,67.98611111111109,67.95833333333333,68.09722222222223,68.18055555555554,68.06944444444443,68.08333333333331,68.1111111111111,68.16666666666666,68.125,68.16666666666666,68.20833333333333,68.34722222222223,68.26388888888887,68.125,68.20833333333334,68.34722222222223,68.36111111111111,68.2638888888889,68.40277777777779,68.3888888888889,68.48611111111111,68.61111111111111,69.2638888888889,69.2638888888889,69.31944444444444,69.40277777777777,69.38888888888889,69.52777777777779,69.6111111111111,69.76388888888889,69.76388888888889,69.83333333333334,69.84722222222223,69.66666666666667,69.69444444444444,69.68055555555554,69.69444444444443,69.65277777777779,68.94444444444446,68.90277777777779,68.93055555555557,68.94444444444444,69.05555555555556,69.25,69.18055555555556,69.08333333333333,69.04166666666666,69.06944444444443,69.05555555555556,68.97222222222223,69.02777777777777,69.06944444444443,69.13888888888887,69.18055555555553,69.06944444444443,69.05555555555554,68.97222222222221,68.99999999999999,68.9861111111111,68.87499999999999,68.84722222222221,68.8611111111111,68.90277777777776,68.97222222222221,69.04166666666667,69.09722222222223,69.08333333333334,69.02777777777777,69.68055555555554,69.73611111111111,69.69444444444446,69.625,69.52777777777779,69.40277777777779,69.47222222222224,69.47222222222223,69.44444444444444,69.52777777777777,69.52777777777777,69.65277777777779,69.54166666666666,69.5,69.48611111111111,69.4861111111111,69.40277777777777,69.29166666666666,69.37500000000001,69.31944444444446,69.45833333333334,69.56944444444444,69.55555555555557,69.50000000000001,69.37500000000001,69.40277777777779,69.43055555555556,69.33333333333334,69.29166666666667,69.29166666666667,69.375,69.40277777777777,68.72222222222223,68.66666666666669,68.72222222222221,68.74999999999999,68.81944444444444,68.77777777777777,68.76388888888889,68.77777777777779,68.70833333333333,68.69444444444443,68.74999999999999,68.70833333333331,68.66666666666666,68.65277777777777,68.79166666666667,68.83333333333334,68.83333333333334,68.87500000000001,68.75,68.70833333333331,68.65277777777777,68.30555555555556,68.3611111111111,68.37499999999999,68.3611111111111,68.40277777777776,68.44444444444444,68.44444444444444,68.51388888888889,68.55555555555556,69.36111111111111,69.52777777777779,69.54166666666667,69.22222222222223,69.15277777777779,69.16666666666667,69.20833333333333,69.04166666666666,69.08333333333333,69.06944444444443,68.97222222222221,69.06944444444444,69.13888888888887,69.16666666666666,69.15277777777776,69.13888888888887,69.04166666666666,68.97222222222221,69.05555555555556,69.06944444444444,69.06944444444444,69.34722222222223,69.31944444444446,69.20833333333334,69.16666666666667,69.16666666666667,69.20833333333334,69.2638888888889,68.625,68.45833333333334,68.38888888888889,68.31944444444444,68.26388888888889,68.54166666666666,68.51388888888889,68.56944444444446,68.58333333333333,68.66666666666666,68.63888888888889,68.62500000000001,68.65277777777777,68.54166666666666,67.93055555555556,67.8611111111111,67.86111111111109,67.81944444444443,67.88888888888889,67.9861111111111,67.93055555555556,67.76388888888889,67.77777777777777,67.87499999999999,67.16666666666666,67.30555555555554,67.24999999999999,67.15277777777777,67.22222222222223,67.20833333333334,67.79166666666667,67.80555555555554,67.79166666666666,67.76388888888889,67.875,67.93055555555554,67.94444444444443,67.95833333333331,67.9861111111111,67.97222222222221,68.06944444444446,68.09722222222223,67.43055555555556,67.44444444444444,67.65277777777777,67.65277777777777,67.65277777777777,67.73611111111111,67.83333333333336,67.73611111111111,67.70833333333333,67.86111111111111,67.88888888888889,67.80555555555556,68.47222222222223,68.5138888888889,68.55555555555556,68.66666666666667,68.52777777777777,68.44444444444443,68.44444444444444,68.51388888888889,68.41666666666667,68.34722222222223,68.22222222222223,68.08333333333333,68.08333333333333,68.13888888888889,68.125,68.23611111111111,68.18055555555554,68.22222222222223,68.875,69.0,69.3472222222222,69.16666666666666,69.1388888888889,69.15277777777777,69.05555555555554,69.04166666666667,69.06944444444446,69.04166666666669,69.0138888888889,69.0138888888889,69.06944444444444,68.91666666666667,68.93055555555556,68.83333333333333,68.80555555555556,68.81944444444444,68.88888888888889,68.81944444444444,68.90277777777777,68.25,68.30555555555554,68.44444444444443,68.33333333333333,68.18055555555554,68.2222222222222,68.19444444444443,68.20833333333333,68.13888888888889,68.25,68.09722222222223,68.09722222222223,68.29166666666667,68.33333333333336,68.31944444444446,68.33333333333333,68.41666666666667,68.40277777777779,68.40277777777779,68.36111111111111,68.41666666666667,68.37499999999999,68.49999999999999,68.47222222222221,68.59722222222221,68.62499999999997,68.65277777777776,68.4861111111111,68.45833333333331,68.44444444444443,69.26388888888889,69.29166666666666,69.29166666666666,69.41666666666666,69.5,69.59722222222223,69.59722222222221,69.62499999999999,69.69444444444444,69.68055555555556,69.33333333333334,69.36111111111111,69.33333333333333,69.375,69.36111111111111,68.62500000000001,68.65277777777779,68.11111111111111,68.16666666666667,68.19444444444444,68.19444444444444,68.26388888888889,68.18055555555556,68.26388888888889,68.15277777777777,68.19444444444443,68.19444444444444,68.33333333333333,68.44444444444444,68.58333333333333,67.76388888888887,67.83333333333333,67.79166666666667,67.69444444444444,67.62499999999999,67.49999999999999,67.49999999999999,67.29166666666666,67.02777777777777,66.90277777777779,67.25,67.16666666666669,66.72222222222221,66.69444444444444,66.625,67.34722222222223,67.29166666666667,67.81944444444444,67.79166666666666,67.81944444444444,67.81944444444444,67.74999999999999,67.7222222222222,67.72222222222221,67.68055555555556,67.63888888888889,67.63888888888889,67.59722222222223,67.55555555555556,67.41666666666666,68.09722222222221,68.02777777777777,68.04166666666666,68.13888888888889,68.27777777777779,68.26388888888889,68.16666666666667,68.30555555555556,68.41666666666667,68.44444444444444,68.51388888888887,68.5138888888889,68.8888888888889,68.83333333333333,68.79166666666666,68.7361111111111,68.68055555555554,68.7361111111111,68.76388888888887,68.04166666666667,67.94444444444444,67.90277777777777,67.90277777777776,67.88888888888887,67.90277777777777,68.02777777777776,67.94444444444443,67.88888888888889,67.90277777777777,67.93055555555554,67.93055555555554,67.95833333333331,67.24999999999999,67.30555555555554,67.13888888888887,67.18055555555556,67.26388888888889,67.30555555555556,67.38888888888889,67.38888888888889,67.41666666666667,67.43055555555557,67.51388888888889,67.44444444444444,67.61111111111111,67.63888888888889,67.75,67.68055555555554,67.79166666666666,68.52777777777777,68.6111111111111,68.68055555555554,68.69444444444444,68.63888888888889,68.58333333333334,68.58333333333333,68.625,68.59722222222221,68.625,68.6388888888889,68.70833333333334,68.56944444444446,69.34722222222223,69.2638888888889,69.40277777777777,69.36111111111111,69.36111111111111,69.36111111111111,69.31944444444444,69.37499999999999,69.38888888888889,69.47222222222221,69.4722222222222,69.45833333333333,69.41666666666666,69.45833333333333,69.44444444444443,69.4861111111111,69.26388888888889,69.26388888888889,68.52777777777779,68.55555555555556,68.5138888888889,68.22222222222223,68.38888888888889,68.29166666666667,68.2638888888889,68.36111111111113,68.16666666666667,68.19444444444446,68.125,67.52777777777779,67.52777777777779,67.59722222222223,67.55555555555557,67.56944444444446,67.61111111111111,67.54166666666666,67.59722222222223,67.59722222222223,67.54166666666667,67.52777777777779,67.5138888888889,67.45833333333334,67.38888888888889,67.34722222222223,67.19444444444444,67.30555555555556,67.38888888888889,67.29166666666667,68.0,67.8888888888889,67.84722222222223,68.13888888888889,68.05555555555556,68.0,67.97222222222223,67.95833333333334,68.09722222222223,68.09722222222223,68.13888888888887,68.76388888888889,68.75000000000001,68.70833333333334,68.77777777777779,68.73611111111111,68.58333333333333,68.56944444444443,68.63888888888889,68.65277777777777,68.66666666666666,68.54166666666666,68.47222222222221,68.69444444444443,68.7222222222222,68.74999999999999,68.91666666666664,68.84722222222221,68.90277777777777,68.99999999999999,69.02777777777774,69.12499999999997,69.2361111111111,69.20833333333333,69.30555555555554,69.45833333333331,69.51388888888887,69.52777777777777,69.625,69.51388888888889,69.47222222222221,69.52777777777777,69.51388888888889,69.45833333333334,69.36111111111111,69.3888888888889,69.5277777777778,69.52777777777779,68.73611111111111,68.7638888888889,68.73611111111111,68.84722222222221,68.94444444444444,68.8611111111111,68.91666666666664,68.79166666666664,68.80555555555553,68.68055555555554,68.59722222222221,68.49999999999999,68.43055555555553,68.47222222222221,68.44444444444443,68.43055555555554,68.4722222222222,68.31944444444443,68.3611111111111,68.27777777777776,68.27777777777776,68.29166666666666,68.31944444444444,68.23611111111109,68.20833333333333,68.22222222222221,68.19444444444444,68.29166666666666,68.24999999999999,67.58333333333333,68.24999999999999,68.125,68.08333333333331,67.9861111111111,67.98611111111111,67.90277777777777,67.80555555555554,67.45833333333333,67.38888888888887,67.40277777777777,67.20833333333333,67.22222222222221,67.33333333333331,67.2222222222222,67.29166666666666,67.31944444444443,67.19444444444443,67.30555555555554,67.26388888888887,67.36111111111111,67.26388888888889,67.36111111111111,67.27777777777779,67.3888888888889,67.08333333333333,67.11111111111111,67.09722222222221,66.875,66.91666666666667,67.63888888888889,67.70833333333333,67.80555555555556,67.90277777777779,68.01388888888889,68.0138888888889,68.125,68.19444444444444,68.65277777777777,68.65277777777777,68.74999999999999,68.93055555555554,68.97222222222223,68.95833333333334,68.95833333333334,68.72222222222223,68.76388888888889,68.66666666666667,67.90277777777779,67.70833333333334,67.56944444444446,67.6388888888889,67.61111111111111,67.59722222222223,67.62500000000001,67.97222222222224,68.02777777777779,68.0416666666667,68.31944444444446,68.30555555555556,68.40277777777779,68.44444444444446,68.44444444444446,68.41666666666667,68.36111111111111,68.34722222222221,68.33333333333333,68.30555555555554,68.31944444444443,68.29166666666667,68.18055555555556,68.26388888888889,68.34722222222221,68.30555555555556,68.38888888888887,68.58333333333333,68.61111111111111,68.80555555555556,69.45833333333333,69.66666666666667,69.76388888888889,69.69444444444444,69.72222222222223,69.84722222222223,69.84722222222221,69.69444444444443,69.47222222222223,69.55555555555557,69.47222222222224,69.47222222222224,69.31944444444444,69.23611111111111,69.1527777777778,69.23611111111111,69.34722222222221,69.31944444444446,69.27777777777777,69.29166666666667,69.27777777777779,69.27777777777779,69.43055555555556,69.43055555555556,69.34722222222223,69.37500000000001,69.38888888888891,69.33333333333334,69.34722222222223,69.29166666666667,69.45833333333333,69.33333333333334,69.26388888888889,69.20833333333333,69.12499999999999,69.15277777777776,69.18055555555554,69.37499999999997,68.80555555555554,68.72222222222223,68.62500000000001,68.05555555555554,68.12499999999999,68.26388888888889,68.3611111111111,68.33333333333333,68.30555555555556,68.375,68.5,68.51388888888889,68.54166666666666,68.56944444444444,68.56944444444446,68.55555555555557,68.66666666666667,68.66666666666669,68.68055555555557,68.75000000000001,68.70833333333333,68.73611111111111,68.65277777777779,68.86111111111111,68.90277777777779,69.0138888888889,69.08333333333336,69.01388888888891,69.05555555555557,68.97222222222223,69.63888888888889,69.65277777777779,69.72222222222223,70.26388888888889,70.22222222222223,70.08333333333334,70.06944444444444,70.04166666666667,69.9861111111111,69.9861111111111,69.94444444444444,70.0,69.90277777777777,69.91666666666666,69.80555555555554,69.84722222222221,69.69444444444446,69.59722222222223,69.56944444444444,69.4861111111111,69.50000000000001,69.45833333333334,69.47222222222224,69.45833333333334,69.47222222222223,69.52777777777777,69.52777777777777,69.51388888888889,69.43055555555556,69.43055555555556,69.5138888888889,69.52777777777779,69.54166666666667,69.56944444444444,69.59722222222221,69.47222222222221,69.48611111111111,69.47222222222221,69.52777777777776,69.5,68.73611111111111,68.75,68.88888888888889,68.15277777777779,68.16666666666667,68.06944444444444,68.16666666666667,68.18055555555554,68.15277777777777,68.18055555555554,68.19444444444444,68.27777777777777,68.22222222222223,68.18055555555554,68.18055555555554,68.16666666666666,68.15277777777776,68.13888888888887,68.18055555555556,68.1111111111111,68.01388888888889,67.9722222222222,67.93055555555556,67.97222222222221,68.02777777777777,68.125,68.1388888888889,68.09722222222223,68.06944444444444,68.18055555555554,68.91666666666666,68.91666666666666,68.88888888888889,69.73611111111111,69.76388888888889,69.81944444444446,69.79166666666667,69.76388888888889,69.75000000000001,69.90277777777779,69.77777777777779,69.66666666666666,69.66666666666666,69.59722222222221,69.6111111111111,69.59722222222221,69.51388888888887,69.54166666666667,69.52777777777779,69.59722222222221,69.62499999999999,69.66666666666666,69.55555555555556,69.52777777777777,69.4861111111111,69.58333333333333,69.52777777777779,69.48611111111111,69.45833333333331,69.31944444444443,69.31944444444443,69.24999999999999,69.22222222222221,69.09722222222221,69.04166666666667,68.52777777777777,68.55555555555556,68.69444444444444,68.77777777777779,68.625,68.77777777777777,68.09722222222221,68.02777777777779,68.05555555555556,68.02777777777777,67.84722222222221,67.91666666666667,67.95833333333333,67.93055555555554,67.90277777777779,67.93055555555556,68.01388888888887,68.125,68.13888888888889,68.13888888888889,68.04166666666667,68.04166666666667,68.0138888888889,67.81944444444444,67.90277777777779,67.93055555555557,67.91666666666667,67.91666666666667,67.91666666666667,68.125,68.63888888888889,68.59722222222223,68.49999999999999,68.47222222222223,68.52777777777777,68.47222222222221,69.125,69.2638888888889,69.31944444444444,69.375,69.41666666666667,69.375,69.48611111111111,69.45833333333334,69.54166666666669,69.61111111111113,69.52777777777779,69.5138888888889,69.58333333333334,69.65277777777779,69.80555555555554,69.81944444444444,69.93055555555556,70.04166666666664,69.94444444444444,69.87500000000001,69.8611111111111,69.91666666666666,69.19444444444444,69.06944444444444,68.95833333333333,68.91666666666666,69.01388888888889,69.08333333333333,69.09722222222223,69.05555555555557,69.05555555555556,69.04166666666667,69.08333333333334,69.05555555555554,69.18055555555554,69.34722222222221,69.2361111111111,68.72222222222221,68.59722222222221,68.47222222222223,68.47222222222221,68.52777777777779,68.41666666666667,67.75000000000001,66.93055555555556,66.97222222222224,67.02777777777779,67.20833333333334,67.25,67.29166666666666,67.33333333333333,67.25,68.02777777777777,68.05555555555554,68.20833333333333,68.31944444444444,68.25,68.27777777777777,68.20833333333333,68.22222222222221,68.33333333333334,68.29166666666667,68.33333333333334,68.37500000000001,68.33333333333333,68.20833333333333,68.26388888888889,68.81944444444444,68.83333333333333,69.01388888888889,68.98611111111111,68.91666666666666,68.8611111111111,69.34722222222221,70.04166666666667,69.93055555555556,69.7638888888889,69.73611111111111,69.77777777777777,69.79166666666666,69.77777777777777,69.76388888888887,69.68055555555554,69.66666666666667,69.62500000000001,69.54166666666667,69.55555555555556,69.375,69.41666666666667,69.37499999999999,69.27777777777776,69.26388888888889,69.2361111111111,69.18055555555553,69.2222222222222,69.20833333333331,69.1111111111111,69.0972222222222,69.15277777777776,68.9722222222222,68.9861111111111,68.98611111111109,68.68055555555553,68.8472222222222,68.77777777777777,68.83333333333334,68.90277777777779,68.90277777777779,68.90277777777777,68.8611111111111,68.79166666666666,68.75,68.77777777777777,68.02777777777779,67.97222222222223,67.95833333333333,67.8611111111111,67.94444444444444,67.93055555555556,68.1111111111111,68.06944444444446,68.08333333333333,67.95833333333333,68.0,68.01388888888889,67.97222222222221,67.99999999999999,68.0,68.01388888888889,68.11111111111111,68.05555555555556,68.19444444444444,68.6111111111111,68.56944444444444,68.66666666666666,68.69444444444443,68.68055555555554,68.62499999999999,68.70833333333333,68.79166666666666,68.95833333333331,69.11111111111109,69.04166666666664,69.7222222222222,69.8333333333333,69.87499999999999,69.9722222222222,69.94444444444443,69.94444444444444,69.88888888888889,69.9722222222222,69.74999999999999,69.76388888888886,69.77777777777777,69.70833333333333,69.77777777777777,69.65277777777777,69.69444444444444,69.72222222222223,69.70833333333333,69.77777777777777,69.63888888888889,69.61111111111111,69.5138888888889,69.48611111111113,69.5,69.5,69.56944444444446,69.50000000000001,69.37500000000001,69.23611111111113,69.16666666666667,69.16666666666667,69.13888888888889,69.09722222222223,69.13888888888889,69.16666666666667,69.19444444444446,69.34722222222223,69.31944444444444,69.22222222222221,69.45833333333333,69.5,69.38888888888889,69.37500000000001,69.38888888888891,69.44444444444446,69.31944444444446,69.23611111111111,69.18055555555554,69.16666666666666,69.16666666666667,69.31944444444444,69.38888888888887,69.44444444444444,69.3888888888889,69.41666666666666,69.25,69.25,69.34722222222224,69.34722222222223,69.31944444444446,69.37500000000001,69.5,69.40277777777777,69.43055555555554,69.41666666666666,69.41666666666666,69.34722222222221,69.2361111111111,69.29166666666666,69.19444444444443,69.125,69.16666666666666,69.19444444444443,68.88888888888887,68.23611111111111,68.31944444444444,68.30555555555554,68.3611111111111,68.24999999999999,68.26388888888889,68.04166666666666,68.01388888888889,67.97222222222221,67.95833333333331,67.95833333333331,68.12499999999999,68.05555555555554,67.95833333333333,68.0,68.06944444444444,68.13888888888889,68.01388888888889,67.97222222222223,67.90277777777779,67.80555555555556,67.75000000000001,67.68055555555556,67.80555555555556,67.8611111111111,67.90277777777777,67.7361111111111,67.74999999999999,67.79166666666666,68.09722222222221,68.76388888888889,68.69444444444444,68.77777777777777,68.7361111111111,68.93055555555556,68.90277777777777,68.9861111111111,69.02777777777776,69.01388888888887,69.05555555555556,69.04166666666667,68.97222222222221,68.97222222222221,69.08333333333331,69.04166666666666,69.02777777777777,68.94444444444444,69.0,69.1111111111111,69.16666666666666,69.13888888888887,69.24999999999999,69.24999999999999,69.02777777777777,69.01388888888889,69.05555555555556,69.31944444444446,69.34722222222224,69.29166666666669,69.25000000000001,69.2638888888889,69.40277777777777,69.45833333333333,69.44444444444444,69.33333333333331,69.31944444444444,68.62500000000001,67.8888888888889,67.93055555555557,68.0,67.75000000000001,67.84722222222223,67.88888888888889,67.84722222222221,67.81944444444444,67.69444444444446,67.79166666666667,67.77777777777779,67.79166666666666,67.59722222222221,67.7222222222222,67.68055555555556,67.69444444444444,67.90277777777777,67.91666666666666,68.0138888888889,68.04166666666667,68.01388888888889,67.97222222222223,67.97222222222223,68.02777777777777,67.875,67.83333333333334,67.72222222222224,67.73611111111113,67.70833333333334,68.375,69.1388888888889,68.40277777777779,68.30555555555556,68.51388888888889,68.48611111111111,68.5,68.45833333333334,68.52777777777779,68.70833333333334,68.69444444444444,68.79166666666667,68.68055555555557,68.80555555555557,68.6388888888889,68.59722222222223,68.54166666666667,68.55555555555556,68.52777777777779,68.41666666666667,68.45833333333333,68.45833333333333,68.55555555555556,68.44444444444443,68.45833333333333,68.4861111111111,68.44444444444443,68.6111111111111,68.56944444444443,68.66666666666666,68.55555555555556,68.4861111111111,69.02777777777777,69.09722222222221,69.20833333333333,68.44444444444444,68.43055555555554,68.45833333333333,67.75,67.66666666666666,67.22222222222221,67.18055555555554,67.16666666666667,67.20833333333333,67.41666666666666,67.34722222222221,67.40277777777776,67.38888888888889,67.40277777777777,67.41666666666666,67.36111111111111,67.40277777777779,67.2638888888889,67.19444444444446,67.22222222222223,67.20833333333334,67.23611111111113,67.25000000000001,67.41666666666669,67.33333333333334,67.43055555555556,67.50000000000001,67.69444444444444,67.72222222222221,67.73611111111111,68.41666666666666,68.31944444444444,68.29166666666667,69.00000000000001,68.91666666666667,69.30555555555556,69.22222222222221,69.375,69.3888888888889,69.34722222222223,69.34722222222221,69.33333333333333,69.24999999999999,69.26388888888889,69.30555555555556,69.30555555555556,69.29166666666669,69.45833333333333,69.56944444444444,69.40277777777777,69.38888888888889,69.47222222222223,69.41666666666667,69.34722222222223,69.47222222222223,69.375,69.29166666666666,69.22222222222221,69.22222222222221,69.06944444444444,69.05555555555556,69.19444444444444,69.33333333333334,69.3611111111111,69.43055555555554,69.51388888888889,69.47222222222221,69.34722222222223,69.34722222222223,69.34722222222221,69.45833333333333,69.47222222222223,69.59722222222221,69.58333333333334,69.58333333333336,69.61111111111113,69.65277777777779,69.65277777777779,69.80555555555556,69.8888888888889,69.98611111111111,69.83333333333333,69.91666666666666,69.16666666666667,69.11111111111111,69.27777777777777,69.33333333333331,69.45833333333331,69.45833333333331,69.45833333333333,69.4861111111111,69.41666666666667,69.29166666666667,69.27777777777777,69.22222222222221,69.15277777777777,69.29166666666666,69.3611111111111,69.44444444444443,69.43055555555556,69.375,69.27777777777779,69.27777777777777,69.27777777777777,69.20833333333331,69.12499999999999,69.06944444444444,69.09722222222223,69.04166666666667,69.15277777777777,69.1111111111111,69.16666666666667,69.1388888888889,69.88888888888891,69.88888888888891,69.83333333333334,69.88888888888889,69.81944444444444,69.87500000000001,69.94444444444446,70.05555555555556,69.36111111111111,69.41666666666667,69.48611111111111,69.51388888888887,69.4861111111111,69.38888888888889,69.33333333333333,69.33333333333333,69.31944444444444,69.375,69.44444444444444,69.27777777777779,69.1388888888889,69.13888888888889,69.18055555555556,69.16666666666667,69.11111111111111,69.16666666666667,69.0972222222222,69.05555555555556,69.0138888888889,69.09722222222223,68.34722222222224,68.34722222222223,68.33333333333333,68.15277777777777,68.08333333333333,68.0,67.98611111111111,67.88888888888889,68.68055555555556,68.625,68.63888888888889,68.66666666666667,68.69444444444444,68.77777777777777,68.84722222222223,68.6388888888889,68.58333333333334,68.47222222222223,68.40277777777779,67.8888888888889,68.08333333333336,68.125,68.09722222222224,68.06944444444447,67.9861111111111,67.97222222222221,67.76388888888889,67.80555555555556,67.80555555555556,67.43055555555556,68.09722222222221,68.125,68.09722222222221,68.19444444444444,68.12499999999999,67.9861111111111,67.9861111111111,67.97222222222223,67.70833333333333,67.65277777777777,67.56944444444444,67.68055555555556,67.70833333333333,67.63888888888887,67.625,67.68055555555556,67.5,67.65277777777777,67.66666666666666,68.29166666666667,68.26388888888889,68.30555555555556,68.38888888888889,68.38888888888889,68.45833333333334,68.41666666666667,68.66666666666666,68.79166666666667,68.80555555555557,68.98611111111111,69.0138888888889,68.98611111111111,68.97222222222223,68.90277777777777,69.06944444444446,68.625,68.65277777777779,68.68055555555556,68.80555555555556,68.90277777777779,68.86111111111111,68.70833333333333,68.68055555555554,68.72222222222221,68.7361111111111,68.83333333333331,69.0972222222222,69.01388888888889,69.1111111111111,69.09722222222223,69.05555555555556,68.94444444444444,68.875,68.93055555555556,68.80555555555556,68.8888888888889,68.86111111111111,68.79166666666667,68.79166666666667,68.88888888888889,68.90277777777777,68.90277777777779,68.98611111111111,69.05555555555556,68.95833333333333,69.54166666666667,69.50000000000001,69.51388888888889,69.58333333333333,69.58333333333334,69.61111111111113,69.625,69.61111111111111,69.5,69.52777777777779,69.54166666666667,69.56944444444444,69.59722222222224,68.84722222222224,68.77777777777779,68.69444444444446,68.86111111111113,68.83333333333334,68.7638888888889,68.84722222222223,68.68055555555556,68.65277777777779,68.62500000000001,68.68055555555557,68.56944444444446,68.66666666666666,68.61111111111111,68.63888888888889,68.62500000000001,68.76388888888889,68.72222222222221,68.72222222222221,68.7361111111111,68.68055555555556,68.65277777777777,68.63888888888889,68.69444444444443,68.62499999999999,68.79166666666664,68.74999999999999,68.70833333333333,68.47222222222221,68.41666666666666,69.18055555555556,69.31944444444443,69.38888888888887,69.22222222222221,69.26388888888889,69.29166666666667,69.2777777777778,69.29166666666667,69.2638888888889,69.19444444444446,69.15277777777777,69.16666666666667,68.98611111111111,69.02777777777779,68.91666666666666,68.90277777777776,68.77777777777774,68.76388888888887,68.875,68.90277777777777,68.98611111111111,69.02777777777777,69.01388888888887,68.93055555555554,69.01388888888887,68.90277777777776,68.9861111111111,68.6111111111111,68.80555555555556,68.76388888888889,68.70833333333334,68.70833333333333,68.79166666666667,68.84722222222223,68.73611111111113,68.75000000000001,68.77777777777779,68.81944444444446,68.87500000000001,68.94444444444446,68.22222222222224,68.3888888888889,68.51388888888889,68.56944444444446,68.65277777777779,68.6388888888889,68.74999999999999,68.68055555555556,68.66666666666666,68.62499999999999,68.58333333333333,68.52777777777779,68.59722222222223,68.625,68.56944444444444,68.59722222222223,68.54166666666669,68.9027777777778,69.02777777777779,69.05555555555556,69.02777777777777,68.91666666666667,68.84722222222223,68.86111111111111,68.87499999999999,68.81944444444443,68.76388888888889,68.76388888888887,68.70833333333333,68.65277777777777,69.3611111111111,69.3611111111111,69.26388888888886,69.16666666666664,69.1111111111111,69.16666666666666,69.13888888888889,69.2638888888889,69.0,68.93055555555556,68.94444444444444,68.94444444444444,68.81944444444444,68.8888888888889,68.95833333333334,69.11111111111111,68.90277777777777,68.81944444444443,68.68055555555554,68.63888888888889,68.55555555555554,68.4861111111111,68.4722222222222,68.44444444444443,68.55555555555556,68.30555555555553,68.37499999999997,68.3611111111111,68.26388888888889,68.27777777777777,68.29166666666666,68.09722222222221,68.13888888888889,68.125,68.08333333333333,68.04166666666664,66.90277777777776,66.97222222222223,67.11111111111111,67.24999999999999,67.24999999999999,66.95833333333333,67.08333333333333,67.1111111111111,67.0972222222222,66.91666666666664,67.08333333333333,67.15277777777776,67.12499999999999,67.20833333333331,67.29166666666666,67.41666666666667,67.41666666666666,67.44444444444443,67.43055555555557,67.5,67.43055555555556,67.47222222222221,67.63888888888889,67.66666666666667,67.79166666666667,67.91666666666667,67.91666666666667,67.98611111111111,68.02777777777779,68.16666666666667,69.36111111111111,69.26388888888889,69.33333333333334,69.25,69.26388888888889,69.61111111111111,69.56944444444444,69.5,69.56944444444444,69.59722222222223,69.6388888888889,69.6388888888889,69.625,69.625,69.75,69.66666666666667,69.70833333333333,69.65277777777777,69.59722222222223,69.77777777777777,69.8472222222222,69.79166666666664,69.69444444444441,69.68055555555554,69.61111111111111,69.68055555555554,69.76388888888886,69.79166666666664,69.76388888888887,69.77777777777776,69.80555555555554,69.69444444444444,68.98611111111111,69.04166666666667,68.97222222222223,68.98611111111111,69.06944444444444,68.98611111111111,68.95833333333334,69.0,68.97222222222221,68.23611111111111,68.33333333333334,68.40277777777777,68.31944444444444,68.33333333333331,68.26388888888887,68.34722222222223,68.41666666666667,68.47222222222221,68.36111111111111,68.31944444444446,68.40277777777779,68.375,68.26388888888889,68.22222222222223,68.12499999999997,68.06944444444443,68.15277777777777,68.04166666666666,67.86111111111111,68.01388888888889,68.77777777777777,68.76388888888889,68.36111111111111,68.33333333333334,68.29166666666669,68.37500000000001,68.31944444444446,68.29166666666669,68.30555555555556,68.95833333333334,68.95833333333334,68.83333333333334,68.79166666666667,68.79166666666667,68.84722222222223,68.83333333333333,68.90277777777777,68.72222222222223,68.72222222222224,68.75000000000001,68.77777777777779,68.81944444444446,68.83333333333333,68.87499999999999,68.19444444444444,68.22222222222223,68.13888888888889,68.04166666666667,68.09722222222223,68.04166666666667,68.01388888888889,67.94444444444444,68.41666666666667,68.45833333333334,68.26388888888889,68.27777777777777,68.29166666666667,68.22222222222223,68.13888888888889,68.26388888888889,68.22222222222223,68.26388888888889,68.31944444444444,67.81944444444443,67.875,67.93055555555556,67.83333333333333,67.94444444444444,67.95833333333334,67.91666666666667,67.77777777777779,67.90277777777779,67.90277777777777,67.86111111111111,68.58333333333333,68.61111111111111,67.93055555555557,67.98611111111111,67.95833333333333,67.97222222222221,67.94444444444446,68.06944444444444,68.04166666666667,67.95833333333334,68.16666666666667,68.06944444444446,68.06944444444444,68.125,68.11111111111111,67.98611111111111,67.98611111111111,67.5,66.80555555555556,67.47222222222221,67.41666666666666,67.30555555555554,67.19444444444444,66.33333333333331,66.41666666666666,66.38888888888889,66.44444444444443,66.34722222222221,66.3472222222222,66.27777777777777,66.26388888888887,66.29166666666666,66.93055555555556,66.81944444444444,66.84722222222223,66.66666666666666,66.70833333333334,66.6111111111111,66.65277777777779,66.6388888888889,66.4861111111111,66.56944444444444,66.56944444444443,65.87500000000001,65.23611111111111,65.34722222222223,65.31944444444444,65.79166666666667,66.47222222222221,66.36111111111111,66.34722222222223,66.36111111111111,66.47222222222221,67.45833333333333,67.41666666666666,67.40277777777777,67.38888888888887,67.38888888888887,67.45833333333334,67.5138888888889,67.58333333333333,67.30555555555556,67.41666666666667,67.56944444444444,67.62500000000001,67.79166666666667,67.81944444444444,67.63888888888889,67.65277777777779,67.625,67.7638888888889,67.7638888888889,67.80555555555556,68.5138888888889,69.30555555555556,69.15277777777777,69.13888888888889,69.2361111111111,69.3611111111111,69.2638888888889,69.33333333333334,69.33333333333333,69.34722222222223,69.23611111111111,69.15277777777777,69.24999999999999,69.1111111111111,69.05555555555553,68.30555555555556,68.2361111111111,68.15277777777777,68.22222222222221,68.06944444444444,67.97222222222223,67.90277777777777,67.90277777777777,67.75,67.80555555555556,67.66666666666667,67.66666666666666,67.69444444444444,67.54166666666666,67.45833333333333,67.20833333333333,67.12499999999999,67.13888888888889,67.06944444444443,66.80555555555554,66.61111111111111,66.625,66.625,66.625,66.48611111111111,66.55555555555556,66.68055555555556,66.62500000000001,66.77777777777779,66.7638888888889,67.5138888888889,67.43055555555556,67.48611111111111,67.63888888888889,67.74999999999999,67.91666666666666,67.91666666666667,67.91666666666667,67.8611111111111,67.93055555555554,67.98611111111109,68.06944444444443,67.98611111111111,68.18055555555556,68.13888888888889,68.29166666666664,68.19444444444443,68.3611111111111,68.40277777777777,68.63888888888889,68.72222222222221,68.77777777777777,68.69444444444444,68.75,68.61111111111111,68.59722222222223,68.61111111111111,68.59722222222223,68.61111111111111,67.94444444444446,67.83333333333334,67.94444444444446,67.86111111111113,67.875,67.86111111111111,67.75,67.7361111111111,67.66666666666666,67.81944444444444,67.875,67.84722222222221,67.81944444444443,67.76388888888889,67.70833333333333,67.7361111111111,67.94444444444444,68.06944444444444,67.91666666666667,67.95833333333334,67.98611111111111,67.93055555555556,67.91666666666667,67.90277777777777,67.90277777777779,68.1111111111111,68.09722222222221,68.0972222222222,68.2222222222222,68.12499999999999,68.76388888888887,68.93055555555556,68.94444444444443,68.95833333333331,69.02777777777777,69.09722222222221,69.09722222222221,69.20833333333333,69.25,69.29166666666667,69.29166666666667,69.3888888888889,69.41666666666667,69.48611111111113,69.47222222222221,69.51388888888887,69.30555555555554,69.27777777777779,69.33333333333334,69.29166666666667,68.83333333333334,68.875,68.97222222222221,69.0138888888889,68.90277777777779,68.84722222222223,68.86111111111111,68.84722222222223,68.86111111111111,68.87500000000001,68.93055555555556,68.97222222222221,68.97222222222221,68.99999999999999,68.93055555555554,68.81944444444443,68.20833333333333,68.125,68.15277777777776,67.99999999999999,67.9861111111111,67.81944444444444,67.8611111111111,67.88888888888889,67.94444444444443,67.93055555555556,68.08333333333334,67.95833333333334,68.02777777777779,68.12500000000001,68.25000000000001,68.29166666666669,68.22222222222224,68.22222222222224,68.3888888888889,68.48611111111113,68.50000000000001,68.47222222222224,68.44444444444446,68.55555555555557,68.61111111111113,68.44444444444444,68.41666666666667,68.45833333333336,68.41666666666667,68.56944444444443,69.20833333333333,69.23611111111111,69.29166666666666,69.36111111111111,69.44444444444444,69.52777777777777,69.41666666666667,69.18055555555556,69.11111111111111,69.08333333333333,69.11111111111111,69.19444444444444,69.06944444444444,69.06944444444446,69.30555555555556,69.22222222222221,69.16666666666664,69.19444444444441,69.01388888888887,69.0,68.9861111111111,69.04166666666664,69.0,68.83333333333333,68.79166666666666,68.83333333333333,68.88888888888889,68.8888888888889,69.0,68.83333333333333,68.88888888888889,68.90277777777777,68.80555555555554,68.8611111111111,68.80555555555554,68.8611111111111,68.93055555555554,69.22222222222223,68.69444444444444,68.75,68.68055555555554,68.80555555555554,68.90277777777777,68.79166666666667,68.77777777777777,68.77777777777776,68.90277777777776,68.91666666666667,69.04166666666667,69.04166666666667,68.99999999999999,68.9861111111111,69.06944444444444,69.23611111111111,69.25,69.16666666666667,69.08333333333334,69.04166666666667,68.95833333333334,69.0,69.02777777777777,69.04166666666667,69.12500000000001,69.0,68.97222222222223,68.8611111111111,68.69444444444443,67.90277777777779,68.45833333333336,68.36111111111113,68.31944444444444,68.31944444444444,68.22222222222223,68.29166666666666,68.34722222222221,68.43055555555556,68.375,68.30555555555556,68.31944444444444,68.40277777777777,68.48611111111113,68.45833333333333,68.34722222222223,68.30555555555559,68.34722222222224,68.45833333333336,68.43055555555559,67.72222222222224,67.75000000000001,67.90277777777779,67.77777777777779,67.7638888888889,67.72222222222224,67.90277777777777,67.86111111111111,68.00000000000001,68.15277777777777,68.93055555555554,68.98611111111111,69.0,69.02777777777777,68.91666666666666,68.95833333333331,68.9722222222222,68.90277777777777,68.8888888888889,68.83333333333333,68.90277777777777,68.75,68.66666666666667,68.70833333333333,68.40277777777777,68.47222222222221,68.5,68.48611111111111,68.47222222222221,68.52777777777777,69.18055555555556,69.18055555555556,69.09722222222221,68.43055555555556,68.43055555555557,68.38888888888889,68.09722222222223,68.1111111111111,68.04166666666664,68.05555555555556,67.95833333333333,67.94444444444443,67.94444444444444,67.95833333333333,68.04166666666667,68.0,68.01388888888889,68.13888888888889,67.98611111111111,67.86111111111111,67.875,67.93055555555556,67.91666666666667,67.79166666666667,68.23611111111111,68.2361111111111,68.18055555555554,68.125,67.8888888888889,67.94444444444444,67.9861111111111,67.83333333333333,67.77777777777777,68.4861111111111,68.37499999999999,68.41666666666666,68.66666666666667,68.72222222222221,68.7361111111111,68.66666666666666,68.70833333333333,68.70833333333333,68.72222222222221,68.84722222222221,68.875,68.98611111111111,68.91666666666667,68.84722222222221,68.93055555555554,69.13888888888887,69.06944444444443,69.24999999999999,69.27777777777777,69.30555555555554,69.20833333333333,69.24999999999999,69.24999999999999,69.27777777777776,69.47222222222223,69.41666666666667,69.44444444444444,69.69444444444444,69.7361111111111,69.66666666666664,69.74999999999999,69.73611111111111,69.68055555555556,69.72222222222223,69.81944444444443,69.88888888888887,69.88888888888887,69.95833333333331,69.9722222222222,69.8472222222222,69.74999999999999,69.76388888888889,69.76388888888887,69.80555555555554,69.91666666666666,69.74999999999999,69.77777777777777,69.72222222222221,69.19444444444444,69.26388888888889,69.29166666666666,69.26388888888887,69.33333333333331,69.37499999999999,69.38888888888889,69.44444444444444,69.59722222222223,69.47222222222223,69.41666666666666,69.55555555555554,69.54166666666667,69.59722222222224,69.61111111111113,69.47222222222224,69.41666666666667,69.43055555555557,69.41666666666667,69.40277777777777,69.45833333333333,69.52777777777779,69.6527777777778,69.54166666666669,69.66666666666667,69.65277777777777,69.58333333333334,69.44444444444444,69.43055555555556,69.36111111111111,69.97222222222221,69.97222222222221,69.90277777777777,69.93055555555556,69.87499999999999,69.81944444444444,69.80555555555556,69.65277777777779,69.51388888888889,69.47222222222223,69.54166666666667,69.54166666666667,69.625,69.59722222222221,69.65277777777779,69.79166666666667,69.77777777777777,69.7361111111111],\"type\":\"scatter\"},{\"line\":{\"color\":\"#0AF\"},\"mode\":\"lines\",\"name\":\"NEW test dataset accuracy (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[60.84444444444443,61.511111111111106,61.599999999999994,61.599999999999994,62.17777777777777,62.42222222222222,63.03333333333333,62.977777777777774,63.666666666666664,64.35555555555555,64.3,63.81111111111111,63.78888888888888,63.844444444444434,64.03333333333333,63.98888888888888,63.97777777777778,64.04444444444445,64.41111111111113,64.34444444444445,64.34444444444445,64.3,64.42222222222222,64.44444444444444,64.53333333333333,64.7,64.62222222222222,64.5,64.66666666666667,65.11111111111111,65.75555555555556,65.7,65.72222222222223,65.70000000000002,65.75555555555556,65.66666666666667,65.66666666666667,65.78888888888889,65.65555555555557,65.61111111111111,65.75555555555556,65.75555555555556,65.75555555555556,65.82222222222224,65.85555555555557,65.82222222222222,65.82222222222222,65.9,65.97777777777777,65.37777777777778,65.43333333333334,65.58888888888889,65.56666666666666,65.52222222222221,65.53333333333333,65.53333333333333,65.62222222222222,65.7,65.71111111111111,65.74444444444444,65.71111111111111,65.28888888888889,65.27777777777777,64.82222222222222,64.86666666666667,64.95555555555556,65.05555555555556,65.1,65.16666666666666,65.2222222222222,65.16666666666666,65.74444444444444,65.74444444444443,65.73333333333333,65.77777777777777,65.76666666666665,65.69999999999999,65.59999999999998,65.58888888888887,66.19999999999999,66.14444444444445,66.08888888888889,66.15555555555557,66.17777777777778,66.14444444444445,66.28888888888889,66.3,66.30000000000001,66.27777777777779,66.24444444444444,66.35555555555557,66.80000000000001,66.7,66.93333333333334,66.92222222222222,66.77777777777777,66.6222222222222,66.52222222222221,66.55555555555554,66.6,66.63333333333333,66.71111111111111,66.64444444444443,66.61111111111111,66.54444444444444,66.66666666666666,66.83333333333333,66.91111111111111,66.91111111111111,66.91111111111111,66.88888888888889,66.74444444444445,66.7,66.74444444444444,66.7,66.55555555555554,66.56666666666665,66.57777777777777,66.56666666666666,66.58888888888889,66.42222222222222,66.4888888888889,66.56666666666666,66.84444444444445,66.88888888888889,67.14444444444443,67.04444444444445,67.17777777777779,67.2,67.13333333333334,67.12222222222222,67.18888888888888,67.27777777777777,67.27777777777777,67.27777777777777,67.16666666666666,67.1,67.14444444444443,66.49999999999999,66.58888888888889,66.54444444444444,66.73333333333333,66.76666666666667,66.69999999999999,66.74444444444444,66.83333333333333,66.81111111111112,66.93333333333334,66.94444444444444,66.95555555555555,67.11111111111111,67.12222222222222,67.12222222222222,67.05555555555554,67.02222222222221,66.84444444444443,67.09999999999998,67.08888888888887,67.05555555555554,67.05555555555554,67.03333333333333,66.96666666666665,66.95555555555555,66.99999999999999,67.06666666666665,67.12222222222222,67.14444444444445,67.16666666666667,67.83333333333333,67.84444444444443,67.92222222222222,67.94444444444444,67.96666666666665,68.05555555555554,68.16666666666666,68.19999999999999,68.24444444444443,68.13333333333333,68.11111111111109,68.02222222222221,68.02222222222221,67.96666666666664,67.9111111111111,67.93333333333332,67.94444444444444,67.56666666666665,67.4888888888889,67.42222222222222,67.39999999999999,67.39999999999999,67.35555555555555,67.41111111111111,67.39999999999999,67.28888888888889,67.25555555555556,67.26666666666665,67.23333333333332,67.18888888888888,67.19999999999999,67.0111111111111,66.94444444444443,66.88888888888887,66.85555555555554,66.89999999999999,66.82222222222221,66.74444444444444,66.61111111111111,66.70000000000002,66.74444444444444,66.85555555555555,66.14444444444445,66.16666666666667,66.17777777777778,66.27777777777777,66.24444444444444,66.74444444444444,66.82222222222221,66.91111111111111,66.96666666666665,66.96666666666667,66.9,66.83333333333333,66.83333333333331,66.96666666666665,66.8,66.74444444444445,66.71111111111112,66.6111111111111,66.6,66.74444444444444,66.76666666666668,66.78888888888889,66.8,66.66666666666664,66.65555555555555,66.67777777777778,66.74444444444444,66.77777777777777,66.76666666666665,66.67777777777778,67.34444444444443,67.32222222222221,67.25555555555556,67.06666666666666,67.0777777777778,67.11111111111113,67.0,66.94444444444444,66.26666666666667,66.33333333333333,66.31111111111112,66.30000000000001,66.21111111111111,66.24444444444444,66.22222222222223,65.83333333333333,65.82222222222222,65.91111111111111,65.92222222222223,65.84444444444445,65.26666666666667,65.24444444444444,65.1888888888889,65.26666666666668,65.3888888888889,65.41111111111111,65.43333333333334,65.34444444444443,65.27777777777777,65.38888888888889,65.42222222222222,65.4111111111111,65.52222222222221,65.6,65.66666666666666,65.57777777777777,65.6222222222222,64.94444444444444,65.54444444444444,65.46666666666665,65.62222222222222,65.7,65.78888888888888,65.64444444444445,65.78888888888889,66.27777777777777,66.38888888888889,66.30000000000001,66.27777777777777,66.24444444444445,66.91111111111111,66.85555555555557,66.84444444444446,66.81111111111112,66.6888888888889,66.65555555555555,66.65555555555557,66.61111111111111,66.71111111111111,66.64444444444445,66.66666666666667,66.6888888888889,66.66666666666667,66.67777777777778,66.67777777777778,66.72222222222221,66.7,67.34444444444445,67.37777777777778,67.22222222222221,67.2,67.12222222222223,67.07777777777778,67.16666666666666,67.16666666666667,67.15555555555557,67.03333333333333,66.97777777777777,66.99999999999999,67.0111111111111,66.94444444444444,66.96666666666667,66.98888888888888,66.97777777777779,67.02222222222223,67.00000000000001,66.9888888888889,67.0,66.9888888888889,67.0111111111111,66.28888888888889,66.21111111111111,66.24444444444445,66.26666666666667,66.16666666666667,66.16666666666667,66.02222222222223,66.12222222222222,66.22222222222221,66.33333333333333,66.34444444444445,66.37777777777777,66.36666666666667,65.87777777777778,65.94444444444444,65.91111111111111,65.93333333333334,66.13333333333334,66.11111111111111,66.1888888888889,66.2,66.25555555555556,66.23333333333335,66.31111111111112,66.3111111111111,66.33333333333333,66.27777777777777,66.34444444444445,66.26666666666667,65.55555555555556,66.24444444444444,66.41111111111111,66.34444444444445,66.34444444444443,66.25555555555556,66.21111111111111,66.41111111111113,66.36666666666667,66.17777777777779,66.17777777777778,66.11111111111111,65.85555555555555,65.8111111111111,66.33333333333334,66.34444444444445,66.3,66.33333333333331,66.05555555555554,66.08888888888887,66.08888888888887,66.17777777777776,66.22222222222221,66.3,66.28888888888888,66.23333333333333,66.23333333333332,66.24444444444444,66.15555555555557,66.14444444444446,66.80000000000001,66.66666666666667,66.61111111111111,66.7,66.73333333333333,66.84444444444445,66.9,66.83333333333336,66.7666666666667,67.00000000000001,67.03333333333335,67.15555555555557,67.36666666666667,67.3777777777778,67.30000000000001,67.24444444444445,67.22222222222223,67.21111111111112,67.2888888888889,67.26666666666668,67.20000000000002,67.14444444444445,67.07777777777777,66.97777777777777,66.93333333333332,66.96666666666667,66.91111111111111,66.93333333333334,67.02222222222223,67.03333333333333,67.05555555555556,67.07777777777778,67.02222222222223,66.95555555555556,66.98888888888891,66.93333333333332,66.84444444444443,66.88888888888889,66.84444444444443,66.64444444444446,66.71111111111112,66.56666666666666,66.66666666666667,66.6,66.55555555555554,66.47777777777777,66.55555555555556,66.5,66.64444444444445,65.97777777777777,66.04444444444445,66.03333333333333,66.01111111111112,66.05555555555556,66.02222222222223,65.9888888888889,66.06666666666668,66.1,66.03333333333333,65.43333333333334,65.42222222222223,65.44444444444444,65.43333333333334,65.45555555555555,65.37777777777777,65.42222222222222,65.5111111111111,65.6,65.62222222222222,65.80000000000001,65.77777777777779,65.75555555555556,65.75555555555556,65.85555555555557,65.95555555555556,65.96666666666668,65.95555555555556,66.03333333333333,66.03333333333335,66.75555555555556,66.87777777777778,66.97777777777777,67.06666666666666,66.96666666666667,66.96666666666665,66.91111111111111,66.7,66.72222222222221,66.68888888888888,67.3111111111111,67.35555555555555,67.47777777777777,67.5111111111111,67.45555555555553,67.4222222222222,67.44444444444444,67.33333333333333,67.23333333333332,67.24444444444443,67.1,67.12222222222222,67.28888888888888,67.26666666666667,66.74444444444444,66.67777777777779,66.53333333333333,66.51111111111112,66.5,66.42222222222222,66.34444444444443,66.2,65.91111111111111,65.75555555555555,65.87777777777778,65.96666666666665,66.0,66.06666666666666,65.98888888888887,66.1222222222222,66.2111111111111,66.17777777777776,66.1222222222222,66.16666666666666,66.32222222222221,66.37777777777777,66.38888888888887,66.47777777777776,66.54444444444442,66.53333333333332,66.57777777777775,66.49999999999999,66.45555555555553,66.42222222222222,67.0111111111111,67.06666666666665,67.15555555555554,67.14444444444445,67.15555555555555,66.78888888888889,66.84444444444445,66.85555555555557,67.06666666666668,67.12222222222223,67.0888888888889,67.03333333333333,67.06666666666668,67.26666666666668,67.21111111111112,67.12222222222223,67.10000000000001,67.07777777777778,67.06666666666668,67.00000000000001,66.77777777777779,66.74444444444447,66.67777777777779,66.63333333333334,66.4888888888889,66.5,66.45555555555556,66.53333333333335,66.45555555555556,66.42222222222223,66.34444444444445,66.34444444444443,66.47777777777777,66.55555555555556,66.18888888888888,66.49999999999999,66.24444444444444,66.23333333333332,66.23333333333332,66.04444444444442,66.07777777777777,66.1,66.1111111111111,66.03333333333333,66.16666666666666,66.23333333333333,65.8888888888889,65.93333333333332,65.93333333333334,65.88888888888889,65.95555555555556,65.97777777777779,66.04444444444445,66.07777777777778,66.12222222222223,66.23333333333335,66.26666666666668,66.24444444444445,66.41111111111111,66.47777777777779,66.35555555555557,65.66666666666669,65.00000000000003,64.8777777777778,64.55555555555557,64.62222222222223,64.83333333333334,64.84444444444446,64.84444444444445,65.10000000000001,65.02222222222223,65.04444444444445,65.03333333333335,65.00000000000001,64.94444444444446,64.94444444444444,65.24444444444445,64.7,64.67777777777779,64.51111111111112,64.66666666666667,64.38888888888889,64.14444444444445,63.488888888888894,63.51111111111111,63.41111111111111,63.388888888888886,63.35555555555555,63.23333333333333,63.222222222222214,63.322222222222216,63.955555555555534,64.58888888888889,64.67777777777776,65.34444444444443,65.35555555555555,65.38888888888887,65.41111111111111,65.39999999999999,65.36666666666666,65.43333333333334,65.4,65.37777777777778,65.39999999999999,65.44444444444444,65.37777777777778,65.36666666666666,65.84444444444443,65.86666666666666,66.12222222222222,66.06666666666665,66.35555555555555,66.65555555555555,67.28888888888888,67.32222222222222,67.33333333333333,67.33333333333333,67.36666666666666,67.42222222222222,67.47777777777777,67.55555555555556,67.52222222222221,67.47777777777777,67.41111111111113,67.42222222222222,67.46666666666665,67.39999999999999,67.42222222222222,67.41111111111111,67.45555555555555,67.47777777777777,67.46666666666665,67.52222222222221,67.54444444444445,67.57777777777777,67.63333333333333,67.65555555555555,67.57777777777777,67.62222222222222,67.54444444444445,67.43333333333334,67.42222222222223,67.37777777777778,67.44444444444446,67.51111111111112,67.54444444444445,67.55555555555557,67.50000000000001,67.50000000000001,67.46666666666668,67.34444444444446,67.27777777777777,67.34444444444445,67.37777777777778,67.37777777777778,67.41111111111111,67.51111111111112,67.5,67.52222222222221,67.5222222222222,67.54444444444444,67.55555555555556,67.57777777777777,67.46666666666665,67.44444444444443,67.46666666666665,67.48888888888888,67.46666666666667,67.36666666666666,67.5111111111111,67.50000000000001,67.5,67.45555555555555,66.75555555555555,66.72222222222223,66.6888888888889,66.26666666666667,66.24444444444445,66.24444444444444,66.22222222222221,66.3111111111111,66.38888888888889,66.37777777777778,66.33333333333333,66.2888888888889,66.23333333333333,66.2,66.12222222222222,66.14444444444443,66.12222222222222,66.08888888888889,66.04444444444444,65.94444444444443,66.04444444444444,66.0111111111111,65.95555555555555,65.96666666666665,66.04444444444444,66.05555555555556,65.94444444444446,66.14444444444445,66.14444444444446,66.20000000000002,66.82222222222224,66.74444444444445,66.75555555555556,66.72222222222223,66.81111111111113,66.85555555555557,66.78888888888889,66.75555555555556,66.8,66.87777777777778,66.94444444444444,66.3111111111111,65.37777777777778,65.4,65.46666666666667,65.5,65.5,65.41111111111111,65.34444444444443,65.39999999999999,65.4,65.47777777777777,65.55555555555556,65.45555555555556,65.45555555555555,65.52222222222223,65.51111111111112,65.4,65.39999999999999,65.38888888888889,65.27777777777779,65.31111111111112,65.27777777777779,65.75555555555556,65.7,65.64444444444445,65.73333333333333,65.77777777777779,65.84444444444445,65.72222222222223,65.72222222222223,66.41111111111111,67.25555555555556,67.15555555555557,67.04444444444445,66.8888888888889,66.92222222222223,67.02222222222221,67.11111111111111,67.0888888888889,67.12222222222223,67.0111111111111,66.93333333333335,66.34444444444445,66.43333333333334,66.34444444444445,66.3777777777778,66.4,66.38888888888889,66.4888888888889,66.56666666666666,66.6,66.57777777777777,66.58888888888889,66.6888888888889,66.66666666666667,66.58888888888889,66.56666666666668,66.47777777777779,66.55555555555556,66.52222222222223,66.45555555555555,66.60000000000001,66.65555555555555,66.7111111111111,66.75555555555553,66.64444444444443,66.6111111111111,66.54444444444444,66.6,66.52222222222223,66.6,66.60000000000001,67.28888888888889,67.2,67.26666666666667,67.27777777777779,67.24444444444445,67.21111111111112,67.0888888888889,67.0888888888889,67.10000000000001,67.15555555555557,67.18888888888891,67.06666666666669,67.12222222222225,67.15555555555558,67.18888888888891,67.16666666666669,66.4888888888889,66.43333333333334,66.44444444444446,66.44444444444446,66.46666666666667,66.55555555555556,66.63333333333333,66.7,66.77777777777777,66.81111111111112,66.8111111111111,66.86666666666667,66.75555555555556,66.81111111111112,66.74444444444444,66.83333333333334,66.92222222222222,66.97777777777779,66.97777777777777,67.10000000000001,67.11111111111111,67.25555555555556,67.27777777777779,67.36666666666667,67.31111111111112,67.31111111111113,67.26666666666668,67.28888888888889,67.2888888888889,67.36666666666667,68.02222222222223,68.11111111111111,68.1,67.9888888888889,67.92222222222223,67.95555555555558,67.93333333333334,67.92222222222222,67.81111111111112,67.88888888888889,67.86666666666666,67.86666666666667,67.94444444444446,67.92222222222222,67.91111111111111,67.85555555555554,67.77777777777777,67.74444444444444,67.76666666666665,67.7,67.64444444444443,67.57777777777777,67.43333333333332,67.43333333333331,67.43333333333331,67.43333333333332,67.43333333333332,67.41111111111111,67.47777777777777,67.45555555555555,67.47777777777777,67.47777777777776,66.85555555555554,66.84444444444443,66.8111111111111,66.8,66.71111111111111,66.73333333333332,66.74444444444444,66.66666666666666,66.63333333333333,66.63333333333334,66.6111111111111,66.6,66.65555555555555,66.77777777777776,66.72222222222221,66.72222222222221,66.63333333333333,66.57777777777777,66.56666666666666,66.52222222222221,66.57777777777778,66.27777777777777,66.25555555555555,66.25555555555556,66.16666666666666,66.08888888888889,66.03333333333333,66.07777777777777,66.04444444444444,65.99999999999999,66.6222222222222,66.66666666666666,66.78888888888886,66.43333333333331,66.48888888888888,66.49999999999999,66.51111111111109,66.55555555555554,66.53333333333332,66.45555555555553,66.52222222222221,66.52222222222223,66.5111111111111,66.37777777777777,66.34444444444445,66.27777777777779,66.45555555555555,66.6111111111111,66.58888888888889,66.64444444444445,66.6,66.76666666666667,66.75555555555555,66.69999999999999,66.74444444444444,66.86666666666666,66.89999999999999,66.8111111111111,66.35555555555554,66.34444444444445,66.44444444444446,66.43333333333334,66.53333333333333,66.86666666666666,66.84444444444442,66.77777777777777,66.67777777777778,66.74444444444445,66.75555555555555,66.8,66.7,66.63333333333333,66.08888888888889,66.18888888888888,66.28888888888889,66.30000000000001,66.07777777777778,65.94444444444446,66.04444444444445,65.92222222222222,66.03333333333333,66.05555555555557,65.44444444444446,65.56666666666668,65.56666666666668,65.54444444444445,65.46666666666667,65.4,65.96666666666668,66.01111111111112,65.93333333333334,65.94444444444444,65.80000000000001,65.75555555555556,65.75555555555555,65.71111111111111,65.83333333333334,65.8,65.91111111111111,65.92222222222222,65.3111111111111,65.37777777777778,65.5111111111111,65.39999999999999,65.36666666666666,65.34444444444443,65.5,65.52222222222221,65.4888888888889,65.61111111111111,65.53333333333335,65.53333333333335,66.24444444444444,66.26666666666667,66.25555555555555,66.16666666666666,66.16666666666667,66.27777777777779,66.2,66.16666666666666,66.2,66.25555555555555,66.24444444444443,66.33333333333333,66.44444444444443,66.5,66.45555555555555,66.43333333333334,66.41111111111111,66.37777777777777,67.07777777777777,67.08888888888887,67.45555555555556,67.26666666666667,67.26666666666667,67.27777777777779,67.22222222222221,67.27777777777776,67.27777777777777,67.25555555555555,67.28888888888888,67.30000000000001,67.1888888888889,67.03333333333333,67.11111111111113,67.12222222222225,67.0888888888889,67.05555555555556,67.0,67.06666666666666,67.05555555555556,66.35555555555557,66.28888888888889,66.18888888888888,66.1,66.16666666666666,66.13333333333333,66.12222222222222,66.05555555555554,66.09999999999998,66.06666666666666,66.07777777777777,66.1,66.32222222222221,66.25555555555556,66.24444444444445,66.26666666666668,66.23333333333333,66.27777777777777,66.21111111111111,66.26666666666667,66.28888888888889,66.37777777777777,66.53333333333333,66.54444444444442,66.6222222222222,66.68888888888888,66.72222222222221,66.74444444444443,66.67777777777776,66.69999999999997,67.34444444444443,67.42222222222222,67.44444444444443,67.49999999999999,67.42222222222223,67.5,67.43333333333334,67.45555555555556,67.5111111111111,67.6,67.34444444444445,67.44444444444444,67.49999999999999,67.64444444444443,67.65555555555555,66.98888888888888,66.96666666666664,66.38888888888887,66.46666666666667,66.32222222222221,66.31111111111109,66.28888888888886,66.25555555555553,66.19999999999999,66.12222222222222,66.12222222222222,66.16666666666666,66.08888888888889,66.08888888888889,66.02222222222221,65.37777777777777,65.35555555555555,65.32222222222222,65.27777777777777,65.31111111111109,65.36666666666666,65.47777777777777,65.4111111111111,65.15555555555555,64.98888888888888,65.22222222222221,65.16666666666666,64.65555555555554,64.61111111111111,64.6222222222222,65.27777777777777,65.39999999999999,65.95555555555556,65.97777777777777,66.05555555555556,66.08888888888889,66.08888888888889,66.02222222222223,66.14444444444445,66.12222222222222,66.1,66.02222222222223,66.13333333333334,66.15555555555555,66.21111111111111,66.85555555555555,66.94444444444443,66.95555555555555,66.97777777777776,67.0222222222222,66.98888888888887,66.92222222222222,67.02222222222223,67.24444444444444,67.2888888888889,67.1888888888889,67.15555555555557,67.64444444444443,67.68888888888888,67.77777777777779,67.75555555555556,67.64444444444446,67.6111111111111,67.56666666666666,66.92222222222222,66.85555555555555,66.8,66.9,66.8,66.92222222222222,66.87777777777777,66.94444444444444,66.87777777777778,66.92222222222222,66.95555555555555,66.95555555555556,66.83333333333333,66.19999999999999,66.26666666666667,66.24444444444445,66.21111111111111,66.12222222222222,66.06666666666666,66.06666666666668,66.16666666666666,66.25555555555555,66.28888888888888,66.25555555555556,66.14444444444445,66.04444444444445,66.10000000000001,66.15555555555557,66.16666666666667,66.23333333333335,66.84444444444446,66.83333333333334,66.82222222222222,66.74444444444445,66.70000000000002,66.58888888888889,66.64444444444445,66.62222222222223,66.65555555555557,66.63333333333334,66.52222222222223,66.50000000000001,66.55555555555557,67.21111111111112,67.15555555555557,67.17777777777778,67.15555555555557,67.2,67.23333333333333,67.17777777777778,67.12222222222222,67.17777777777778,67.05555555555556,67.04444444444444,67.2111111111111,67.21111111111111,67.15555555555555,67.06666666666666,67.03333333333333,66.96666666666665,66.95555555555553,66.34444444444443,66.36666666666666,66.37777777777777,66.16666666666666,66.18888888888888,66.22222222222221,66.08888888888889,66.13333333333331,66.02222222222223,66.02222222222221,65.95555555555555,65.28888888888889,65.26666666666667,65.28888888888888,65.33333333333331,65.34444444444443,65.41111111111111,65.37777777777778,65.4,65.38888888888889,65.3,65.39999999999999,65.3888888888889,65.22222222222223,65.32222222222222,65.3,65.32222222222222,65.3777777777778,65.33333333333334,65.25555555555556,65.85555555555555,65.73333333333335,65.61111111111113,65.82222222222222,65.8777777777778,65.77777777777779,65.82222222222224,65.83333333333333,65.9,65.97777777777779,66.07777777777778,66.67777777777778,66.64444444444443,66.53333333333335,66.4,66.35555555555555,66.35555555555555,66.35555555555557,66.31111111111112,66.33333333333333,66.43333333333335,66.43333333333334,66.55555555555557,66.52222222222224,66.4,66.45555555555556,66.43333333333335,66.3888888888889,66.34444444444445,66.46666666666667,66.46666666666665,66.58888888888889,66.73333333333333,66.72222222222221,66.75555555555555,66.82222222222221,66.87777777777777,66.9,66.86666666666667,66.8111111111111,66.84444444444445,66.91111111111111,66.9,66.96666666666667,66.98888888888888,67.06666666666666,67.07777777777778,67.07777777777777,66.47777777777776,66.35555555555554,66.27777777777777,66.22222222222221,66.1111111111111,66.1111111111111,66.17777777777776,66.15555555555555,66.16666666666666,66.15555555555555,66.23333333333333,66.1111111111111,66.3,66.36666666666665,66.32222222222221,66.25555555555555,66.24444444444444,66.31111111111112,66.30000000000001,66.26666666666665,66.33333333333331,66.34444444444445,66.35555555555555,66.35555555555555,66.35555555555557,66.36666666666666,66.37777777777778,66.33333333333334,66.30000000000001,65.65555555555557,66.25555555555555,66.35555555555555,66.34444444444445,66.46666666666667,66.52222222222223,66.5111111111111,66.45555555555555,66.02222222222221,65.97777777777776,66.05555555555554,65.92222222222222,65.96666666666667,65.76666666666667,65.56666666666666,65.58888888888889,65.66666666666667,65.64444444444445,65.52222222222221,65.4888888888889,65.52222222222223,65.44444444444444,65.45555555555556,65.45555555555556,65.36666666666667,65.16666666666667,65.16666666666667,65.24444444444445,65.17777777777779,65.17777777777779,65.80000000000001,65.8888888888889,65.9,65.95555555555555,65.85555555555557,65.85555555555555,65.8888888888889,65.83333333333333,66.26666666666667,66.35555555555554,66.45555555555553,66.6,66.66666666666666,66.77777777777779,67.01111111111112,66.86666666666666,66.86666666666667,66.83333333333334,66.23333333333333,66.16666666666667,66.07777777777778,66.12222222222222,66.12222222222222,66.06666666666666,66.1888888888889,66.5,66.4888888888889,66.47777777777779,66.54444444444447,66.56666666666668,66.6,66.61111111111113,66.5888888888889,66.5777777777778,66.66666666666669,66.60000000000002,66.70000000000002,66.74444444444445,66.71111111111112,66.67777777777779,66.52222222222224,66.55555555555557,66.56666666666669,66.4777777777778,66.38888888888891,66.46666666666668,66.48888888888891,66.51111111111113,67.12222222222223,67.25555555555557,67.23333333333335,67.15555555555555,67.13333333333334,67.16666666666666,67.12222222222222,66.98888888888888,66.9,66.91111111111111,66.95555555555556,66.95555555555555,66.98888888888888,66.95555555555556,66.95555555555556,66.97777777777779,66.87777777777778,66.81111111111112,66.77777777777779,66.78888888888889,66.95555555555555,66.88888888888889,66.95555555555555,66.92222222222222,67.02222222222221,67.05555555555554,67.08888888888887,67.15555555555555,67.1111111111111,67.1,67.14444444444443,67.11111111111111,67.14444444444446,67.23333333333332,67.23333333333333,67.30000000000001,67.24444444444445,67.2888888888889,66.73333333333335,66.6888888888889,66.6888888888889,66.16666666666669,66.10000000000001,66.17777777777778,66.14444444444445,66.15555555555555,66.15555555555555,66.18888888888888,66.17777777777778,66.21111111111111,66.10000000000001,66.16666666666666,66.14444444444445,66.12222222222222,66.08888888888889,66.13333333333333,66.15555555555555,66.13333333333334,66.22222222222223,66.16666666666667,66.2,66.21111111111111,66.2,66.25555555555555,66.27777777777777,66.22222222222221,66.27777777777776,66.3111111111111,66.87777777777778,66.83333333333334,66.77777777777777,67.34444444444445,67.35555555555557,67.24444444444445,67.3,67.26666666666667,67.32222222222222,67.3,67.33333333333331,67.33333333333331,67.28888888888888,67.24444444444444,67.26666666666665,67.3111111111111,67.17777777777778,67.17777777777776,67.12222222222222,67.08888888888887,67.06666666666665,67.17777777777776,67.15555555555555,67.13333333333333,67.15555555555555,67.07777777777777,67.13333333333333,67.17777777777776,67.16666666666666,67.1222222222222,67.1888888888889,67.25555555555556,67.27777777777779,67.21111111111111,67.27777777777779,67.1888888888889,67.12222222222223,67.13333333333334,67.12222222222222,67.23333333333333,66.54444444444445,66.47777777777779,66.52222222222224,65.91111111111111,65.8888888888889,65.82222222222222,65.8,65.75555555555556,65.80000000000001,65.8888888888889,65.81111111111112,65.71111111111111,65.72222222222223,65.77777777777779,65.82222222222222,65.78888888888889,65.76666666666668,65.67777777777778,65.66666666666667,65.73333333333333,65.81111111111112,65.78888888888889,65.8,65.88888888888889,65.89999999999999,65.99999999999999,66.02222222222223,66.08888888888889,66.05555555555554,66.08888888888887,66.73333333333332,66.8111111111111,66.83333333333331,67.47777777777776,67.5111111111111,67.56666666666666,67.63333333333333,67.68888888888888,67.71111111111111,67.68888888888888,67.8,67.83333333333333,67.82222222222222,67.8,67.71111111111111,67.73333333333333,67.65555555555555,67.6,67.58888888888889,67.62222222222223,67.6,67.58888888888889,67.62222222222222,67.56666666666668,67.52222222222223,67.4888888888889,67.47777777777777,67.32222222222222,67.27777777777777,67.22222222222223,67.21111111111112,67.16666666666667,67.1,67.13333333333333,66.99999999999999,66.54444444444444,66.59999999999998,66.62222222222222,66.63333333333333,66.53333333333332,66.44444444444443,65.79999999999997,65.78888888888888,65.83333333333333,65.87777777777777,65.91111111111111,65.92222222222223,65.97777777777779,65.95555555555556,65.94444444444446,65.86666666666669,65.82222222222224,65.83333333333336,65.76666666666668,65.63333333333335,65.67777777777779,65.73333333333336,65.7777777777778,65.67777777777779,65.67777777777779,65.73333333333335,65.81111111111113,65.84444444444445,65.80000000000001,65.8888888888889,66.31111111111112,66.3111111111111,66.26666666666667,66.16666666666667,66.19999999999999,66.26666666666667,66.87777777777778,66.85555555555555,66.82222222222224,66.72222222222223,66.76666666666667,66.73333333333333,66.66666666666667,66.71111111111111,66.67777777777778,66.75555555555555,66.8,66.66666666666666,66.83333333333333,66.98888888888888,67.04444444444444,67.01111111111112,66.96666666666665,67.15555555555557,67.1888888888889,67.1,67.05555555555556,67.05555555555556,66.42222222222223,66.3777777777778,66.33333333333334,66.39999999999999,66.36666666666666,66.45555555555556,66.51111111111112,66.55555555555556,66.63333333333334,66.81111111111113,66.83333333333334,66.98888888888888,66.91111111111111,66.94444444444444,67.05555555555554,66.6,66.6,66.58888888888889,66.61111111111111,66.6888888888889,66.67777777777778,66.13333333333334,65.42222222222222,65.35555555555555,65.37777777777778,65.36666666666666,65.27777777777779,65.33333333333333,65.22222222222223,65.24444444444445,65.87777777777778,65.88888888888889,65.97777777777777,65.88888888888889,65.88888888888889,65.86666666666667,65.92222222222222,65.86666666666666,65.83333333333334,65.73333333333335,65.72222222222223,65.71111111111111,65.73333333333333,65.76666666666667,65.71111111111112,66.1,66.10000000000001,66.04444444444445,65.95555555555556,65.9,65.68888888888888,66.16666666666667,66.82222222222221,66.94444444444444,66.92222222222222,66.88888888888889,67.0111111111111,67.0111111111111,67.13333333333333,67.17777777777778,67.18888888888888,67.24444444444444,67.1888888888889,67.17777777777778,67.14444444444445,67.16666666666667,67.13333333333334,67.22222222222223,67.17777777777779,67.12222222222223,67.14444444444446,67.02222222222224,67.06666666666668,67.10000000000002,67.18888888888891,67.20000000000002,67.22222222222224,67.30000000000001,67.35555555555557,67.4,67.21111111111112,67.25555555555557,67.34444444444445,67.27777777777779,67.32222222222222,67.31111111111112,67.16666666666667,67.15555555555557,67.1888888888889,67.07777777777778,67.08888888888889,66.3888888888889,66.35555555555557,66.31111111111112,66.34444444444446,66.26666666666668,66.33333333333334,66.23333333333333,66.3111111111111,66.42222222222222,66.45555555555556,66.55555555555556,66.56666666666668,66.46666666666667,66.39999999999999,66.5111111111111,66.48888888888888,66.45555555555556,66.46666666666667,66.51111111111112,66.84444444444445,66.88888888888889,66.7,66.76666666666667,66.78888888888889,66.82222222222224,66.9,66.8888888888889,66.78888888888889,66.81111111111112,66.82222222222222,67.45555555555556,67.6111111111111,67.62222222222222,67.67777777777778,67.6888888888889,67.56666666666666,67.6,67.58888888888889,67.25555555555556,67.21111111111111,67.16666666666666,67.08888888888889,67.12222222222222,67.08888888888889,67.07777777777777,67.09999999999998,67.12222222222222,67.1111111111111,67.1,67.06666666666666,67.0111111111111,67.1111111111111,67.06666666666666,67.07777777777778,67.04444444444447,67.07777777777778,67.12222222222223,67.20000000000002,67.24444444444445,67.17777777777779,67.17777777777779,67.12222222222223,67.07777777777778,67.03333333333335,66.9888888888889,66.95555555555556,66.9,66.82222222222222,67.1,67.06666666666665,67.07777777777777,67.1111111111111,67.2,67.24444444444445,67.31111111111112,67.23333333333332,67.27777777777777,67.32222222222221,67.28888888888889,67.23333333333333,67.24444444444444,67.18888888888888,67.13333333333333,66.98888888888888,67.03333333333333,66.89999999999999,66.82222222222221,66.79999999999998,66.7,66.67777777777779,66.69999999999999,66.6222222222222,66.66666666666667,66.71111111111111,66.73333333333335,66.85555555555557,66.85555555555557,66.92222222222223,66.9,66.91111111111111,67.0,66.95555555555555,66.73333333333332,66.06666666666666,65.97777777777777,65.94444444444444,65.75555555555556,65.7,65.64444444444445,65.7111111111111,65.6111111111111,65.58888888888889,65.55555555555554,65.6,65.65555555555555,65.77777777777776,65.82222222222221,65.8222222222222,65.89999999999999,65.93333333333334,65.9,65.97777777777777,66.0111111111111,65.9888888888889,66.02222222222223,65.96666666666665,66.02222222222223,66.0,65.91111111111111,65.72222222222223,65.64444444444445,65.62222222222223,65.8111111111111,66.46666666666665,66.5,66.55555555555556,66.56666666666668,66.47777777777777,66.46666666666667,66.45555555555555,66.53333333333333,66.54444444444444,66.65555555555557,66.77777777777779,66.78888888888889,66.72222222222223,66.7,66.72222222222223,66.8,66.86666666666666,66.88888888888889,66.74444444444444,66.72222222222221,66.67777777777778,66.72222222222221,66.67777777777776,66.56666666666665,66.62222222222222,66.6111111111111,66.76666666666667,66.71111111111111,66.8,66.75555555555555,66.68888888888888,66.6,66.6,66.69999999999999,66.83333333333333,66.87777777777778,66.3,65.65555555555555,65.76666666666667,65.68888888888888,65.4,65.32222222222222,65.42222222222223,65.36666666666666,65.34444444444443,65.21111111111111,65.15555555555555,65.18888888888888,65.3,65.34444444444445,65.26666666666667,65.23333333333333,65.25555555555556,65.32222222222222,65.27777777777777,65.33333333333333,65.32222222222224,65.33333333333333,65.24444444444445,65.30000000000001,65.31111111111112,65.42222222222223,65.47777777777779,65.52222222222223,65.55555555555556,65.6,66.18888888888888,66.85555555555557,66.15555555555555,66.22222222222221,66.44444444444444,66.38888888888889,66.3111111111111,66.39999999999999,66.38888888888889,66.44444444444443,66.5111111111111,66.52222222222221,66.4888888888889,66.43333333333334,66.60000000000001,66.62222222222223,66.62222222222225,66.63333333333335,66.57777777777778,66.46666666666667,66.56666666666669,66.63333333333334,66.66666666666667,66.65555555555557,66.73333333333333,66.67777777777778,66.6222222222222,66.58888888888887,66.48888888888888,66.51111111111109,66.45555555555555,66.42222222222222,67.05555555555554,67.04444444444442,67.06666666666665,66.47777777777776,66.5111111111111,66.54444444444444,65.89999999999999,65.86666666666666,65.42222222222222,65.31111111111112,65.34444444444445,65.3888888888889,65.28888888888889,65.1888888888889,65.17777777777778,65.21111111111111,65.33333333333333,65.48888888888888,65.39999999999999,65.34444444444443,65.4111111111111,65.3111111111111,65.3111111111111,65.36666666666666,65.39999999999999,65.38888888888887,65.45555555555556,65.34444444444443,65.33333333333333,65.28888888888889,65.36666666666667,65.44444444444443,65.3777777777778,66.01111111111112,65.98888888888888,66.05555555555556,66.67777777777776,66.76666666666665,67.22222222222221,67.26666666666665,67.29999999999998,67.26666666666667,67.27777777777777,67.3111111111111,67.29999999999998,67.24444444444443,67.16666666666666,67.17777777777776,67.16666666666666,67.15555555555557,67.14444444444443,67.21111111111112,67.22222222222221,67.08888888888889,67.13333333333334,67.15555555555555,67.16666666666667,67.3,67.36666666666667,67.3888888888889,67.28888888888889,67.28888888888889,67.26666666666667,67.21111111111112,67.23333333333335,67.1888888888889,67.1888888888889,67.1888888888889,67.13333333333334,67.19999999999999,67.2,67.26666666666665,67.37777777777777,67.44444444444444,67.41111111111111,67.46666666666667,67.5111111111111,67.46666666666665,67.49999999999999,67.58888888888889,67.52222222222223,67.5,67.46666666666667,67.45555555555556,67.3777777777778,67.3888888888889,66.7,66.61111111111113,66.60000000000001,66.6888888888889,66.74444444444447,66.66666666666669,66.73333333333335,66.74444444444445,66.71111111111112,66.65555555555555,66.72222222222221,66.65555555555557,66.6888888888889,66.67777777777779,66.64444444444446,66.5888888888889,66.53333333333333,66.4888888888889,66.5888888888889,66.6,66.58888888888889,66.65555555555557,66.66666666666667,66.62222222222222,66.65555555555555,66.69999999999999,66.63333333333334,66.7,66.77777777777779,66.75555555555556,67.41111111111111,67.38888888888889,67.4,67.37777777777778,67.34444444444446,67.34444444444445,67.47777777777777,67.42222222222222,66.77777777777777,66.77777777777777,66.64444444444445,66.67777777777778,66.62222222222222,66.58888888888889,66.58888888888889,66.69999999999999,66.66666666666666,66.71111111111111,66.66666666666669,66.65555555555555,66.56666666666666,66.5,66.46666666666668,66.41111111111111,66.4,66.3888888888889,66.42222222222222,66.44444444444446,66.36666666666666,66.4,65.74444444444444,65.91111111111111,65.88888888888889,65.82222222222222,65.91111111111111,65.93333333333332,65.84444444444445,65.97777777777777,66.61111111111111,66.62222222222222,66.7111111111111,66.76666666666665,66.78888888888888,66.86666666666666,66.88888888888889,66.81111111111112,66.75555555555555,66.77777777777777,66.74444444444443,66.17777777777778,66.25555555555556,66.18888888888888,66.19999999999999,66.24444444444444,66.25555555555556,66.3,66.2,66.23333333333335,66.27777777777779,66.03333333333335,66.71111111111111,66.54444444444444,66.60000000000001,66.64444444444445,66.58888888888889,66.5,66.5,66.45555555555555,66.5,66.45555555555555,66.49999999999999,66.47777777777776,66.47777777777777,66.36666666666666,66.4111111111111,66.45555555555555,66.25555555555556,66.2222222222222,66.33333333333331,66.9222222222222,66.91111111111108,66.97777777777776,67.04444444444442,67.05555555555554,67.1222222222222,67.08888888888889,67.25555555555555,67.22222222222221,67.2111111111111,67.44444444444443,67.38888888888889,67.34444444444446,67.23333333333335,67.26666666666667,67.26666666666667,66.9,66.92222222222222,66.92222222222222,66.91111111111111,66.95555555555555,66.95555555555553,66.87777777777777,66.89999999999999,66.93333333333332,66.89999999999998,66.89999999999999,67.15555555555554,67.05555555555554,66.99999999999999,66.9222222222222,66.91111111111111,66.83333333333333,66.75555555555556,66.76666666666667,66.63333333333333,66.65555555555555,66.61111111111111,66.63333333333331,66.55555555555556,66.54444444444444,66.57777777777777,66.74444444444443,66.78888888888889,66.69999999999999,66.66666666666666,67.07777777777778,66.97777777777776,67.04444444444442,66.98888888888888,67.03333333333333,67.03333333333333,66.93333333333332,66.88888888888889,66.84444444444443,66.87777777777777,66.83333333333333,66.91111111111111,66.96666666666665,66.3111111111111,66.34444444444443,66.24444444444444,66.3111111111111,66.26666666666665,66.19999999999999,66.24444444444443,66.15555555555555,66.17777777777778,66.08888888888887,66.21111111111111,66.23333333333333,66.18888888888888,66.0,65.93333333333334,66.0,65.97777777777777,66.04444444444444,66.08888888888887,65.97777777777777,66.07777777777778,66.05555555555554,65.95555555555556,66.07777777777778,66.03333333333335,66.13333333333333,66.10000000000001,66.15555555555555,65.94444444444444,65.9888888888889,66.54444444444445,66.6222222222222,66.77777777777777,66.78888888888888,66.87777777777778,66.94444444444444,67.0111111111111,67.1,67.06666666666668,67.11111111111111,67.1111111111111,66.92222222222222,67.07777777777778,67.24444444444445,67.35555555555555,67.35555555555557,67.38888888888889,67.35555555555555,67.47777777777777,67.44444444444446,67.35555555555555,67.36666666666666,67.42222222222222,67.37777777777777,67.38888888888889,67.3111111111111,67.3111111111111,66.91111111111111,67.1222222222222,67.07777777777777,67.11111111111111,67.02222222222223,66.96666666666665,66.93333333333332,66.86666666666667,66.9,66.84444444444445,66.82222222222222,66.93333333333332,66.94444444444444,66.24444444444445,66.32222222222224,66.12222222222222,66.04444444444445,66.0888888888889,66.13333333333334,66.13333333333333,66.06666666666668,65.8777777777778,66.0,66.06666666666666,65.97777777777777,66.07777777777778,66.08888888888889,66.22222222222223,66.31111111111112,66.14444444444445,66.48888888888888,66.38888888888889,66.45555555555555,66.5111111111111,66.55555555555554,66.57777777777777,66.62222222222223,66.64444444444445,66.55555555555554,66.54444444444442,66.58888888888889,66.49999999999999,66.4111111111111,67.07777777777778,67.12222222222223,67.14444444444445,67.12222222222222,66.95555555555555,66.86666666666666,66.84444444444443,66.86666666666666,66.69999999999999,66.77777777777777,66.74444444444443,66.82222222222221,66.64444444444443,66.73333333333333,66.65555555555555,66.63333333333333,66.73333333333332,66.61111111111111,66.58888888888889,66.46666666666667,66.41111111111111,66.23333333333333,66.14444444444445,66.13333333333333,66.07777777777777,65.95555555555555,66.0,65.86666666666666,65.9111111111111,66.02222222222221,65.86666666666665,65.85555555555555,65.86666666666666,65.77777777777777,65.92222222222222,65.98888888888888,65.14444444444445,65.16666666666667,65.47777777777779,65.33333333333333,65.3,65.2,65.31111111111112,65.31111111111112,65.3111111111111,65.18888888888888,65.22222222222221,65.24444444444444,65.21111111111111,65.3111111111111,65.33333333333333,65.55555555555554,65.66666666666664,65.56666666666665,65.58888888888887,65.63333333333333,65.55555555555554,65.58888888888887,65.62222222222222,65.66666666666667,65.87777777777778,65.92222222222222,65.97777777777777,66.13333333333333,66.13333333333333,66.12222222222222,66.96666666666667,67.0,66.98888888888888,67.04444444444444,67.0111111111111,67.12222222222222,67.1,67.04444444444444,67.02222222222223,67.04444444444445,67.05555555555556,67.24444444444445,67.28888888888889,67.15555555555555,67.21111111111112,66.97777777777777,67.0,67.03333333333333,67.14444444444443,67.28888888888888,67.39999999999999,67.44444444444443,67.39999999999998,67.33333333333331,67.27777777777777,67.32222222222221,67.35555555555554,67.33333333333333,67.3,67.3,67.33333333333333,67.23333333333333,66.52222222222223,66.52222222222221,66.56666666666666,66.48888888888888,66.52222222222221,66.42222222222222,66.42222222222222,66.55555555555556,66.57777777777777,65.82222222222222,65.8111111111111,65.94444444444444,65.94444444444444,66.1,66.03333333333333,66.13333333333333,66.14444444444445,66.16666666666666,66.12222222222222,66.14444444444445,66.11111111111111,66.15555555555557,66.11111111111111,66.02222222222223,66.03333333333333,66.0,66.04444444444445,66.0111111111111,65.94444444444444,65.9888888888889,66.72222222222223,66.75555555555555,66.35555555555555,66.44444444444444,66.3888888888889,66.5111111111111,66.66666666666666,66.67777777777778,66.65555555555554,67.28888888888889,67.35555555555555,67.35555555555555,67.26666666666667,67.21111111111111,67.24444444444444,67.23333333333333,67.14444444444445,66.97777777777777,66.78888888888889,66.78888888888888,66.77777777777777,66.75555555555555,66.75555555555555,66.8,66.09999999999998,66.17777777777776,66.14444444444443,66.1222222222222,66.2111111111111,66.22222222222221,66.1111111111111,66.09999999999998,66.49999999999999,66.4111111111111,66.37777777777775,66.39999999999998,66.28888888888888,66.19999999999999,66.18888888888888,66.19999999999999,66.19999999999999,66.22222222222221,66.37777777777777,65.96666666666665,65.87777777777778,65.92222222222223,65.93333333333332,66.0,66.13333333333334,66.04444444444445,66.07777777777778,66.13333333333333,66.11111111111111,66.12222222222223,66.8,66.78888888888889,66.11111111111111,66.12222222222222,66.1,66.15555555555555,66.24444444444444,66.22222222222221,66.38888888888889,66.43333333333334,66.44444444444444,66.26666666666667,66.25555555555555,66.25555555555555,66.2111111111111,66.27777777777777,66.21111111111111,65.73333333333333,65.02222222222223,65.56666666666668,65.61111111111113,65.51111111111112,65.44444444444444,64.74444444444445,64.76666666666667,64.8111111111111,64.76666666666667,64.73333333333332,64.66666666666666,64.62222222222222,64.53333333333332,64.47777777777776,65.1222222222222,65.13333333333333,65.13333333333333,64.85555555555555,64.77777777777779,64.78888888888889,64.61111111111111,64.4888888888889,64.46666666666667,64.55555555555554,64.57777777777778,63.93333333333333,63.33333333333333,63.25555555555555,63.25555555555555,63.7,64.45555555555555,64.36666666666666,64.33333333333333,64.30000000000001,64.28888888888889,65.04444444444445,65.10000000000001,65.15555555555557,65.11111111111111,65.02222222222223,65.17777777777778,65.2,65.21111111111112,65.25555555555556,65.25555555555556,65.20000000000002,65.23333333333333,65.45555555555558,65.47777777777779,65.4888888888889,65.44444444444446,65.6888888888889,65.76666666666668,65.75555555555556,65.72222222222223,66.28888888888889,66.9,66.87777777777778,66.97777777777777,66.96666666666667,66.8888888888889,66.93333333333334,66.88888888888889,67.0,67.08888888888889,67.13333333333335,67.13333333333335,67.0777777777778,67.16666666666669,67.25555555555557,66.56666666666668,66.7,66.6888888888889,66.66666666666669,66.66666666666669,66.72222222222223,66.72222222222223,66.73333333333333,66.66666666666667,66.63333333333334,66.63333333333334,66.53333333333333,66.46666666666665,66.44444444444444,66.54444444444445,66.44444444444444,66.45555555555555,66.45555555555556,66.33333333333334,66.15555555555557,66.0888888888889,66.02222222222223,66.04444444444445,66.04444444444444,66.04444444444444,65.96666666666667,65.95555555555555,65.95555555555556,65.97777777777777,65.97777777777777,66.47777777777777,66.32222222222222,66.44444444444444,66.45555555555555,66.55555555555554,66.6222222222222,66.52222222222223,66.4888888888889,66.35555555555555,66.37777777777778,66.54444444444444,66.55555555555556,66.55555555555554,66.63333333333333,66.52222222222223,66.75555555555557,66.80000000000001,66.82222222222224,66.88888888888889,66.98888888888888,67.03333333333335,67.06666666666666,67.2,67.17777777777779,66.93333333333335,66.95555555555556,66.97777777777776,66.9888888888889,66.92222222222223,66.22222222222221,66.28888888888888,66.3111111111111,66.18888888888887,66.15555555555555,66.07777777777777,66.02222222222221,66.07777777777777,66.07777777777778,66.27777777777777,66.2,66.0888888888889,66.02222222222223,66.12222222222223,66.03333333333333,66.07777777777778,65.97777777777777,65.98888888888891,66.03333333333335,66.01111111111112,66.0888888888889,66.08888888888889,66.11111111111111,66.03333333333333,65.96666666666665,66.24444444444445,66.22222222222221,66.2,66.24444444444444,66.22222222222221,66.83333333333333,66.97777777777777,66.93333333333334,66.96666666666665,67.03333333333333,66.95555555555556,66.97777777777777,67.0,67.04444444444444,67.03333333333332,67.06666666666665,67.04444444444445,67.04444444444445,67.0,67.03333333333333,67.04444444444444,67.16666666666667,67.15555555555557,67.1,66.96666666666667,66.56666666666666,66.47777777777777,66.45555555555555,66.44444444444444,66.44444444444446,66.4888888888889,66.46666666666665,66.46666666666667,66.43333333333334,66.52222222222223,66.53333333333333,66.42222222222222,66.4,66.43333333333334,66.37777777777778,66.43333333333334,65.65555555555557,65.66666666666667,65.7,65.7,65.74444444444444,65.73333333333333,65.76666666666667,65.75555555555555,65.8,65.77777777777777,65.65555555555555,65.6111111111111,65.57777777777777,65.79999999999998,65.94444444444444,66.04444444444444,66.03333333333332,66.02222222222221,66.04444444444444,65.88888888888889,65.95555555555555,65.94444444444443,65.83333333333334,65.82222222222222,65.82222222222222,65.8,65.83333333333333,65.82222222222221,65.85555555555555,65.85555555555554,66.58888888888889,66.5111111111111,66.45555555555555,66.39999999999999,66.43333333333334,66.43333333333332,66.37777777777778,66.36666666666667,66.27777777777779,66.32222222222222,66.30000000000001,66.34444444444446,66.46666666666667,66.39999999999999,66.69999999999999,66.66666666666666,66.5111111111111,66.5,66.53333333333333,66.65555555555555,66.65555555555555,66.65555555555555,66.75555555555556,66.72222222222223,66.76666666666667,66.8888888888889,66.97777777777777,66.96666666666668,67.0,67.06666666666666,67.03333333333333,67.13333333333333,67.07777777777778,67.19999999999999,67.12222222222222,67.18888888888888,67.24444444444444,67.2111111111111,66.75555555555553,66.7111111111111,66.73333333333332,66.65555555555554,66.63333333333331,66.63333333333331,66.6222222222222,66.6111111111111,66.75555555555555,66.87777777777778,66.8111111111111,66.78888888888889,66.67777777777778,66.65555555555555,66.73333333333333,66.67777777777778,66.6111111111111,66.52222222222223,66.39999999999999,66.43333333333334,66.3888888888889,66.37777777777777,66.44444444444444,66.3888888888889,66.43333333333332,66.38888888888889,66.44444444444444,66.41111111111111,66.27777777777777,65.67777777777778,66.17777777777776,66.13333333333333,66.16666666666666,66.22222222222221,66.21111111111111,66.19999999999999,66.07777777777777,66.06666666666666,66.06666666666666,65.93333333333334,65.96666666666667,65.93333333333332,66.0111111111111,66.13333333333333,66.0111111111111,66.03333333333332,66.03333333333332,66.02222222222221,65.96666666666667,65.3,65.29999999999998,65.18888888888888,65.14444444444445,65.16666666666666,65.17777777777776,65.16666666666666,65.07777777777777,65.15555555555555,65.27777777777777,65.93333333333332,66.04444444444444,66.13333333333333,66.14444444444443,66.19999999999999,66.17777777777778,66.12222222222222,66.04444444444445,66.0,66.0111111111111,66.07777777777777,66.02222222222223,66.0,66.02222222222221,65.68888888888888,65.76666666666668,65.73333333333335,65.78888888888889,65.9,66.07777777777777,66.71111111111111,66.72222222222221,66.75555555555555,66.13333333333333,66.1111111111111,66.17777777777778,65.9888888888889,65.97777777777777,65.9111111111111,65.76666666666667,65.73333333333333,65.68888888888888,65.63333333333333,65.66666666666667,65.57777777777777,65.62222222222222,65.70000000000002,65.92222222222223,66.01111111111112,66.03333333333333,66.12222222222222,66.12222222222223,66.2,66.13333333333334,66.42222222222223,66.3888888888889,66.43333333333335,66.41111111111111,66.37777777777778,66.24444444444445,66.28888888888889,66.28888888888888,66.25555555555555,66.82222222222222,66.77777777777776,66.66666666666666,66.83333333333334,66.87777777777777,66.85555555555555,66.97777777777777,66.97777777777777,66.95555555555555,66.94444444444443,66.89999999999999,66.94444444444444,66.88888888888887,66.88888888888887,66.88888888888889,66.82222222222221,66.8111111111111,66.71111111111111,66.85555555555555,66.86666666666667,67.01111111111112,66.95555555555555,67.0,67.01111111111112,67.08888888888889,67.05555555555556,67.07777777777777,67.12222222222223,67.14444444444445,67.23333333333333,67.26666666666667,67.35555555555554,67.42222222222222,67.4888888888889,67.5888888888889,67.64444444444445,67.66666666666667,67.64444444444443,67.68888888888888,67.6888888888889,67.71111111111111,67.70000000000002,67.72222222222224,67.66666666666669,67.66666666666669,67.75555555555557,67.71111111111112,67.73333333333335,67.73333333333335,67.21111111111112,67.12222222222223,67.05555555555557,67.01111111111113,67.06666666666668,67.06666666666666,67.04444444444445,67.12222222222222,67.08888888888889,67.03333333333333,67.0111111111111,67.07777777777777,67.04444444444444,67.02222222222223,66.97777777777777,66.94444444444443,66.9,66.91111111111111,66.99999999999999,66.99999999999999,67.08888888888889,67.03333333333332,67.07777777777777,67.1,67.17777777777778,67.15555555555557,67.15555555555557,67.03333333333335,67.05555555555556,66.94444444444444,67.46666666666667,67.42222222222222,67.46666666666668,67.62222222222223,67.53333333333333,67.5,67.55555555555556,67.51111111111112,67.5,67.4888888888889,67.41111111111111,67.3888888888889,67.33333333333333,67.37777777777778,67.34444444444445,67.39999999999999,67.44444444444444,67.47777777777777],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"width\":1200,\"height\":600,\"xaxis\":{\"title\":{\"text\":\"trial No.\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy (%)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a37a2bc8-c3d5-4f31-9d2c-16eac6491e6a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 차이 값의 변화\n",
        "\n",
        "# 성능 차이 및 그 이동 평균\n",
        "difference = [float(acc_hpo) - float(acc_new) for acc_hpo, acc_new in zip(hpo_accuracy, new_dataset_accuracy)]\n",
        "difference_ma = np.convolve(difference, np.ones(WINDOW_SIZE) / WINDOW_SIZE, mode='valid')\n",
        "\n",
        "# 그래프로 표시\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=trial_nos,\n",
        "                         y=difference,\n",
        "                         mode='markers',\n",
        "                         marker={'size': 5},\n",
        "                         name='Accuracy Difference'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trial_nos[WINDOW_SIZE:],\n",
        "                         y=difference_ma,\n",
        "                         mode='lines',\n",
        "                         name='Accuracy Difference (Moving Average)'))\n",
        "\n",
        "fig.update_layout(width=1200,\n",
        "                  height=600,\n",
        "                  title='Difference : (HPO dataset ACC) - (NEW dataset ACC)',\n",
        "                  xaxis_title='trial No.',\n",
        "                  yaxis_title='Accuracy Difference (%)')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "T4ml_ctoO81v",
        "outputId": "1cbe7ade-d16e-468e-940a-2e7c33224658"
      },
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"26f60d67-30ae-4087-9e60-6df0fc691f19\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"26f60d67-30ae-4087-9e60-6df0fc691f19\")) {                    Plotly.newPlot(                        \"26f60d67-30ae-4087-9e60-6df0fc691f19\",                        [{\"marker\":{\"size\":5},\"mode\":\"markers\",\"name\":\"Accuracy Difference\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[0.25,-0.3333333333333286,1.75,0.25,0.6666666666666643,0.25,2.5,0.25,0.25,1.8333333333333428,0.5833333333333357,-1.9166666666666714,-1.3333333333333286,-0.5833333333333357,0.5,2.750000000000014,1.1666666666666714,1.8333333333333357,1.9166666666666714,3.1666666666666714,5.0,4.75,4.083333333333343,4.0,2.666666666666657,1.0,0.4166666666666714,0.1666666666666714,2.4166666666666643,0.25,2.750000000000014,1.1666666666666714,2.1666666666666714,4.583333333333329,0.4166666666666714,-1.0,2.9166666666666714,-1.6666666666666714,-0.4166666666666572,5.583333333333329,0.25,-0.4166666666666572,4.500000000000014,1.6666666666666714,0.1666666666666714,0.1666666666666714,2.083333333333343,-2.5,3.083333333333343,3.5833333333333286,5.916666666666657,4.833333333333343,-0.75,0.0833333333333286,1.8333333333333428,0.4166666666666714,4.5,1.4166666666666714,0.3333333333333286,-0.3333333333333428,1.5,-0.75,4.083333333333343,3.750000000000014,5.583333333333329,1.9166666666666714,1.3333333333333286,5.25,-0.75,-2.5,0.25,1.6666666666666714,0.4166666666666714,-3.9166666666666643,4.083333333333343,0.5833333333333428,1.4166666666666714,1.0,0.25,1.0833333333333428,-2.0833333333333286,3.0,4.333333333333343,3.083333333333343,3.500000000000014,-0.1666666666666572,4.666666666666671,0.2500000000000142,1.8333333333333428,1.9166666666666714,0.8333333333333286,-0.8333333333333286,0.25,2.833333333333343,3.750000000000014,-1.0833333333333286,-0.4166666666666572,-0.0833333333333286,-1.1666666666666714,1.2500000000000142,2.9166666666666714,0.4166666666666714,-0.9166666666666714,-1.5,1.5,3.833333333333343,1.0833333333333286,2.1666666666666714,1.5,5.25,5.416666666666671,1.0,2.4166666666666714,-0.5,0.0,2.833333333333343,5.500000000000014,3.4166666666666714,0.75,-2.6666666666666856,0.8333333333333428,4.666666666666671,1.1666666666666572,1.5000000000000142,1.4166666666666643,4.416666666666671,0.08333333333334281,0.1666666666666714,-3.75,1.0833333333333428,-0.6666666666666714,2.0,5.083333333333329,0.9166666666666714,-2.1666666666666714,-3.6666666666666856,-0.8333333333333286,0.9166666666666714,0.6666666666666572,3.0,1.4166666666666643,1.5000000000000142,3.583333333333343,7.083333333333329,1.4166666666666714,-0.4166666666666572,2.6666666666666714,-1.6666666666666572,-1.1666666666666714,5.25,0.5,1.9166666666666714,1.1666666666666714,-0.25,0.8333333333333428,-0.9166666666666643,-1.8333333333333428,1.1666666666666714,1.5833333333333286,0.1666666666666714,-4.75,-0.6666666666666714,0.5,1.3333333333333286,3.6666666666666714,0.4166666666666714,-2.583333333333343,0.25,-0.75,1.4166666666666714,2.833333333333343,-2.000000000000014,-0.6666666666666572,4.083333333333343,-0.8333333333333286,3.583333333333343,-0.5833333333333428,-0.75,-1.0833333333333286,-2.333333333333343,-0.6666666666666714,1.0833333333333428,3.1666666666666714,4.083333333333329,2.833333333333343,2.25,0.5833333333333286,1.3333333333333286,-2.5833333333333286,4.166666666666686,-0.25,1.75,0.0,-2.333333333333343,0.3333333333333286,-0.6666666666666714,-4.500000000000014,2.333333333333343,-1.0833333333333286,-2.5833333333333357,3.416666666666657,0.2499999999999858,-0.8333333333333286,-0.9166666666666714,-1.0000000000000142,1.0,1.5,0.75,3.25,-1.9166666666666714,0.1666666666666714,1.9166666666666714,1.6666666666666714,-0.8333333333333286,-0.4166666666666714,2.9166666666666714,0.5,3.25,-0.0833333333333286,2.583333333333343,-1.5,0.8333333333333428,1.25,0.3333333333333286,-0.8333333333333286,2.0,0.5833333333333286,-0.5,4.583333333333343,5.666666666666671,1.75,-0.4166666666666572,1.1666666666666714,0.5833333333333428,4.25,4.166666666666671,-0.75,1.0833333333333428,-0.08333333333334281,0.25,-0.0833333333333286,1.1666666666666714,-2.1666666666666714,2.25,0.4166666666666714,1.0,-1.3333333333333428,0.75,1.5833333333333286,2.9166666666666714,3.4166666666666714,1.6666666666666714,0.1666666666666714,3.666666666666657,1.2500000000000142,2.1666666666666714,1.9166666666666714,-2.249999999999986,-0.5833333333333286,6.25,1.5000000000000142,0.5,0.5833333333333428,2.5833333333333286,1.5000000000000142,1.75,0.3333333333333286,3.500000000000014,0.0833333333333286,1.9166666666666714,1.0,5.25,3.0833333333333286,0.2500000000000142,-1.4166666666666714,0.5833333333333428,2.0,0.25,-2.9166666666666714,1.9166666666666714,-0.4166666666666572,1.8333333333333428,-2.5,1.4166666666666643,2.0833333333333215,3.750000000000014,3.416666666666657,-0.5,4.25,0.25,1.75,0.0833333333333286,0.3333333333333286,-2.333333333333343,-2.916666666666657,-1.0,1.3333333333333286,3.0,-3.6666666666666856,-3.25,1.3333333333333286,1.5000000000000142,1.1666666666666714,0.3333333333333286,3.333333333333343,1.3333333333333286,0.25,4.333333333333343,0.6666666666666714,2.6666666666666714,2.25,-0.8333333333333286,2.6666666666666714,0.8333333333333428,-0.9166666666666714,-0.8333333333333286,4.0,3.083333333333343,3.1666666666666714,2.333333333333343,3.833333333333343,3.333333333333343,1.3333333333333286,1.75,1.4166666666666714,-0.1666666666666572,0.5833333333333428,-1.6666666666666714,-0.4166666666666572,-0.5833333333333428,1.9166666666666714,2.5833333333333286,5.416666666666671,-0.5,-1.3333333333333428,2.833333333333343,3.0,0.0,-1.749999999999993,0.0,2.9166666666666714,2.5833333333333286,1.25,0.8333333333333428,-2.250000000000014,-2.166666666666657,2.3333333333333286,1.5833333333333286,2.833333333333343,2.250000000000014,3.5833333333333286,1.8333333333333428,0.4166666666666714,2.500000000000014,3.750000000000014,-0.6666666666666714,4.833333333333343,1.1666666666666714,-2.333333333333343,0.25,2.583333333333343,0.3333333333333286,-0.6666666666666714,3.333333333333343,1.5833333333333286,0.5,0.0,-0.5,2.0,0.9166666666666714,0.6666666666666714,3.750000000000014,0.5,-1.1666666666666714,-1.6666666666666714,0.5,-2.4166666666666714,1.0,2.1666666666666714,1.5,-0.1666666666666572,4.166666666666686,1.0,-3.3333333333333286,1.4166666666666714,2.6666666666666714,2.0,5.166666666666686,0.25,1.25,-2.833333333333343,1.5,-0.25,8.083333333333329,0.0,-0.5,-1.5833333333333428,3.9166666666666714,1.1666666666666714,2.9166666666666714,-2.0833333333333286,0.9166666666666714,-0.5833333333333428,-0.25,0.0833333333333286,2.0,3.8333333333333286,-0.4166666666666572,-0.75,-0.75,-3.1666666666666714,-1.9166666666666714,-0.75,3.333333333333343,0.5833333333333428,3.5833333333333286,3.833333333333343,3.0,1.8333333333333428,5.25,0.5,0.9166666666666572,-1.25,-0.6666666666666714,0.8333333333333428,2.75,4.166666666666686,-3.9166666666666714,3.500000000000014,-2.833333333333343,2.0,-0.6666666666666572,2.5833333333333286,1.0,3.6666666666666714,1.0833333333333428,6.916666666666671,1.5000000000000142,3.3333333333333286,2.1666666666666714,0.0833333333333286,1.9166666666666714,1.8333333333333428,0.6666666666666714,3.500000000000014,2.9166666666666714,-1.3333333333333428,2.250000000000014,3.6666666666666714,5.0,2.5833333333333286,4.166666666666686,-0.1666666666666714,0.1666666666666714,4.750000000000014,1.8333333333333428,4.25,3.75,-2.6666666666666856,4.833333333333343,-2.250000000000014,0.5,1.8333333333333428,2.0833333333333286,-0.3333333333333428,4.0,1.75,0.25,-0.75,0.8333333333333428,3.6666666666666714,1.0,3.25,2.083333333333343,0.3333333333333286,1.9166666666666714,0.25,0.25,-0.1666666666666572,2.6666666666666714,0.4166666666666714,2.6666666666666714,-1.1666666666666714,0.5,0.0,-0.4166666666666714,0.6666666666666572,-2.4166666666666714,-0.75,5.5,-2.6666666666666856,4.583333333333343,2.1666666666666714,5.500000000000014,-1.25,1.6666666666666714,-1.1666666666666714,-2.250000000000014,-1.5,-0.5,-2.333333333333343,2.3333333333333286,1.1666666666666714,3.75,2.5,1.25,4.166666666666671,1.1666666666666714,1.8333333333333428,-1.8333333333333428,1.0833333333333428,4.333333333333343,4.416666666666671,0.6666666666666714,3.3333333333333286,4.666666666666671,4.083333333333343,4.833333333333343,-3.083333333333343,-0.3333333333333428,0.5,0.2499999999999929,2.9166666666666714,4.833333333333329,-1.4166666666666572,0.3333333333333286,2.833333333333343,0.5,3.25,5.666666666666657,2.75,-1.75,-0.6666666666666714,3.5833333333333286,5.916666666666657,2.75,-1.5,-1.5,1.1666666666666714,-0.1666666666666572,-1.5,-1.5833333333333428,-1.0,1.1666666666666714,1.0833333333333428,-0.6666666666666714,3.5833333333333286,2.6666666666666714,2.5833333333333286,2.6666666666666714,-1.4166666666666572,0.9166666666666572,-2.5,5.5,2.6666666666666714,0.8333333333333428,-0.3333333333333286,-1.5833333333333428,0.4166666666666714,1.4166666666666714,0.25,0.9166666666666714,3.083333333333343,1.3333333333333286,-3.4166666666666714,0.2500000000000142,-0.0833333333333286,0.8333333333333428,1.0,2.25,1.75,6.333333333333329,1.2500000000000142,4.0,2.0,3.6666666666666714,-2.166666666666657,2.3333333333333286,-0.5833333333333428,4.583333333333329,1.6666666666666714,3.25,0.8333333333333428,1.0833333333333428,-1.3333333333333428,1.0,2.833333333333343,1.0833333333333357,3.6666666666666714,0.5833333333333428,0.9166666666666714,-0.5,-0.5,1.8333333333333428,-1.0833333333333286,2.500000000000014,0.0,6.58333333333335,0.0833333333333286,1.0,3.500000000000014,1.4166666666666714,0.5833333333333428,2.0,1.4166666666666714,4.833333333333343,-3.4166666666666714,1.75,0.5,-1.25,0.5,3.5833333333333286,0.25,0.25,4.833333333333343,0.25,-1.2499999999999858,1.4166666666666714,3.333333333333343,1.0,-0.0833333333333286,3.083333333333343,-0.3333333333333428,3.4166666666666714,-0.0833333333333286,1.2500000000000142,2.500000000000014,3.4166666666666714,1.4166666666666714,2.083333333333343,5.166666666666657,-1.1666666666666714,5.166666666666671,3.0833333333333215,0.25,4.166666666666686,1.6666666666666714,3.25,-1.4166666666666572,4.916666666666671,0.8333333333333428,3.500000000000014,0.8333333333333428,0.8333333333333428,0.9166666666666572,1.0833333333333428,0.9166666666666714,-0.4166666666666572,3.9166666666666714,-0.75,3.4166666666666714,-1.8333333333333286,1.0833333333333428,2.833333333333343,4.25,1.1666666666666714,3.25,1.6666666666666714,1.2500000000000142,1.0,-0.8333333333333286,0.0833333333333286,1.9166666666666714,-0.9166666666666714,2.500000000000014,-0.1666666666666572,2.1666666666666714,2.0,-3.25,3.25,-0.8333333333333286,1.5833333333333286,1.4166666666666714,4.666666666666671,0.4166666666666714,0.75,-0.4166666666666572,1.1666666666666714,0.3333333333333286,0.8333333333333428,0.0,0.8333333333333428,1.8333333333333428,-1.3333333333333428,-1.4166666666666572,0.1666666666666714,0.3333333333333286,3.083333333333343,2.75,-2.4166666666666714,1.5,3.833333333333343,1.0,-2.0833333333333286,-0.3333333333333428,-3.4166666666666714,0.75,0.8333333333333428,3.833333333333343,0.75,-1.9166666666666714,3.1666666666666714,4.666666666666657,2.6666666666666714,0.6666666666666714,0.3333333333333286,-0.1666666666666714,-0.5833333333333428,0.6666666666666714,2.25,1.6666666666666714,1.4166666666666714,-0.1666666666666572,3.416666666666657,-1.0,1.25,-1.5833333333333428,0.75,2.5833333333333286,5.166666666666686,-2.4166666666666714,3.75,0.1666666666666714,2.1666666666666714,0.25,0.9166666666666572,1.75,1.8333333333333357,3.6666666666666714,-0.5,1.6666666666666714,0.9166666666666714,2.75,3.4166666666666714,5.333333333333343,0.0,1.5000000000000142,2.500000000000014,4.666666666666671,2.0,1.9166666666666714,1.1666666666666714,-0.9166666666666572,4.333333333333343,-1.9166666666666572,-0.25,1.3333333333333286,1.6666666666666714,3.5833333333333286,-1.0,-2.416666666666657,-3.9166666666666714,0.5833333333333428,1.75,2.0,0.75,-0.25,-2.5833333333333357,-0.6666666666666714,-1.4166666666666714,1.5833333333333428,3.5833333333333286,0.5833333333333428,0.6666666666666572,2.9166666666666714,0.25,-0.0833333333333357,1.0,-3.166666666666657,-0.25,2.333333333333343,3.833333333333343,6.083333333333343,1.4166666666666714,2.25,-1.3333333333333428,-1.4166666666666714,1.3333333333333286,2.3333333333333286,1.5833333333333286,1.6666666666666714,1.5000000000000142,-0.25,1.6666666666666714,5.333333333333329,-1.0833333333333286,4.083333333333343,-1.0833333333333286,2.6666666666666714,3.1666666666666856,1.0,1.0,1.5,4.750000000000014,0.4166666666666714,-0.8333333333333286,1.6666666666666572,2.75,6.833333333333343,3.583333333333343,-0.3333333333333428,0.4166666666666714,2.5833333333333286,0.0,1.25,0.75,-1.1666666666666714,0.25,0.0833333333333286,5.083333333333343,1.0833333333333428,2.500000000000014,-1.1666666666666714,-5.500000000000014,0.9166666666666714,3.333333333333343,3.9166666666666714,2.750000000000014,2.166666666666657,0.5,3.750000000000014,2.500000000000014,5.833333333333343,1.1666666666666714,2.6666666666666714,2.4166666666666714,1.5,-1.4166666666666572,1.0,4.750000000000014,7.166666666666671,1.8333333333333428,1.6666666666666572,2.500000000000014,3.1666666666666714,1.3333333333333286,2.5833333333333286,-0.8333333333333286,2.75,4.75,3.25,3.083333333333343,4.0,0.6666666666666714,5.500000000000014,3.0,4.333333333333343,2.1666666666666714,0.4166666666666714,-0.3333333333333428,2.333333333333343,1.9166666666666714,5.25,0.25,3.083333333333343,2.9166666666666714,1.9166666666666572,1.25,4.166666666666671,0.3333333333333286,2.25,-1.75,1.5,2.083333333333343,-1.0,6.333333333333343,2.1666666666666714,3.25,1.3333333333333286,-1.25,1.1666666666666714,0.5833333333333428,1.1666666666666714,-0.0833333333333286,-2.1666666666666714,1.5,2.0833333333333286,5.083333333333329,2.500000000000014,3.083333333333343,3.333333333333343,1.5000000000000142,1.25,0.1666666666666714,2.083333333333343,2.0,3.1666666666666714,0.3333333333333286,-0.5833333333333428,3.083333333333343,2.5833333333333286,0.75,1.6666666666666714,2.750000000000014,2.750000000000014,0.6666666666666714,1.5833333333333286,3.1666666666666714,3.0,-1.4166666666666572,-1.1666666666666714,2.4166666666666714,1.5000000000000142,5.75,3.1666666666666856,5.416666666666671,0.4166666666666714,1.3333333333333286,3.333333333333343,3.9166666666666714,1.0833333333333428,-1.75,1.9166666666666714,2.0,2.9166666666666714,0.25,1.8333333333333428,3.0,0.5833333333333286,7.833333333333343,0.6666666666666714,0.0,4.416666666666671,1.6666666666666714,2.333333333333343,3.0,0.6666666666666714,0.2500000000000142,-1.0833333333333428,4.416666666666671,0.0833333333333286,5.083333333333343,4.416666666666671,2.3333333333333286,3.25,2.083333333333343,-1.0,3.6666666666666714,3.750000000000014,6.166666666666686,4.666666666666671,1.1666666666666714,0.5833333333333286,5.083333333333329,5.5,5.75,5.5,-0.25,1.6666666666666643,4.083333333333343,0.75,0.9166666666666714,-1.9166666666666572,3.5833333333333286,4.25,-1.9166666666666714,3.583333333333343,2.6666666666666714,3.750000000000014,5.0,1.6666666666666714,-3.1666666666666714,-2.333333333333343,5.500000000000014,2.0,3.4166666666666714,2.3333333333333286,3.1666666666666714,2.0833333333333286,3.5833333333333286,1.0,1.4166666666666714,4.916666666666671,-0.4166666666666714,0.8333333333333428,0.6666666666666572,3.750000000000014,-4.916666666666671,0.0,3.9166666666666714,4.416666666666671,4.333333333333329,-1.4166666666666714,2.4166666666666714,2.500000000000014,1.9166666666666714,2.250000000000014,0.6666666666666714,-1.3333333333333428,2.0,0.0833333333333286,5.583333333333329,4.583333333333343,0.8333333333333428,0.6666666666666714,0.5,4.583333333333343,0.25,2.5833333333333286,1.9166666666666714,-1.25,5.833333333333343,6.500000000000014,0.0833333333333286,-0.0833333333333286,2.5833333333333286,2.5833333333333286,2.750000000000014,3.0,4.333333333333343,6.166666666666686,1.5000000000000142,-0.8333333333333286,2.0,3.0,0.25,0.6666666666666714,2.9166666666666643,2.0,3.0,3.25,3.8333333333333286,1.0,1.0,1.5833333333333286,3.6666666666666714,2.083333333333343,-1.0833333333333286,3.166666666666657,3.500000000000014,4.750000000000014,1.6666666666666714,0.6666666666666714,2.4166666666666714,3.0,-1.3333333333333428,-1.1666666666666714,-0.6666666666666714,-3.833333333333343,1.0,6.166666666666671,2.4166666666666714,3.1666666666666856,1.0,5.25,-1.1666666666666714,4.083333333333329,2.3333333333333286,2.249999999999993,2.1666666666666714,3.333333333333343,2.5833333333333286,-1.0833333333333286,1.8333333333333428,1.4166666666666714,1.8333333333333428,1.75,3.9166666666666714,3.250000000000014,1.5833333333333286,1.5,1.8333333333333428,2.083333333333343,6.166666666666671,-1.0833333333333286,1.5000000000000142,0.25,3.0,3.333333333333343,0.3333333333333286,-0.4166666666666572,4.666666666666671,2.6666666666666714,3.4166666666666714,1.8333333333333428,3.1666666666666856,-0.8333333333333286,1.6666666666666714,1.4166666666666714,5.416666666666671,3.25,2.333333333333343,2.4166666666666714,0.0833333333333286,3.4166666666666714,-1.0833333333333286,2.750000000000014,0.0,2.3333333333333286,0.4166666666666714,2.9166666666666714,0.6666666666666714,1.9166666666666714,0.5,0.0833333333333286,0.4166666666666714,5.5,1.5000000000000142,2.6666666666666714,2.4166666666666714,4.416666666666671,5.25,4.666666666666671,3.583333333333343,2.25,0.0833333333333286,-3.583333333333343,-0.5,-1.0833333333333286,2.3333333333333286,2.500000000000014,0.25,3.9166666666666714,1.1666666666666714,2.750000000000014,4.083333333333343,3.083333333333343,2.750000000000014,0.8333333333333428,4.583333333333343,1.9166666666666714,1.9166666666666714,0.5833333333333286,7.000000000000014,3.4166666666666714,6.583333333333329,0.25,4.25,2.4166666666666714,0.8333333333333428,1.3333333333333286,-0.1666666666666714,1.3333333333333286,-0.6666666666666572,2.0,1.3333333333333286,-0.1666666666666572,-1.3333333333333428,0.9166666666666643,2.833333333333343,0.0833333333333286,2.25,-1.4166666666666714,0.3333333333333286,1.25,2.5833333333333286,2.083333333333343,0.6666666666666714,2.0,0.9166666666666572,1.3333333333333286,1.3333333333333286,2.9166666666666714,2.4166666666666714,1.5000000000000142,0.75,1.3333333333333286,-0.5,2.500000000000014,3.083333333333343,4.166666666666671,0.4166666666666714,0.4166666666666714,0.5,-1.3333333333333428,0.8333333333333428,4.916666666666671,-0.3333333333333428,-2.5,-0.1666666666666714,-3.833333333333343,1.2500000000000142,0.2500000000000142,3.0,3.4166666666666714,0.25,1.1666666666666714,1.0833333333333286,-1.0000000000000142,3.500000000000014,-1.9166666666666714,6.416666666666671,-1.5833333333333428,2.75,0.5833333333333286,0.5833333333333286,1.3333333333333286,4.0,0.25,2.749999999999986,-0.1666666666666572,2.6666666666666714,5.583333333333329,3.4166666666666714,1.1666666666666714,-2.1666666666666714,3.083333333333343,-0.9166666666666714,1.0,1.0833333333333286,4.166666666666686,0.4166666666666714,1.9166666666666572,0.5833333333333428,4.75,4.0,4.0,3.500000000000014,1.75,3.1666666666666714,-0.2499999999999858,4.75,0.3333333333333286,0.9166666666666714,2.083333333333343,4.333333333333343,4.083333333333343,-1.8333333333333286,3.9166666666666714,1.9166666666666714,3.333333333333343,2.083333333333343,4.25,2.4166666666666714,1.5833333333333428,1.1666666666666714,1.8333333333333428,5.25,1.3333333333333286,-4.333333333333343,2.9166666666666714,3.333333333333343,4.166666666666686,2.833333333333343,0.0833333333333286,4.333333333333343,0.25,3.6666666666666714,0.1666666666666714,0.7499999999999929,4.083333333333343,0.8333333333333428,3.5,2.500000000000014,-0.4166666666666572,5.166666666666686,4.0,0.25,4.583333333333343,3.333333333333343,0.75,2.1666666666666714,3.500000000000014,1.3333333333333286,2.5833333333333286,1.5000000000000142,2.833333333333343,1.8333333333333428,1.2500000000000142,-1.0,-2.1666666666666714,2.75,-1.0833333333333286,4.5,3.9166666666666714,3.75,3.500000000000014,3.999999999999986,2.5833333333333286,3.1666666666666714,-0.0833333333333286,2.1666666666666714,1.3333333333333286,1.75,1.75,2.833333333333343,2.25,1.0,5.166666666666686,5.416666666666671,6.833333333333343,2.250000000000014,-1.0833333333333286,0.9166666666666714,6.000000000000014,1.25,0.2499999999999858,-1.9166666666666572,-4.500000000000014,6.666666666666671,2.3333333333333286,1.9166666666666714,4.583333333333343,3.750000000000014,6.916666666666671,3.0,4.333333333333343,3.25,1.5833333333333286,2.6666666666666714,1.8333333333333428,4.75,1.3333333333333286,1.5,5.666666666666671,1.1666666666666714,0.0,0.6666666666666714,5.083333333333343,1.75,3.25,0.75,2.750000000000014,0.9166666666666714,0.25,5.750000000000014,1.75,3.083333333333343,1.75,4.166666666666671,2.0,-1.1666666666666714,4.666666666666671,0.3333333333333286,2.083333333333343,3.75,-3.4166666666666714,2.500000000000014,2.083333333333343,4.25,3.416666666666657,-1.8333333333333428,2.9166666666666714,0.0,3.6666666666666714,1.2500000000000142,0.5,-1.8333333333333286,4.25,1.8333333333333428,2.083333333333343,5.000000000000014,2.500000000000014,0.25,2.250000000000014,-1.0,0.8333333333333428,-3.500000000000014,0.0833333333333286,2.0,0.75,1.4166666666666714,3.9166666666666714,-1.5833333333333428,0.2499999999999929,2.833333333333343,5.916666666666671,5.166666666666671,3.500000000000014,2.75,0.3333333333333286,5.166666666666686,2.6666666666666714,1.9166666666666572,3.083333333333343,3.833333333333343,-2.000000000000014,4.166666666666671,1.0833333333333286,2.6666666666666714,-0.6666666666666714,0.3333333333333428,3.750000000000014,3.25,1.6666666666666714,1.5833333333333286,2.083333333333343,2.833333333333343,0.0833333333333286,4.333333333333343,4.500000000000014,2.1666666666666714,1.25,-1.6666666666666714,1.3333333333333286,2.083333333333343,2.1666666666666714,-1.8333333333333428,0.7499999999999929,4.0,-1.5833333333333286,0.25,-1.1666666666666714,0.4166666666666714,3.833333333333343,3.0,-0.75,1.3333333333333286,2.1666666666666714,4.666666666666671,0.0833333333333286,6.666666666666671,2.6666666666666714,5.166666666666671,2.5833333333333286,2.25,1.5833333333333286,-1.5,1.6666666666666714,0.9166666666666572,2.3333333333333286,3.5833333333333286,1.4166666666666714,-0.3333333333333428,2.833333333333343,4.25,3.5833333333333286,3.333333333333343,4.25,4.166666666666686,3.583333333333343,1.5,1.0833333333333428,4.0,4.083333333333343,4.500000000000014,2.0,2.6666666666666714,1.5833333333333428,0.6666666666666714,2.25,2.833333333333343,2.6666666666666714,-0.4166666666666572,1.0833333333333428,-0.25,3.416666666666657,4.833333333333343,2.833333333333343,0.6666666666666714,2.4166666666666714,-1.8333333333333286,3.4166666666666714,2.25,3.833333333333343,-1.25,3.4166666666666714,2.750000000000014,0.5833333333333428,5.916666666666671,2.25,5.166666666666671,-1.6666666666666572,0.9166666666666714,-0.25,2.0,0.8333333333333428,5.166666666666686,6.083333333333329,0.25,1.0833333333333428,-0.0833333333333286,1.249999999999993,3.6666666666666714,2.916666666666657,3.6666666666666714,2.25,4.0,3.9166666666666714,4.75,1.8333333333333428,2.333333333333343,2.25,2.9166666666666714,4.083333333333343,3.0833333333333286,2.083333333333343,2.500000000000014,3.333333333333343,2.0,4.750000000000014,1.6666666666666714,4.25,2.500000000000014,1.4166666666666714,3.4166666666666714,0.4166666666666714,4.75,2.5833333333333286,3.250000000000014,2.833333333333343,3.6666666666666714,0.5,2.083333333333343,2.083333333333343,1.5833333333333286,2.4166666666666714,0.6666666666666714,4.583333333333329,2.500000000000014,3.500000000000014,0.75,4.0,-1.0833333333333286,4.000000000000014,2.5,-0.8333333333333286,3.333333333333343,1.8333333333333428,3.083333333333343,0.1666666666666714,2.750000000000014,4.500000000000014,2.25,5.416666666666671,1.75,-1.3333333333333428,2.5833333333333286,3.9166666666666714,3.750000000000014,1.25,3.4166666666666714,3.333333333333343,0.9166666666666572,1.0,4.0,1.6666666666666714,2.6666666666666714,0.4166666666666714,0.25,5.916666666666671,3.583333333333343,0.25,0.0,3.083333333333343,6.083333333333343,0.9166666666666714,1.1666666666666714,0.0,5.833333333333343,5.666666666666671,0.75,1.5833333333333286,0.9166666666666572,6.000000000000014,2.0,0.9166666666666714,4.166666666666686,-0.1666666666666572,-1.5,0.6666666666666714,1.8333333333333428,1.9166666666666572,2.25,0.9166666666666714,3.750000000000014,-1.5833333333333428,2.833333333333343,2.749999999999986,3.0,3.583333333333343,2.083333333333343,6.333333333333329,-0.1666666666666714,3.083333333333343,3.25,-1.5833333333333428,0.0833333333333286,5.25,-1.25,1.3333333333333286,1.0833333333333428,0.1666666666666714,4.0,4.916666666666671,1.8333333333333428,3.4166666666666714,4.083333333333343,0.9166666666666572,0.0,2.25,-2.5,2.750000000000014,2.333333333333343,4.833333333333343,2.4166666666666714,1.8333333333333428,3.3333333333333286,0.2500000000000142,3.333333333333343,2.833333333333343,3.25,1.5833333333333286,2.1666666666666714,1.3333333333333428,2.4166666666666714,1.9166666666666572,2.25,3.6666666666666714,6.000000000000014,0.25,-0.6666666666666714,-0.3333333333333428,1.8333333333333428,-1.5,3.5833333333333286,3.0,3.9166666666666714,0.4166666666666714,3.1666666666666714,6.083333333333329,0.5,5.166666666666686,6.333333333333329,0.5833333333333428,0.75,-0.3333333333333428,0.5,2.750000000000014,2.500000000000014,0.0833333333333286,2.25,2.9166666666666714,5.75,4.083333333333343,1.1666666666666714,0.3333333333333286,4.416666666666671,4.333333333333343,2.333333333333343,1.5,4.166666666666686,2.333333333333343,6.500000000000014,-1.5833333333333428,3.3333333333333286,8.333333333333329,1.75,3.9166666666666714,2.9166666666666714,2.25,4.083333333333343,2.249999999999986,3.75,3.5,2.1666666666666714,4.333333333333343,-1.8333333333333286,-1.1666666666666714,3.083333333333343,1.0,3.9166666666666714,0.25,3.333333333333343,2.0833333333333286,-2.0833333333333286,4.25,3.8333333333333286,3.083333333333343,-0.25,-0.8333333333333286,-1.5833333333333286,2.9166666666666714,1.0,4.500000000000014,7.333333333333329,1.6666666666666714,0.0,0.1666666666666714,-0.5,1.5833333333333286,3.4166666666666714,-0.7500000000000142,0.0833333333333357,0.25,5.416666666666671,5.333333333333343,3.9166666666666714,2.75,2.6666666666666714,5.583333333333329,0.75,4.583333333333343,3.833333333333343,4.000000000000014,3.9166666666666714,2.1666666666666714,5.333333333333329,-0.6666666666666714,1.8333333333333428,3.500000000000014,0.1666666666666714,4.5,2.5833333333333286,2.5833333333333286,2.5833333333333286,5.000000000000014,5.0,0.5833333333333428,6.583333333333329,3.4166666666666714,3.0,3.9166666666666714,0.3333333333333286,1.4166666666666714,-1.5833333333333428,1.0,4.083333333333343,0.3333333333333286,3.083333333333343,1.5000000000000142,-1.0000000000000142,1.75,1.75,4.416666666666671,1.75,3.5833333333333286,-0.75,1.5833333333333286,-2.0833333333333286,1.9166666666666714,1.4166666666666714,3.0,4.583333333333329,2.500000000000014,1.1666666666666714,-0.5833333333333428,4.25,1.5833333333333286,-1.1666666666666714,2.1666666666666714,1.6666666666666714,0.4166666666666643,4.000000000000014,-3.333333333333343,2.083333333333343,1.75,4.416666666666671,4.666666666666671,2.1666666666666714,-1.5833333333333428,1.0833333333333286,2.25,0.25,3.75,2.6666666666666714,-0.3333333333333428,4.083333333333343,-0.8333333333333286,6.333333333333329,-1.6666666666666714,-1.5,-1.75,2.833333333333343,2.5833333333333286,2.9166666666666714,2.25,0.9166666666666572,2.6666666666666714,2.750000000000014,0.1666666666666714,4.5,2.9166666666666714,1.4166666666666714,5.25,0.9166666666666572,0.6666666666666714,1.75,4.833333333333343,5.000000000000014,6.416666666666671,5.000000000000014,-0.1666666666666572,1.6666666666666714,2.416666666666657,3.5833333333333286,0.9166666666666572,2.9166666666666714,2.833333333333343,3.6666666666666714,1.1666666666666714,1.8333333333333286,0.0,4.583333333333343,2.833333333333343,4.0,-0.5,2.500000000000014,2.833333333333343,1.6666666666666714,2.5833333333333286,0.6666666666666714,3.083333333333343,0.1666666666666714,1.4166666666666714,2.6666666666666714,0.3333333333333286,4.833333333333343,1.75,-0.0833333333333286,-0.0833333333333286,1.5833333333333286,1.8333333333333428,0.8333333333333428,2.833333333333343,6.166666666666686,3.083333333333343,5.083333333333343,8.416666666666671,4.500000000000014,0.5833333333333428,0.5833333333333286,2.25,0.9166666666666714,1.4166666666666714,1.75,-0.1666666666666572,-3.250000000000014,2.6666666666666714,-1.3333333333333428,0.8333333333333428,1.6666666666666714,9.333333333333343,1.9166666666666714,4.750000000000014,2.6666666666666714,5.5,-1.5,5.750000000000014,5.166666666666686,0.5833333333333428,3.75,4.166666666666671,3.9166666666666714,2.250000000000014,5.666666666666671,1.3333333333333286,4.416666666666671,2.6666666666666714,1.1666666666666714,0.2500000000000142,-1.6666666666666714,-0.1666666666666572,-0.5,3.5833333333333286,-0.7499999999999929,0.25,1.9166666666666714,3.250000000000014,6.0,-0.8333333333333286,3.75,0.6666666666666714,4.083333333333343,4.166666666666671,3.250000000000014,4.166666666666671,1.8333333333333428,0.0,0.9166666666666714,1.8333333333333428,3.500000000000014,5.25,1.1666666666666714,-1.3333333333333428,2.5833333333333286,-0.9166666666666714,1.75,2.25,3.25,2.5833333333333286,2.250000000000014,0.5,2.25,5.500000000000014,2.750000000000014,0.5833333333333428,-1.1666666666666714,4.083333333333343,4.416666666666671,7.666666666666671,3.250000000000014,3.500000000000014,3.0,3.4166666666666714,1.1666666666666714,0.0833333333333286,-0.5833333333333428,2.0,4.916666666666671,-0.0833333333333286,0.75,0.75,2.1666666666666714,6.333333333333329,4.916666666666671,-0.4166666666666572,3.75,3.5833333333333286,-0.08333333333331439,0.5,3.833333333333343,3.750000000000014,4.750000000000014,1.1666666666666714,2.833333333333343,3.0,5.666666666666671,5.75,1.0,0.3333333333333286,1.5,0.0,0.25,1.3333333333333286,5.583333333333343,1.250000000000007,4.666666666666671,0.2499999999999858,5.333333333333343,-0.25,1.0,5.333333333333343,0.75,3.4166666666666714,-2.249999999999986,5.666666666666671,3.500000000000014,3.333333333333343,4.166666666666686,2.25,5.083333333333329,4.916666666666671,3.5833333333333286,2.583333333333343,1.1666666666666714,4.333333333333343,-2.250000000000014,2.833333333333343,-3.6666666666666714,-0.25,-0.6666666666666714,2.333333333333343,3.1666666666666856,0.25,0.6666666666666714,0.8333333333333428,5.500000000000014,3.0,1.4166666666666714,2.1666666666666714,4.75,2.9166666666666714,3.333333333333343,1.0833333333333286,3.1666666666666714,-4.333333333333343,1.5833333333333286,1.6666666666666714,4.25,3.083333333333343,5.083333333333329,3.166666666666657,1.5833333333333286,4.500000000000014,-1.8333333333333286,2.4166666666666714,0.2500000000000142,3.25,2.333333333333343,1.5,1.5833333333333286,0.6666666666666572,2.083333333333343,-2.499999999999986,3.083333333333343,3.500000000000014,0.25,1.5833333333333286,1.25,0.25,3.25,2.9166666666666643,5.416666666666671,-0.3333333333333428,3.083333333333343,4.916666666666671,2.5,3.6666666666666714,2.833333333333343,-0.1666666666666714,0.8333333333333428,4.166666666666686,4.500000000000014,-1.6666666666666714,-0.9166666666666643,3.25,-1.8333333333333428,3.083333333333343,3.083333333333343,4.5,2.4166666666666714,3.9166666666666714,5.500000000000014,1.0,1.5833333333333286,5.916666666666671,1.6666666666666714,-0.6666666666666714,-1.5833333333333428,2.833333333333343,-1.9166666666666714,0.9166666666666572,1.5833333333333428,3.25,4.500000000000014,3.333333333333343,1.5,3.5833333333333286,2.0,2.5833333333333286,1.75,4.500000000000014,4.416666666666671,3.6666666666666714,0.4166666666666714,-2.0833333333333286,1.75,4.249999999999986,0.75,2.083333333333343,2.1666666666666714,-1.0,2.3333333333333286,1.9166666666666714,1.5833333333333286,2.0,2.9166666666666714,2.833333333333343,3.916666666666657,3.6666666666666714,0.1666666666666714,5.083333333333329,-1.6666666666666714,-0.5,2.500000000000014,0.0,2.833333333333343,5.0,4.083333333333329,0.8333333333333428,3.083333333333343,4.333333333333343,3.0,5.666666666666671,5.666666666666671,1.4166666666666714,5.0,2.0,2.9166666666666714,0.25,3.1666666666666714,4.333333333333343,1.3333333333333286,4.000000000000014,3.9166666666666714,0.0,3.4166666666666714,1.75,1.8333333333333428,1.25,0.5,2.0,2.833333333333343,2.5833333333333286,6.666666666666671,1.25,2.500000000000014,-0.9166666666666714,3.75,1.1666666666666714,-1.0000000000000142,1.5000000000000142,2.6666666666666714,5.5,2.6666666666666714,6.75,1.75,1.3333333333333286,2.750000000000014,3.083333333333343,3.833333333333343,2.333333333333343,3.6666666666666714,2.9166666666666714,5.583333333333329,-1.9166666666666714,8.416666666666657,0.25,3.500000000000014,7.333333333333343,0.3333333333333286,2.833333333333343,0.9166666666666714,0.9166666666666714,3.3333333333333286,1.8333333333333428,2.833333333333343,2.500000000000014,-0.9166666666666714,-0.3333333333333286,1.0,3.750000000000014,3.9166666666666714,4.166666666666686,4.666666666666671,3.6666666666666714,-0.1666666666666572,2.4166666666666714,4.249999999999986,0.25,-1.1666666666666714,2.5833333333333286,0.25,-1.8333333333333428,2.4166666666666714,0.3333333333333286,1.5000000000000142,5.000000000000014,1.5000000000000142,5.083333333333329,-0.5,3.0,1.0833333333333286,2.333333333333343,-0.5833333333333286,1.8333333333333428,-1.1666666666666714,1.4166666666666714,0.6666666666666714,3.1666666666666856,4.25,2.5833333333333286,1.75,1.3333333333333286,2.9166666666666714,0.4166666666666643,0.0833333333333286,1.0833333333333428,0.3333333333333428,-0.0833333333333286,4.666666666666671,0.0833333333333286,1.8333333333333428,-2.249999999999986,0.9166666666666714,0.3333333333333286,2.4166666666666714,-4.250000000000007,1.1666666666666714,1.25,3.5,3.833333333333343,2.3333333333333286,0.5833333333333286,-0.25,2.4166666666666643,4.416666666666671,-1.5,1.75,2.6666666666666714,3.500000000000014,3.0833333333333286,1.4166666666666714,1.4166666666666714,2.6666666666666714,2.9166666666666714,4.833333333333343,1.8333333333333428,-1.25,2.4166666666666714,5.166666666666671,3.0,-1.25,2.750000000000014,-1.4166666666666714,0.5,3.25,-0.1666666666666572,2.750000000000014,0.0,1.2500000000000142,2.333333333333343,2.5833333333333286,2.0,2.6666666666666714,2.6666666666666714,4.916666666666671,3.083333333333343,3.6666666666666714,1.75,2.5,3.333333333333343,2.750000000000014,1.6666666666666572,4.5,3.4166666666666714,2.083333333333343,4.166666666666671,2.0,1.8333333333333428,0.1666666666666714,4.166666666666686,3.500000000000014,0.8333333333333428,3.750000000000014,2.250000000000014,1.6666666666666714,3.5833333333333286,1.4166666666666714,0.8333333333333428,4.666666666666657,3.25,0.5833333333333428,1.8333333333333428,4.416666666666671,1.1666666666666714,4.083333333333343,0.25,0.5833333333333428,2.25,5.5,3.833333333333343,2.6666666666666714,2.833333333333343,2.1666666666666714,1.9166666666666714,3.9166666666666714,2.1666666666666714,-2.000000000000014,6.083333333333329,4.166666666666671,7.000000000000014,1.0833333333333428,5.666666666666671,0.5,0.9166666666666714,5.416666666666671,-1.0833333333333286,1.25,3.4166666666666714,2.6666666666666714,2.5,2.5833333333333286,1.5833333333333286,1.5,0.4166666666666643,1.0833333333333428,6.500000000000014,2.416666666666657,-0.3333333333333428,0.1666666666666714,2.4166666666666714,1.5000000000000142,0.4166666666666714,-0.0833333333333286,2.083333333333343,0.5,0.9166666666666572,4.083333333333329,-4.000000000000014,0.4166666666666714,0.3333333333333286,0.6666666666666714,0.9166666666666714,1.0833333333333428,0.5833333333333286,7.25,4.083333333333343,2.1666666666666714,1.3333333333333286,1.5,4.666666666666671,1.5833333333333428,4.083333333333329,2.25,-0.08333333333334281,1.1666666666666714,3.833333333333343,5.083333333333329,3.833333333333343,2.833333333333343,1.0833333333333286,0.9166666666666572,2.9166666666666714,1.8333333333333428,0.4166666666666714,2.25,0.25,6.75,5.750000000000014,4.416666666666671,1.5,-1.0833333333333286,4.25,1.0,5.833333333333343,2.333333333333343,0.8333333333333428,3.1666666666666714,0.4166666666666714,2.0,-1.0000000000000142,-0.25,7.416666666666671,2.750000000000014,6.666666666666671,0.0,1.3333333333333286,0.4166666666666714,1.0833333333333428,1.9166666666666714,0.8333333333333428,1.9166666666666714,1.5833333333333428,0.5,1.4166666666666714,3.250000000000014,1.5000000000000142,5.416666666666671,2.1666666666666714,2.1666666666666714,4.833333333333343,3.25,4.083333333333343,4.083333333333343,2.9166666666666643,-2.0833333333333286,2.25,0.8333333333333428,2.0,1.4166666666666714,3.4166666666666714,5.0,-1.8333333333333286,3.9166666666666714,3.1666666666666714,2.4166666666666714,0.5,3.666666666666657,3.3333333333333286,1.4166666666666714,5.833333333333343,-1.9166666666666643,2.333333333333343,4.083333333333343,-2.833333333333343,0.3333333333333286,6.583333333333329,-0.0833333333333286,3.083333333333343,4.416666666666657,-0.75,0.0,-4.75,5.5,-2.250000000000014,6.416666666666671,3.25,-4.916666666666664,2.4166666666666714,2.25,3.0,3.250000000000014,2.1666666666666714,5.333333333333343,3.3333333333333286,1.9166666666666714,2.3333333333333286,0.75,0.0,5.25,4.750000000000014,-1.1666666666666714,2.583333333333343,4.333333333333343,1.1666666666666714,-0.1666666666666714,3.999999999999986,2.333333333333343,1.4166666666666714,1.8333333333333428,0.5,4.5,5.75,1.5833333333333286,0.1666666666666714,2.25,4.666666666666671,2.1666666666666714,1.8333333333333428,1.8333333333333428,5.75,3.4166666666666714,3.083333333333343,-0.3333333333333428,1.5833333333333428,5.916666666666657,4.416666666666671,5.25,0.5833333333333286,2.583333333333343,-0.25,-0.0833333333333286,1.3333333333333286,1.3333333333333286,-0.4166666666666572,1.4166666666666714,3.583333333333343,3.0833333333333286,2.9166666666666714,3.333333333333343,0.6666666666666714,4.916666666666657,5.583333333333329,1.25,0.25,3.9166666666666714,1.2500000000000142,4.916666666666671,3.333333333333343,2.3333333333333286,4.916666666666671,0.6666666666666572,1.5833333333333286,0.25,4.833333333333343,4.000000000000014,1.9166666666666714,1.0,0.5,2.083333333333343,1.5,0.9166666666666572,-0.6666666666666714,-0.5833333333333286,3.083333333333343,-0.75,1.5833333333333428,4.500000000000014,-0.3333333333333428,2.6666666666666714,1.8333333333333428,2.5833333333333286,2.1666666666666714,4.500000000000014,1.1666666666666714,2.500000000000014,1.1666666666666714,1.4166666666666714,3.750000000000014,1.1666666666666714,-1.4166666666666714,-0.5,2.6666666666666714,0.8333333333333428,2.833333333333343,0.2500000000000142,3.3333333333333286,2.6666666666666714,1.1666666666666714,2.0,6.25,0.5,4.999999999999986,0.2500000000000142,4.25,1.1666666666666714,2.0,4.416666666666671,0.25,1.1666666666666714,0.3333333333333286,0.3333333333333286,1.1666666666666714,2.500000000000014,3.6666666666666714,0.75,3.333333333333343,5.333333333333343,-1.0833333333333144,0.9166666666666572,2.333333333333343,0.0833333333333286,0.5,4.25,1.5833333333333286,0.8333333333333428,0.3333333333333286,0.0,5.500000000000014,2.3333333333333286,3.0,1.8333333333333428,1.4166666666666714,1.6666666666666572,-0.9166666666666714,3.249999999999986,2.6666666666666714,2.833333333333343,1.5833333333333286,2.333333333333343,0.25,1.6666666666666714,1.0,1.25,0.1666666666666714,5.166666666666671,-2.5,1.5000000000000142,4.833333333333343,3.3333333333333286,2.6666666666666714,1.75,1.4166666666666714,-1.5,3.5833333333333286,0.5833333333333286,0.8333333333333286,3.666666666666657,2.500000000000014,2.0,1.6666666666666572,-2.999999999999993,3.25,-0.5,2.083333333333343,1.3333333333333286,4.666666666666657,2.083333333333343,3.833333333333343,4.833333333333343,0.0833333333333286,-2.0,1.8333333333333428,4.166666666666671,3.750000000000014,1.9166666666666714,4.083333333333343,4.75,0.9166666666666714,3.1666666666666714,2.0,0.25,0.25,4.166666666666686,2.75,1.4166666666666714,-1.4166666666666714,3.0,3.083333333333343,3.4166666666666714,5.333333333333343,3.9166666666666714,0.3333333333333286,-2.5833333333333286,3.0,4.0,2.083333333333343,3.083333333333343,5.583333333333343,-4.833333333333329,3.4166666666666714,4.25,2.500000000000014,2.500000000000014,3.9166666666666714,-3.8333333333333286,5.833333333333343,-3.4166666666666714,2.750000000000014,3.500000000000014,4.25,4.500000000000014,5.666666666666671,0.25,-0.6666666666666714,4.666666666666671,4.666666666666657,-1.25,6.500000000000014,0.0833333333333286,3.083333333333343,-0.75,-2.1666666666666714,2.0,-3.8333333333333286,-0.3333333333333428,0.25,-3.000000000000014,3.4166666666666714,-2.0833333333333144,-1.1666666666666714,-0.3333333333333428,0.4166666666666714,2.1666666666666714,1.3333333333333286,-1.1666666666666714,1.6666666666666572,-0.4166666666666572,5.583333333333343,-0.4166666666666572,-1.25,0.0,2.833333333333343,0.6666666666666572,0.9166666666666714,2.0833333333333215,0.8333333333333428,1.1666666666666714,5.833333333333343,0.0833333333333286,-1.0833333333333286,3.6666666666666714,1.9166666666666714,0.3333333333333286,0.0833333333333286,-0.75,7.75,-0.8333333333333286,1.4166666666666714,2.1666666666666714,-0.8333333333333286,2.6666666666666714,3.4166666666666714,3.1666666666666714,3.6666666666666714,0.2500000000000142,-1.6666666666666714,1.75,3.083333333333343,3.083333333333343,0.8333333333333428,-2.4166666666666714,-1.4166666666666572,5.000000000000014,0.1666666666666714,6.166666666666686,2.0,1.8333333333333428,-0.6666666666666714,2.4166666666666714,2.0833333333333357,2.5833333333333286,1.6666666666666714,-0.4166666666666572,2.500000000000014,0.25,2.4166666666666714,1.8333333333333428,2.583333333333343,3.5833333333333286,1.0833333333333428,1.0,1.3333333333333286,1.0833333333333286,2.25,4.25,0.8333333333333428,2.9166666666666714,-1.5833333333333428,4.083333333333343,0.3333333333333286,6.833333333333343,2.0,-0.9166666666666714,2.083333333333343,4.666666666666671,0.3333333333333286,0.75,1.2500000000000142,4.416666666666671,0.0,2.833333333333343,2.333333333333343,2.0,0.25,1.0833333333333286,3.0833333333333286,3.5833333333333286,2.0,3.6666666666666714,5.500000000000014,0.3333333333333286,4.000000000000014,1.0,3.833333333333343,3.25,4.416666666666671,3.750000000000014,1.8333333333333428,2.6666666666666714,1.25,-3.083333333333343,1.5000000000000142,2.4166666666666714,4.833333333333329,2.9166666666666643,4.25,4.333333333333343,2.833333333333343,1.0833333333333286,-3.000000000000014,3.9166666666666714,1.9166666666666714,3.4166666666666714,-2.000000000000014,2.4166666666666714,7.666666666666671,4.25,1.8333333333333428,3.25,0.5,5.333333333333336,1.1666666666666714,0.8333333333333428,-0.75,1.5000000000000142,-0.2499999999999858,4.000000000000014,3.0,3.0,1.5000000000000142,5.166666666666686,-0.9166666666666572,5.500000000000014,1.0833333333333286,2.3333333333333357,2.500000000000014,2.5833333333333286,3.1666666666666714,5.416666666666671,4.583333333333329,2.333333333333343,1.4166666666666714,5.916666666666657,1.6666666666666714,4.083333333333343,3.3333333333333286,2.4166666666666714,3.4166666666666714,1.0,5.083333333333329,2.500000000000014,4.333333333333343,4.166666666666686,3.0,3.0,2.250000000000014,2.3333333333333286,-3.749999999999993,3.583333333333343,-0.6666666666666714,6.666666666666671,0.2500000000000142,-1.9166666666666714,3.083333333333343,0.4166666666666714,1.0,5.583333333333343,4.333333333333343,-1.0,0.5,1.9166666666666714,3.083333333333343,1.6666666666666714,-2.3333333333333286,1.5000000000000142,0.9166666666666572,1.4166666666666714,3.750000000000014,3.333333333333343,-1.9166666666666714,5.166666666666686,1.75,2.9166666666666714,1.0,3.6666666666666714,1.9166666666666714,2.750000000000014,6.000000000000014,1.4166666666666643,2.333333333333343,3.9166666666666714,6.333333333333343,1.6666666666666714,-0.25,0.3333333333333286,1.3333333333333286,5.000000000000014,1.0833333333333286,4.750000000000014,1.1666666666666714,4.0,3.333333333333343,1.8333333333333428,4.333333333333343,3.9166666666666714,1.0833333333333286,2.583333333333343,1.5000000000000142,2.1666666666666714,-0.3333333333333428,4.000000000000014,3.833333333333343,4.083333333333343,-1.4166666666666572,1.1666666666666714,-0.4166666666666572,1.75,0.25,3.083333333333343,0.75,1.6666666666666714,4.666666666666671,-0.9166666666666714,2.1666666666666714,5.666666666666671,4.166666666666686,3.333333333333343,3.0,4.166666666666686,4.666666666666671,4.166666666666686,-1.1666666666666714,2.1666666666666714,2.4166666666666714,5.166666666666686,4.750000000000014,3.416666666666657,0.25,3.0,7.583333333333329,1.5833333333333428,2.750000000000014,2.500000000000014,4.333333333333343,2.583333333333343,1.4166666666666714,2.6666666666666714,3.9166666666666714,1.4166666666666714,-1.5,2.1666666666666714,-0.3333333333333428,1.0,4.25,5.916666666666671,5.083333333333343,1.3333333333333286,3.083333333333343,1.25,2.833333333333343,4.75,-0.3333333333333357,1.9166666666666714,4.25,3.083333333333343,1.0,-0.25,0.8333333333333428,2.6666666666666714,4.083333333333343,0.25,3.4166666666666714,-0.75,1.249999999999993,3.3333333333333286,1.3333333333333286,7.416666666666671,2.0,2.333333333333343,0.1666666666666714,1.5833333333333286,4.833333333333343,-1.5833333333333428,2.333333333333343,3.0,-2.1666666666666714,-3.0833333333333144,0.8333333333333428,2.9166666666666714,0.0833333333333286,3.0,4.333333333333329,2.9166666666666714,1.2500000000000142,2.083333333333343,-5.083333333333336,5.416666666666671,0.75,-1.9166666666666572,3.4166666666666714,4.500000000000014,1.4166666666666714,3.833333333333343,3.750000000000014,3.6666666666666714,2.4166666666666714,1.6666666666666714,3.25,3.0,0.9166666666666714,6.666666666666671,4.333333333333343,3.4166666666666714,0.2500000000000142,0.9166666666666572,2.3333333333333286,3.500000000000014,1.75,3.999999999999986,0.5833333333333286,-0.5,3.083333333333343,2.833333333333343,0.9166666666666714,0.5833333333333286,1.75,3.083333333333343,0.2499999999999858,4.916666666666657,2.0,1.4166666666666714,1.25,1.4166666666666714,0.0833333333333286,1.9166666666666572,3.6666666666666714,3.083333333333343,3.9166666666666714,3.75,1.3333333333333286,2.25,1.75,3.1666666666666856,1.9166666666666714,2.1666666666666714,3.0,-0.1666666666666714,1.9166666666666714,2.3333333333333286,0.4166666666666643,4.25,5.916666666666671,3.333333333333343,1.3333333333333286,1.8333333333333428,2.833333333333343,2.4166666666666714,5.833333333333343,2.833333333333343,1.0,3.583333333333343,1.8333333333333428,3.750000000000014,1.8333333333333428,-1.25,3.333333333333343,3.1666666666666856,0.8333333333333428,3.333333333333343,0.3333333333333286,6.000000000000014,4.166666666666671,-0.8333333333333286,3.333333333333343,2.4166666666666714,0.9166666666666572,-0.6666666666666572,0.8333333333333428,3.5833333333333286,3.0833333333333286,5.583333333333343,2.500000000000014,-0.5,2.3333333333333286,1.1666666666666714,0.75,-0.8333333333333286,2.0,1.9166666666666714,5.416666666666671,4.25,6.000000000000014,1.5833333333333286,4.500000000000014,1.25,1.5833333333333286,0.9166666666666572],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Accuracy Difference (Moving Average)\",\"x\":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999],\"y\":[1.3500000000000016,1.4333333333333356,1.4833333333333356,1.4972222222222247,1.641666666666669,1.633333333333336,1.5916666666666692,1.605555555555558,1.541666666666669,1.519444444444447,1.6444444444444464,1.633333333333335,1.6833333333333356,1.8777777777777804,1.9527777777777806,1.9416666666666698,1.8555555555555583,1.8861111111111137,1.7416666666666696,1.7805555555555586,1.7944444444444472,1.8250000000000022,1.8277777777777808,1.6666666666666694,1.5361111111111136,1.5083333333333364,1.4888888888888923,1.6250000000000029,1.6666666666666694,1.597222222222225,1.57777777777778,1.5361111111111128,1.4722222222222239,1.536111111111113,1.508333333333336,1.6805555555555578,1.7777777777777801,1.7250000000000023,1.955555555555558,1.9444444444444466,1.6750000000000027,1.6750000000000025,1.744444444444447,1.6083333333333356,1.4222222222222243,1.55277777777778,1.566666666666669,1.5444444444444467,1.6611111111111134,1.5666666666666687,1.4833333333333358,1.2166666666666697,1.155555555555558,1.3250000000000028,1.4250000000000034,1.480555555555559,1.4611111111111146,1.4666666666666701,1.4277777777777814,1.4777777777777816,1.5527777777777823,1.53055555555556,1.5277777777777823,1.4000000000000041,1.3694444444444487,1.3083333333333385,1.2083333333333384,1.1500000000000055,0.972222222222228,0.9583333333333388,1.0833333333333395,1.1722222222222283,1.1305555555555615,1.0861111111111168,1.1666666666666725,1.080555555555561,1.188888888888894,1.177777777777783,1.2166666666666717,1.2583333333333384,1.3972222222222275,1.6472222222222275,1.5805555555555608,1.5166666666666717,1.397222222222227,1.2805555555555599,1.38055555555556,1.4083333333333379,1.5138888888888933,1.4777777777777814,1.3250000000000028,1.3250000000000033,1.5083333333333366,1.5388888888888914,1.4944444444444474,1.416666666666669,1.6000000000000023,1.6166666666666687,1.6250000000000022,1.5388888888888914,1.5333333333333359,1.4138888888888907,1.4666666666666686,1.6666666666666687,1.7472222222222242,1.6250000000000018,1.3750000000000009,1.3111111111111122,1.2694444444444457,1.2416666666666676,1.1666666666666676,1.033333333333334,1.0500000000000014,1.0888888888888903,1.341666666666668,1.3888888888888902,1.2805555555555568,1.1861111111111122,1.0166666666666682,0.9527777777777791,1.2166666666666688,1.2055555555555573,1.1138888888888905,1.1138888888888907,1.055555555555557,1.036111111111113,0.8583333333333351,0.7944444444444456,0.8277777777777792,1.0055555555555566,0.9750000000000011,0.8388888888888901,0.7500000000000011,0.5972222222222235,0.6111111111111122,0.8055555555555569,0.9416666666666688,0.8833333333333349,0.8611111111111124,0.8138888888888904,0.7611111111111128,0.8083333333333355,0.6916666666666679,0.5500000000000013,0.45000000000000173,0.3750000000000017,0.508333333333335,0.4000000000000012,0.4305555555555564,0.43333333333333457,0.1805555555555564,0.14166666666666738,0.11388888888888976,0.18055555555555639,0.32500000000000073,0.3916666666666674,0.49722222222222284,0.5777777777777785,0.5833333333333338,0.44444444444444514,0.5777777777777791,0.727777777777779,0.8083333333333347,0.7916666666666681,0.6694444444444457,0.5583333333333342,0.5222222222222228,0.4583333333333339,0.5277777777777786,0.5166666666666676,0.383333333333334,0.4027777777777778,0.47777777777777786,0.47222222222222204,0.3055555555555549,0.29999999999999877,0.21388888888888738,0.28333333333333205,0.3333333333333321,0.47777777777777636,0.4916666666666654,0.5194444444444435,0.5472222222222212,0.4972222222222212,0.3333333333333326,0.22499999999999884,0.24722222222222118,0.24444444444444355,0.3083333333333326,0.391666666666666,0.3388888888888879,0.2972222222222212,0.26666666666666594,0.3083333333333326,0.3972222222222217,0.3583333333333331,0.44722222222222213,0.6166666666666669,0.5222222222222221,0.7111111111111111,0.9861111111111114,0.9305555555555562,0.9083333333333348,0.9750000000000015,1.025000000000002,1.2000000000000022,1.305555555555558,1.230555555555558,1.2416666666666694,1.1305555555555582,1.2027777777777806,1.1944444444444473,1.1694444444444472,1.041666666666669,1.1444444444444468,1.172222222222225,1.1083333333333356,1.0472222222222243,0.9638888888888908,1.0194444444444462,1.030555555555557,1.194444444444446,1.2222222222222237,1.186111111111113,1.2972222222222238,1.3666666666666687,1.3722222222222247,1.4166666666666694,1.3583333333333365,1.186111111111114,1.2055555555555582,1.1972222222222253,1.2277777777777805,1.2083333333333364,1.2750000000000026,1.1833333333333365,1.1027777777777805,1.1388888888888915,1.219444444444447,1.2250000000000028,1.2805555555555586,1.3166666666666695,1.4527777777777806,1.6277777777777807,1.561111111111114,1.5000000000000027,1.4861111111111143,1.5972222222222257,1.580555555555559,1.4305555555555594,1.3972222222222261,1.2694444444444482,1.275000000000004,1.186111111111115,1.1111111111111152,1.1388888888888917,1.19166666666667,1.2416666666666694,1.300000000000002,1.461111111111113,1.2611111111111133,1.2694444444444462,1.255555555555557,1.2472222222222231,1.083333333333334,0.9361111111111116,0.8444444444444452,0.8777777777777784,0.8611111111111115,0.736111111111111,0.5638888888888887,0.5749999999999995,0.4500000000000002,0.38611111111111135,0.38888888888888856,0.5472222222222225,0.572222222222222,0.5138888888888885,0.6499999999999999,0.7694444444444448,0.7944444444444447,0.8833333333333333,0.7944444444444443,0.9666666666666665,0.9472222222222225,0.8472222222222229,0.6944444444444449,0.7138888888888896,0.8333333333333344,0.7972222222222233,0.866666666666668,0.9361111111111128,1.0444444444444467,1.07777777777778,1.2138888888888912,1.3583333333333356,1.3861111111111137,1.3611111111111143,1.2055555555555584,1.3138888888888924,1.402777777777781,1.4222222222222258,1.4583333333333366,1.6000000000000032,1.5722222222222255,1.4166666666666694,1.46666666666667,1.5583333333333367,1.4138888888888923,1.3333333333333368,1.2444444444444476,1.2666666666666697,1.3805555555555584,1.3333333333333361,1.333333333333336,1.2888888888888914,1.2444444444444474,1.1888888888888913,1.138888888888891,1.1277777777777798,1.125000000000002,1.1166666666666683,1.0666666666666682,1.036111111111113,1.0611111111111136,1.1388888888888915,1.1222222222222245,1.2638888888888913,1.3583333333333356,1.2944444444444463,1.3222222222222242,1.3444444444444468,1.2694444444444468,1.0666666666666687,1.1944444444444466,1.291666666666669,1.213888888888891,1.1138888888888911,1.0972222222222245,1.222222222222224,1.2527777777777798,1.17777777777778,1.2166666666666694,1.1916666666666693,1.1250000000000022,1.1444444444444468,1.2333333333333354,1.0750000000000022,1.0555555555555578,1.0333333333333357,1.008333333333335,0.8833333333333356,0.9611111111111138,0.9805555555555581,0.7861111111111134,0.7083333333333354,0.8194444444444469,0.7250000000000019,0.8583333333333356,0.9444444444444471,0.9777777777777803,0.797222222222224,0.8361111111111131,0.8500000000000023,1.008333333333335,0.9555555555555576,0.9222222222222242,0.869444444444446,1.0166666666666684,0.9888888888888908,1.0555555555555576,0.9638888888888909,0.8694444444444461,0.8333333333333348,0.8638888888888905,0.9222222222222239,0.972222222222224,1.1805555555555574,1.1333333333333353,1.036111111111113,0.961111111111113,0.8611111111111124,0.6583333333333339,0.6000000000000004,0.8222222222222227,0.7944444444444452,0.8250000000000004,0.8861111111111116,0.8138888888888889,0.866666666666667,1.0000000000000002,1.1111111111111116,1.091666666666667,1.0583333333333336,0.7666666666666673,0.7944444444444454,0.9027777777777787,1.0944444444444463,0.833333333333335,0.9111111111111132,0.7194444444444459,0.8555555555555567,0.8027777777777791,0.9083333333333349,0.9500000000000015,1.0694444444444462,1.038888888888891,1.1416666666666688,1.205555555555558,1.341666666666669,1.4388888888888913,1.5472222222222245,1.6750000000000027,1.7611111111111142,1.672222222222225,1.7694444444444473,1.7472222222222256,1.5750000000000026,1.5500000000000032,1.6111111111111143,1.602777777777781,1.6722222222222254,1.7805555555555594,1.8166666666666704,1.8444444444444485,1.9750000000000043,1.944444444444449,1.9472222222222264,2.202777777777782,1.9972222222222253,2.2527777777777818,2.1111111111111143,2.150000000000003,2.125000000000003,2.1611111111111136,2.0277777777777803,2.125000000000002,1.9527777777777797,1.9111111111111125,1.7750000000000017,1.7305555555555574,1.8500000000000023,1.8194444444444466,1.8666666666666685,1.913888888888891,1.8083333333333347,1.7750000000000015,1.8277777777777795,1.7611111111111122,1.6333333333333346,1.5555555555555571,1.483333333333335,1.4333333333333342,1.4000000000000012,1.4111111111111123,1.2527777777777784,1.177777777777778,1.0583333333333333,0.8527777777777775,0.9166666666666673,0.938888888888889,0.925,1.0611111111111116,1.0722222222222224,1.1861111111111118,1.1555555555555566,1.077777777777779,0.9805555555555566,0.8972222222222228,0.8722222222222227,0.8277777777777781,0.6277777777777774,0.6722222222222217,0.6027777777777775,0.6583333333333328,0.7305555555555552,0.7083333333333328,0.8388888888888886,0.8694444444444444,0.9361111111111109,0.7861111111111105,0.8083333333333329,0.8638888888888885,1.05,1.0555555555555556,1.1666666666666665,1.3361111111111112,1.450000000000001,1.6916666666666682,1.61388888888889,1.4194444444444452,1.5250000000000012,1.3805555555555562,1.4055555555555561,1.3833333333333333,1.3777777777777782,1.3333333333333333,1.4666666666666672,1.5583333333333342,1.7166666666666677,1.9222222222222232,2.0916666666666677,1.9555555555555568,1.894444444444445,1.8888888888888895,2.002777777777778,2.052777777777778,1.8638888888888892,1.775,1.7527777777777775,1.8083333333333338,1.7222222222222223,1.5249999999999992,1.3444444444444437,1.3611111111111103,1.2861111111111108,1.1083333333333327,1.0916666666666657,1.0194444444444435,1.2083333333333324,1.308333333333333,1.2444444444444447,1.2666666666666668,1.086111111111111,1.1083333333333332,1.2444444444444442,1.2611111111111113,1.1555555555555557,1.0861111111111108,0.9916666666666667,0.8500000000000004,0.7666666666666672,0.855555555555556,0.9805555555555564,0.9055555555555567,0.5944444444444456,0.5111111111111128,0.5583333333333352,0.6361111111111133,0.6305555555555575,0.7111111111111128,0.8194444444444461,1.0833333333333353,1.1583333333333357,1.25277777777778,1.2833333333333352,1.42777777777778,1.2361111111111138,1.2250000000000023,1.1194444444444467,1.1833333333333353,1.2861111111111128,1.3638888888888911,1.4750000000000028,1.3277777777777806,1.1944444444444469,1.2000000000000022,1.305555555555558,1.3944444444444473,1.5027777777777809,1.4750000000000032,1.4972222222222256,1.450000000000003,1.3305555555555582,1.3472222222222252,1.4250000000000034,1.5000000000000033,1.5027777777777809,1.6944444444444478,1.6638888888888919,1.6222222222222251,1.6805555555555591,1.5166666666666702,1.4944444444444476,1.4277777777777811,1.408333333333337,1.4472222222222262,1.405555555555559,1.3861111111111144,1.4222222222222263,1.2277777777777819,1.1888888888888927,1.2000000000000035,1.1805555555555587,1.1527777777777806,1.3583333333333367,1.3333333333333366,1.1972222222222262,1.2083333333333373,1.1972222222222262,1.2111111111111148,1.1777777777777818,1.2972222222222265,1.3027777777777816,1.3555555555555592,1.3888888888888926,1.3472222222222259,1.4305555555555596,1.3250000000000037,1.3694444444444482,1.4055555555555599,1.4611111111111146,1.375000000000003,1.5277777777777808,1.5638888888888918,1.5250000000000026,1.5027777777777807,1.6722222222222254,1.7222222222222257,1.6583333333333372,1.8638888888888927,1.8750000000000042,1.872222222222227,1.8916666666666717,1.9111111111111165,1.7805555555555603,1.8083333333333385,1.8805555555555604,1.8194444444444495,1.8388888888888937,1.7805555555555606,1.897222222222227,1.7333333333333378,1.7805555555555608,1.7611111111111166,1.9055555555555606,1.9027777777777826,1.927777777777782,1.869444444444449,1.8638888888888936,1.8277777777777824,1.627777777777783,1.6694444444444494,1.561111111111116,1.427777777777783,1.5027777777777833,1.3583333333333385,1.3750000000000053,1.3333333333333386,1.2722222222222273,1.2166666666666714,1.1611111111111156,1.0972222222222263,1.1166666666666702,1.2444444444444482,1.227777777777782,1.2166666666666706,1.172222222222226,1.2250000000000036,1.105555555555559,1.158333333333337,1.044444444444448,1.1333333333333369,1.1583333333333368,1.0194444444444475,0.8305555555555592,0.7972222222222257,0.7000000000000035,0.7472222222222258,0.7972222222222253,0.6833333333333362,0.761111111111114,0.8861111111111144,0.8555555555555586,0.8166666666666701,0.7222222222222248,0.613888888888891,0.5666666666666687,0.5277777777777801,0.7638888888888916,0.6805555555555582,0.6444444444444468,0.697222222222225,0.8055555555555577,0.7388888888888909,0.7472222222222243,0.7333333333333353,0.741666666666668,0.6833333333333343,0.6944444444444458,0.7416666666666676,0.7972222222222233,0.8166666666666675,0.7500000000000009,0.9083333333333342,0.9222222222222228,0.9583333333333337,0.8944444444444448,0.8166666666666668,0.8111111111111109,1.0638888888888896,0.9333333333333338,0.9305555555555557,0.902777777777778,1.0444444444444447,1.0638888888888893,1.208333333333334,1.2416666666666671,1.275,1.2694444444444446,1.227777777777778,1.3472222222222225,1.2722222222222226,1.2083333333333341,1.2333333333333338,1.3888888888888897,1.3777777777777787,1.4333333333333347,1.5361111111111132,1.6694444444444467,1.6611111111111132,1.6694444444444465,1.661111111111113,1.6361111111111133,1.6666666666666696,1.6361111111111142,1.5861111111111144,1.6833333333333367,1.7138888888888923,1.7472222222222258,1.5416666666666698,1.54166666666667,1.2861111111111143,1.3000000000000034,1.2861111111111143,1.3444444444444477,1.3388888888888926,1.272222222222226,1.1250000000000033,0.9805555555555583,0.9500000000000027,0.9472222222222253,1.0361111111111139,0.963888888888892,0.872222222222225,0.7916666666666694,0.8000000000000027,0.7472222222222243,0.6972222222222237,0.43611111111111284,0.3611111111111129,0.37500000000000194,0.463888888888891,0.6972222222222243,0.6000000000000019,0.7388888888888905,0.7027777777777791,0.6111111111111124,0.600000000000001,0.5583333333333342,0.6444444444444453,0.7805555555555561,0.9611111111111124,0.9333333333333342,0.9305555555555566,1.0416666666666676,0.9805555555555565,1.1250000000000016,1.1750000000000016,1.286111111111113,1.4388888888888918,1.4194444444444472,1.3333333333333361,1.3638888888888914,1.500000000000003,1.4166666666666698,1.3805555555555589,1.4388888888888918,1.4972222222222251,1.8305555555555584,1.9583333333333364,1.869444444444447,1.7555555555555578,1.6388888888888906,1.5916666666666683,1.5583333333333351,1.6277777777777798,1.636111111111113,1.600000000000002,1.5250000000000021,1.6416666666666693,1.622222222222225,1.6555555555555583,1.6250000000000027,1.3861111111111133,1.2388888888888914,1.3861111111111137,1.380555555555558,1.5083333333333362,1.491666666666669,1.4027777777777795,1.4944444444444467,1.544444444444447,1.6888888888888918,1.5694444444444466,1.6444444444444468,1.7527777777777802,1.747222222222225,1.6083333333333367,1.4138888888888919,1.4527777777777813,1.702777777777782,1.750000000000004,1.7194444444444483,1.8027777777777816,1.8666666666666711,1.886111111111115,2.011111111111115,1.975000000000004,2.063888888888893,2.052777777777781,2.125000000000003,2.144444444444448,2.31666666666667,2.5222222222222266,2.6750000000000043,2.6638888888888936,2.677777777777783,2.6583333333333377,2.6000000000000045,2.5722222222222264,2.5250000000000035,2.5055555555555595,2.4861111111111143,2.4555555555555584,2.4694444444444477,2.4861111111111147,2.5000000000000036,2.5888888888888917,2.6944444444444473,2.5472222222222247,2.383333333333336,2.263888888888891,2.2583333333333355,2.244444444444447,2.105555555555558,2.272222222222225,2.258333333333336,2.394444444444447,2.3472222222222245,2.147222222222225,2.0777777777777806,1.9944444444444471,1.9000000000000028,1.8750000000000027,1.6194444444444467,1.5694444444444466,1.494444444444446,1.591666666666668,1.6611111111111128,1.7750000000000021,1.8083333333333353,1.7944444444444467,1.6611111111111139,1.658333333333336,1.6250000000000027,1.594444444444447,1.636111111111114,1.6055555555555583,1.4472222222222246,1.5388888888888916,1.550000000000003,1.633333333333336,1.638888888888892,1.661111111111114,1.786111111111115,1.5972222222222257,1.5777777777777808,1.5750000000000035,1.6305555555555593,1.6250000000000042,1.547222222222226,1.608333333333337,1.6194444444444485,1.8138888888888927,1.9916666666666711,2.122222222222227,2.0666666666666718,1.9416666666666715,1.9694444444444494,1.997222222222227,1.9222222222222267,1.813888888888893,1.8361111111111152,1.8972222222222264,1.925000000000004,1.8666666666666705,1.8222222222222262,1.9111111111111152,1.9500000000000044,2.108333333333338,2.044444444444449,2.0194444444444493,2.1111111111111156,2.075000000000004,2.061111111111115,2.138888888888893,2.108333333333338,2.011111111111116,1.8750000000000044,2.069444444444449,2.1111111111111156,2.2000000000000046,2.297222222222226,2.183333333333337,2.1861111111111144,2.0750000000000033,2.027777777777781,2.1055555555555587,2.1194444444444476,2.194444444444448,2.3138888888888927,2.4111111111111154,2.3666666666666707,2.469444444444448,2.555555555555559,2.7388888888888925,2.861111111111114,2.752777777777781,2.7888888888888914,2.663888888888892,2.6666666666666696,2.6972222222222255,2.4861111111111143,2.550000000000003,2.6138888888888916,2.450000000000003,2.547222222222225,2.62777777777778,2.7888888888888923,2.8083333333333367,2.8611111111111147,2.5861111111111144,2.361111111111114,2.4666666666666694,2.425000000000003,2.469444444444447,2.580555555555558,2.5638888888888918,2.508333333333335,2.4222222222222234,2.3000000000000007,2.3083333333333345,2.4527777777777793,2.269444444444446,2.1138888888888907,1.9444444444444455,1.8861111111111128,1.7305555555555572,1.6750000000000018,1.669444444444446,1.7916666666666683,1.905555555555557,1.9222222222222234,1.8833333333333349,1.8250000000000017,1.9527777777777802,1.9083333333333359,1.8416666666666692,1.6722222222222238,1.5722222222222237,1.5194444444444455,1.8111111111111122,2.0416666666666683,1.8861111111111128,1.8416666666666686,1.7444444444444458,1.8194444444444464,1.7222222222222239,1.7388888888888907,1.6833333333333358,1.6083333333333358,1.7555555555555582,1.8083333333333362,1.825000000000003,1.7944444444444474,1.8583333333333363,1.8194444444444469,2.0750000000000033,2.1750000000000034,2.188888888888892,2.2472222222222262,2.152777777777782,2.172222222222227,2.158333333333338,2.1750000000000043,2.1194444444444485,2.0666666666666704,2.1416666666666706,2.252777777777782,2.286111111111116,2.391666666666671,2.333333333333337,2.213888888888892,2.219444444444447,2.250000000000002,2.3555555555555583,2.272222222222225,2.2277777777777805,2.247222222222225,2.300000000000003,2.5000000000000036,2.3611111111111147,2.16666666666667,2.244444444444448,2.347222222222226,2.2166666666666703,2.09166666666667,1.9777777777777803,1.7500000000000022,1.6388888888888908,1.6388888888888904,1.6694444444444458,1.8027777777777798,1.7694444444444464,1.8444444444444468,1.797222222222224,1.9111111111111128,1.891666666666668,1.9000000000000012,1.8722222222222231,1.875000000000001,1.8333333333333344,1.7638888888888902,1.7916666666666683,1.786111111111113,1.7250000000000016,1.7138888888888903,1.880555555555557,1.8833333333333357,1.8194444444444462,1.7111111111111126,1.7166666666666681,1.7638888888888906,1.8888888888888906,1.7527777777777795,1.8472222222222248,1.8944444444444473,2.0166666666666693,2.255555555555559,2.233333333333337,2.013888888888893,2.0888888888888926,2.0722222222222255,2.1527777777777812,2.0388888888888923,2.1833333333333376,2.019444444444449,1.9972222222222271,1.9694444444444497,2.077777777777783,2.0750000000000046,2.066666666666672,2.1833333333333385,2.125000000000005,2.1916666666666718,2.0944444444444494,2.1277777777777835,1.9972222222222276,1.9666666666666717,1.9277777777777831,1.9750000000000052,1.9361111111111162,1.9305555555555607,1.7416666666666711,1.7805555555555597,1.7444444444444485,1.9194444444444485,1.869444444444449,1.8472222222222268,1.9166666666666714,2.077777777777782,2.0972222222222263,2.163888888888893,2.169444444444449,2.183333333333338,2.0805555555555597,1.9888888888888923,1.9166666666666698,1.8333333333333364,1.7305555555555583,1.7055555555555586,1.6361111111111135,1.6861111111111136,1.7222222222222248,1.700000000000003,1.8722222222222256,1.8833333333333364,1.9750000000000036,1.9250000000000043,2.0638888888888935,2.0305555555555603,2.072222222222227,2.027777777777782,2.2444444444444493,2.3555555555555605,2.561111111111116,2.3861111111111155,2.4777777777777823,2.4694444444444485,2.416666666666671,2.313888888888893,2.1333333333333377,2.0222222222222257,1.8805555555555589,1.8722222222222258,1.9138888888888923,2.027777777777782,2.000000000000004,2.0666666666666704,2.0833333333333375,2.002777777777781,2.0694444444444478,1.8916666666666697,1.8638888888888916,1.813888888888891,1.7638888888888906,1.7305555555555574,1.6611111111111125,1.700000000000001,1.5777777777777782,1.5583333333333333,1.5388888888888885,1.6166666666666665,1.4638888888888888,1.4000000000000001,1.2055555555555557,1.2416666666666667,1.0833333333333335,1.0861111111111115,1.1611111111111114,1.2555555555555562,1.275000000000001,1.244444444444446,1.2833333333333345,1.1722222222222232,1.1555555555555568,1.325000000000001,1.3583333333333345,1.2444444444444458,1.144444444444445,1.0138888888888893,0.9805555555555566,1.0361111111111125,1.1250000000000018,1.1972222222222242,1.1194444444444467,1.088888888888891,1.1027777777777794,1.002777777777779,1.0888888888888908,0.9805555555555576,1.1500000000000026,1.000000000000002,1.0111111111111128,0.9805555555555567,0.9750000000000011,0.9750000000000009,1.125000000000001,1.0500000000000007,1.0388888888888885,0.8944444444444442,0.9694444444444442,1.1416666666666662,1.2388888888888885,1.3222222222222222,1.2222222222222217,1.161111111111111,1.1416666666666664,1.2583333333333333,1.2999999999999998,1.5666666666666675,1.5388888888888896,1.5944444444444446,1.5138888888888893,1.5583333333333331,1.6833333333333336,1.7777777777777777,1.8583333333333338,1.9500000000000013,1.9388888888888898,1.9944444444444462,1.93888888888889,2.002777777777779,1.9416666666666682,1.9916666666666685,2.116666666666669,2.2083333333333357,2.013888888888892,2.1361111111111137,2.108333333333337,2.2250000000000036,2.2055555555555593,2.161111111111115,2.1277777777777818,2.1416666666666706,2.252777777777782,2.2111111111111157,2.4166666666666714,2.4277777777777825,2.2472222222222267,2.2055555555555593,2.3027777777777816,2.3777777777777827,2.4527777777777824,2.297222222222227,2.308333333333338,2.1833333333333385,2.188888888888893,2.1361111111111155,2.05555555555556,2.2000000000000046,2.069444444444449,2.1750000000000047,2.227777777777783,2.14444444444445,2.1722222222222283,2.1694444444444496,2.238888888888894,2.2611111111111164,2.3083333333333393,2.2222222222222276,2.225000000000005,2.2000000000000055,2.1638888888888936,2.197222222222227,2.2083333333333375,2.241666666666671,2.1277777777777827,2.1250000000000058,2.2361111111111165,2.066666666666672,2.047222222222228,1.8722222222222271,1.9277777777777823,2.0555555555555602,2.036111111111116,2.1444444444444493,2.1555555555555603,2.236111111111115,2.316666666666671,2.1777777777777816,2.222222222222226,2.150000000000004,2.1250000000000036,2.197222222222225,2.1194444444444476,2.0611111111111144,2.0861111111111144,2.105555555555559,2.175000000000004,2.3777777777777818,2.3805555555555595,2.2277777777777814,2.2138888888888935,2.3277777777777833,2.319444444444449,2.2333333333333365,2.1083333333333365,1.9166666666666692,2.1722222222222247,2.3222222222222246,2.294444444444447,2.483333333333336,2.458333333333336,2.5583333333333362,2.5333333333333363,2.561111111111114,2.5361111111111145,2.5027777777777813,2.4861111111111147,2.5500000000000034,2.6361111111111146,2.6361111111111146,2.627777777777781,2.758333333333337,2.702777777777781,2.6277777777777813,2.6166666666666707,2.6138888888888925,2.49166666666667,2.3722222222222253,2.3222222222222246,2.450000000000003,2.450000000000003,2.258333333333336,2.4083333333333363,2.4583333333333366,2.6250000000000036,2.833333333333337,2.7500000000000036,2.738888888888893,2.6361111111111146,2.6388888888888924,2.5250000000000026,2.363888888888892,2.388888888888892,2.130555555555558,2.1055555555555587,2.122222222222226,2.1750000000000034,2.2277777777777805,2.0083333333333355,2.061111111111114,2.0111111111111137,1.944444444444447,1.947222222222225,1.9638888888888921,1.8805555555555586,1.8527777777777805,1.8555555555555583,1.8166666666666695,1.9583333333333368,1.9500000000000037,1.9277777777777811,1.9944444444444482,1.769444444444448,1.7388888888888925,1.5194444444444475,1.4638888888888915,1.3916666666666688,1.3500000000000023,1.4361111111111138,1.4111111111111139,1.3472222222222248,1.2861111111111132,1.2555555555555582,1.5666666666666695,1.6555555555555581,1.7027777777777806,1.6527777777777806,1.550000000000003,1.7833333333333377,1.775000000000004,1.8388888888888926,1.8194444444444484,1.905555555555559,1.8222222222222253,2.0222222222222253,1.9166666666666696,1.9444444444444473,1.8527777777777803,1.6972222222222249,1.7388888888888914,1.8388888888888915,1.819444444444447,1.905555555555558,1.9472222222222246,2.158333333333336,2.1583333333333363,2.2361111111111143,2.3611111111111147,2.3861111111111146,2.2972222222222256,2.294444444444448,2.330555555555559,2.3055555555555585,2.1805555555555585,1.9472222222222255,1.8555555555555576,1.8972222222222246,1.8333333333333364,1.6694444444444467,1.5416666666666687,1.4916666666666691,1.5166666666666688,1.4888888888888907,1.5305555555555577,1.4361111111111131,1.4722222222222245,1.5388888888888916,1.5638888888888913,1.7750000000000021,1.7388888888888907,1.8027777777777798,1.833333333333335,1.855555555555557,1.8388888888888903,1.6944444444444453,1.7472222222222233,1.6333333333333342,1.5611111111111113,1.6083333333333332,1.6138888888888885,1.6583333333333328,1.7083333333333333,1.7805555555555552,1.827777777777777,1.9999999999999998,2.116666666666667,2.1222222222222227,2.2944444444444456,2.3361111111111126,2.4111111111111128,2.530555555555557,2.53888888888889,2.5888888888888903,2.680555555555557,2.7250000000000023,2.705555555555558,2.572222222222225,2.6444444444444475,2.5166666666666697,2.5166666666666697,2.330555555555559,2.280555555555559,2.1972222222222255,2.2583333333333364,2.469444444444448,2.508333333333337,2.500000000000004,2.502777777777782,2.322222222222227,2.3888888888888937,2.475000000000005,2.5083333333333386,2.3250000000000055,2.3194444444444504,2.300000000000006,2.177777777777784,2.2361111111111165,2.191666666666672,2.3138888888888944,2.222222222222228,2.11944444444445,1.975000000000005,1.8916666666666713,1.852777777777783,1.936111111111117,2.0861111111111166,2.0722222222222273,2.033333333333339,1.9361111111111164,1.888888888888894,2.0250000000000052,2.0861111111111157,2.2166666666666712,2.1777777777777825,2.1500000000000044,2.186111111111115,2.322222222222226,2.3027777777777816,2.4416666666666704,2.4027777777777817,2.4250000000000043,2.4333333333333376,2.5777777777777815,2.533333333333337,2.525000000000004,2.6166666666666707,2.486111111111115,2.569444444444449,2.452777777777783,2.6500000000000044,2.702777777777783,2.7583333333333386,2.8055555555555607,2.7916666666666714,2.7777777777777817,2.6611111111111145,2.761111111111115,2.819444444444448,2.944444444444448,2.9194444444444483,2.8666666666666707,2.838888888888893,2.7694444444444484,2.7750000000000044,2.6638888888888936,2.686111111111116,2.6111111111111165,2.6666666666666723,2.6138888888888947,2.672222222222228,2.5388888888888945,2.5361111111111163,2.516666666666672,2.4194444444444496,2.4472222222222273,2.3972222222222275,2.4333333333333393,2.2805555555555608,2.316666666666672,2.3250000000000055,2.3166666666666718,2.4500000000000055,2.3944444444444497,2.336111111111116,2.263888888888893,2.3083333333333376,2.325000000000005,2.272222222222227,2.2638888888888937,2.3583333333333387,2.3194444444444495,2.283333333333338,2.363888888888894,2.338888888888894,2.4055555555555603,2.2666666666666715,2.1916666666666713,2.2722222222222266,2.366666666666671,2.241666666666671,2.277777777777782,2.2472222222222267,2.366666666666671,2.4250000000000047,2.3527777777777823,2.2916666666666705,2.3833333333333373,2.5666666666666704,2.5000000000000036,2.4027777777777803,2.3583333333333356,2.377777777777781,2.386111111111114,2.461111111111115,2.5138888888888937,2.377777777777782,2.2027777777777815,2.183333333333338,2.1305555555555595,2.083333333333336,2.1277777777777813,2.1250000000000036,2.1166666666666707,2.008333333333337,2.0138888888888924,2.0916666666666694,2.1833333333333367,2.1055555555555587,2.055555555555559,2.2583333333333364,2.252777777777781,2.252777777777781,2.1583333333333363,2.075000000000003,2.038888888888891,2.213888888888891,1.9777777777777794,1.8333333333333348,1.8444444444444463,1.7972222222222245,1.9000000000000024,1.863888888888891,1.8583333333333356,1.9416666666666687,1.9388888888888909,1.9750000000000012,2.0250000000000017,2.0777777777777793,1.9333333333333342,1.9611111111111128,1.9638888888888908,2.0944444444444468,2.050000000000002,2.1638888888888914,2.180555555555558,2.0972222222222254,2.1083333333333365,2.0833333333333366,2.122222222222225,1.9638888888888917,2.04166666666667,1.9833333333333365,1.9555555555555588,2.0722222222222255,2.144444444444448,2.0916666666666703,2.3333333333333375,2.2972222222222265,2.2388888888888925,2.2222222222222254,2.1500000000000035,1.9361111111111147,1.9944444444444474,1.9805555555555583,1.9750000000000028,1.9583333333333366,2.063888888888892,2.1916666666666695,2.2916666666666696,2.3722222222222253,2.505555555555558,2.3638888888888916,2.308333333333336,2.236111111111113,2.141666666666669,2.2250000000000023,2.197222222222225,2.105555555555558,2.072222222222224,2.116666666666669,2.2361111111111134,2.3277777777777797,2.286111111111113,2.2333333333333356,2.305555555555558,2.32777777777778,2.2055555555555575,2.247222222222224,2.408333333333336,2.497222222222226,2.6527777777777812,2.650000000000003,2.6416666666666697,2.8194444444444478,2.747222222222226,2.863888888888892,2.855555555555559,2.7277777777777814,2.8472222222222263,2.750000000000003,2.6638888888888923,2.761111111111114,2.8083333333333367,2.963888888888893,2.886111111111115,2.755555555555559,2.775000000000004,2.8055555555555594,2.8611111111111143,2.7722222222222253,2.69166666666667,2.6250000000000027,2.5166666666666693,2.6472222222222253,2.6277777777777804,2.5861111111111144,2.500000000000003,2.422222222222225,2.2305555555555583,2.250000000000002,2.066666666666668,2.2694444444444466,2.40277777777778,2.180555555555558,2.122222222222225,1.997222222222225,1.8833333333333355,1.8611111111111134,1.8388888888888912,1.738888888888891,1.6166666666666687,1.5083333333333353,1.6166666666666687,1.650000000000002,1.8416666666666686,1.9722222222222243,1.9583333333333355,2.111111111111113,2.005555555555557,2.1500000000000012,2.1666666666666687,2.230555555555558,2.430555555555558,2.3611111111111134,2.4111111111111136,2.2861111111111128,2.3555555555555574,2.500000000000002,2.5583333333333353,2.611111111111113,2.6638888888888905,2.6000000000000014,2.441666666666668,2.55277777777778,2.7194444444444463,2.733333333333335,2.969444444444446,3.0305555555555572,3.0166666666666684,3.1722222222222243,3.1805555555555576,3.2194444444444468,2.9861111111111134,2.841666666666669,2.847222222222225,2.7666666666666693,2.7805555555555586,2.644444444444448,2.5861111111111144,2.4916666666666694,2.4222222222222243,2.4361111111111127,2.3638888888888903,2.411111111111112,2.208333333333335,2.283333333333335,2.1527777777777795,2.1000000000000014,2.141666666666668,2.0916666666666677,2.1583333333333345,2.1555555555555572,2.1083333333333356,1.9222222222222232,1.8972222222222235,1.9305555555555562,1.672222222222223,1.630555555555556,1.5861111111111117,1.4694444444444448,1.5916666666666677,1.433333333333334,1.5555555555555567,1.5805555555555568,1.5916666666666681,1.7361111111111127,1.7055555555555573,1.602777777777778,1.6722222222222232,1.68888888888889,1.6388888888888897,1.6166666666666671,1.647222222222223,1.5166666666666675,1.677777777777779,1.5972222222222237,1.8777777777777789,1.758333333333334,1.6611111111111116,1.5027777777777782,1.4444444444444453,1.4472222222222226,1.5055555555555558,1.6000000000000005,1.4888888888888892,1.5250000000000006,1.6555555555555568,1.5888888888888903,1.6833333333333342,1.7666666666666677,1.6805555555555565,1.966666666666668,1.9277777777777785,1.8916666666666675,1.8027777777777785,1.808333333333334,1.9027777777777788,2.169444444444446,2.300000000000002,2.219444444444447,2.2666666666666697,2.222222222222225,2.25277777777778,2.2944444444444474,2.2555555555555578,2.37777777777778,2.2888888888888914,2.3833333333333364,2.494444444444447,2.5527777777777807,2.611111111111114,2.619444444444447,2.655555555555558,2.5638888888888918,2.6166666666666702,2.622222222222226,2.5861111111111144,2.666666666666669,2.5388888888888923,2.5444444444444483,2.5027777777777813,2.375000000000004,2.4333333333333376,2.4222222222222265,2.5250000000000044,2.422222222222226,2.2527777777777813,2.036111111111114,1.9222222222222252,1.9888888888888918,1.9611111111111141,1.9750000000000036,2.0611111111111153,2.1333333333333386,2.205555555555561,2.391666666666672,2.4194444444444496,2.4000000000000057,2.358333333333339,2.4333333333333393,2.3111111111111167,2.2638888888888946,2.1888888888888944,2.200000000000006,2.008333333333338,2.002777777777782,1.9027777777777815,1.8444444444444488,1.8777777777777824,2.0861111111111157,2.144444444444449,2.2555555555555604,2.2555555555555604,2.4277777777777825,2.2166666666666717,2.3500000000000054,2.525000000000006,2.5472222222222287,2.619444444444451,2.6972222222222286,2.800000000000006,2.780555555555561,2.763888888888894,2.70555555555556,2.683333333333338,2.491666666666672,2.38055555555556,2.369444444444449,2.294444444444449,2.213888888888894,2.1666666666666714,2.2388888888888934,2.1555555555555603,2.1694444444444487,2.341666666666672,2.3611111111111165,2.605555555555562,2.5500000000000056,2.6194444444444502,2.3305555555555606,2.4027777777777835,2.383333333333338,2.402777777777783,2.3583333333333387,2.46944444444445,2.277777777777783,2.136111111111116,2.1777777777777825,2.1694444444444496,2.20555555555556,2.113888888888894,1.994444444444449,1.8916666666666706,1.8166666666666706,1.7277777777777816,1.7138888888888926,1.7833333333333368,1.861111111111114,1.99166666666667,2.0138888888888924,2.105555555555559,2.1694444444444483,2.2861111111111154,2.2972222222222265,2.1944444444444486,2.2222222222222263,2.1694444444444487,2.452777777777782,2.436111111111116,2.5305555555555608,2.4944444444444493,2.469444444444449,2.4000000000000044,2.2638888888888933,2.183333333333337,2.250000000000004,2.3833333333333373,2.3194444444444486,2.2277777777777805,2.07777777777778,2.111111111111114,2.366666666666669,2.444444444444447,2.461111111111115,2.527777777777781,2.572222222222226,2.4611111111111152,2.391666666666671,2.4444444444444486,2.5527777777777825,2.636111111111116,2.491666666666671,2.4944444444444485,2.575000000000004,2.802777777777782,2.858333333333337,2.744444444444448,2.5000000000000036,2.44166666666667,2.325000000000003,2.233333333333336,2.1638888888888914,2.3111111111111136,2.350000000000003,2.525000000000004,2.46666666666667,2.480555555555559,2.475000000000003,2.4833333333333365,2.6361111111111146,2.5888888888888917,2.49166666666667,2.252777777777781,2.455555555555559,2.447222222222226,2.4388888888888935,2.58055555555556,2.6388888888888937,2.68055555555556,2.719444444444448,2.6805555555555594,2.727777777777782,2.672222222222225,2.7166666666666703,2.452777777777781,2.3555555555555583,2.200000000000003,2.1805555555555585,2.108333333333336,2.186111111111114,2.2833333333333368,2.247222222222226,2.0833333333333375,2.0694444444444486,2.0972222222222268,2.188888888888894,2.0583333333333385,2.138888888888894,2.2638888888888937,2.183333333333338,2.2694444444444497,2.1916666666666718,2.3722222222222267,2.0388888888888927,1.9750000000000032,1.9194444444444476,1.9222222222222245,1.9500000000000028,1.9500000000000024,1.8916666666666688,1.8250000000000022,1.888888888888891,1.7888888888888914,1.7250000000000023,1.8083333333333362,1.822222222222225,2.0222222222222253,2.080555555555559,2.1555555555555586,2.1000000000000028,2.0638888888888918,1.9722222222222252,2.052777777777781,2.14166666666667,1.9666666666666694,1.9194444444444474,1.9138888888888916,1.8500000000000025,1.8000000000000027,1.800000000000002,1.8694444444444467,1.8222222222222242,1.8194444444444462,2.12777777777778,2.158333333333336,2.2250000000000028,2.1777777777777803,2.069444444444447,1.9277777777777805,1.9611111111111148,2.0583333333333376,1.8527777777777814,1.8833333333333369,1.9111111111111145,1.8416666666666694,1.8361111111111141,1.8611111111111143,1.9611111111111144,1.9888888888888925,2.097222222222226,2.211111111111115,2.327777777777781,2.277777777777781,2.358333333333336,2.4055555555555586,2.3305555555555584,2.236111111111114,2.322222222222225,2.1500000000000026,2.0833333333333357,1.9555555555555584,2.0750000000000033,2.122222222222226,2.069444444444448,2.0361111111111145,2.0333333333333368,2.005555555555558,2.097222222222225,2.12777777777778,2.138888888888891,2.136111111111113,2.3138888888888904,2.358333333333335,2.1805555555555576,2.3000000000000025,2.33888888888889,2.2611111111111124,2.1805555555555576,2.1722222222222243,2.008333333333335,1.902777777777779,1.933333333333335,1.933333333333335,1.8027777777777791,1.8444444444444457,1.961111111111113,2.144444444444446,2.1722222222222234,2.241666666666668,2.380555555555557,2.272222222222223,2.1472222222222235,2.080555555555557,1.9694444444444459,2.0138888888888906,2.061111111111113,2.1305555555555573,2.0722222222222246,2.1166666666666694,2.1111111111111134,2.063888888888891,2.1305555555555578,2.3055555555555576,2.4222222222222243,2.5305555555555577,2.4555555555555584,2.527777777777781,2.4666666666666694,2.5000000000000027,2.6777777777777807,2.6444444444444475,2.713888888888892,2.79166666666667,2.725000000000003,2.74166666666667,2.705555555555558,2.6361111111111137,2.5555555555555585,2.5666666666666687,2.4638888888888917,2.613888888888892,2.7166666666666694,2.8555555555555583,2.8972222222222244,2.8861111111111137,2.6888888888888918,2.6777777777777807,2.6888888888888918,2.5527777777777803,2.458333333333336,2.447222222222225,2.4416666666666695,2.3416666666666694,2.519444444444447,2.4111111111111136,2.388888888888891,2.383333333333336,2.477777777777781,2.500000000000003,2.4333333333333367,2.5111111111111146,2.475000000000003,2.530555555555558,2.466666666666669,2.6333333333333355,2.583333333333336,2.6388888888888915,2.8416666666666694,2.836111111111114,2.863888888888892,2.800000000000003,2.7444444444444476,2.633333333333337,2.6527777777777812,2.663888888888892,2.7777777777777817,2.622222222222226,2.5722222222222255,2.6388888888888924,2.7138888888888926,2.755555555555559,2.711111111111115,2.777777777777782,2.6750000000000047,2.611111111111116,2.6472222222222275,2.697222222222227,2.6027777777777823,2.436111111111115,2.4444444444444478,2.3305555555555584,2.1722222222222243,2.0666666666666695,2.1416666666666693,1.9111111111111148,2.0694444444444486,2.0027777777777818,1.9277777777777814,1.900000000000004,1.9055555555555594,1.9111111111111145,1.9583333333333373,1.8277777777777817,1.8277777777777815,1.6944444444444478,1.6583333333333363,1.7111111111111144,1.8277777777777815,1.9361111111111144,1.8972222222222255,1.8250000000000028,1.7305555555555574,1.6722222222222238,1.5638888888888909,1.5722222222222235,1.5277777777777792,1.3972222222222246,1.3861111111111137,1.5805555555555584,1.4972222222222251,1.5500000000000032,1.536111111111115,1.486111111111115,1.4861111111111147,1.51666666666667,1.208333333333336,1.1972222222222246,1.0694444444444469,1.2027777777777802,1.2305555555555583,1.2722222222222253,1.2138888888888912,1.2250000000000023,1.2444444444444465,1.430555555555558,1.3333333333333355,1.3694444444444462,1.3527777777777792,1.3277777777777797,1.3444444444444466,1.3333333333333355,1.3361111111111135,1.32777777777778,1.4111111111111134,1.569444444444447,1.5944444444444472,1.541666666666669,1.6250000000000022,1.6416666666666693,1.7388888888888916,1.6361111111111135,1.8027777777777805,1.7250000000000023,1.7305555555555583,1.7583333333333355,1.8944444444444473,1.9472222222222253,1.9055555555555588,1.8305555555555593,1.7805555555555597,1.7888888888888932,1.8361111111111155,1.9333333333333378,1.941666666666671,1.958333333333338,2.111111111111116,2.1750000000000047,2.144444444444449,2.111111111111115,2.1194444444444493,2.163888888888894,2.172222222222227,2.2333333333333374,2.250000000000004,2.158333333333337,2.2361111111111147,2.344444444444448,2.325000000000004,2.158333333333337,2.1972222222222264,2.3555555555555605,2.291666666666671,2.463888888888894,2.522222222222228,2.4694444444444508,2.5944444444444503,2.550000000000006,2.577777777777784,2.6916666666666726,2.7222222222222276,2.655555555555561,2.650000000000006,2.7083333333333393,2.65833333333334,2.6305555555555618,2.5361111111111163,2.4333333333333393,2.450000000000006,2.5500000000000056,2.5666666666666726,2.5638888888888944,2.6027777777777836,2.525000000000006,2.475000000000006,2.5361111111111168,2.4694444444444503,2.336111111111116,2.4777777777777823,2.6111111111111156,2.70555555555556,2.6250000000000044,2.786111111111116,2.677777777777782,2.6333333333333373,2.7583333333333373,2.6027777777777823,2.5972222222222263,2.683333333333337,2.6166666666666707,2.591666666666671,2.6583333333333368,2.6500000000000035,2.5527777777777803,2.5277777777777803,2.4277777777777807,2.6361111111111146,2.697222222222225,2.611111111111114,2.433333333333336,2.3861111111111133,2.3472222222222245,2.2666666666666684,2.191666666666668,2.197222222222224,2.083333333333336,2.041666666666669,2.244444444444447,1.9083333333333354,1.7833333333333352,1.5611111111111122,1.5472222222222232,1.3888888888888902,1.408333333333335,1.3972222222222235,1.4583333333333344,1.6305555555555569,1.6611111111111128,1.5916666666666683,1.5527777777777791,1.6250000000000013,1.5916666666666683,1.6750000000000016,1.7000000000000017,1.683333333333335,1.6861111111111124,1.5972222222222232,1.6861111111111122,1.825000000000002,1.9138888888888912,1.8694444444444465,1.850000000000001,1.933333333333334,1.9972222222222231,1.9416666666666675,2.000000000000001,1.9777777777777787,2.066666666666668,2.3916666666666693,2.525000000000002,2.563888888888891,2.5055555555555578,2.6166666666666694,2.6138888888888903,2.788888888888891,2.6250000000000027,2.516666666666669,2.550000000000002,2.519444444444447,2.536111111111114,2.3472222222222245,2.286111111111113,2.397222222222225,2.4138888888888923,2.638888888888893,2.6000000000000036,2.5166666666666697,2.361111111111114,2.2694444444444475,2.2388888888888916,2.2305555555555587,2.263888888888893,2.2194444444444485,2.175000000000004,2.2083333333333375,2.241666666666671,2.283333333333338,2.238888888888894,2.119444444444449,2.044444444444449,2.1555555555555603,2.3000000000000047,2.29444444444445,2.397222222222228,2.300000000000005,2.152777777777783,2.200000000000005,2.1222222222222276,2.1750000000000056,2.155555555555561,2.3027777777777843,2.477777777777784,2.1694444444444496,2.208333333333338,2.0916666666666717,2.1722222222222274,2.1444444444444497,2.252777777777782,2.3277777777777824,2.311111111111116,2.4777777777777823,2.3500000000000045,2.3750000000000044,2.494444444444449,2.3527777777777823,2.255555555555559,2.425000000000003,2.241666666666669,2.272222222222225,2.347222222222224,2.161111111111113,2.05277777777778,1.7583333333333355,1.8055555555555574,1.6333333333333346,1.9166666666666679,1.9500000000000015,1.7583333333333346,1.7722222222222235,1.8000000000000014,1.786111111111112,1.7277777777777794,1.8611111111111127,1.9083333333333348,1.91388888888889,1.8972222222222235,1.9583333333333344,1.8611111111111125,1.7500000000000013,1.8777777777777793,1.8416666666666681,1.8666666666666678,1.8750000000000013,1.8833333333333346,2.016666666666669,2.000000000000002,1.9138888888888905,1.994444444444446,1.9388888888888904,1.8527777777777799,1.8944444444444464,2.0444444444444465,2.3944444444444466,2.2638888888888906,2.3444444444444463,2.2055555555555575,2.25277777777778,2.488888888888891,2.4694444444444468,2.4555555555555584,2.547222222222225,2.55277777777778,2.5833333333333353,2.394444444444446,2.336111111111113,2.4694444444444463,2.5388888888888914,2.688888888888891,2.7083333333333353,2.619444444444446,2.4527777777777793,2.4888888888888903,2.4472222222222237,2.347222222222223,2.2944444444444456,2.347222222222224,2.333333333333336,2.3583333333333356,2.408333333333336,2.4583333333333357,2.463888888888892,2.4777777777777805,2.4722222222222245,2.4611111111111135,2.463888888888891,2.5194444444444457,2.4055555555555572,2.497222222222224,2.5472222222222243,2.5638888888888904,2.5361111111111136,2.444444444444446,2.3944444444444453,2.41388888888889,2.5222222222222235,2.4583333333333353,2.375000000000002,2.233333333333335,2.230555555555558,2.213888888888891,2.272222222222224,2.305555555555557,2.2388888888888903,2.1750000000000016,2.2916666666666683,2.2194444444444463,2.15277777777778,2.200000000000003,2.091666666666669,2.0694444444444464,2.1083333333333356,2.0305555555555577,1.916666666666669,2.025000000000003,2.055555555555559,2.008333333333337,2.0055555555555586,1.888888888888892,1.9027777777777808,1.8638888888888923,1.6527777777777808,1.6138888888888925,1.650000000000004,1.6694444444444487,1.602777777777782,1.477777777777782,1.5250000000000041,1.58055555555556,1.6027777777777823,1.6000000000000043,1.7583333333333375,1.7444444444444487,1.9333333333333371,1.9611111111111157,2.000000000000004,2.063888888888893,2.077777777777782,2.0750000000000037,2.094444444444448,2.0444444444444483,1.9944444444444474,1.9194444444444474,1.886111111111114,1.8194444444444473,1.9027777777777806,1.844444444444447,1.9166666666666692,2.047222222222225,1.886111111111114,1.8777777777777802,2.002777777777781,2.0222222222222253,1.9500000000000026,2.0638888888888913,2.0222222222222244,2.0416666666666687,1.9416666666666684,1.8527777777777796,1.9972222222222242,2.008333333333335,1.9000000000000021,1.9444444444444469,1.825000000000003,1.872222222222224,1.7000000000000022,1.769444444444446,1.791666666666668,1.7388888888888907,1.783333333333335,1.822222222222224,1.8194444444444466,1.8638888888888914,1.8583333333333356,1.8166666666666689,1.700000000000002,1.8472222222222245,1.6527777777777801,1.5250000000000026,1.722222222222224,1.80277777777778,1.8138888888888907,1.8694444444444467,1.9000000000000024,1.7083333333333353,1.775000000000002,1.7666666666666682,1.7833333333333348,1.9055555555555568,1.8055555555555565,1.7944444444444456,1.7500000000000007,1.5888888888888895,1.6500000000000004,1.5777777777777784,1.677777777777779,1.6138888888888903,1.680555555555557,1.6555555555555568,1.730555555555557,1.8138888888888904,1.8083333333333351,1.6861111111111127,1.7138888888888903,1.811111111111113,1.9305555555555578,1.8222222222222244,2.041666666666669,2.150000000000002,2.0194444444444466,2.013888888888891,1.9916666666666685,1.9416666666666687,1.9027777777777795,2.0916666666666694,2.0638888888888913,2.0916666666666694,2.0166666666666693,1.9944444444444476,2.013888888888892,2.0611111111111144,2.183333333333337,2.4138888888888923,2.31666666666667,2.2472222222222262,2.2777777777777812,2.3666666666666702,2.2805555555555594,2.313888888888893,2.3722222222222267,2.0500000000000043,2.161111111111116,2.369444444444449,2.3916666666666715,2.336111111111116,2.3416666666666712,2.1500000000000044,2.2083333333333375,1.9361111111111153,1.9972222222222267,2.008333333333338,2.0833333333333384,2.2250000000000054,2.405555555555561,2.275000000000005,2.161111111111116,2.2694444444444493,2.4722222222222276,2.3305555555555606,2.44444444444445,2.333333333333339,2.258333333333338,2.1027777777777827,2.0194444444444493,2.172222222222227,1.9444444444444497,1.8000000000000043,1.7388888888888927,1.536111111111114,1.4638888888888917,1.555555555555559,1.402777777777781,1.2500000000000029,1.180555555555558,1.1694444444444465,1.0833333333333353,1.172222222222224,1.033333333333334,1.1333333333333344,1.227777777777779,1.097222222222223,0.9138888888888899,0.7638888888888893,0.6694444444444453,0.6833333333333339,0.7361111111111119,0.6500000000000002,0.5222222222222231,0.6027777777777789,0.5805555555555564,0.5805555555555564,0.4416666666666673,0.5888888888888897,0.7250000000000012,0.6694444444444453,0.8000000000000007,0.7861111111111122,1.0361111111111119,1.1083333333333347,1.0416666666666683,1.1833333333333342,1.1944444444444458,1.2944444444444463,1.3944444444444462,1.4277777777777794,1.5055555555555575,1.5527777777777805,1.4416666666666693,1.5138888888888915,1.4305555555555582,1.5472222222222247,1.6166666666666698,1.536111111111114,1.3944444444444473,1.5388888888888925,1.5138888888888926,1.6500000000000046,1.6888888888888933,1.7111111111111157,1.4944444444444487,1.5722222222222266,1.677777777777782,1.6416666666666706,1.6333333333333373,1.6083333333333378,1.6888888888888938,1.722222222222227,1.5444444444444496,1.6333333333333384,1.6722222222222274,1.7194444444444494,1.7833333333333385,1.727777777777783,1.6583333333333383,1.5888888888888935,1.541666666666671,1.6750000000000038,1.7583333333333377,1.7972222222222267,1.6416666666666706,1.6750000000000043,1.658333333333337,1.9666666666666708,2.0805555555555597,1.8833333333333364,1.9472222222222255,1.897222222222225,1.841666666666669,1.8055555555555576,1.8694444444444474,1.936111111111114,1.8666666666666694,1.8750000000000033,1.8972222222222257,1.9777777777777807,1.9027777777777801,1.9305555555555578,1.9527777777777797,2.011111111111113,1.9916666666666678,1.994444444444446,2.1416666666666684,2.1194444444444462,2.2083333333333357,2.205555555555558,2.2583333333333364,2.2250000000000028,2.3444444444444468,2.372222222222225,2.4861111111111143,2.438888888888892,2.4694444444444477,2.1388888888888915,2.1222222222222253,2.2333333333333365,2.325000000000003,2.2666666666666697,2.3972222222222257,2.5166666666666706,2.5694444444444478,2.4583333333333366,2.3583333333333356,2.3944444444444466,2.3805555555555578,2.42777777777778,2.3527777777777787,2.397222222222224,2.550000000000002,2.5722222222222246,2.5666666666666695,2.5527777777777807,2.3861111111111137,2.5527777777777807,2.458333333333336,2.452777777777781,2.300000000000003,2.24166666666667,2.0861111111111144,2.0944444444444477,2.133333333333336,2.144444444444447,2.1527777777777803,2.427777777777782,2.347222222222226,2.4500000000000037,2.325000000000004,2.30555555555556,2.247222222222228,2.1888888888888935,2.200000000000004,2.344444444444449,2.597222222222227,2.5444444444444496,2.5277777777777835,2.611111111111116,2.733333333333339,2.7888888888888945,2.64444444444445,2.5833333333333393,2.6361111111111164,2.5611111111111162,2.713888888888894,2.6194444444444502,2.725000000000006,2.8361111111111175,2.961111111111117,3.0111111111111164,3.09444444444445,3.0388888888888936,2.8138888888888944,2.833333333333339,2.7611111111111164,2.8111111111111153,2.850000000000005,2.6027777777777814,2.6694444444444487,2.6055555555555596,2.555555555555559,2.6555555555555594,2.694444444444448,2.4805555555555596,2.3444444444444485,2.3305555555555597,2.386111111111116,2.2444444444444493,2.111111111111116,2.0250000000000044,1.944444444444449,1.9111111111111156,1.9222222222222272,2.0000000000000053,1.766666666666672,1.855555555555561,1.7694444444444495,1.7277777777777825,1.6611111111111159,1.6833333333333382,1.6722222222222272,1.6861111111111167,2.011111111111117,1.9388888888888942,2.0388888888888945,1.947222222222228,2.1500000000000057,2.26944444444445,2.158333333333339,2.1555555555555608,2.166666666666672,2.1472222222222275,2.0388888888888936,2.230555555555561,2.252777777777783,2.3222222222222273,2.330555555555561,2.336111111111117,2.5583333333333393,2.638888888888894,2.6444444444444497,2.683333333333339,2.6083333333333383,2.569444444444449,2.6222222222222267,2.5833333333333375,2.652777777777782,2.6916666666666718,2.6111111111111165,2.5277777777777835,2.450000000000006,2.4166666666666723,2.225000000000005,2.280555555555561,2.2277777777777827,2.152777777777783,2.097222222222227,2.0111111111111155,2.0916666666666712,2.2694444444444493,2.3638888888888943,2.308333333333339,2.3722222222222284,2.352777777777784,2.4694444444444503,2.4750000000000068,2.325000000000006,2.3361111111111175,2.2722222222222284,2.3138888888888953,2.436111111111118,2.4638888888888952,2.422222222222228,2.4500000000000055,2.713888888888895,2.633333333333339,2.5972222222222285,2.544444444444451,2.736111111111118,2.78333333333334,2.8444444444444508,2.875000000000006,2.9972222222222284,2.941666666666673,2.866666666666673,2.88333333333334,2.7166666666666726,2.7805555555555617,2.8500000000000054,2.8583333333333387,2.888888888888894,2.8222222222222273,2.825000000000005,2.727777777777782,2.666666666666671,2.686111111111115,2.7138888888888926,2.7055555555555597,2.7666666666666706,2.697222222222226,2.5722222222222255,2.4500000000000037,2.4694444444444485,2.4583333333333375,2.3416666666666712,2.2972222222222265,2.3194444444444486,2.2111111111111144,2.1083333333333365,2.1333333333333364,2.130555555555558,2.288888888888891,2.2250000000000028,2.255555555555558,2.3111111111111136,2.2916666666666687,2.4638888888888912,2.37777777777778,2.3138888888888913,2.2166666666666694,1.9750000000000023,1.8277777777777808,1.7527777777777807,1.8083333333333362,1.7166666666666692,1.6583333333333359,1.8138888888888915,1.8472222222222245,1.7472222222222251,1.7138888888888917,1.511111111111114,1.700000000000003,1.6972222222222249,1.5444444444444472,1.5222222222222248,1.6638888888888919,1.5972222222222252,1.750000000000003,1.833333333333337,1.8444444444444488,1.8805555555555602,1.6888888888888938,1.7305555555555603,1.7527777777777824,1.7777777777777826,1.947222222222227,1.9305555555555605,2.0972222222222276,2.0277777777777835,1.9583333333333381,2.1083333333333387,2.327777777777783,2.358333333333338,2.3944444444444484,2.411111111111115,2.2944444444444483,2.252777777777782,2.250000000000005,2.238888888888894,2.1888888888888927,2.416666666666671,2.338888888888893,2.322222222222226,2.5500000000000034,2.5027777777777813,2.400000000000003,2.3944444444444475,2.3138888888888913,2.1916666666666687,2.1333333333333346,2.1750000000000007,2.222222222222223,2.2444444444444454,2.2694444444444453,2.283333333333334,2.136111111111112,2.0500000000000003,2.0416666666666674,2.0972222222222228,2.13888888888889,2.1611111111111128,2.03888888888889,2.044444444444445,1.9888888888888903,1.9833333333333347,2.1416666666666684,2.2361111111111125,2.252777777777779,2.266666666666668,2.308333333333335,2.344444444444446,2.3222222222222237,2.5083333333333355,2.4388888888888913,2.4055555555555577,2.4777777777777805,2.497222222222225,2.5750000000000033,2.633333333333337,2.5277777777777817,2.516666666666671,2.5194444444444497,2.416666666666672,2.4027777777777835,2.3694444444444502,2.4944444444444507,2.575000000000006,2.4416666666666718,2.4888888888888943,2.4972222222222276,2.427777777777783,2.411111111111117,2.375000000000006,2.416666666666673,2.5055555555555618,2.5500000000000065,2.436111111111117,2.3083333333333393,2.3416666666666726,2.3194444444444504,2.2500000000000058,2.141666666666672,2.0138888888888937,1.9833333333333383,2.1305555555555604,2.1527777777777826,2.291666666666672,2.219444444444449,2.308333333333338,2.391666666666671,2.333333333333337,2.2583333333333364],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"width\":1200,\"height\":600,\"title\":{\"text\":\"Difference : (HPO dataset ACC) - (NEW dataset ACC)\"},\"xaxis\":{\"title\":{\"text\":\"trial No.\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy Difference (%)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('26f60d67-30ae-4087-9e60-6df0fc691f19');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}