## 목차

* 목차
  * [1. 스트리밍의 개념](#1-스트리밍의-개념)
  * [2. 스트리밍의 필요성](#2-스트리밍의-필요성)
  * [3. 스트리밍 구현 방법](#3-스트리밍-구현-방법)
  * [4. 스트리밍 실습](#4-스트리밍-실습)
    * [4-1. 모델 직접 스트리밍](#4-1-모델-직접-스트리밍)
    * [4-2. 체인 스트리밍](#4-2-체인-스트리밍)
    * [4-3. 비동기 스트리밍](#4-3-비동기-스트리밍)
* ipynb 실습 파일
  * TBU

## 1. 스트리밍의 개념

LangChain에서 **스트리밍 (Streaming)** 은 LLM의 답변을 **token 단위로 실시간 수신** 하는 것을 의미한다.

## 2. 스트리밍의 필요성

스트리밍의 필요성은 다음과 같다.

* 사용자가 긴 응답을 기다릴 필요 없이, **사용자에게 답변의 token이 생성되는 즉시 제공** 하여 UX 향상
  * ChatGPT, Gemini를 포함한 챗봇에서는 스트리밍이 거의 필수

## 3. 스트리밍 구현 방법

스트리밍의 구현 방법은 다음과 같다.

| 구현 방법      | 설명                              | Python 코드                                                           |
|------------|---------------------------------|---------------------------------------------------------------------|
| 모델 직접 스트리밍 | **모델을 직접 호출** 할 때 스트리밍 방식 사용    | ```llm.stream([HumanMessage(content="...")])```                     |
| 체인 스트리밍    | **LLM 체인** 방식을 사용할 때 스트리밍 방식 사용 | ```chain.stream({...})```                                           |
| 비동기 스트리밍   | 비동기적으로 스트리밍 구현                  | ```async for chunk in llm.astream([HumanMessage(content="...")])``` |
| 에이전트 스트리밍  | LLM 에이전트에서의 스트리밍 구현             | ```agent.stream({...}, stream_mode="updates")```                    |

## 4. 스트리밍 실습

### 4-1. 모델 직접 스트리밍

### 4-2. 체인 스트리밍

### 4-3. 비동기 스트리밍