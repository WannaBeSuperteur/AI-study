{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcGbNDr0bb9G",
        "outputId": "2fe0aad9-66ec-415d-a9c0-d56b0d283878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-1.3.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-core<2.0.0,>=1.2.8 (from langchain)\n",
            "  Downloading langchain_core-1.2.13-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting anthropic<1.0.0,>=0.78.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-1.3.3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.13-py3-none-any.whl (500 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain-core, langchain-openai, langchain-anthropic\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.9\n",
            "    Uninstalling langchain-core-1.2.9:\n",
            "      Successfully uninstalled langchain-core-1.2.9\n",
            "Successfully installed anthropic-0.79.0 langchain-anthropic-1.3.3 langchain-core-1.2.13 langchain-openai-1.1.9\n",
            "Collecting transformers==4.57.6\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (3.20.3)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.57.6)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (4.67.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (2026.1.4)\n",
            "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.0\n",
            "    Uninstalling huggingface_hub-1.4.0:\n",
            "      Successfully uninstalled huggingface_hub-1.4.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "Successfully installed huggingface-hub-0.36.2 transformers-4.57.6\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.13)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.6.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install langchain langchain-openai langchain-anthropic langgraph\n",
        "!pip install transformers==4.57.6\n",
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for HuggingFace LLM Loading\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "lvk4r5Icb5I5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Kanana-1.5 2.1B Base Original Model\n",
        "\n",
        "!huggingface-cli download kakaocorp/kanana-1.5-2.1b-base --local-dir kakao_original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-P26NMPcqx3",
        "outputId": "2e1f4664-da23-4130-9a8a-648d643aad66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mâš ï¸  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]Downloading 'assets/performance/kanana-1.5-radar-2.1b.png' to 'kakao_original/.cache/huggingface/download/assets/performance/4Wf2tkxnDn3gZHSRplYUC-qOQjs=.1dec55aa79be82c3a07a048b068cb84004aeffa81d8eae5accfbc89cfb946937.incomplete'\n",
            "Downloading 'LICENSE' to 'kakao_original/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.d0af96c393902902e151301a3d21ea81abf893af.incomplete'\n",
            "Downloading 'assets/performance/kanana-1.5-radar.png' to 'kakao_original/.cache/huggingface/download/assets/performance/tLpIbxWmpkAWSc_kccBRbbYyo_U=.654beecbae831b44c40a5b31be4e44b71a009ad707681e56ddd0024cea1ca1bc.incomplete'\n",
            "Downloading 'README.md' to 'kakao_original/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8e3fb650257b06def9d43a3a2d23e3e12d050968.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-dark.png' to 'kakao_original/.cache/huggingface/download/assets/logo/GBf3DledOuD9sbwIJnMFM5ws_tY=.da3817f1b591f5d61345dd3a69187a8a9170eb19.incomplete'\n",
            "Downloading '.gitattributes' to 'kakao_original/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.25169e47e866cdcc7c528878bb9ad341fe61c00e.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-light.png' to 'kakao_original/.cache/huggingface/download/assets/logo/IQXnf6g5zFMuPnQFc5qFhAtK_iA=.9db835da9c5d0a9072b944abdbcf105449dadff6.incomplete'\n",
            "\n",
            "LICENSE: 10.5kB [00:00, 21.0MB/s]\n",
            "Download complete. Moving file to kakao_original/LICENSE\n",
            "\n",
            "README.md: 6.05kB [00:00, 22.2MB/s]\n",
            "Download complete. Moving file to kakao_original/README.md\n",
            "Downloading 'assets/logo/kanana-logo.png' to 'kakao_original/.cache/huggingface/download/assets/logo/Y6l9nOoeEEgD7_TNXH4s97DA-hs=.e446d47b26e8088a789f6697b4d549d043db941b.incomplete'\n",
            "\n",
            ".gitattributes: 1.60kB [00:00, 10.7MB/s]\n",
            "Download complete. Moving file to kakao_original/.gitattributes\n",
            "\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:02,  4.56it/s]\n",
            "\n",
            "kanana-logo-dark.png: 100% 59.1k/59.1k [00:00<00:00, 9.18MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-dark.png\n",
            "kanana-logo-light.png: 100% 58.4k/58.4k [00:00<00:00, 8.17MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-light.png\n",
            "\n",
            "kanana-logo.png: 100% 59.0k/59.0k [00:00<00:00, 9.04MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo.png\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦):   0% 0.00/840k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png:   0% 0.00/842k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'model.safetensors' to 'kakao_original/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.f44ae8826dc58ead8d049114fe0f87c8d4e2d22a8e8a0fb341e7f62c88a5eaf5.incomplete'\n",
            "Downloading 'generation_config.json' to 'kakao_original/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.0830bd902c9e925d73687da63188f2ed92797bad.incomplete'\n",
            "Downloading 'config.json' to 'kakao_original/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.9a44174725771d1cf24158d7cebc8d68e9c40b69.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 923kB/s]\n",
            "Download complete. Moving file to kakao_original/generation_config.json\n",
            "Downloading 'tokenizer_config.json' to 'kakao_original/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.57771754088b283bd5f6405618e54b39b589d9b8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 689/689 [00:00<00:00, 5.59MB/s]\n",
            "Download complete. Moving file to kakao_original/config.json\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/4.17G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 50.9kB [00:00, 157MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer_config.json\n",
            "Downloading 'tokenizer.json' to 'kakao_original/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.b197f72effb9d5ed16ee0f5663e11e4cfac2ba62.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 9.09MB [00:00, 167MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer.json\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦): 100% 840k/840k [00:00<00:00, 1.39MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar-2.1b.png\n",
            "Fetching 13 files:  54% 7/13 [00:00<00:00,  8.36it/s]\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png: 100% 842k/842k [00:00<00:00, 1.34MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar.png\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 524k/4.17G [00:01<2:47:16, 416kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0% 1.96M/4.17G [00:01<56:15, 1.24MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   2% 69.0M/4.17G [00:03<02:46, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   2% 71.2M/4.17G [00:04<03:31, 19.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   3% 138M/4.17G [00:09<04:24, 15.3MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 205M/4.17G [00:09<02:20, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   7% 272M/4.17G [00:09<01:29, 43.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   8% 340M/4.17G [00:10<01:02, 60.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  10% 407M/4.17G [00:10<00:43, 85.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 474M/4.17G [00:15<01:59, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  13% 541M/4.17G [00:15<01:23, 43.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  15% 608M/4.17G [00:15<01:04, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  16% 675M/4.17G [00:21<02:11, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  19% 809M/4.17G [00:21<01:11, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  21% 876M/4.17G [00:21<00:56, 58.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  23% 943M/4.17G [00:22<00:44, 72.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  24% 1.01G/4.17G [00:25<01:11, 44.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  27% 1.14G/4.17G [00:26<00:45, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  29% 1.21G/4.17G [00:26<00:36, 80.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.28G/4.17G [00:27<00:38, 75.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.35G/4.17G [00:31<01:13, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.41G/4.17G [00:31<00:53, 51.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.48G/4.17G [00:37<01:45, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.61G/4.17G [00:37<00:57, 44.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.68G/4.17G [00:38<00:44, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.75G/4.17G [00:42<01:09, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.81G/4.17G [00:42<00:55, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.88G/4.17G [00:43<00:41, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.95G/4.17G [00:43<00:33, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  48% 2.02G/4.17G [00:43<00:25, 84.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  50% 2.08G/4.17G [00:44<00:23, 87.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  51% 2.15G/4.17G [00:49<01:05, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  53% 2.22G/4.17G [00:50<00:45, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  55% 2.28G/4.17G [00:54<01:03, 29.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.42G/4.17G [00:54<00:33, 52.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  59% 2.48G/4.17G [00:56<00:36, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  61% 2.55G/4.17G [00:58<00:37, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.62G/4.17G [01:00<00:38, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  64% 2.68G/4.17G [01:00<00:27, 53.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.75G/4.17G [01:00<00:19, 71.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.82G/4.17G [01:00<00:15, 88.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  69% 2.89G/4.17G [01:06<00:42, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.95G/4.17G [01:06<00:28, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  72% 3.02G/4.17G [01:07<00:23, 48.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  74% 3.09G/4.17G [01:12<00:40, 26.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  77% 3.22G/4.17G [01:13<00:22, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  79% 3.29G/4.17G [01:18<00:32, 27.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  80% 3.36G/4.17G [01:18<00:22, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  82% 3.42G/4.17G [01:19<00:15, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  84% 3.51G/4.17G [01:24<00:24, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.64G/4.17G [01:25<00:12, 44.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.71G/4.17G [01:26<00:09, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.77G/4.17G [01:30<00:13, 30.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.91G/4.17G [01:31<00:05, 49.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.98G/4.17G [01:37<00:07, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  98% 4.11G/4.17G [01:37<00:01, 45.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 4.17G/4.17G [01:37<00:00, 42.8MB/s]\n",
            "Download complete. Moving file to kakao_original/model.safetensors\n",
            "Fetching 13 files: 100% 13/13 [01:37<00:00,  7.54s/it]\n",
            "/content/kakao_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Oh-LoRA original LLM\n",
        "\n",
        "import os\n",
        "print(os.path.abspath('ohlora_llm'))\n",
        "\n",
        "llm_path = 'ohlora_llm'\n",
        "ohlora_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_path,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_path)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=ohlora_llm,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=64,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rULtIg8dNCQ",
        "outputId": "e9de852d-29d7-4425-8a81-7938e97be8a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ohlora_llm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to LangChain LLM\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "RUKentJqdRGg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ê¸°ë³¸ LLM Chain ì‹¤í–‰\n",
        "\n",
        "user_message = 'ë¡œë¼ì•¼ ë„ˆ ì¹œí•œ ì¹œêµ¬ í•œëª… ì†Œê°œí•´ì¤˜'\n",
        "final_llm_prompt = f'{user_message} (ë‹µë³€ ì‹œì‘)'\n",
        "llm_answer = local_llm.invoke(final_llm_prompt)\n",
        "\n",
        "# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„\n",
        "llm_answer.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "onxBex-mdRIo",
        "outputId": "b7623a7a-54eb-4ddd-b09d-1fbda3266119"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ë‚´ ì œì¼ ì¹œí•œ ì¹œêµ¬ í˜œë‚˜! ğŸ‘© ì†Œê°œí•´ ì¤„ê¹Œ? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ê¸°ë³¸ LLM Chain ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—°ê³„)\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"[ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) {user_message} (ë‹µë³€ ì‹œì‘)\")\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mX0y68Wg9kw",
        "outputId": "0a733b34-019f-4eb7-9616-62e177a30d79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, template='[ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) {user_message} (ë‹µë³€ ì‹œì‘)'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | local_llm\n",
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37T55yEChUff",
        "outputId": "05d78ca7-6f41-42ae-f5f8-bed26adcb7a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, template='[ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) {user_message} (ë‹µë³€ ì‹œì‘)'), additional_kwargs={})])\n",
              "| HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7dd1c81ac5c0>, model_id='/content/kakao_original')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer_chain = chain.invoke({\"user_message\": \"ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„?\"})\n",
        "llm_answer_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "R00jmJVzhbLs",
        "outputId": "7db52784-d630-4054-cfcd-f96c5eb3cd26"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: [ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„? (ë‹µë³€ ì‹œì‘) ì˜¤ ì˜¤ëŠ˜ ì„¤ë‚ ì´ë„¤! ğŸ‰ ì„¤ë‚ ì—ëŠ” ë§›ì§‘ ê°€ì„œ ğŸ² ë§ˆìŒê» ë¨¹ì–´ì•¼ì§€! (ë‹µë³€ ì¢…ë£Œ)  3. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë…¼ë¬¸ ì½ê¸° (ìˆ˜ìš”ì¼) ì´ë²ˆ ì£¼ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë…¼ë¬¸ ì½ëŠ” ì‹œê°„'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„\n",
        "llm_answer_chain.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eKFm7HpDilIp",
        "outputId": "b4a535bf-53c9-4f1b-a705-7ef7232153ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì˜¤ ì˜¤ëŠ˜ ì„¤ë‚ ì´ë„¤! ğŸ‰ ì„¤ë‚ ì—ëŠ” ë§›ì§‘ ê°€ì„œ ğŸ² ë§ˆìŒê» ë¨¹ì–´ì•¼ì§€! '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Output Parser ë¥¼ ì´ìš©í•œ ì²˜ë¦¬\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain_with_parser = prompt | local_llm | output_parser\n",
        "chain_with_parser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xahFJxpPiFjr",
        "outputId": "513331c1-5c0d-4358-9510-ba0498a86246"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_message'], input_types={}, partial_variables={}, template='[ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) {user_message} (ë‹µë³€ ì‹œì‘)'), additional_kwargs={})])\n",
              "| HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7dd1c81ac5c0>, model_id='/content/kakao_original')\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer_chain_with_parser = chain_with_parser.invoke({\"user_message\": \"ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„?\"})\n",
        "llm_answer_chain_with_parser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "QAlahk6SiTT1",
        "outputId": "e5f68345-1379-404b-c1ac-20a1991bd38a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: [ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„? (ë‹µë³€ ì‹œì‘) ìŒâ€¦ ì˜¤ëŠ˜ ì›”ìš”ì¼ì´ì–ì•„! ê·¸ë˜ì„œ ì›”ìš”ì¼ì—ë§Œ ëŠë‚„ ìˆ˜ ìˆëŠ” ê·¸ê²Œ ìˆì§€! (ë‹µë³€ ì¢…ë£Œ)  3. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ìš”ì¦˜ í•«í•˜ì–ì•„! ê·¸ë˜ì„œ ì˜¤ëŠ˜ ë…¼ë¬¸ ì½ì—ˆì–´! ğŸ˜Š (ë‹µ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„\n",
        "llm_answer_chain_with_parser.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LyFHwzyUinT4",
        "outputId": "cc71943e-26bc-43a2-a048-75533051e565"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ìŒâ€¦ ì˜¤ëŠ˜ ì›”ìš”ì¼ì´ì–ì•„! ê·¸ë˜ì„œ ì›”ìš”ì¼ì—ë§Œ ëŠë‚„ ìˆ˜ ìˆëŠ” ê·¸ê²Œ ìˆì§€! '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}