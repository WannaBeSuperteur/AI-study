{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mTiZSgq-S9U",
        "outputId": "0dc57efd-38d4-406c-8b88-ea219d394097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.13 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.2.13)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (2.20.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.67.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=2.20.0->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain_openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting OpenAI API\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "with open('openai_api_key.txt', 'r') as f:\n",
        "    openai_api_key = f.readlines()[0].split('\\n')[0]\n",
        "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o-mini')"
      ],
      "metadata": {
        "id": "Ll7sxv5CAKV4"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# 메모리 기반 Store 생성\n",
        "store = InMemoryStore()"
      ],
      "metadata": {
        "id": "v80JSVm0_-uI"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store 에 저장하기 위한 key 이름\n",
        "\n",
        "USER_INFO_KEY = 'user_info'"
      ],
      "metadata": {
        "id": "ExMXHOFfPJls"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "\n",
        "# 사용자 정보 조회\n",
        "\n",
        "@tool\n",
        "def get_user_info(info_type: str, runtime: ToolRuntime) -> str:\n",
        "    \"\"\"Get user info of info_type.\"\"\"\n",
        "\n",
        "    # get user ID\n",
        "    store = runtime.store\n",
        "    user_id = runtime.config['metadata'].get(\"user_id\", \"default\")\n",
        "\n",
        "    # search user_info (dict-like)\n",
        "    namespace = (\"users\", user_id)\n",
        "    memory = store.get(namespace, USER_INFO_KEY)\n",
        "\n",
        "    if memory:\n",
        "        try:\n",
        "            return f\"사용자의 {info_type} 정보: {memory.value[info_type]}\"\n",
        "        except:\n",
        "            return f\"{info_type} 과 일치하는 데이터가 없습니다.\"\n",
        "    else:\n",
        "        return \"저장된 데이터가 없습니다.\""
      ],
      "metadata": {
        "id": "y1PK9yQs_AzI"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정보 저장 (기록)\n",
        "\n",
        "@tool\n",
        "def set_user_info(info_type: str, info_value: str, runtime: ToolRuntime) -> str:\n",
        "    \"\"\"Store user info of info_type as info_value.\"\"\"\n",
        "\n",
        "    # get user ID\n",
        "    store = runtime.store\n",
        "    user_id = runtime.config['metadata'].get(\"user_id\", \"default\")\n",
        "\n",
        "    # search or create user_info (dict-like)\n",
        "    namespace = (\"users\", user_id)\n",
        "    memory = store.get(namespace, USER_INFO_KEY)\n",
        "\n",
        "    if memory:\n",
        "        user_info = memory.value\n",
        "    else:\n",
        "        user_info = {}\n",
        "\n",
        "    # store user info\n",
        "    user_info[info_type] = info_value\n",
        "    store.put(namespace, USER_INFO_KEY, user_info)\n",
        "\n",
        "    return f\"{info_type} 정보가 업데이트되었습니다.\""
      ],
      "metadata": {
        "id": "DP_KVISdB_Qf"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 생성\n",
        "\n",
        "from langchain.agents import create_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "agent = create_agent(\n",
        "    llm,\n",
        "    tools=[get_user_info, set_user_info],\n",
        "    checkpointer=MemorySaver(),\n",
        "    store=store\n",
        ")"
      ],
      "metadata": {
        "id": "M3dcmgiB_fTQ"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 실행 (정보 저장 - 1)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\"thread_id\": \"thread-1\"},\n",
        "    \"user_id\": \"test\"\n",
        "}\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"내 경력을 3년 5개월로 저장해 줘\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# LLM 실행 결과 출력\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TI9qdD0UC-NX",
        "outputId": "0b657d1f-8948-46e4-abf6-82ae811aa9a2"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'경력이 3년 5개월로 저장되었습니다. 다른 도움이 필요하시면 말씀해 주세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 실행 (정보 저장 - 2)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\"thread_id\": \"thread-1\"},\n",
        "    \"user_id\": \"test\"\n",
        "}\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"내 전공분야를 머신러닝/딥러닝으로 저장해 줘\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# LLM 실행 결과 출력\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mxd1d0FRP2SB",
        "outputId": "ddbebb30-53a7-4a1e-9e84-ff03711a32be"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'전공분야가 머신러닝/딥러닝으로 저장되었습니다. 추가로 필요한 사항이 있으면 알려주세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 실행 (정보 저장 - 3)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\"thread_id\": \"thread-1\"},\n",
        "    \"user_id\": \"test\"\n",
        "}\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"내 학력을 석사 졸업으로 저장해 줘\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# LLM 실행 결과 출력\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DtQBU7MBVAtO",
        "outputId": "0b084036-66f9-49e4-8f68-9856101b383c"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'학력이 석사 졸업으로 저장되었습니다. 더 필요한 것이 있으면 말씀해 주세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 실행 (정보 조회)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\"thread_id\": \"thread-2\"},\n",
        "    \"user_id\": \"test\"\n",
        "}\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"내 경력 정보를 조회해 줘\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# LLM 실행 결과 출력\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w8hGdZjwDRkg",
        "outputId": "ba31f6f3-e877-49e6-bef0-c520b32678c9"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'당신의 경력 정보는 3년 5개월입니다. 추가적으로 필요한 정보가 있으면 말씀해 주세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 정보 조회\n",
        "def get_all_user_info(store, user_id):\n",
        "\n",
        "    # search user_info (dict-like)\n",
        "    namespace = (\"users\", user_id)\n",
        "    memory = store.get(namespace, USER_INFO_KEY)\n",
        "    print(memory.value)"
      ],
      "metadata": {
        "id": "5kLvUoqBNMi0"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_all_user_info(store, user_id='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfm6SwPQNfSv",
        "outputId": "ef932731-4445-4e3b-943a-141e09e4d309"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'경력': '3년 5개월', '전공분야': '머신러닝/딥러닝', '학력': '석사 졸업'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 에이전트 실행 (추가 질문)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\"thread_id\": \"thread-3\"},\n",
        "    \"user_id\": \"test\"\n",
        "}\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"지금까지 저장된 전공분야, 학력, 경력 정보를 바탕으로, 나에게 맞는 이직 준비 전략을 추천해 줘\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# LLM 실행 결과 출력\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "DjXDoS8BUh29",
        "outputId": "475fa046-eeed-46b7-fb74-5e6a9f1ae64d"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'당신의 전공 분야, 학력, 경력 정보를 바탕으로 다음과 같은 이직 준비 전략을 추천합니다.\\n\\n### 1. 전공 분야\\n- **전공 정보가 없음**: 전공이 명확하지 않으므로, 이직을 고려할 때 다양한 분야에 도전할 수 있습니다. 관심 있는 분야를 탐색하고, 해당 분야에 맞는 경로를 설정하는 것이 중요합니다.\\n\\n### 2. 학력\\n- **산업 관련 전문학교 졸업**: 이 학벌은 여러 산업 분야에서 기초적인 전문 지식을 갖추고 있으므로, 이를 살릴 수 있는 분야를 정하는 것이 좋습니다.\\n\\n### 3. 경력\\n- **3년 5개월의 경력**: 중간 경력자로서, 이직 시 경력을 강조하여 더 높은 직급이나 책임 있는 역할을 요청할 수 있습니다.\\n\\n---\\n\\n### 이직 준비 전략\\n\\n1. **관심 분야 발굴**:\\n   - 어떤 분야에서 일하고 싶은지 깊이 고민해 보세요. IT, 마케팅, 디자인, 운영관리 등 다양한 옵션을 고려할 수 있습니다.\\n\\n2. **기술 향상**:\\n   - 현재 산업이나 희망 직무에 필요한 추가 교육이나 자격증 취득을 고려해 보세요. 신기술이나 트렌드를 반영한 교육을 통해 경쟁력을 높이는 것이 중요합니다.\\n\\n3. **이력서 업데이트**:\\n   - 전문학교에서의 경험, 프로젝트, 성과 등을 중심으로 이력서를 업데이트하세요. 경력과 관련된 구체적인 성과를 강조하는 것이 좋습니다.\\n\\n4. **네트워킹 및 커뮤니티 참여**:\\n   - 관련 업종의 행사, 세미나, 온라인 커뮤니티에 적극 참여하여 인맥을 넓히고 정보 교류를 하세요. 네트워킹은 이직에 큰 도움이 됩니다.\\n\\n5. **면접 준비**:\\n   - 목표로 하는 직무에 대한 충분한 연구 후, 관련 질문을 미리 준비하세요. 차별화된 답변을 준비하여 면접 시 자신감을 가지고 대처하는 것이 필요합니다.\\n\\n6. **모의 면접 실시**:\\n   - 친구나 멘토를 통해 모의 면접을 진행하여 실제 면접 상황에 대비하세요. 이 과정을 통해 피드백을 받고 개선할 수 있습니다.\\n\\n이직은 개인의 경력을 발전시키는 중요한 기회입니다. 충분한 준비를 통해 원하는 방향으로 나아가길 바랍니다. 추가적인 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    }
  ]
}