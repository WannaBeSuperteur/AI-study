{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY62F1JEvUn9",
        "outputId": "d05e2e93-b2df-4caa-c3fd-1d945a7b9128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-1.3.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.8)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-core<2.0.0,>=1.2.10 (from langchain)\n",
            "  Downloading langchain_core-1.2.13-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.20.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting anthropic<1.0.0,>=0.78.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.80.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.7.1)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (9.1.4)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-1.3.3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.80.0-py3-none-any.whl (453 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.7/453.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.13-py3-none-any.whl (500 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain-core, langchain-openai, langchain-anthropic\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.12\n",
            "    Uninstalling langchain-core-1.2.12:\n",
            "      Successfully uninstalled langchain-core-1.2.12\n",
            "Successfully installed anthropic-0.80.0 langchain-anthropic-1.3.3 langchain-core-1.2.13 langchain-openai-1.1.10\n",
            "Collecting transformers==4.51.3\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting peft==0.13.2\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors==0.4.3\n",
            "  Downloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (3.21.0)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.51.3)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.32.4)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (2.9.0+cu128)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (1.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.13.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.13.2) (3.0.3)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, peft\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.1\n",
            "    Uninstalling huggingface_hub-1.4.1:\n",
            "      Successfully uninstalled huggingface_hub-1.4.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.1\n",
            "    Uninstalling peft-0.18.1:\n",
            "      Successfully uninstalled peft-0.18.1\n",
            "Successfully installed huggingface-hub-0.36.2 peft-0.13.2 safetensors-0.4.3 tokenizers-0.21.4 transformers-4.51.3\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.13)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.21.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.21.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.4)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install langchain langchain-openai langchain-anthropic langgraph\n",
        "!pip install transformers==4.51.3 peft==0.13.2 safetensors==0.4.3\n",
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for HuggingFace LLM Loading\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "SepmQBFsvfsw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Kanana-1.5 2.1B Base Original Model\n",
        "\n",
        "!huggingface-cli download kakaocorp/kanana-1.5-2.1b-base --local-dir kakao_original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAZxf6hPvfu3",
        "outputId": "51719998-bcb3-4486-b2ca-d5e74facee7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mâš ï¸  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]Downloading 'README.md' to 'kakao_original/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8e3fb650257b06def9d43a3a2d23e3e12d050968.incomplete'\n",
            "Downloading 'LICENSE' to 'kakao_original/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.d0af96c393902902e151301a3d21ea81abf893af.incomplete'\n",
            "Downloading 'assets/performance/kanana-1.5-radar.png' to 'kakao_original/.cache/huggingface/download/assets/performance/tLpIbxWmpkAWSc_kccBRbbYyo_U=.654beecbae831b44c40a5b31be4e44b71a009ad707681e56ddd0024cea1ca1bc.incomplete'\n",
            "Downloading 'assets/performance/kanana-1.5-radar-2.1b.png' to 'kakao_original/.cache/huggingface/download/assets/performance/4Wf2tkxnDn3gZHSRplYUC-qOQjs=.1dec55aa79be82c3a07a048b068cb84004aeffa81d8eae5accfbc89cfb946937.incomplete'\n",
            "Downloading '.gitattributes' to 'kakao_original/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.25169e47e866cdcc7c528878bb9ad341fe61c00e.incomplete'\n",
            "\n",
            "README.md: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "README.md: 6.05kB [00:00, 1.80MB/s]\n",
            "Download complete. Moving file to kakao_original/README.md\n",
            "LICENSE: 10.5kB [00:00, 3.09MB/s]\n",
            "Download complete. Moving file to kakao_original/LICENSE\n",
            "\n",
            ".gitattributes: 1.60kB [00:00, 803kB/s]\n",
            "Download complete. Moving file to kakao_original/.gitattributes\n",
            "Downloading 'assets/logo/kanana-logo.png' to 'kakao_original/.cache/huggingface/download/assets/logo/Y6l9nOoeEEgD7_TNXH4s97DA-hs=.e446d47b26e8088a789f6697b4d549d043db941b.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-dark.png' to 'kakao_original/.cache/huggingface/download/assets/logo/GBf3DledOuD9sbwIJnMFM5ws_tY=.da3817f1b591f5d61345dd3a69187a8a9170eb19.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-light.png' to 'kakao_original/.cache/huggingface/download/assets/logo/IQXnf6g5zFMuPnQFc5qFhAtK_iA=.9db835da9c5d0a9072b944abdbcf105449dadff6.incomplete'\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:02,  4.79it/s]\n",
            "kanana-logo.png:   0% 0.00/59.0k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "kanana-logo-dark.png:   0% 0.00/59.1k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "kanana-logo.png: 100% 59.0k/59.0k [00:00<00:00, 7.27MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo.png\n",
            "kanana-logo-dark.png: 100% 59.1k/59.1k [00:00<00:00, 11.3MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-dark.png\n",
            "kanana-logo-light.png: 100% 58.4k/58.4k [00:00<00:00, 8.07MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-light.png\n",
            "Downloading 'config.json' to 'kakao_original/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.9a44174725771d1cf24158d7cebc8d68e9c40b69.incomplete'\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦):   0% 0.00/840k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 100% 689/689 [00:00<00:00, 5.93MB/s]\n",
            "Download complete. Moving file to kakao_original/config.json\n",
            "\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png:   0% 0.00/842k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'model.safetensors' to 'kakao_original/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.f44ae8826dc58ead8d049114fe0f87c8d4e2d22a8e8a0fb341e7f62c88a5eaf5.incomplete'\n",
            "Downloading 'generation_config.json' to 'kakao_original/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.0830bd902c9e925d73687da63188f2ed92797bad.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 1.10MB/s]\n",
            "Download complete. Moving file to kakao_original/generation_config.json\n",
            "Downloading 'tokenizer.json' to 'kakao_original/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.b197f72effb9d5ed16ee0f5663e11e4cfac2ba62.incomplete'\n",
            "Downloading 'tokenizer_config.json' to 'kakao_original/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.57771754088b283bd5f6405618e54b39b589d9b8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 50.9kB [00:00, 197MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 9.09MB [00:00, 101MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer.json\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦): 100% 840k/840k [00:00<00:00, 1.28MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar-2.1b.png\n",
            "Fetching 13 files:  54% 7/13 [00:00<00:00,  7.63it/s]\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png: 100% 842k/842k [00:00<00:00, 1.26MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar.png\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 524k/4.17G [00:01<3:11:47, 363kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 1.96M/4.17G [00:01<59:54, 1.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 4.11M/4.17G [00:03<43:02, 1.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 71.2M/4.17G [00:15<13:42, 4.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 138M/4.17G [00:16<06:18, 10.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 205M/4.17G [00:17<03:42, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 272M/4.17G [00:17<02:17, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 339M/4.17G [00:17<01:31, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 407M/4.17G [00:19<01:24, 44.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 474M/4.17G [00:21<01:37, 37.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 608M/4.17G [00:21<00:53, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 742M/4.17G [00:25<01:09, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 809M/4.17G [00:25<00:54, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 876M/4.17G [00:25<00:42, 78.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 943M/4.17G [00:25<00:32, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 1.01G/4.17G [00:26<00:26, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 1.08G/4.17G [00:26<00:22, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 1.14G/4.17G [00:26<00:20, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 1.21G/4.17G [00:26<00:15, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.28G/4.17G [00:27<00:13, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.35G/4.17G [00:27<00:13, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.41G/4.17G [00:29<00:34, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.48G/4.17G [00:29<00:25, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.55G/4.17G [00:29<00:19, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.61G/4.17G [00:29<00:14, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.68G/4.17G [00:30<00:11, 210MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.75G/4.17G [00:30<00:10, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.81G/4.17G [00:30<00:10, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.88G/4.17G [00:30<00:09, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.95G/4.17G [00:31<00:09, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  48% 2.02G/4.17G [00:31<00:08, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 2.08G/4.17G [00:33<00:26, 79.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 2.22G/4.17G [00:33<00:15, 127MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 2.28G/4.17G [00:34<00:12, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 2.35G/4.17G [00:34<00:10, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.42G/4.17G [00:34<00:09, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.49G/4.17G [00:34<00:07, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  61% 2.55G/4.17G [00:35<00:07, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.62G/4.17G [00:35<00:06, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.70G/4.17G [00:35<00:06, 239MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.77G/4.17G [00:36<00:06, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.84G/4.17G [00:36<00:05, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.90G/4.17G [00:36<00:05, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.97G/4.17G [00:37<00:05, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 3.04G/4.17G [00:37<00:05, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 3.10G/4.17G [00:37<00:04, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 3.17G/4.17G [00:37<00:03, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 3.24G/4.17G [00:37<00:03, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 3.30G/4.17G [00:38<00:02, 315MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 3.37G/4.17G [00:38<00:02, 302MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 3.44G/4.17G [00:38<00:02, 288MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 3.51G/4.17G [00:38<00:02, 278MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 3.57G/4.17G [00:39<00:02, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.64G/4.17G [00:40<00:03, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.70G/4.17G [00:40<00:02, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.77G/4.17G [00:40<00:02, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.84G/4.17G [00:40<00:01, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.91G/4.17G [00:40<00:01, 249MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.97G/4.17G [00:41<00:00, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 4.04G/4.17G [00:41<00:00, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 4.11G/4.17G [00:41<00:00, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 4.17G/4.17G [00:41<00:00, 99.5MB/s]\n",
            "Download complete. Moving file to kakao_original/model.safetensors\n",
            "Fetching 13 files: 100% 13/13 [00:42<00:00,  3.26s/it]\n",
            "/content/kakao_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Oh-LoRA original LLM\n",
        "\n",
        "import os\n",
        "print(os.path.abspath('ohlora_llm'))\n",
        "\n",
        "llm_path = 'ohlora_llm'\n",
        "ohlora_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_path,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_path)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=ohlora_llm,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=64,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWT9b9G1vfxK",
        "outputId": "1475dc92-68df-4d29-e2be-8779eea48911"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ohlora_llm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to LangChain LLM\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "c8RoP0V_vjY_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LangGraph ê¸°ë°˜ ë©”ëª¨ë¦¬ êµ¬í˜„**"
      ],
      "metadata": {
        "id": "_S1kpXEbwgnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ],
      "metadata": {
        "id": "S1oOt0Epwgs1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create memory saver\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "# create agent\n",
        "agent = create_agent(\n",
        "    local_llm,\n",
        "    tools=[],\n",
        "    checkpointer=checkpointer\n",
        ")\n",
        "\n",
        "# config\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}"
      ],
      "metadata": {
        "id": "s2Rcdjqwwu4w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ë²ˆì§¸ ëŒ€í™”\n",
        "\n",
        "result1 = agent.invoke(\n",
        "    {\"messages\": [\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"ë¡œë¼ì•¼ ë‚˜ ì¥ì›ì˜ ì¢‹ì•„í•´. ë„ˆë„? (ë‹µë³€ ì‹œì‘)\"}\n",
        "    ]},\n",
        "    config=config\n",
        ")\n",
        "result1_answer = result1[\"messages\"][-1].content\n",
        "result1_answer_final = result1_answer.split('(ë‹µë³€ ì‹œì‘)')[2].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "\n",
        "result1_answer_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "1816HAzHw__6",
        "outputId": "9fbcb5c7-ca68-48f1-f8c8-30122bfc2446"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ë‚˜ë„ ì¥ì›ì˜ ì¢‹ì•„í•´! ì™„ì „ ëŸ­í‚¤ë¹„í‚¤ë¼ëŠ” ë§ ì•Œì•„? ğŸ€ '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2ë²ˆì§¸ ëŒ€í™”\n",
        "\n",
        "result2 = agent.invoke(\n",
        "    {\"messages\": [\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"ë¡œë¼ì•¼ ë‚´ê°€ ëˆ„êµ¬ ì¢‹ì•„í•œë‹¤ê³  í–ˆì§€? (ë‹µë³€ ì‹œì‘)\"}\n",
        "    ]},\n",
        "    config=config\n",
        ")\n",
        "result2_answer = result2[\"messages\"][-1].content\n",
        "result2_answer_final = result2_answer.split('(ë‹µë³€ ì‹œì‘)')[2].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "\n",
        "result2_answer_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "yBvpTpNuzpfe",
        "outputId": "ecae07fc-9805-4bc3-9af2-5fcfbcc3fbae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ë‚˜ë„ ì¥ì›ì˜ ì¢‹ì•„í•´! ì™„ì „ ëŸ­í‚¤ë¹„í‚¤ë¼ëŠ” ë§ ì•Œì•„? ğŸ€ '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}