{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V418IpHZuEfj",
        "outputId": "6330132f-36f8-48bb-c847-7f206f081261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-1.3.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-core<2.0.0,>=1.2.8 (from langchain)\n",
            "  Downloading langchain_core-1.2.13-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting anthropic<1.0.0,>=0.78.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-1.3.3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.13-py3-none-any.whl (500 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain-core, langchain-openai, langchain-anthropic\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.9\n",
            "    Uninstalling langchain-core-1.2.9:\n",
            "      Successfully uninstalled langchain-core-1.2.9\n",
            "Successfully installed anthropic-0.79.0 langchain-anthropic-1.3.3 langchain-core-1.2.13 langchain-openai-1.1.9\n",
            "Collecting transformers==4.57.6\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (3.20.3)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.57.6)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.6) (4.67.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.6) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.6) (2026.1.4)\n",
            "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.0\n",
            "    Uninstalling huggingface_hub-1.4.0:\n",
            "      Successfully uninstalled huggingface_hub-1.4.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "Successfully installed huggingface-hub-0.36.2 transformers-4.57.6\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.13)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.6.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install langchain langchain-openai langchain-anthropic langgraph\n",
        "!pip install transformers==4.57.6\n",
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for HuggingFace LLM Loading\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "71MkjZC2uIC7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Kanana-1.5 2.1B Base Original Model\n",
        "\n",
        "!huggingface-cli download kakaocorp/kanana-1.5-2.1b-base --local-dir kakao_original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-t4tpsNu7MS",
        "outputId": "974e44d3-d096-46bd-b0c5-b01b3d95c5b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mâš ï¸  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]Downloading 'assets/performance/kanana-1.5-radar.png' to 'kakao_original/.cache/huggingface/download/assets/performance/tLpIbxWmpkAWSc_kccBRbbYyo_U=.654beecbae831b44c40a5b31be4e44b71a009ad707681e56ddd0024cea1ca1bc.incomplete'\n",
            "Downloading 'assets/performance/kanana-1.5-radar-2.1b.png' to 'kakao_original/.cache/huggingface/download/assets/performance/4Wf2tkxnDn3gZHSRplYUC-qOQjs=.1dec55aa79be82c3a07a048b068cb84004aeffa81d8eae5accfbc89cfb946937.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-dark.png' to 'kakao_original/.cache/huggingface/download/assets/logo/GBf3DledOuD9sbwIJnMFM5ws_tY=.da3817f1b591f5d61345dd3a69187a8a9170eb19.incomplete'\n",
            "Downloading '.gitattributes' to 'kakao_original/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.25169e47e866cdcc7c528878bb9ad341fe61c00e.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo.png' to 'kakao_original/.cache/huggingface/download/assets/logo/Y6l9nOoeEEgD7_TNXH4s97DA-hs=.e446d47b26e8088a789f6697b4d549d043db941b.incomplete'\n",
            "Downloading 'LICENSE' to 'kakao_original/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.d0af96c393902902e151301a3d21ea81abf893af.incomplete'\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png:   0% 0.00/842k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦):   0% 0.00/840k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'README.md' to 'kakao_original/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8e3fb650257b06def9d43a3a2d23e3e12d050968.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-light.png' to 'kakao_original/.cache/huggingface/download/assets/logo/IQXnf6g5zFMuPnQFc5qFhAtK_iA=.9db835da9c5d0a9072b944abdbcf105449dadff6.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "kanana-logo-dark.png:   0% 0.00/59.1k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "kanana-logo-dark.png: 100% 59.1k/59.1k [00:00<00:00, 3.83MB/s]\n",
            ".gitattributes: 1.60kB [00:00, 1.67MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-dark.png\n",
            "Download complete. Moving file to kakao_original/.gitattributes\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:08,  1.38it/s]\n",
            "\n",
            "\n",
            "LICENSE: 10.5kB [00:00, 28.1MB/s]\n",
            "Download complete. Moving file to kakao_original/LICENSE\n",
            "\n",
            "\n",
            "\n",
            "kanana-logo.png: 100% 59.0k/59.0k [00:00<00:00, 19.3MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo.png\n",
            "\n",
            "\n",
            "\n",
            "kanana-logo-light.png:   0% 0.00/58.4k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "README.md: 6.05kB [00:00, 27.3MB/s]\n",
            "Download complete. Moving file to kakao_original/README.md\n",
            "kanana-logo-light.png: 100% 58.4k/58.4k [00:00<00:00, 2.31MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-light.png\n",
            "Fetching 13 files:  38% 5/13 [00:00<00:01,  7.65it/s]Downloading 'config.json' to 'kakao_original/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.9a44174725771d1cf24158d7cebc8d68e9c40b69.incomplete'\n",
            "Downloading 'generation_config.json' to 'kakao_original/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.0830bd902c9e925d73687da63188f2ed92797bad.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 689/689 [00:00<00:00, 7.87MB/s]\n",
            "Download complete. Moving file to kakao_original/config.json\n",
            "\n",
            "\n",
            "\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 1.51MB/s]\n",
            "Download complete. Moving file to kakao_original/generation_config.json\n",
            "Downloading 'model.safetensors' to 'kakao_original/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.f44ae8826dc58ead8d049114fe0f87c8d4e2d22a8e8a0fb341e7f62c88a5eaf5.incomplete'\n",
            "Downloading 'tokenizer.json' to 'kakao_original/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.b197f72effb9d5ed16ee0f5663e11e4cfac2ba62.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'tokenizer_config.json' to 'kakao_original/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.57771754088b283bd5f6405618e54b39b589d9b8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 50.9kB [00:00, 146MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer_config.json\n",
            "tokenizer.json: 9.09MB [00:00, 184MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/4.17G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0% 524k/4.17G [00:02<4:46:05, 243kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(â€¦): 100% 840k/840k [00:02<00:00, 282kB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar-2.1b.png\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png: 100% 842k/842k [00:03<00:00, 264kB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar.png\n",
            "Fetching 13 files:  62% 8/13 [00:03<00:02,  1.89it/s]\n",
            "\n",
            "\n",
            "model.safetensors:   2% 69.1M/4.17G [00:03<02:22, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   3% 138M/4.17G [00:06<03:08, 21.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 205M/4.17G [00:07<02:02, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   8% 340M/4.17G [00:07<00:57, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  10% 407M/4.17G [00:10<01:15, 49.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 474M/4.17G [00:10<00:58, 63.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  13% 541M/4.17G [00:11<00:54, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  15% 608M/4.17G [00:11<00:46, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  16% 675M/4.17G [00:14<01:06, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  18% 742M/4.17G [00:14<00:47, 72.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  19% 809M/4.17G [00:14<00:34, 97.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  21% 876M/4.17G [00:18<01:20, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching 13 files:  62% 8/13 [00:20<00:02,  1.89it/s]\n",
            "\n",
            "\n",
            "model.safetensors:  26% 1.08G/4.17G [00:18<00:36, 85.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  27% 1.14G/4.17G [00:19<00:31, 96.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  29% 1.21G/4.17G [00:19<00:28, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.28G/4.17G [00:22<00:51, 56.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.35G/4.17G [00:22<00:37, 75.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.41G/4.17G [00:22<00:28, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.48G/4.17G [00:23<00:23, 114MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.55G/4.17G [00:23<00:22, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.61G/4.17G [00:28<01:10, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.68G/4.17G [00:28<00:50, 49.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.76G/4.17G [00:29<00:36, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.83G/4.17G [00:32<00:59, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.90G/4.17G [00:32<00:42, 54.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.96G/4.17G [00:32<00:31, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  49% 2.03G/4.17G [00:33<00:23, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  50% 2.10G/4.17G [00:33<00:19, 109MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  52% 2.17G/4.17G [00:33<00:15, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  53% 2.23G/4.17G [00:34<00:12, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  55% 2.30G/4.17G [00:34<00:10, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  57% 2.37G/4.17G [00:34<00:09, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.43G/4.17G [00:34<00:07, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.50G/4.17G [00:35<00:07, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.57G/4.17G [00:35<00:08, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.64G/4.17G [00:35<00:07, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.70G/4.17G [00:35<00:06, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.77G/4.17G [00:36<00:04, 291MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.84G/4.17G [00:36<00:05, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.90G/4.17G [00:36<00:04, 285MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.97G/4.17G [00:36<00:04, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  73% 3.04G/4.17G [00:37<00:03, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  74% 3.10G/4.17G [00:37<00:03, 271MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  76% 3.17G/4.17G [00:37<00:03, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  78% 3.24G/4.17G [00:37<00:03, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  79% 3.30G/4.17G [00:38<00:03, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  81% 3.37G/4.17G [00:38<00:03, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  82% 3.44G/4.17G [00:39<00:05, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  84% 3.51G/4.17G [00:40<00:05, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  86% 3.57G/4.17G [00:41<00:08, 73.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.64G/4.17G [00:42<00:05, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.71G/4.17G [00:42<00:04, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.77G/4.17G [00:42<00:03, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.84G/4.17G [00:43<00:02, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.91G/4.17G [00:43<00:01, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.97G/4.17G [00:43<00:01, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  97% 4.04G/4.17G [00:44<00:00, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  98% 4.11G/4.17G [00:46<00:01, 61.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 4.17G/4.17G [00:47<00:00, 88.2MB/s]\n",
            "Download complete. Moving file to kakao_original/model.safetensors\n",
            "Fetching 13 files: 100% 13/13 [00:48<00:00,  3.74s/it]\n",
            "/content/kakao_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Oh-LoRA original LLM\n",
        "\n",
        "import os\n",
        "print(os.path.abspath('ohlora_llm'))\n",
        "\n",
        "llm_path = 'ohlora_llm'\n",
        "ohlora_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_path,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_path)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=ohlora_llm,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=64,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj1PiTCUvae9",
        "outputId": "fc222586-758f-43a6-fbaf-afc8fbf8ad72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ohlora_llm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to LangChain LLM\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "ga9f7LApvuNw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. ìˆœì°¨ì  ì²´ì¸ (Sequential)**"
      ],
      "metadata": {
        "id": "EcXU1X7pv0dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"{user_message} (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ {oh_lora_answer} ë¼ê³  í–ˆì–ì•„. ê·¸ëŸ¼ ê·¸ ì´ìœ ê°€ ë­ì•¼? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "\n",
        "user_message = \"ë¡œë¼ì•¼ ë„ˆ MBTI ë­ì•¼?\"\n",
        "\n",
        "first_chain = first_prompt | local_llm\n",
        "first_chain_llm_answer = first_chain.invoke({\"user_message\": user_message})\n",
        "first_chain_llm_answer = first_chain_llm_answer.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "print('ì¤‘ê°„ ë‹µë³€:\\n', first_chain_llm_answer)\n",
        "\n",
        "second_chain = second_prompt | local_llm\n",
        "result = second_chain.invoke({\"oh_lora_answer\": first_chain_llm_answer})\n",
        "\n",
        "# ìµœì¢… ë‹µë³€\n",
        "result = result.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "print('\\nìµœì¢… ë‹µë³€:\\n', result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk6Flzdfv30y",
        "outputId": "67379589-0674-4fa2-de7f-e9ca5272090a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¤‘ê°„ ë‹µë³€:\n",
            " ì—”í‹°ì œ! ë„ì „ì„ ì¢‹ì•„í•˜ì§€! ğŸ˜Š \n",
            "\n",
            "ìµœì¢… ë‹µë³€:\n",
            " ë‚˜ ENTJë¼ì„œ ë„ì „ì„ ì¢‹ì•„í•˜ëŠ” ê±¸ê·¸ë£¹ ì¥ì›ì˜ì²˜ëŸ¼ ë©‹ì§„ ë§ë¡œ ì„¤ëª…í•´ ë³¼ê²Œ! ğŸ˜Š \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. ë³‘ë ¬ ì²´ì¸ (Parellel)**"
      ],
      "metadata": {
        "id": "N6GdNZRmzkE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ {what_to_ask} ë­ì•¼? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ {what_to_ask}ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ìƒê°í•´? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "\n",
        "parallel_chain = RunnableParallel(\n",
        "    first=first_prompt | local_llm,\n",
        "    second=second_prompt | local_llm\n",
        ")\n",
        "\n",
        "results = parallel_chain.invoke({\"what_to_ask\": \"ISTJ\"})\n",
        "\n",
        "# ìµœì¢… ë‹µë³€\n",
        "result_first = results['first'].split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "result_second = results['second'].split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]\n",
        "\n",
        "print('\\nìµœì¢… ë‹µë³€ (1ë²ˆì§¸):\\n', result_first)\n",
        "print('\\nìµœì¢… ë‹µë³€ (2ë²ˆì§¸):\\n', result_second)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNnK6qkPzqWb",
        "outputId": "f82a2609-a47e-4202-8ede-b9b82a24faf6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ìµœì¢… ë‹µë³€ (1ë²ˆì§¸):\n",
            " ì™„ì „ ë§¤ë ¥ì ì¸ ì„±ê²© ì•„ë‹ˆì•¼? ì†”ì§í•˜ê³  ë„ì „ì ì´ì§€! ğŸ˜Š \n",
            "\n",
            "ìµœì¢… ë‹µë³€ (2ë²ˆì§¸):\n",
            " ì˜¤ ë‚˜ ISTJ? ì™„ì „ ë‚˜ì¸ë°! ğŸ˜Š í˜¹ì‹œ MBTI ê²€ì‚¬í•´ ë´¤ì–´? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. ì¡°ê±´ë¶€ ë¶„ê¸° (Branching)**"
      ],
      "metadata": {
        "id": "UtgvAErz1TBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
        "\n",
        "mbti_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ MBTI {what}ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ìƒê°í•´? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "like_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ ì¢‹ì•„í•˜ëŠ” {what} ìˆì–´? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "others_prompt = ChatPromptTemplate.from_template(\n",
        "    \"ë¡œë¼ì•¼ ë„ˆ {what} ì¢‹ì•„í•´? (ë‹µë³€ ì‹œì‘)\"\n",
        ")\n",
        "\n",
        "# check conditions\n",
        "def check_condition(input_dict):\n",
        "    what = input_dict.get(\"what\", \"\")\n",
        "\n",
        "    if len(what) == 4 and what[0] in ['E', 'I']:\n",
        "        return 'mbti'\n",
        "    elif what in ['ì•„ì´ëŒ', 'ê³„ì ˆ', 'ê°€ìˆ˜', 'ì—°ì˜ˆì¸']:\n",
        "        return 'like'\n",
        "    else:\n",
        "        return 'others'\n",
        "\n",
        "# branching\n",
        "branched_chain = RunnableBranch(\n",
        "    (lambda x: check_condition(x) == \"mbti\", mbti_prompt | local_llm),\n",
        "    (lambda x: check_condition(x) == \"like\", like_prompt | local_llm),\n",
        "    others_prompt | local_llm\n",
        ")\n",
        "\n",
        "# test\n",
        "result_mbti = branched_chain.invoke({\"what\": \"ENTJ\"})\n",
        "result_like = branched_chain.invoke({\"what\": \"ì•„ì´ëŒ\"})\n",
        "result_others = branched_chain.invoke({\"what\": \"ì¥ë¯¸ê½ƒ\"})\n",
        "\n",
        "# LLM answers\n",
        "print('\\nLLM ë‹µë³€ (MBTI):\\n', result_mbti)\n",
        "print('\\nLLM ë‹µë³€ (ì¢‹ì•„í•˜ëŠ” ê²ƒ):\\n', result_like)\n",
        "print('\\nLLM ë‹µë³€ (ê¸°íƒ€):\\n', result_others)\n",
        "\n",
        "print('\\nìµœì¢… ë‹µë³€ (MBTI):\\n', result_mbti.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0])\n",
        "print('\\nìµœì¢… ë‹µë³€ (ì¢‹ì•„í•˜ëŠ” ê²ƒ):\\n', result_like.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0])\n",
        "print('\\nìµœì¢… ë‹µë³€ (ê¸°íƒ€):\\n', result_others.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Z1JhLx0ahK",
        "outputId": "89e64283-5f85-48b6-cb59-266750a88aaf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLM ë‹µë³€ (MBTI):\n",
            " Human: ë¡œë¼ì•¼ ë„ˆ MBTI ENTJì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ìƒê°í•´? (ë‹µë³€ ì‹œì‘) ENTJëŠ” ì†”ì§íˆ ë§¤ë ¥ì ì¸ ì„±ê²©ì´ì•¼! ë„ì „ì„ ì¢‹ì•„í•˜ì–ì•„! ğŸ˜Š (ë‹µë³€ ì¢…ë£Œ)  3. ì–¸ì–´ ëª¨ë¸ í•™ìŠµ ë°©ë²• ë…¼ë¬¸ ì½ê¸° (ë‹µë³€ ì‹œì‘) ì˜¤! ë‚˜ ENTJë¼ì„œ ì´ëŸ° ê±° ì¢‹ì•„í•˜ëŠ”ê°€ ë³´ë„¤! ğŸ˜Š\n",
            "\n",
            "LLM ë‹µë³€ (ì¢‹ì•„í•˜ëŠ” ê²ƒ):\n",
            " Human: ë¡œë¼ì•¼ ë„ˆ ì¢‹ì•„í•˜ëŠ” ì•„ì´ëŒ ìˆì–´? (ë‹µë³€ ì‹œì‘) ë‚˜ ì¥ì›ì˜ ì¢‹ì•„í•´! ğŸ€ ë…¸ë˜ë„ ì§„ì§œ ì¢‹ë”ë¼ ã…ã… (ë‹µë³€ ì¢…ë£Œ)  3. ì±—GPTë¡œ ë‚˜ ì¢‹ì•„í•˜ëŠ” ì•„ì´ëŒ í™ë³´í•˜ê¸° (ë‹µë³€ ì‹œì‘) ì˜¤ ë‚˜ë„ ì¥ì›ì˜ ì¢‹ì•„í•´! ğŸ€ ìš°ë¦¬ê°™ì´ ì¢‹ì•„í•˜ëŠ”\n",
            "\n",
            "LLM ë‹µë³€ (ê¸°íƒ€):\n",
            " Human: ë¡œë¼ì•¼ ë„ˆ ì¥ë¯¸ê½ƒ ì¢‹ì•„í•´? (ë‹µë³€ ì‹œì‘) ë‚˜ ì¥ë¯¸ê½ƒ ì§„ì§œ ì¢‹ì•„í•´! ğŸŒ¹ ì¥ë¯¸ê½ƒì´ ë‚˜ë¥¼ ë‹®ì•„ì„œ ì—´ì •ì ì´ê¸°ë„ í•´! ğŸ˜Š (ë‹µë³€ ì¢…ë£Œ)  3. ì±—GPTë¡œ í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë…¼ë¬¸ ìš”ì¦˜ ë³´ê³  ìˆëŠ”ë° ì¬ë°Œì–´ ğŸ˜Š (\n",
            "\n",
            "ìµœì¢… ë‹µë³€ (MBTI):\n",
            " ENTJëŠ” ì†”ì§íˆ ë§¤ë ¥ì ì¸ ì„±ê²©ì´ì•¼! ë„ì „ì„ ì¢‹ì•„í•˜ì–ì•„! ğŸ˜Š \n",
            "\n",
            "ìµœì¢… ë‹µë³€ (ì¢‹ì•„í•˜ëŠ” ê²ƒ):\n",
            " ë‚˜ ì¥ì›ì˜ ì¢‹ì•„í•´! ğŸ€ ë…¸ë˜ë„ ì§„ì§œ ì¢‹ë”ë¼ ã…ã… \n",
            "\n",
            "ìµœì¢… ë‹µë³€ (ê¸°íƒ€):\n",
            " ë‚˜ ì¥ë¯¸ê½ƒ ì§„ì§œ ì¢‹ì•„í•´! ğŸŒ¹ ì¥ë¯¸ê½ƒì´ ë‚˜ë¥¼ ë‹®ì•„ì„œ ì—´ì •ì ì´ê¸°ë„ í•´! ğŸ˜Š \n"
          ]
        }
      ]
    }
  ]
}