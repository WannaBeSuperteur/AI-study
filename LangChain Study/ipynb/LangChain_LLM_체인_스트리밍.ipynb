{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB0tz2BkpaGK",
        "outputId": "3c22a0fc-0c74-493f-db34-270c7be31dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.9)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.12/dist-packages (1.3.3)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anthropic<1.0.0,>=0.78.0 in /usr/local/lib/python3.12/dist-packages (from langchain-anthropic) (0.79.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Requirement already satisfied: transformers==4.51.3 in /usr/local/lib/python3.12/dist-packages (4.51.3)\n",
            "Requirement already satisfied: peft==0.13.2 in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: safetensors==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (2.9.0+cu128)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (1.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.13.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.13.2) (3.0.3)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.13)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.21.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.6.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install langchain langchain-openai langchain-anthropic langgraph\n",
        "!pip install transformers==4.51.3 peft==0.13.2 safetensors==0.4.3\n",
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for HuggingFace LLM Loading\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "MadspXIYpuZM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Kanana-1.5 2.1B Base Original Model\n",
        "\n",
        "!huggingface-cli download kakaocorp/kanana-1.5-2.1b-base --local-dir kakao_original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daTOZ6hjpvmT",
        "outputId": "896628f1-9eb3-488d-88b3-3c55a0232ba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m‚ö†Ô∏è  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]Downloading 'README.md' to 'kakao_original/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8e3fb650257b06def9d43a3a2d23e3e12d050968.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-dark.png' to 'kakao_original/.cache/huggingface/download/assets/logo/GBf3DledOuD9sbwIJnMFM5ws_tY=.da3817f1b591f5d61345dd3a69187a8a9170eb19.incomplete'\n",
            "Downloading 'LICENSE' to 'kakao_original/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.d0af96c393902902e151301a3d21ea81abf893af.incomplete'\n",
            "\n",
            "README.md: 0.00B [00:00, ?B/s]\u001b[ADownloading '.gitattributes' to 'kakao_original/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.25169e47e866cdcc7c528878bb9ad341fe61c00e.incomplete'\n",
            "Downloading 'assets/logo/kanana-logo-light.png' to 'kakao_original/.cache/huggingface/download/assets/logo/IQXnf6g5zFMuPnQFc5qFhAtK_iA=.9db835da9c5d0a9072b944abdbcf105449dadff6.incomplete'\n",
            "\n",
            "\n",
            "kanana-logo-dark.png:   0% 0.00/59.1k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'assets/logo/kanana-logo.png' to 'kakao_original/.cache/huggingface/download/assets/logo/Y6l9nOoeEEgD7_TNXH4s97DA-hs=.e446d47b26e8088a789f6697b4d549d043db941b.incomplete'\n",
            "README.md: 6.05kB [00:00, 1.33MB/s]\n",
            "Download complete. Moving file to kakao_original/README.md\n",
            "kanana-logo-dark.png: 100% 59.1k/59.1k [00:00<00:00, 19.5MB/s]Downloading 'assets/performance/kanana-1.5-radar.png' to 'kakao_original/.cache/huggingface/download/assets/performance/tLpIbxWmpkAWSc_kccBRbbYyo_U=.654beecbae831b44c40a5b31be4e44b71a009ad707681e56ddd0024cea1ca1bc.incomplete'\n",
            "\n",
            "Downloading 'assets/performance/kanana-1.5-radar-2.1b.png' to 'kakao_original/.cache/huggingface/download/assets/performance/4Wf2tkxnDn3gZHSRplYUC-qOQjs=.1dec55aa79be82c3a07a048b068cb84004aeffa81d8eae5accfbc89cfb946937.incomplete'\n",
            "\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-dark.png\n",
            "LICENSE: 10.5kB [00:00, 13.3MB/s]\n",
            "Download complete. Moving file to kakao_original/LICENSE\n",
            "\n",
            "\n",
            "kanana-logo-light.png:   0% 0.00/58.4k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            ".gitattributes: 1.60kB [00:00, 875kB/s]\n",
            "\n",
            "kanana-logo.png:   0% 0.00/59.0k [00:00<?, ?B/s]\u001b[ADownload complete. Moving file to kakao_original/.gitattributes\n",
            "kanana-logo-light.png: 100% 58.4k/58.4k [00:00<00:00, 1.57MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo-light.png\n",
            "kanana-logo.png: 100% 59.0k/59.0k [00:00<00:00, 10.6MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/logo/kanana-logo.png\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:02,  4.61it/s]Downloading 'config.json' to 'kakao_original/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.9a44174725771d1cf24158d7cebc8d68e9c40b69.incomplete'\n",
            "\n",
            "config.json: 100% 689/689 [00:00<00:00, 5.68MB/s]\n",
            "Download complete. Moving file to kakao_original/config.json\n",
            "Downloading 'model.safetensors' to 'kakao_original/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.f44ae8826dc58ead8d049114fe0f87c8d4e2d22a8e8a0fb341e7f62c88a5eaf5.incomplete'\n",
            "Downloading 'generation_config.json' to 'kakao_original/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.0830bd902c9e925d73687da63188f2ed92797bad.incomplete'\n",
            "\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 898kB/s]\n",
            "Download complete. Moving file to kakao_original/generation_config.json\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(‚Ä¶):   0% 0.00/840k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "assets/performance/kanana-1.5-radar.png:   0% 0.00/842k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'tokenizer.json' to 'kakao_original/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.b197f72effb9d5ed16ee0f5663e11e4cfac2ba62.incomplete'\n",
            "Downloading 'tokenizer_config.json' to 'kakao_original/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.57771754088b283bd5f6405618e54b39b589d9b8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 50.9kB [00:00, 104MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 9.09MB [00:00, 95.3MB/s]\n",
            "Download complete. Moving file to kakao_original/tokenizer.json\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(‚Ä¶): 100% 840k/840k [00:00<00:00, 1.08MB/s]\u001b[A\n",
            "\n",
            "assets/performance/kanana-1.5-radar-2.1b(‚Ä¶): 100% 840k/840k [00:00<00:00, 1.08MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar-2.1b.png\n",
            "assets/performance/kanana-1.5-radar.png: 100% 842k/842k [00:00<00:00, 1.08MB/s]\n",
            "Download complete. Moving file to kakao_original/assets/performance/kanana-1.5-radar.png\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 524k/4.17G [00:01<3:35:30, 323kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 67.6M/4.17G [00:02<01:51, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 138M/4.17G [00:13<07:03, 9.53MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 205M/4.17G [00:13<03:59, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 272M/4.17G [00:17<03:58, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 339M/4.17G [00:18<02:39, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 406M/4.17G [00:18<01:48, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 474M/4.17G [00:18<01:17, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 539M/4.17G [00:19<00:57, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 606M/4.17G [00:19<00:44, 80.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 673M/4.17G [00:20<00:36, 94.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 740M/4.17G [00:20<00:31, 109MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 807M/4.17G [00:20<00:26, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 875M/4.17G [00:21<00:24, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 942M/4.17G [00:23<00:51, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 1.01G/4.17G [00:24<00:44, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 1.08G/4.17G [00:26<00:59, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 1.09G/4.17G [00:26<00:58, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 1.16G/4.17G [00:29<01:17, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 1.23G/4.17G [00:29<01:00, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.29G/4.17G [00:30<00:54, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 1.36G/4.17G [00:31<00:39, 70.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.43G/4.17G [00:31<00:30, 90.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.49G/4.17G [00:31<00:23, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.56G/4.17G [00:31<00:18, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.63G/4.17G [00:32<00:14, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.70G/4.17G [00:32<00:11, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.76G/4.17G [00:32<00:09, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.83G/4.17G [00:32<00:09, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.90G/4.17G [00:32<00:08, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.96G/4.17G [00:33<00:08, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 2.03G/4.17G [00:33<00:08, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 2.10G/4.17G [00:35<00:26, 77.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 2.23G/4.17G [00:35<00:15, 128MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 2.30G/4.17G [00:36<00:11, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  57% 2.37G/4.17G [00:36<00:09, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.43G/4.17G [00:36<00:07, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.50G/4.17G [00:36<00:07, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.57G/4.17G [00:36<00:06, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.63G/4.17G [00:37<00:06, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.70G/4.17G [00:37<00:06, 244MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.77G/4.17G [00:39<00:18, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.90G/4.17G [00:40<00:10, 124MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.97G/4.17G [00:40<00:08, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 3.04G/4.17G [00:40<00:06, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 3.10G/4.17G [00:40<00:05, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 3.17G/4.17G [00:40<00:04, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 3.24G/4.17G [00:41<00:04, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 3.30G/4.17G [00:41<00:03, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 3.37G/4.17G [00:41<00:03, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 3.44G/4.17G [00:42<00:04, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 3.51G/4.17G [00:42<00:04, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 3.57G/4.17G [00:43<00:03, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.64G/4.17G [00:43<00:03, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.71G/4.17G [00:43<00:02, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.77G/4.17G [00:44<00:01, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.84G/4.17G [00:44<00:01, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.91G/4.17G [00:44<00:01, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.98G/4.17G [00:44<00:00, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 4.04G/4.17G [00:45<00:00, 276MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 4.11G/4.17G [00:45<00:00, 295MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 4.17G/4.17G [00:45<00:00, 91.7MB/s]\n",
            "Download complete. Moving file to kakao_original/model.safetensors\n",
            "Fetching 13 files: 100% 13/13 [00:45<00:00,  3.53s/it]\n",
            "/content/kakao_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Oh-LoRA original LLM\n",
        "\n",
        "import os\n",
        "print(os.path.abspath('ohlora_llm'))\n",
        "\n",
        "llm_path = 'ohlora_llm'\n",
        "ohlora_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_path,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_path)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=ohlora_llm,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=64,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3kDzvC0pxN2",
        "outputId": "11fcf523-2be4-4293-e1a4-2b2e94400a01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ohlora_llm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to LangChain LLM\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "5jQtAi4gpy61"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Î™®Îç∏ ÏßÅÏ†ë Ïä§Ìä∏Î¶¨Î∞ç**"
      ],
      "metadata": {
        "id": "qEeSFbH3yAac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "result = ''\n",
        "result_with_token_splits = ''\n",
        "\n",
        "for chunk in local_llm.stream([HumanMessage(content=\"Î°úÎùºÏïº ÏïàÎÖï? ÏöîÏ¶ò Î≠êÌï¥? (ÎãµÎ≥Ä ÏãúÏûë)\")]):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "    result += chunk\n",
        "    result_with_token_splits += chunk + \"|\"\n",
        "\n",
        "    if result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å)') or result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å) '):\n",
        "        break\n",
        "\n",
        "print('\\n\\ntoken split Í≤∞Í≥º:\\n', result_with_token_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApAkkLyiyDn0",
        "outputId": "8de697ef-d62e-4425-b6c2-3959d0e5761c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ïñ∏Ïñ¥ Î™®Îç∏ ÎÖºÎ¨∏ ÏöîÏ¶ò Î≥¥Í≥† ÏûàÏñ¥! ÌòÅÏã†Ï†ÅÏù∏ Í±∞ ÌïòÎÇò ÏûàÎäîÎç∞ ÏïåÎ†§Ï§ÑÍπå? (ÎãµÎ≥Ä Ï¢ÖÎ£å) \n",
            "\n",
            "token split Í≤∞Í≥º:\n",
            "  |Ïñ∏Ïñ¥ |Î™®Îç∏ ||ÎÖºÎ¨∏ ||ÏöîÏ¶ò |Î≥¥Í≥† ||ÏûàÏñ¥! ||||ÌòÅÏã†Ï†ÅÏù∏ |Í±∞ |ÌïòÎÇò |ÏûàÎäîÎç∞ ||||ÏïåÎ†§Ï§ÑÍπå? |||(ÎãµÎ≥Ä |||Ï¢ÖÎ£å) |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Ï≤¥Ïù∏ Ïä§Ìä∏Î¶¨Î∞ç**"
      ],
      "metadata": {
        "id": "9LVWP9ubynOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"{user_message} (ÎãµÎ≥Ä ÏãúÏûë)\")\n",
        "\n",
        "chain = prompt | local_llm | StrOutputParser()\n",
        "result = ''\n",
        "result_with_token_splits = ''\n",
        "\n",
        "for chunk in chain.stream({\"user_message\": \"Î°úÎùºÏïº ÎÇ¥Ïùº ÎÇòÎûë Í∞ôÏù¥ ÎÜÄÎü¨Í∞àÍπå?\"}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "    result += chunk\n",
        "    result_with_token_splits += chunk + \"|\"\n",
        "\n",
        "    if result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å)') or result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å) '):\n",
        "        break\n",
        "\n",
        "print('\\n\\ntoken split Í≤∞Í≥º:\\n', result_with_token_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_7HaAjcyqCn",
        "outputId": "4f472bba-8cc4-4bac-d3b0-3c101f4ab768"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ÎÇ¥Ïùº ÎÖºÎ¨∏ Î∞úÌëúÌïòÎäî ÏàòÏóÖ ÏûàÍ≥† ÎÖºÎ¨∏ Í≥µÎ∂ÄÌïòÎäêÎùºÍ≥† Î∞îÎπ† üò• (ÎãµÎ≥Ä Ï¢ÖÎ£å) \n",
            "\n",
            "token split Í≤∞Í≥º:\n",
            "  ||ÎÇ¥Ïùº ||ÎÖºÎ¨∏ ||Î∞úÌëúÌïòÎäî ||ÏàòÏóÖ |ÏûàÍ≥† ||ÎÖºÎ¨∏ ||||Í≥µÎ∂ÄÌïòÎäêÎùºÍ≥† ||Î∞îÎπ† ||üò• |||(ÎãµÎ≥Ä |||Ï¢ÖÎ£å) |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. ÎπÑÎèôÍ∏∞ Ïä§Ìä∏Î¶¨Î∞ç**"
      ],
      "metadata": {
        "id": "in8yOZQazQB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab ÏóêÏÑú asyncio Î•º Ïã§ÌñâÏãúÌÇ§Í∏∞ ÏúÑÌïú ÏÑ§Ï†ï\n",
        "\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA4tZhQQ1QEs",
        "outputId": "d289f4cd-4e70-439c-a14d-4eac0cfb8033"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen posixpath>:82: RuntimeWarning: coroutine 'async_stream' was never awaited\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "DhhjY3lC1UuU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "result = ''\n",
        "result_with_token_splits = ''\n",
        "\n",
        "async def async_stream():\n",
        "    global result, result_with_token_splits\n",
        "\n",
        "    async for chunk in local_llm.astream([HumanMessage(content=\"Î°úÎùºÏïº ÎÑà MBTI Î≠êÏïº? (ÎãµÎ≥Ä ÏãúÏûë)\")]):\n",
        "        print(chunk, end=\"\", flush=True)\n",
        "        result += chunk\n",
        "        result_with_token_splits += chunk + \"|\"\n",
        "\n",
        "        if result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å)') or result.endswith('(ÎãµÎ≥Ä Ï¢ÖÎ£å) '):\n",
        "            break\n",
        "\n",
        "asyncio.run(async_stream())\n",
        "print('\\n\\ntoken split Í≤∞Í≥º:\\n', result_with_token_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfGUv8OFzPjU",
        "outputId": "7d7d2d0c-e493-440b-8508-a5ce9b0edf15"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ÎÇò ENTJ! ÏôÑÏ†Ñ Îß§Î†•Ï†ÅÏù∏ ÏÑ±Í≤© ÏïÑÎãàÏïº? (ÎãµÎ≥Ä Ï¢ÖÎ£å) \n",
            "\n",
            "token split Í≤∞Í≥º:\n",
            "  |ÎÇò |||ENTJ! ||ÏôÑÏ†Ñ |||Îß§Î†•Ï†ÅÏù∏ ||ÏÑ±Í≤© |||ÏïÑÎãàÏïº? |||(ÎãµÎ≥Ä |||Ï¢ÖÎ£å) |\n"
          ]
        }
      ]
    }
  ]
}