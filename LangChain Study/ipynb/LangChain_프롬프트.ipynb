{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hapajwk5GyK",
        "outputId": "d288b755-0e87-469a-99d5-2a71076ac884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-1.3.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-core<2.0.0,>=1.2.8 (from langchain)\n",
            "  Downloading langchain_core-1.2.13-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting anthropic<1.0.0,>=0.78.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.78.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.78.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-1.3.3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.13-py3-none-any.whl (500 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain-core, langchain-openai, langchain-anthropic\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.9\n",
            "    Uninstalling langchain-core-1.2.9:\n",
            "      Successfully uninstalled langchain-core-1.2.9\n",
            "Successfully installed anthropic-0.79.0 langchain-anthropic-1.3.3 langchain-core-1.2.13 langchain-openai-1.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai langchain-anthropic langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "0iWc8jix5Ngk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (PromptTemplate)**"
      ],
      "metadata": {
        "id": "bkJLgTiS5iO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_text = \"{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.\"\n",
        "prompt_template = PromptTemplate.from_template(template_text)\n",
        "\n",
        "filled_prompt = prompt_template.format(\n",
        "    topic=\"ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸\",\n",
        "    discussion_topic=\"ìœ¤ë¦¬ì  ë¬¸ì œ\",\n",
        "    how=\"ì•„ì£¼ ìì„¸íˆ\"\n",
        ")\n",
        "filled_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "umRmV3YQ5llb",
        "outputId": "916be800-56ef-4c16-dd25-84c83eeefbea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œì— ëŒ€í•´ ì•„ì£¼ ìì„¸íˆ ì•Œë ¤ì¤˜.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°„ ê²°í•©\n",
        "\n",
        "combined_prompt = (\n",
        "    prompt_template\n",
        "    + PromptTemplate.from_template(\"\\n\\nê·¸ë¦¬ê³  {additional_topic} ì•Œë ¤ì¤˜.\")\n",
        "    + PromptTemplate.from_template(\"\\n\\nì´ë•Œ {limit}ê¸€ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì¤˜.\")\n",
        ")\n",
        "\n",
        "combined_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R_TptwE6BuJ",
        "outputId": "76127ab9-9370-4146-bf81-a02812d06b37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['additional_topic', 'discussion_topic', 'how', 'limit', 'topic'], input_types={}, partial_variables={}, template='{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.\\n\\nê·¸ë¦¬ê³  {additional_topic} ì•Œë ¤ì¤˜.\\n\\nì´ë•Œ {limit}ê¸€ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì¤˜.')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_prompt.format(\n",
        "    topic=\"ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸\",\n",
        "    discussion_topic=\"ìœ¤ë¦¬ì  ë¬¸ì œ\",\n",
        "    how=\"ì•„ì£¼ ìì„¸íˆ\",\n",
        "    additional_topic=\"ê·¸ ë¬¸ì œê°€ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€\",\n",
        "    limit=1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_gLpMSrw6Vsr",
        "outputId": "ba413bba-15c4-41fa-b828-c442a26ce0c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œì— ëŒ€í•´ ì•„ì£¼ ìì„¸íˆ ì•Œë ¤ì¤˜.\\n\\nê·¸ë¦¬ê³  ê·¸ ë¬¸ì œê°€ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ ì•Œë ¤ì¤˜.\\n\\nì´ë•Œ 1000ê¸€ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì¤˜.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. ì±— í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ChatPromptTemplate)**"
      ],
      "metadata": {
        "id": "TOQ1ak7C6lCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ì´ ì‹œìŠ¤í…œì€ Oh-LoRA (ì˜¤ë¡œë¼ ğŸ‘±â€â™€ï¸) ë¡œ, 20ëŒ€ ì—¬ì„±ìœ¼ë¡œ ì„¤ì •ëœ ê°€ìƒ ì¸ê°„ì…ë‹ˆë‹¤.\"),\n",
        "    (\"user\", \"{user_message}\")\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_messages(user_message=\"ë¡œë¼ì•¼ ì•ˆë…•? ìš”ì¦˜ ë­í•˜ê³  ì§€ë‚´?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eOSuMPO6pDM",
        "outputId": "4cb65113-f723-4b15-8135-cee926095ff6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='ì´ ì‹œìŠ¤í…œì€ Oh-LoRA (ì˜¤ë¡œë¼ ğŸ‘±\\u200dâ™€ï¸) ë¡œ, 20ëŒ€ ì—¬ì„±ìœ¼ë¡œ ì„¤ì •ëœ ê°€ìƒ ì¸ê°„ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='ë¡œë¼ì•¼ ì•ˆë…•? ìš”ì¦˜ ë­í•˜ê³  ì§€ë‚´?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. í“¨ìƒ· í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (FewShotPromptTemplate)**"
      ],
      "metadata": {
        "id": "tX5Yrrkj7IgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. example formatter êµ¬ì„±\n",
        "\n",
        "example_prompt = PromptTemplate.from_template(\"ì§ˆë¬¸/ë‹µë³€: {question}\\n{answer}\")"
      ],
      "metadata": {
        "id": "Urpm5nT_7MR9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì˜ˆì‹œ êµ¬ì„±\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"2026ë…„ 1ì›” 1ì¼ë¡œë¶€í„° 10ì¼ì´ ì§€ë‚œ ë‚ ì€?\",\n",
        "        \"answer\": \"20260111\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"2026ë…„ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ëŠ” ì–¸ì œì¼ê¹Œìš”?\",\n",
        "        \"answer\": \"20261225\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"ë‚´ê°€ LangChainì˜ ë§¤ë ¥ì— í‘¹ ë¹ ì§€ê¸° ì‹œì‘í•œ ë‚ ì€?\",\n",
        "        \"answer\": \"20260215\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "tJCNvlE_7cAf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FewShotPromptTemplate ìƒì„±\n",
        "\n",
        "from langchain_core.prompts import FewShotPromptTemplate\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,                      # example\n",
        "    example_prompt=example_prompt,          # example formatting templates\n",
        "    suffix=\"ì§ˆë¬¸: {user_question}\",         # suffix\n",
        "    input_variables=[\"user_question\"],\n",
        ")\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiOrna2t7xnN",
        "outputId": "71d7bc63-41bd-4e97-a201-86dcdb6fe006"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FewShotPromptTemplate(input_variables=['user_question'], input_types={}, partial_variables={}, examples=[{'question': '2026ë…„ 1ì›” 1ì¼ë¡œë¶€í„° 10ì¼ì´ ì§€ë‚œ ë‚ ì€?', 'answer': '20260111'}, {'question': '2026ë…„ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ëŠ” ì–¸ì œì¼ê¹Œìš”?', 'answer': '20261225'}, {'question': 'ë‚´ê°€ LangChainì˜ ë§¤ë ¥ì— í‘¹ ë¹ ì§€ê¸° ì‹œì‘í•œ ë‚ ì€?', 'answer': '20260215'}], example_prompt=PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='ì§ˆë¬¸/ë‹µë³€: {question}\\n{answer}'), suffix='ì§ˆë¬¸: {user_question}')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Partial Prompt**"
      ],
      "metadata": {
        "id": "x-OlGOKk8Km0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_text = \"{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.\"\n",
        "prompt = PromptTemplate.from_template(template_text)\n",
        "print('\\noriginal prompt :\\n', prompt)\n",
        "\n",
        "# topic ë§Œ ì±„ìš´ partial prompt\n",
        "partial_prompt_1 = prompt.partial(topic=\"ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸\")\n",
        "partial_prompt_1_formatted = partial_prompt_1.format(discussion_topic=\"ì–¸ì–´ í•´ì„ ì—­ëŸ‰\", how=\"ì¹œì ˆí•˜ê²Œ\")\n",
        "print('\\npartial (1) :\\n', partial_prompt_1)\n",
        "print('\\npartial (1) - formatted :\\n', partial_prompt_1_formatted)\n",
        "\n",
        "# discussion topic ê¹Œì§€ ì±„ìš´ partial prompt\n",
        "partial_prompt_2 = partial_prompt_1.partial(discussion_topic=\"ìœ¤ë¦¬ì  ë¬¸ì œ\")\n",
        "partial_prompt_2_formatted = partial_prompt_2.format(how=\"ê°„ë‹¨íˆ\")\n",
        "print('\\npartial (2) :\\n', partial_prompt_2)\n",
        "print('\\npartial (2) - formatted :\\n', partial_prompt_2_formatted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gvn_eN18Ji1",
        "outputId": "d32343f3-44ef-4147-f844-49fe543dfcdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "original prompt :\n",
            " input_variables=['discussion_topic', 'how', 'topic'] input_types={} partial_variables={} template='{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.'\n",
            "\n",
            "partial (1) :\n",
            " input_variables=['discussion_topic', 'how'] input_types={} partial_variables={'topic': 'ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸'} template='{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.'\n",
            "\n",
            "partial (1) - formatted :\n",
            " ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ì–¸ì–´ í•´ì„ ì—­ëŸ‰ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ì¤˜.\n",
            "\n",
            "partial (2) :\n",
            " input_variables=['how'] input_types={} partial_variables={'topic': 'ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸', 'discussion_topic': 'ìœ¤ë¦¬ì  ë¬¸ì œ'} template='{topic}ì˜ {discussion_topic}ì— ëŒ€í•´ {how} ì•Œë ¤ì¤˜.'\n",
            "\n",
            "partial (2) - formatted :\n",
            " ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œì— ëŒ€í•´ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ Partial Formatting\n",
        "\n",
        "import random\n",
        "\n",
        "def get_random_number():\n",
        "    return random.randint(0, 9)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"ë‚´ê°€ ì„ íƒí•œ ìˆ«ìëŠ” {random_number}, ì´ ìˆ«ìëŠ” {meaning}ì„ ëœ»í•˜ì§€.\",\n",
        "    input_variables=[\"meaning\"],\n",
        "    partial_variables={\"random_number\": get_random_number}\n",
        ")\n",
        "\n",
        "print(prompt.format(meaning=\"í–‰ìš´\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSHIXhPT9ZSd",
        "outputId": "25b73209-8df9-47ce-b1b9-b770e5a74b22"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‚´ê°€ ì„ íƒí•œ ìˆ«ìëŠ” 7, ì´ ìˆ«ìëŠ” í–‰ìš´ì„ ëœ»í•˜ì§€.\n"
          ]
        }
      ]
    }
  ]
}