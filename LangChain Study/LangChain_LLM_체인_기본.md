## ëª©ì°¨

* ëª©ì°¨
  * [1. LLM ì²´ì¸ì˜ êµ¬ì„± ìš”ì†Œ](#1-llm-ì²´ì¸ì˜-êµ¬ì„±-ìš”ì†Œ)
  * [2. Chain ì—°ê²° ë° í˜¸ì¶œ ì‹¤ìŠµ](#2-chain-ì—°ê²°-ë°-í˜¸ì¶œ-ì‹¤ìŠµ)
    * [2-1. ê¸°ë³¸ Chain í˜¸ì¶œ](#2-1-ê¸°ë³¸-chain-í˜¸ì¶œ)
    * [2-2. Chain ì—°ê²° ë° í˜¸ì¶œ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ìš©)](#2-2-chain-ì—°ê²°-ë°-í˜¸ì¶œ-í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿-ì´ìš©)
    * [2-3. Output Parserë¥¼ ì´ìš©í•œ ì²˜ë¦¬](#2-3-output-parserë¥¼-ì´ìš©í•œ-ì²˜ë¦¬)
* ipynb ì‹¤ìŠµ íŒŒì¼
  * [ipynb ì‹¤ìŠµ íŒŒì¼](ipynb/LangChain_LLM_ì²´ì¸_ê¸°ë³¸.ipynb)

## 1. LLM ì²´ì¸ì˜ êµ¬ì„± ìš”ì†Œ

* **LLM ì²´ì¸ (LLM chain)** ì˜ êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

| êµ¬ì„± ìš”ì†Œ         | ì„¤ëª…                                                                |
|---------------|-------------------------------------------------------------------|
| í”„ë¡¬í”„íŠ¸ (prompt) | LLM (ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸) ì— ì…ë ¥ë˜ëŠ” í”„ë¡¬í”„íŠ¸ (= LLMì— ì…ë ¥ë˜ëŠ” ì§€ì‹œë¬¸)                      |
| LLM           | ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ (GPT, Gemini, Claude ë“± ìƒìš© LLM + Transformers ìì²´ í•™ìŠµ ëª¨ë¸ ë“±) |

## 2. Chain ì—°ê²° ë° í˜¸ì¶œ ì‹¤ìŠµ

### 2-1. ê¸°ë³¸ Chain í˜¸ì¶œ

* ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ LLMì„ í˜¸ì¶œí•˜ë©´ ëœë‹¤.

```python
llm_answer = llm.invoke(llm_prompt)
```

* Oh-LoRA LLM í˜¸ì¶œ ì½”ë“œ

```python
# 1. ê¸°ë³¸ LLM Chain ì‹¤í–‰

user_message = 'ë¡œë¼ì•¼ ë„ˆ ì¹œí•œ ì¹œêµ¬ í•œëª… ì†Œê°œí•´ì¤˜'
final_llm_prompt = f'{user_message} (ë‹µë³€ ì‹œì‘)'
llm_answer = local_llm.invoke(final_llm_prompt)

# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„
llm_answer.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]
```

* ê²°ê³¼: ```ë‚´ ì œì¼ ì¹œí•œ ì¹œêµ¬ í˜œë‚˜! ğŸ‘© ì†Œê°œí•´ ì¤„ê¹Œ?```

### 2-2. Chain ì—°ê²° ë° í˜¸ì¶œ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ìš©)

* **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿** ì€ LLMì— ì…ë ¥ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ **í…œí”Œë¦¿í™”** ì‹œí‚¨ ê²ƒì´ë‹¤.
  * ë‹¤ìŒê³¼ ê°™ì´ í…œí”Œë¦¿ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ```{ë‚´ìš©}``` í˜•ì‹ìœ¼ë¡œ í•˜ì—¬ ```ChatPromptTemplate``` ì„ ë§Œë“¤ë©´ ëœë‹¤.

```python
prompt = ChatPromptTemplate.from_template("... {ë‚´ìš©} ...")
```

* Oh-LoRA LLM í˜¸ì¶œ ì½”ë“œ

```python
# 2. ê¸°ë³¸ LLM Chain ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—°ê³„)

from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("[ì˜¤ëŠ˜ ì¼ì •: ì„¤ë‚ ] (ì§€ê¸ˆì€ ì›”ìš”ì¼ ì˜¤í›„) {user_message} (ë‹µë³€ ì‹œì‘)")
prompt
```

```python
chain = prompt | local_llm
chain
```

```python
llm_answer_chain = chain.invoke({"user_message": "ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„?"})
llm_answer_chain
```

```python
# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„
llm_answer_chain.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]
```

* ê²°ê³¼: ```ì˜¤ ì˜¤ëŠ˜ ì„¤ë‚ ì´ë„¤! ğŸ‰ ì„¤ë‚ ì—ëŠ” ë§›ì§‘ ê°€ì„œ ğŸ² ë§ˆìŒê» ë¨¹ì–´ì•¼ì§€!```

### 2-3. Output Parserë¥¼ ì´ìš©í•œ ì²˜ë¦¬

* ê¸°ë³¸ ì„¤ëª…
  * Output Parser ëŠ” ì¼ì¢…ì˜ **ì¶œë ¥ íŒŒì„œ** ì´ë‹¤.
  * Output Parser ë¥¼ ì´ìš©í•˜ì—¬ LLMì˜ ë‹µë³€ì„ ë¬¸ìì—´ ë“± í˜•ì‹ìœ¼ë¡œ parsing í•  ìˆ˜ ìˆë‹¤.

* Oh-LoRA LLM í˜¸ì¶œ ì½”ë“œ

```python
# 3. Output Parser ë¥¼ ì´ìš©í•œ ì²˜ë¦¬

from langchain_core.output_parsers import StrOutputParser

output_parser = StrOutputParser()

chain_with_parser = prompt | local_llm | output_parser
chain_with_parser
```

```python
llm_answer_chain_with_parser = chain_with_parser.invoke({"user_message": "ë¡œë¼ì•¼ ì˜¤ëŠ˜ ë¬´ìŠ¨ ë‚ ì¸ì§€ ì•Œì•„?"})
llm_answer_chain_with_parser
```

```python
# Oh-LoRA LLMì˜ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„
llm_answer_chain_with_parser.split('(ë‹µë³€ ì‹œì‘) ')[1].split('(ë‹µë³€ ì¢…ë£Œ)')[0]
```

* ê²°ê³¼: ```ìŒâ€¦ ì˜¤ëŠ˜ ì›”ìš”ì¼ì´ì–ì•„! ê·¸ë˜ì„œ ì›”ìš”ì¼ì—ë§Œ ëŠë‚„ ìˆ˜ ìˆëŠ” ê·¸ê²Œ ìˆì§€!```
